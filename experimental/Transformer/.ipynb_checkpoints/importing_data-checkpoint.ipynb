{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install tensorflow-gpu\n",
    "# This cell has the latest set up for AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "\n",
    "import TransformCode as tc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20')\n",
    "\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['authentic', 'fake']\n",
      "Total data: 2 classes for 3600 files for train\n",
      "Total data: 2 classes for 700 files for train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras\n",
    "import VideoFrameGenerator\n",
    "# use sub directories names as classes\n",
    "classes = [i.split(os.path.sep)[-1] for i in glob.glob('../restructured-all-faces/home/jupyter/restructured_data/train/*')]\n",
    "classes.sort() # actually already within source code\n",
    "print(classes)\n",
    "# some global params\n",
    "SIZE = (224, 224)\n",
    "CHANNELS = 3\n",
    "NBFRAME = 20\n",
    "BS = 8\n",
    "# pattern to get videos and classes\n",
    "\n",
    "glob_pattern_train = '../restructured-all-faces/home/jupyter/restructured_data/train/{classname}/*'\n",
    "glob_pattern_val = '../restructured-all-faces/home/jupyter/restructured_data/validation/{classname}/*'\n",
    "\n",
    "#glob_pattern='videos/{classname}/*.avi'\n",
    "# for data augmentation\n",
    "data_aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=8,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "\n",
    "# Create video frame generator\n",
    "\n",
    "train_data = VideoFrameGenerator.VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern_train,\n",
    "    nb_frames=NBFRAME,\n",
    "#    split=0, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug)\n",
    "\n",
    "val_data = VideoFrameGenerator.VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern_val,\n",
    "    nb_frames=NBFRAME,\n",
    "#    split=0, \n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch out for USE_HEADER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import \\\n",
    "    img_to_array\n",
    "# Watch out for USE_HEADER!\n",
    "#img_to_array('../restructured-all-faces/home/jupyter/restructured_data/train/authentic/Original_001/0000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VideoFrameGenerator.utils.show_sample(train)\n",
    "print(train_data.indexes[0:30])\n",
    "# what are indexes?\n",
    "print(train_data.classes_count)\n",
    "print(train_data.on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = '../restructured-all-faces/home/jupyter/restructured_data/train/authentic/Original_001'\n",
    "word + '/' + (sorted(os.listdir(word))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.files[0:4])\n",
    "#print(train._framecounters)\n",
    "print(train.nbframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('../restructured-all-faces/home/jupyter/restructured_data/train/authentic/')))\n",
    "# 720 vs 2880\n",
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "video = '../restructured-all-faces/home/jupyter/restructured_data/train/authentic/Original_397'\n",
    "video = os.path.realpath(video)\n",
    "pattern = os.path.realpath(glob_pattern_train)\n",
    "\n",
    "# remove special regexp chars\n",
    "pattern = re.escape(pattern)\n",
    "\n",
    "# get back \"*\" to make it \".*\" in regexp\n",
    "pattern = pattern.replace('\\\\*', '.*')\n",
    "\n",
    "# use {classname} as a capture\n",
    "pattern = pattern.replace('\\\\{classname\\\\}', '(.*?)')\n",
    "\n",
    "# and find all occurence\n",
    "classname = re.findall(pattern, video)[0]\n",
    "label = np.zeros(len(classes))\n",
    "col = classes.index(classname)\n",
    "label[col] = 1.\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below hopefully now relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout, lr_rate, architecture = 'lstm'):\n",
    "    frames = 20\n",
    "    channels = 3\n",
    "    rows = 224\n",
    "    columns = 224\n",
    "    \n",
    "    embed_dim = 32  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    \n",
    "    video = tf.keras.layers.Input(shape=(frames,\n",
    "                         rows,\n",
    "                         columns,\n",
    "                         channels,))\n",
    "    \n",
    "    \n",
    "    if architecture == 'lstm':\n",
    "        \n",
    "        from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        conv_base = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                            input_shape=(224,224,3))\n",
    "    \n",
    "        cnn_out = GlobalAveragePooling2D()(conv_base.output)\n",
    "        cnn = tf.keras.Model(inputs=conv_base.input, outputs=cnn_out)\n",
    "        #cnn.trainable = False\n",
    "    \n",
    "        encoded_frames = tf.keras.layers.TimeDistributed(cnn)(video)\n",
    "        \n",
    "        encoded_sequence = tf.keras.layers.LSTM(512)(encoded_frames)\n",
    "        hidden_layer = Dense(512, activation=\"relu\")(encoded_sequence)\n",
    "        hidden_layer2 = Dense(128, activation=\"relu\")(hidden_layer)\n",
    "        outputs = Dense(2, activation=\"softmax\")(hidden_layer2)\n",
    "        model = Model([video], outputs)\n",
    "    \n",
    "        \n",
    "    if architecture == 'transformer':\n",
    "        \n",
    "        embedding_layer = tc.TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "        x = embedding_layer(cnn.output)\n",
    "        transformer_block = tc.TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        x = transformer_block(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "        model = Model([video], outputs)\n",
    "                \n",
    "        \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Nadam(lr=lr_rate,\n",
    "                      beta_1=0.9,\n",
    "                      beta_2=0.999,\n",
    "                      epsilon=1e-08,\n",
    "                      schedule_decay=0.004)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"acc\"]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 224, 224, 3)] 0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 20, 1280)          2257984   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 512)               3672064   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,258,626\n",
      "Trainable params: 6,224,514\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    \n",
    "with strategy.scope(): # Everything that creates variables should be under the strategy scope.\n",
    "    model = build_model(0.1,0.001)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 4, 1: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 505s 1s/step - acc: 0.5158 - loss: 1.1192 - val_acc: 0.8003 - val_loss: 0.6549\n",
      "Epoch 2/30\n",
      "394/450 [=========================>....] - ETA: 56s - acc: 0.4042 - loss: 1.1034"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6ed312353ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0;31m# maximum size for the generator queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0;31m# maximum number of processes to spin up when using process-based threading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               use_multiprocessing=False)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(train_data, epochs=epochs,# shuffle=True,\n",
    "            #  steps_per_epoch = train_data.n//train_data.batch_size,\n",
    "              validation_data = val_data, \n",
    "           #   validation_steps = val_data.n//val_data.batch_size,\n",
    "              class_weight=class_weights,\n",
    "              callbacks=[plot_losses],\n",
    "              verbose=1,\n",
    "              max_queue_size=30,                # maximum size for the generator queue\n",
    "              workers=16,                        # maximum number of processes to spin up when using process-based threading\n",
    "              use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss starts at 1.5/1.6\n",
    "# loss has been seen dipping below 1!!!!!!\n",
    "# hmm val_acc 0.7989\n",
    "# whne starting new epoch it seems to completely restart\n",
    "# 0.65 loss!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
