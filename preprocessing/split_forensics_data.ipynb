{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the split data from FaceForenscis++ github (dataset/splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['953', '974']\n",
      "['012', '026']\n",
      "['078', '955']\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "test = open('FaceForensics-master/dataset/splits/test.json',) \n",
    "test_videos = json.load(test) \n",
    "for i in test_videos[0:3]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['071', '054']\n",
      "['087', '081']\n",
      "['881', '856']\n"
     ]
    }
   ],
   "source": [
    "train = open('FaceForensics-master/dataset/splits/train.json',) \n",
    "train_videos = json.load(train) \n",
    "for i in train_videos[0:3]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['720', '672']\n",
      "['939', '115']\n",
      "['284', '263']\n"
     ]
    }
   ],
   "source": [
    "val = open('FaceForensics-master/dataset/splits/val.json',) \n",
    "val_videos = json.load(val) \n",
    "for i in val_videos[0:3]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing checks that there are no overlaps in the videos for any split category\n",
    "\n",
    "The main idea is that if a given video appears in a train set, it must not appear in any way in the validation or test set (this includes facial region or the background: for example a training original video must not be used as a source or target in any validation or test video).\n",
    "\n",
    "First check obtains a list of all distinct videos in the pairs from .json files and finds that there is no overlap for any two categories. Second check counts the number of distinct pairs ((a, b) = (b, a)) and verifies that they match perfectly onto the originally provided pairs.\n",
    "Last check verifiess that there is no intersept in pairs for any two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 720 360 360 True\n",
      "Validation: 140 70 70 True\n",
      "Testing: 140 70 70 True\n"
     ]
    }
   ],
   "source": [
    "distinct_train = []\n",
    "distinct_train_pairs = []\n",
    "for el in train_videos:\n",
    "    if not el[0] in distinct_train: distinct_train.append(el[0])\n",
    "    if not el[1] in distinct_train: distinct_train.append(el[1])\n",
    "    if not el in distinct_train_pairs and not [el[1], el[0]] in distinct_train_pairs:\n",
    "        distinct_train_pairs.append(el)\n",
    "print(\"Training:\", len(distinct_train), len(train_videos), len(distinct_train_pairs),\n",
    "     train_videos == distinct_train_pairs)\n",
    "\n",
    "distinct_val = []\n",
    "distinct_val_pairs = []\n",
    "for el in val_videos:\n",
    "    if not el[0] in distinct_val: distinct_val.append(el[0])\n",
    "    if not el[1] in distinct_val: distinct_val.append(el[1])\n",
    "    if not el in distinct_val_pairs and not [el[1], el[0]] in distinct_val_pairs:\n",
    "        distinct_val_pairs.append(el)\n",
    "print(\"Validation:\", len(distinct_val), len(val_videos), len(distinct_val_pairs),\n",
    "     val_videos == distinct_val_pairs)\n",
    "\n",
    "distinct_test = []\n",
    "distinct_test_pairs = []\n",
    "for el in test_videos:\n",
    "    if not el[0] in distinct_test: distinct_test.append(el[0])\n",
    "    if not el[1] in distinct_test: distinct_test.append(el[1])\n",
    "    if not el in distinct_test_pairs and not [el[1], el[0]] in distinct_test_pairs:\n",
    "        distinct_test_pairs.append(el)\n",
    "print(\"Testing:\", len(distinct_test), len(test_videos), len(distinct_test_pairs),\n",
    "     test_videos == distinct_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "test_set = set(distinct_test)\n",
    "train_set = set(distinct_train)\n",
    "val_set = set(distinct_val)\n",
    "\n",
    "print(len(test_set.intersection(train_set)),\n",
    "      len(test_set.intersection(val_set)), len(train_set.intersection(val_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "train_test_intersept = []\n",
    "for el in distinct_train_pairs:\n",
    "    if el in distinct_test_pairs or [el[1], el[0]] in distinct_test_pairs:\n",
    "        train_test_intersept.append(el)\n",
    "        \n",
    "train_val_intersept = []\n",
    "for el in distinct_train_pairs:\n",
    "    if el in distinct_val_pairs or [el[1], el[0]] in distinct_val_pairs:\n",
    "        train_val_intersept.append(el)\n",
    "        \n",
    "val_test_intersept = []\n",
    "for el in distinct_val_pairs:\n",
    "    if el in distinct_test_pairs or [el[1], el[0]] in distinct_test_pairs:\n",
    "        val_test_intersept.append(el)\n",
    "        \n",
    "print(len(train_test_intersept), len(train_val_intersept), len(val_test_intersept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_path(method, folder):\n",
    "    '''This function provides a new path for a given method and folder based on the distinct\n",
    "    video numbers calculated earlier\n",
    "    \n",
    "    This path is used in the second function (next cell) to move a copy on an image to that \n",
    "    location'''\n",
    "    \n",
    "    if method == 'Original':\n",
    "        if folder in distinct_test: split_categoty = 'test/'\n",
    "        elif folder in distinct_train: split_categoty = 'train/'\n",
    "        elif folder in distinct_val: split_categoty = 'validation/'\n",
    "        \n",
    "        class_category = 'authentic/'\n",
    "        \n",
    "    else:\n",
    "        folder_1 = folder[0:3]\n",
    "        folder_2 = folder[4:7]\n",
    "        \n",
    "        if folder_1 in distinct_test and folder_2 in distinct_test:\n",
    "            split_categoty = 'test/'\n",
    "        elif folder_1 in distinct_train and folder_2 in distinct_train:\n",
    "            split_categoty = 'train/'\n",
    "        elif folder_1 in distinct_val and folder_2 in distinct_val:\n",
    "            split_categoty = 'validation/'\n",
    "        else: print('There is a mismatch in folders for the fake class')\n",
    "        \n",
    "        class_category = 'fake/'\n",
    "          \n",
    "    additional_name = method + '_' + folder + '_'\n",
    "    \n",
    "    new_path = 'forensics_split/' + split_categoty + class_category + additional_name\n",
    "    \n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_move(methods, n):\n",
    "    '''Loops through all cropped images and moves their coppies to required new locations\n",
    "    (split by category (train, test or validation) and class (fake or authentic))'''\n",
    "    \n",
    "    for method in methods:\n",
    "        if method == 'Original': path = 'original_sequences/youtube/c0/'\n",
    "        else: path = 'manipulated_sequences/' + method + '/c0/'\n",
    "            \n",
    "        \n",
    "        print(\"Starting to copy\", method, \"images\")\n",
    "        folders =  os.listdir(path + method + '_images')\n",
    "        folders = sorted(list(set(folders).difference(set(['.DS_Store']))))\n",
    "\n",
    "        # only look at the first n videos for a given method\n",
    "        for folder in folders[0:n]:\n",
    "             # output progress\n",
    "            if folder[2] == '0' and folder[1] == '0': print(folder)\n",
    "\n",
    "            full_path = path + method + '_images/' + folder\n",
    "            # obtain full paths for all images\n",
    "            images_list = os.listdir(full_path)\n",
    "          \n",
    "            for el in images_list:\n",
    "                img = cv2.imread(full_path + '/' + el) #[:,:,::-1] \n",
    "                # save image in a new place\n",
    "                new_path = assign_path(method, folder)\n",
    "                cv2.imwrite(new_path + el, img)\n",
    "                # print(new_path + el)\n",
    "                \n",
    "        print(\"Copying\", method, \"images is complete\\n\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to copy Original images\n",
      "000\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "Copying Original images is complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "copy_and_move(['Original'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to copy Deepfakes images\n",
      "000_003\n",
      "100_077\n",
      "200_189\n",
      "300_304\n",
      "400_476\n",
      "500_592\n",
      "600_505\n",
      "700_813\n",
      "800_840\n",
      "900_926\n",
      "Copying Deepfakes images is complete\n",
      "\n",
      "Starting to copy Face2Face images\n",
      "000_003\n",
      "100_077\n",
      "200_189\n",
      "300_304\n",
      "400_476\n",
      "500_592\n",
      "600_505\n",
      "700_813\n",
      "800_840\n",
      "900_926\n",
      "Copying Face2Face images is complete\n",
      "\n",
      "Starting to copy FaceSwap images\n",
      "000_003\n",
      "100_077\n",
      "200_189\n",
      "300_304\n",
      "400_476\n",
      "500_592\n",
      "600_505\n",
      "700_813\n",
      "800_840\n",
      "900_926\n",
      "Copying FaceSwap images is complete\n",
      "\n",
      "Starting to copy NeuralTextures images\n",
      "000_003\n",
      "100_077\n",
      "200_189\n",
      "300_304\n",
      "400_476\n",
      "500_592\n",
      "600_505\n",
      "700_813\n",
      "800_840\n",
      "900_926\n",
      "Copying NeuralTextures images is complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "copy_and_move(['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures'], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the total counts for each class and split category\n",
    "\n",
    "Here I wanted to verify that the numbers match those quoted in the FaceForensics++ paper (page 12, appendix). Since we only took every 15th frame, our numbers equate to those in the paper divided by 15. Note, this is only approximate because a given video rarely contained a number of frames divisible by 15, hence our cropped images represent a slightly larger proportion of the video (more than a fifteenth). \n",
    "\n",
    "My numbers are usually around a 1000 images more that the paper's equivalent numbers, hence there is very unlikely to be any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "train: 24789\n",
      "validation: 4629\n",
      "test: 4981\n",
      "\n",
      "\n",
      "Deepfakes\n",
      "train: 24775\n",
      "validation: 4629\n",
      "test: 4986\n",
      "\n",
      "\n",
      "Face2Face\n",
      "train: 24785\n",
      "validation: 4629\n",
      "test: 4987\n",
      "\n",
      "\n",
      "FaceSwap\n",
      "train: 19790\n",
      "validation: 3702\n",
      "test: 4049\n",
      "\n",
      "\n",
      "NeuralTextures\n",
      "train: 19789\n",
      "validation: 3702\n",
      "test: 4051\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in ['Original', 'Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "    if method == 'Original': method_group = 'authentic/'; print(method)\n",
    "    else: method_group = 'fake/'; print(method)\n",
    "    \n",
    "    for split_group in ['train', 'validation', 'test']:\n",
    "        path = 'forensics_split/' + split_group + '/' + method_group\n",
    "        data = os.listdir(path)\n",
    "        data = [el for el in data if el.startswith(method)]\n",
    "        print(split_group + ':', len(data))\n",
    "        \n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
