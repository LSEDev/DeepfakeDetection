{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udRhv-d-2i8l"
   },
   "source": [
    "# Run autoaugment to obtain best parameters\n",
    "       -- built for FF+ dataset with file structure as required by Keras' flow_from_directory method\n",
    "       \n",
    "Requires 50GB RAM, at least 4 CPU workers and a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t7E1CjC9fqhq",
    "outputId": "abdef6eb-823c-4fb1-ad28-7521345d04fc"
   },
   "outputs": [],
   "source": [
    "# See available GPU RAM \n",
    "# !nvidia-smi # can also be run from linux shell while GPU is training\n",
    "# !nvidia-smi dmon # this will stream memory utilisation\n",
    "# !watch -n0.1 nvidia-smi # better way to see GPU utilisation\n",
    "# !htop # cpu threads and if they're all working\n",
    "# !pip3 install --no-cache-dir -I tensorflow==2.2 #Â use if no gpu is attached so code will run \n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number\n",
    "# !sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches' # clear CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoaugment installations and run TF2 upgrade scripts\n",
    "# !tf_upgrade_v2 --intree ../augmentations/deepaugment-master --outtree ../augmentations/deepaugment_updated\n",
    "# Then make some manual changes to ensure it runs using TF2\n",
    "# Now install packages required by DeepAugment\n",
    "# !pip install scikit-optimize\n",
    "# !pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Llx-HRnYiWQU",
    "outputId": "6e6a3556-fbb1-4972-b046-8586183f768a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/deepaugment.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "import deepaugment as dp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "\n",
    "# # Augmentation libraries\n",
    "# import face_recognition\n",
    "# import cutout_augmentation as ca\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/authentic')\n",
    "train_authentic_images = []\n",
    "\n",
    "# Training data\n",
    "for image_path in train_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_authentic_images.append(img)\n",
    "    if len(train_authentic_images) % 1000 == 0: print(len(train_authentic_images))\n",
    "        \n",
    "    if len(train_authentic_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "train_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/fake')\n",
    "train_fake_images = []\n",
    "\n",
    "for image_path in train_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_fake_images.append(img)\n",
    "    if len(train_fake_images) % 1000 == 0: print(len(train_fake_images))\n",
    "        \n",
    "    if len(train_fake_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "# Validation data\n",
    "val_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic')\n",
    "val_authentic_images = []\n",
    "\n",
    "for image_path in val_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_authentic_images.append(img)\n",
    "    if len(val_authentic_images) % 1000 == 0: print(len(val_authentic_images))\n",
    "        \n",
    "    if len(val_authentic_images) == 50:\n",
    "        break\n",
    "        \n",
    "        \n",
    "val_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/fake')\n",
    "val_fake_images = []\n",
    "\n",
    "for image_path in val_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_fake_images.append(img)\n",
    "    if len(val_fake_images) % 1000 == 0: print(len(val_fake_images))\n",
    "        \n",
    "    if len(val_fake_images) == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import fashion_mnist\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# train_authentic_images\n",
    "# train_fake_images\n",
    "# val_authentic_images\n",
    "# val_fake_images\n",
    "\n",
    "# Concatenate authentic and fake images\n",
    "training_data = np.array(train_authentic_images + train_fake_images)\n",
    "\n",
    "# Create training labels\n",
    "train_labels = np.array([0]*len(train_authentic_images) + [1]*len(train_fake_images))\n",
    "train_labels\n",
    "\n",
    "print(training_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 training images\n",
      "BasicCNN model built as child model.\n",
      " Model summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               95552000  \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 95,618,594\n",
      "Trainable params: 95,618,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "load_pre_augment_weights()'s runtime:  0.5366 sec.\n",
      "19/19 - 82s - loss: 4.1508 - accuracy: 0.4842 - val_loss: 0.6954 - val_accuracy: 0.4900\n",
      "fit()'s runtime:  88.0879 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.5346 sec.\n",
      "19/19 - 81s - loss: 8.6194 - accuracy: 0.5158 - val_loss: 0.6998 - val_accuracy: 0.4900\n",
      "fit()'s runtime:  86.7063 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.529 sec.\n",
      "19/19 - 82s - loss: 7.2286 - accuracy: 0.4867 - val_loss: 0.6932 - val_accuracy: 0.5100\n",
      "fit()'s runtime:  86.993 sec.\n",
      "0, 0.503333330154419, ['rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Run DeepAugment\n",
    "\n",
    "config = {\n",
    "    \"model\": \"basiccnn\",\n",
    "    \"method\": \"bayesian_optimization\",\n",
    "    \"train_set_size\": 2000,\n",
    "    \"opt_samples\": 3,\n",
    "    \"opt_last_n_epochs\": 3,\n",
    "    \"opt_initial_points\": 10,\n",
    "    \"child_epochs\": 1,\n",
    "    \"child_first_train_epochs\": 0,\n",
    "    \"child_batch_size\": 64\n",
    "}\n",
    "\n",
    "deepaug = dp.DeepAugment(training_data, train_labels, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1 \n",
      " ['gamma-contrast', 0.8442657485810175, 'coarse-salt-pepper', 0.8472517387841256, 'brighten', 0.38438170729269994, 'translate-y', 0.056712977317443194, 'translate-y', 0.47766511732135, 'add-to-hue-and-saturation', 0.47997717237505744, 'emboss', 0.8360787635373778, 'sharpen', 0.6481718720511973, 'emboss', 0.9571551589530466, 'rotate', 0.8700872583584366]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "first transform is unvalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e4177d62765d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_policies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/deepaugment.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, iterations)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mtrial_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trial:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_hyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_hyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, trial_no, trial_hyperparams)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         augmented_data = augment_by_policy(\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtrial_hyperparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/augmenter.py\u001b[0m in \u001b[0;36maugment_by_policy\u001b[0;34m(X, y, *hyperparams)\u001b[0m\n\u001b[1;32m    158\u001b[0m         assert (\n\u001b[1;32m    159\u001b[0m             \u001b[0mX_portion_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX_portion_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m255.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         ), \"first transform is unvalid\"\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_portion_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_portion_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: first transform is unvalid"
     ]
    }
   ],
   "source": [
    "best_policies = deepaug.optimize(300)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-6Yocnrq2u4F"
   ],
   "name": "25_May.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
