{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udRhv-d-2i8l"
   },
   "source": [
    "# Run autoaugment to obtain best parameters\n",
    "       -- built for FF+ dataset with file structure as required by Keras' flow_from_directory method\n",
    "       \n",
    "Requires 50GB RAM, at least 4 CPU workers and a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t7E1CjC9fqhq",
    "outputId": "abdef6eb-823c-4fb1-ad28-7521345d04fc"
   },
   "outputs": [],
   "source": [
    "# See available GPU RAM \n",
    "# !nvidia-smi # can also be run from linux shell while GPU is training\n",
    "# !nvidia-smi dmon # this will stream memory utilisation\n",
    "# !watch -n0.1 nvidia-smi # better way to see GPU utilisation\n",
    "# !htop # cpu threads and if they're all working\n",
    "# !pip3 install --no-cache-dir -I tensorflow==2.2 #Â use if no gpu is attached so code will run \n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number\n",
    "# !sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches' # clear CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoaugment installations and run TF2 upgrade scripts\n",
    "# !tf_upgrade_v2 --intree ../augmentations/deepaugment-master --outtree ../augmentations/deepaugment_updated\n",
    "# Then make some manual changes to ensure it runs using TF2\n",
    "# Now install packages required by DeepAugment\n",
    "# !pip install scikit-optimize\n",
    "# !pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Llx-HRnYiWQU",
    "outputId": "6e6a3556-fbb1-4972-b046-8586183f768a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/deepaugment.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "import deepaugment as dp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "\n",
    "# # Augmentation libraries\n",
    "# import face_recognition\n",
    "# import cutout_augmentation as ca\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/authentic')\n",
    "train_authentic_images = []\n",
    "\n",
    "# Training data\n",
    "for image_path in train_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_authentic_images.append(img)\n",
    "    if len(train_authentic_images) % 1000 == 0: print(len(train_authentic_images))\n",
    "        \n",
    "    if len(train_authentic_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "train_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/fake')\n",
    "train_fake_images = []\n",
    "\n",
    "for image_path in train_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_fake_images.append(img)\n",
    "    if len(train_fake_images) % 1000 == 0: print(len(train_fake_images))\n",
    "        \n",
    "    if len(train_fake_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "# Validation data\n",
    "val_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic')\n",
    "val_authentic_images = []\n",
    "\n",
    "for image_path in val_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_authentic_images.append(img)\n",
    "    if len(val_authentic_images) % 1000 == 0: print(len(val_authentic_images))\n",
    "        \n",
    "    if len(val_authentic_images) == 50:\n",
    "        break\n",
    "        \n",
    "        \n",
    "val_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/fake')\n",
    "val_fake_images = []\n",
    "\n",
    "for image_path in val_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_fake_images.append(img)\n",
    "    if len(val_fake_images) % 1000 == 0: print(len(val_fake_images))\n",
    "        \n",
    "    if len(val_fake_images) == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import fashion_mnist\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# x_train[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# train_authentic_images\n",
    "# train_fake_images\n",
    "# val_authentic_images\n",
    "# val_fake_images\n",
    "\n",
    "# Concatenate authentic and fake images\n",
    "training_data = np.array(train_authentic_images + train_fake_images)\n",
    "\n",
    "# Create training labels\n",
    "train_labels = np.array([0]*len(train_authentic_images) + [1]*len(train_fake_images))\n",
    "train_labels\n",
    "\n",
    "print(training_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 training images\n",
      "BasicCNN model built as child model.\n",
      " Model summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               95552000  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 95,618,594\n",
      "Trainable params: 95,618,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "load_pre_augment_weights()'s runtime:  0.4907 sec.\n",
      "1/1 - 32s - loss: 0.7479 - accuracy: 0.4167 - val_loss: 1.4190 - val_accuracy: 0.4850\n",
      "fit()'s runtime:  36.479 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4821 sec.\n",
      "1/1 - 31s - loss: 0.6856 - accuracy: 0.5833 - val_loss: 4.8768 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  33.7185 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.463 sec.\n",
      "1/1 - 31s - loss: 0.6231 - accuracy: 0.6667 - val_loss: 14.1412 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.2437 sec.\n",
      "0, nan, ['rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Run DeepAugment\n",
    "\n",
    "config = {\n",
    "    \"model\": \"basiccnn\",\n",
    "    \"method\": \"bayesian_optimization\",\n",
    "#     \"train_set_size\": 2000,\n",
    "    \"train_set_size\": 2,\n",
    "    \"opt_samples\": 3,\n",
    "    \"opt_last_n_epochs\": 3,\n",
    "    \"opt_initial_points\": 10,\n",
    "    \"child_epochs\": 1,\n",
    "    \"child_first_train_epochs\": 0,\n",
    "    \"child_batch_size\": 64\n",
    "}\n",
    "\n",
    "deepaug = dp.DeepAugment(training_data, train_labels, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1 \n",
      " ['brighten', 0.9023485831739845, 'gaussian-blur', 0.969809067746749, 'invert', 0.17090958513604518, 'emboss', 0.7506861412184564, 'brighten', 0.32504722900835253, 'crop', 0.6342740579573352, 'vertical-flip', 0.652790317005491, 'brighten', 0.9952995676778879, 'gamma-contrast', 0.4143685882263689, 'dropout', 0.6235101011318683]\n",
      "brighten\n",
      "invert\n",
      "brighten\n",
      "vertical-flip\n",
      "gamma-contrast\n",
      "load_pre_augment_weights()'s runtime:  0.5126 sec.\n",
      "1/1 - 36s - loss: 0.7519 - accuracy: 0.3333 - val_loss: 5.1203 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  38.8751 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.5167 sec.\n",
      "1/1 - 31s - loss: 0.6369 - accuracy: 0.5833 - val_loss: 3.2387 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.43 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.457 sec.\n",
      "1/1 - 32s - loss: 0.7019 - accuracy: 0.5000 - val_loss: 4.0446 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.5682 sec.\n",
      "1, 0.5, ['brighten', 0.9023485831739845, 'gaussian-blur', 0.969809067746749, 'invert', 0.17090958513604518, 'emboss', 0.7506861412184564, 'brighten', 0.32504722900835253, 'crop', 0.6342740579573352, 'vertical-flip', 0.652790317005491, 'brighten', 0.9952995676778879, 'gamma-contrast', 0.4143685882263689, 'dropout', 0.6235101011318683]\n",
      "trial: 2 \n",
      " ['sharpen', 0.6747523222590208, 'sharpen', 0.7783454820259093, 'horizontal-flip', 0.6625268669500444, 'crop', 0.6228460955466696, 'invert', 0.971945002499666, 'coarse-salt-pepper', 0.5096243767199002, 'gaussian-blur', 0.4511592145209282, 'crop', 0.4417109212488455, 'vertical-flip', 0.35944446396932156, 'dropout', 0.6886611828057705]\n",
      "sharpen\n",
      "horizontal-flip\n",
      "invert\n",
      "gaussian-blur\n",
      "vertical-flip\n",
      "load_pre_augment_weights()'s runtime:  0.4848 sec.\n",
      "1/1 - 31s - loss: 0.6497 - accuracy: 0.6667 - val_loss: 6.6276 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.6407 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4662 sec.\n",
      "1/1 - 31s - loss: 0.7112 - accuracy: 0.4167 - val_loss: 6.3656 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  33.6361 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4598 sec.\n",
      "1/1 - 31s - loss: 0.6886 - accuracy: 0.5000 - val_loss: 3.8831 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  33.9242 sec.\n",
      "2, nan, ['sharpen', 0.6747523222590208, 'sharpen', 0.7783454820259093, 'horizontal-flip', 0.6625268669500444, 'crop', 0.6228460955466696, 'invert', 0.971945002499666, 'coarse-salt-pepper', 0.5096243767199002, 'gaussian-blur', 0.4511592145209282, 'crop', 0.4417109212488455, 'vertical-flip', 0.35944446396932156, 'dropout', 0.6886611828057705]\n",
      "trial: 3 \n",
      " ['coarse-salt-pepper', 0.9182354663621449, 'translate-x', 0.5651888666048754, 'coarse-salt-pepper', 0.5089689606670146, 'horizontal-flip', 0.9211576102372, 'gaussian-blur', 0.2777185612810325, 'crop', 0.8423420796677312, 'brighten', 0.8413861191973546, 'translate-y', 0.39782075275862916, 'gamma-contrast', 0.16494046024188416, 'emboss', 0.14644176272911227]\n",
      "coarse-salt-pepper\n",
      "coarse-salt-pepper\n",
      "gaussian-blur\n",
      "brighten\n",
      "gamma-contrast\n",
      "load_pre_augment_weights()'s runtime:  0.4712 sec.\n",
      "1/1 - 32s - loss: 0.6668 - accuracy: 0.5000 - val_loss: 1.7890 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.4551 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4943 sec.\n",
      "1/1 - 31s - loss: 0.8228 - accuracy: 0.2500 - val_loss: 1.0405 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.0784 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4721 sec.\n",
      "1/1 - 31s - loss: 0.5792 - accuracy: 0.5833 - val_loss: 10.0022 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  33.4816 sec.\n",
      "3, 0.5, ['coarse-salt-pepper', 0.9182354663621449, 'translate-x', 0.5651888666048754, 'coarse-salt-pepper', 0.5089689606670146, 'horizontal-flip', 0.9211576102372, 'gaussian-blur', 0.2777185612810325, 'crop', 0.8423420796677312, 'brighten', 0.8413861191973546, 'translate-y', 0.39782075275862916, 'gamma-contrast', 0.16494046024188416, 'emboss', 0.14644176272911227]\n",
      "top-20 policies: 20\n",
      "    trial_no         A_aug1_type  A_aug1_magnitude         A_aug2_type  \\\n",
      "3          1      gamma-contrast             0.844  coarse-salt-pepper   \n",
      "6          2             dropout             0.801      coarse-dropout   \n",
      "13         3  coarse-salt-pepper             0.918         translate-x   \n",
      "0          0              rotate             0.000              rotate   \n",
      "\n",
      "    A_aug2_magnitude         B_aug1_type  B_aug1_magnitude      B_aug2_type  \\\n",
      "3              0.847            brighten             0.384      translate-y   \n",
      "6              0.679                 fog             0.582   coarse-dropout   \n",
      "13             0.565  coarse-salt-pepper             0.509  horizontal-flip   \n",
      "0              0.000              rotate             0.000           rotate   \n",
      "\n",
      "    B_aug2_magnitude    C_aug1_type  ...  D_aug1_type D_aug1_magnitude  \\\n",
      "3              0.057    translate-y  ...       emboss            0.836   \n",
      "6              0.759         rotate  ...  translate-x            0.135   \n",
      "13             0.921  gaussian-blur  ...     brighten            0.841   \n",
      "0              0.000         rotate  ...       rotate            0.000   \n",
      "\n",
      "    D_aug2_type D_aug2_magnitude     E_aug1_type E_aug1_magnitude  \\\n",
      "3       sharpen            0.648          emboss            0.957   \n",
      "6       sharpen            0.150     translate-x            0.386   \n",
      "13  translate-y            0.398  gamma-contrast            0.165   \n",
      "0        rotate            0.000          rotate            0.000   \n",
      "\n",
      "        E_aug2_type E_aug2_magnitude  mean_late_val_acc  \\\n",
      "3            rotate            0.870             0.5000   \n",
      "6   horizontal-flip            0.450             0.5000   \n",
      "13           emboss            0.146             0.5000   \n",
      "0            rotate            0.000             0.4925   \n",
      "\n",
      "   expected_accuracy_increase(%)  \n",
      "3                           0.75  \n",
      "6                           0.75  \n",
      "13                          0.75  \n",
      "0                           0.00  \n",
      "\n",
      "[4 rows x 23 columns]\n",
      "Top policies are saved to /home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/reports/experiments/07-17_15-30/top4_policies.csv\n",
      "\n",
      "top policies are:\n",
      "     trial_no         A_aug1_type  A_aug1_magnitude         A_aug2_type  \\\n",
      "3          1      gamma-contrast             0.844  coarse-salt-pepper   \n",
      "6          2             dropout             0.801      coarse-dropout   \n",
      "13         3  coarse-salt-pepper             0.918         translate-x   \n",
      "0          0              rotate             0.000              rotate   \n",
      "\n",
      "    A_aug2_magnitude         B_aug1_type  B_aug1_magnitude      B_aug2_type  \\\n",
      "3              0.847            brighten             0.384      translate-y   \n",
      "6              0.679                 fog             0.582   coarse-dropout   \n",
      "13             0.565  coarse-salt-pepper             0.509  horizontal-flip   \n",
      "0              0.000              rotate             0.000           rotate   \n",
      "\n",
      "    B_aug2_magnitude    C_aug1_type  ...  D_aug1_type D_aug1_magnitude  \\\n",
      "3              0.057    translate-y  ...       emboss            0.836   \n",
      "6              0.759         rotate  ...  translate-x            0.135   \n",
      "13             0.921  gaussian-blur  ...     brighten            0.841   \n",
      "0              0.000         rotate  ...       rotate            0.000   \n",
      "\n",
      "    D_aug2_type D_aug2_magnitude     E_aug1_type E_aug1_magnitude  \\\n",
      "3       sharpen            0.648          emboss            0.957   \n",
      "6       sharpen            0.150     translate-x            0.386   \n",
      "13  translate-y            0.398  gamma-contrast            0.165   \n",
      "0        rotate            0.000          rotate            0.000   \n",
      "\n",
      "        E_aug2_type E_aug2_magnitude  mean_late_val_acc  \\\n",
      "3            rotate            0.870             0.5000   \n",
      "6   horizontal-flip            0.450             0.5000   \n",
      "13           emboss            0.146             0.5000   \n",
      "0            rotate            0.000             0.4925   \n",
      "\n",
      "   expected_accuracy_increase(%)  \n",
      "3                           0.75  \n",
      "6                           0.75  \n",
      "13                          0.75  \n",
      "0                           0.00  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "best_policies = deepaug.optimize(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_no</th>\n",
       "      <th>A_aug1_type</th>\n",
       "      <th>A_aug1_magnitude</th>\n",
       "      <th>A_aug2_type</th>\n",
       "      <th>A_aug2_magnitude</th>\n",
       "      <th>B_aug1_type</th>\n",
       "      <th>B_aug1_magnitude</th>\n",
       "      <th>B_aug2_type</th>\n",
       "      <th>B_aug2_magnitude</th>\n",
       "      <th>C_aug1_type</th>\n",
       "      <th>...</th>\n",
       "      <th>D_aug1_type</th>\n",
       "      <th>D_aug1_magnitude</th>\n",
       "      <th>D_aug2_type</th>\n",
       "      <th>D_aug2_magnitude</th>\n",
       "      <th>E_aug1_type</th>\n",
       "      <th>E_aug1_magnitude</th>\n",
       "      <th>E_aug2_type</th>\n",
       "      <th>E_aug2_magnitude</th>\n",
       "      <th>mean_late_val_acc</th>\n",
       "      <th>expected_accuracy_increase(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gamma-contrast</td>\n",
       "      <td>0.844</td>\n",
       "      <td>coarse-salt-pepper</td>\n",
       "      <td>0.847</td>\n",
       "      <td>brighten</td>\n",
       "      <td>0.384</td>\n",
       "      <td>translate-y</td>\n",
       "      <td>0.057</td>\n",
       "      <td>translate-y</td>\n",
       "      <td>...</td>\n",
       "      <td>emboss</td>\n",
       "      <td>0.836</td>\n",
       "      <td>sharpen</td>\n",
       "      <td>0.648</td>\n",
       "      <td>emboss</td>\n",
       "      <td>0.957</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>dropout</td>\n",
       "      <td>0.801</td>\n",
       "      <td>coarse-dropout</td>\n",
       "      <td>0.679</td>\n",
       "      <td>fog</td>\n",
       "      <td>0.582</td>\n",
       "      <td>coarse-dropout</td>\n",
       "      <td>0.759</td>\n",
       "      <td>rotate</td>\n",
       "      <td>...</td>\n",
       "      <td>translate-x</td>\n",
       "      <td>0.135</td>\n",
       "      <td>sharpen</td>\n",
       "      <td>0.150</td>\n",
       "      <td>translate-x</td>\n",
       "      <td>0.386</td>\n",
       "      <td>horizontal-flip</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>coarse-salt-pepper</td>\n",
       "      <td>0.918</td>\n",
       "      <td>translate-x</td>\n",
       "      <td>0.565</td>\n",
       "      <td>coarse-salt-pepper</td>\n",
       "      <td>0.509</td>\n",
       "      <td>horizontal-flip</td>\n",
       "      <td>0.921</td>\n",
       "      <td>gaussian-blur</td>\n",
       "      <td>...</td>\n",
       "      <td>brighten</td>\n",
       "      <td>0.841</td>\n",
       "      <td>translate-y</td>\n",
       "      <td>0.398</td>\n",
       "      <td>gamma-contrast</td>\n",
       "      <td>0.165</td>\n",
       "      <td>emboss</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>...</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>rotate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_no         A_aug1_type  A_aug1_magnitude         A_aug2_type  \\\n",
       "3          1      gamma-contrast             0.844  coarse-salt-pepper   \n",
       "6          2             dropout             0.801      coarse-dropout   \n",
       "13         3  coarse-salt-pepper             0.918         translate-x   \n",
       "0          0              rotate             0.000              rotate   \n",
       "\n",
       "    A_aug2_magnitude         B_aug1_type  B_aug1_magnitude      B_aug2_type  \\\n",
       "3              0.847            brighten             0.384      translate-y   \n",
       "6              0.679                 fog             0.582   coarse-dropout   \n",
       "13             0.565  coarse-salt-pepper             0.509  horizontal-flip   \n",
       "0              0.000              rotate             0.000           rotate   \n",
       "\n",
       "    B_aug2_magnitude    C_aug1_type  ...  D_aug1_type D_aug1_magnitude  \\\n",
       "3              0.057    translate-y  ...       emboss            0.836   \n",
       "6              0.759         rotate  ...  translate-x            0.135   \n",
       "13             0.921  gaussian-blur  ...     brighten            0.841   \n",
       "0              0.000         rotate  ...       rotate            0.000   \n",
       "\n",
       "    D_aug2_type D_aug2_magnitude     E_aug1_type E_aug1_magnitude  \\\n",
       "3       sharpen            0.648          emboss            0.957   \n",
       "6       sharpen            0.150     translate-x            0.386   \n",
       "13  translate-y            0.398  gamma-contrast            0.165   \n",
       "0        rotate            0.000          rotate            0.000   \n",
       "\n",
       "        E_aug2_type E_aug2_magnitude  mean_late_val_acc  \\\n",
       "3            rotate            0.870             0.5000   \n",
       "6   horizontal-flip            0.450             0.5000   \n",
       "13           emboss            0.146             0.5000   \n",
       "0            rotate            0.000             0.4925   \n",
       "\n",
       "   expected_accuracy_increase(%)  \n",
       "3                           0.75  \n",
       "6                           0.75  \n",
       "13                          0.75  \n",
       "0                           0.00  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_train_val_sets(X, y, train_set_size, val_set_size):\n",
    "        \"\"\"Splits given images randomly into `train` and `val_seed` groups\n",
    "\n",
    "        val_seed -> is validation seed dataset, from where validation sets are sampled\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array):\n",
    "            y (numpy.array):\n",
    "            train_set_size (int):\n",
    "            val_set_size (int):\n",
    "        return:\n",
    "            dict: dict with keys `X_train`, `y_train`, `X_val_seed`, `y_val_seed`\n",
    "        \"\"\"\n",
    "        if train_set_size == None:\n",
    "            print(f\"Using all training images\")\n",
    "            train_set_size = len(X) - val_set_size\n",
    "        else:\n",
    "            print(f\"Using {train_set_size} training images\")\n",
    "\n",
    "        # reduce training dataset\n",
    "        ix = np.random.choice(len(X), train_set_size, False)\n",
    "        X_train = X[ix]\n",
    "        y_train = y[ix]\n",
    "\n",
    "        other_ix = set(np.arange(len(X))).difference(set(ix))\n",
    "        other_ix = list(other_ix)\n",
    "        X_val_seed = X[other_ix]\n",
    "        y_val_seed = y[other_ix]\n",
    "\n",
    "        data = {\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val_seed\": X_val_seed,\n",
    "            \"y_val_seed\": y_val_seed,\n",
    "        }\n",
    "        return data\n",
    "\n",
    "def preprocess(X, y, train_set_size, val_set_size=1000):\n",
    "        \"\"\"Preprocess images by:\n",
    "            1. normalize to 0-1 range (divide by 255)\n",
    "            2. convert labels to categorical)\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array):\n",
    "            y (numpy.array):\n",
    "            train_set_size (int):\n",
    "            val_set_size (int):\n",
    "\n",
    "        Returns:\n",
    "            dict: preprocessed data\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        data = split_train_val_sets(X, y, train_set_size, val_set_size)\n",
    "\n",
    "        # normalize images\n",
    "        data[\"X_train\"] = data[\"X_train\"].astype(\"float32\") / 255\n",
    "        data[\"X_val_seed\"] = data[\"X_val_seed\"].astype(\"float32\") / 255\n",
    "\n",
    "        # convert labels to categorical\n",
    "        data[\"y_train\"] = tf.keras.utils.to_categorical(data[\"y_train\"])\n",
    "        data[\"y_val_seed\"] = tf.keras.utils.to_categorical(data[\"y_val_seed\"])\n",
    "        return data\n",
    "    \n",
    "a=preprocess(training_data, train_labels, 500)['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug\n",
    "magnitude= 0.8472517387841256\n",
    "X_norm=a\n",
    "b=imgaug.augmenters.AddToHue(\n",
    "            (int(-45 * magnitude), int(45 * magnitude))\n",
    "        ).augment_images(\n",
    "            X_norm.astype(np.uint8)\n",
    "        )  # needs 0-1 values\n",
    "b.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a.astype(np.uint64)[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-6Yocnrq2u4F"
   ],
   "name": "25_May.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
