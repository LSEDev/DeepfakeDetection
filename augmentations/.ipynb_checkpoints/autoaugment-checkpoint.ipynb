{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udRhv-d-2i8l"
   },
   "source": [
    "# Run autoaugment to obtain best parameters\n",
    "       -- built for FF+ dataset with file structure as required by Keras' flow_from_directory method\n",
    "       \n",
    "Requires 50GB RAM, at least 4 CPU workers and a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t7E1CjC9fqhq",
    "outputId": "abdef6eb-823c-4fb1-ad28-7521345d04fc"
   },
   "outputs": [],
   "source": [
    "# See available GPU RAM \n",
    "# !nvidia-smi # can also be run from linux shell while GPU is training\n",
    "# !nvidia-smi dmon # this will stream memory utilisation\n",
    "# !watch -n0.1 nvidia-smi # better way to see GPU utilisation\n",
    "# !htop # cpu threads and if they're all working\n",
    "# !pip3 install --no-cache-dir -I tensorflow==2.2 #Â use if no gpu is attached so code will run \n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number\n",
    "# !sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches' # clear CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoaugment installations and run TF2 upgrade scripts\n",
    "# !tf_upgrade_v2 --intree ../augmentations/deepaugment-master --outtree ../augmentations/deepaugment_updated\n",
    "# Then make some manual changes to ensure it runs using TF2\n",
    "# Now install packages required by DeepAugment\n",
    "# !pip install scikit-optimize\n",
    "# !pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Llx-HRnYiWQU",
    "outputId": "6e6a3556-fbb1-4972-b046-8586183f768a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment/deepaugment.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations/deepaugment_updated/deepaugment')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "import deepaugment as dp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "\n",
    "# # Augmentation libraries\n",
    "# import face_recognition\n",
    "# import cutout_augmentation as ca\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/authentic')\n",
    "train_authentic_images = []\n",
    "\n",
    "# Training data\n",
    "for image_path in train_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_authentic_images.append(img)\n",
    "    if len(train_authentic_images) % 1000 == 0: print(len(train_authentic_images))\n",
    "        \n",
    "    if len(train_authentic_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "train_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/train/fake')\n",
    "train_fake_images = []\n",
    "\n",
    "for image_path in train_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/train/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    train_fake_images.append(img)\n",
    "    if len(train_fake_images) % 1000 == 0: print(len(train_fake_images))\n",
    "        \n",
    "    if len(train_fake_images) == 500:\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "# Validation data\n",
    "val_authentic_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic')\n",
    "val_authentic_images = []\n",
    "\n",
    "for image_path in val_authentic_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/authentic/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_authentic_images.append(img)\n",
    "    if len(val_authentic_images) % 1000 == 0: print(len(val_authentic_images))\n",
    "        \n",
    "    if len(val_authentic_images) == 50:\n",
    "        break\n",
    "        \n",
    "        \n",
    "val_fake_image_paths = os.listdir('../../all_faces_disk/home/jupyter/forensics_split/validation/fake')\n",
    "val_fake_images = []\n",
    "\n",
    "for image_path in val_fake_image_paths:\n",
    "    img = cv2.imread('../../all_faces_disk/home/jupyter/forensics_split/validation/fake/' + image_path)\n",
    "    # resizing is optional\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    val_fake_images.append(img)\n",
    "    if len(val_fake_images) % 1000 == 0: print(len(val_fake_images))\n",
    "        \n",
    "    if len(val_fake_images) == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import fashion_mnist\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# x_train[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# train_authentic_images\n",
    "# train_fake_images\n",
    "# val_authentic_images\n",
    "# val_fake_images\n",
    "\n",
    "# Concatenate authentic and fake images\n",
    "training_data = np.array(train_authentic_images + train_fake_images)\n",
    "\n",
    "# Create training labels\n",
    "train_labels = np.array([0]*len(train_authentic_images) + [1]*len(train_fake_images))\n",
    "train_labels\n",
    "\n",
    "print(training_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 training images\n",
      "BasicCNN model built as child model.\n",
      " Model summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               95552000  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 95,618,594\n",
      "Trainable params: 95,618,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "rotate\n",
      "load_pre_augment_weights()'s runtime:  0.4907 sec.\n",
      "1/1 - 32s - loss: 0.7479 - accuracy: 0.4167 - val_loss: 1.4190 - val_accuracy: 0.4850\n",
      "fit()'s runtime:  36.479 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.4821 sec.\n",
      "1/1 - 31s - loss: 0.6856 - accuracy: 0.5833 - val_loss: 4.8768 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  33.7185 sec.\n",
      "load_pre_augment_weights()'s runtime:  0.463 sec.\n",
      "1/1 - 31s - loss: 0.6231 - accuracy: 0.6667 - val_loss: 14.1412 - val_accuracy: 0.5000\n",
      "fit()'s runtime:  34.2437 sec.\n",
      "0, nan, ['rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0, 'rotate', 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Run DeepAugment\n",
    "\n",
    "config = {\n",
    "    \"model\": \"basiccnn\",\n",
    "    \"method\": \"bayesian_optimization\",\n",
    "#     \"train_set_size\": 2000,\n",
    "    \"train_set_size\": 2,\n",
    "    \"opt_samples\": 3,\n",
    "    \"opt_last_n_epochs\": 3,\n",
    "    \"opt_initial_points\": 10,\n",
    "    \"child_epochs\": 1,\n",
    "    \"child_first_train_epochs\": 0,\n",
    "    \"child_batch_size\": 64\n",
    "}\n",
    "\n",
    "deepaug = dp.DeepAugment(training_data, train_labels, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1 \n",
      " ['brighten', 0.9023485831739845, 'gaussian-blur', 0.969809067746749, 'invert', 0.17090958513604518, 'emboss', 0.7506861412184564, 'brighten', 0.32504722900835253, 'crop', 0.6342740579573352, 'vertical-flip', 0.652790317005491, 'brighten', 0.9952995676778879, 'gamma-contrast', 0.4143685882263689, 'dropout', 0.6235101011318683]\n",
      "brighten\n",
      "invert\n",
      "brighten\n",
      "vertical-flip\n",
      "gamma-contrast\n",
      "load_pre_augment_weights()'s runtime:  0.5126 sec.\n"
     ]
    }
   ],
   "source": [
    "best_policies = deepaug.optimize(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_policies\n",
    "# train_authentic_images\n",
    "training_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_train_val_sets(X, y, train_set_size, val_set_size):\n",
    "        \"\"\"Splits given images randomly into `train` and `val_seed` groups\n",
    "\n",
    "        val_seed -> is validation seed dataset, from where validation sets are sampled\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array):\n",
    "            y (numpy.array):\n",
    "            train_set_size (int):\n",
    "            val_set_size (int):\n",
    "        return:\n",
    "            dict: dict with keys `X_train`, `y_train`, `X_val_seed`, `y_val_seed`\n",
    "        \"\"\"\n",
    "        if train_set_size == None:\n",
    "            print(f\"Using all training images\")\n",
    "            train_set_size = len(X) - val_set_size\n",
    "        else:\n",
    "            print(f\"Using {train_set_size} training images\")\n",
    "\n",
    "        # reduce training dataset\n",
    "        ix = np.random.choice(len(X), train_set_size, False)\n",
    "        X_train = X[ix]\n",
    "        y_train = y[ix]\n",
    "\n",
    "        other_ix = set(np.arange(len(X))).difference(set(ix))\n",
    "        other_ix = list(other_ix)\n",
    "        X_val_seed = X[other_ix]\n",
    "        y_val_seed = y[other_ix]\n",
    "\n",
    "        data = {\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val_seed\": X_val_seed,\n",
    "            \"y_val_seed\": y_val_seed,\n",
    "        }\n",
    "        return data\n",
    "\n",
    "def preprocess(X, y, train_set_size, val_set_size=1000):\n",
    "        \"\"\"Preprocess images by:\n",
    "            1. normalize to 0-1 range (divide by 255)\n",
    "            2. convert labels to categorical)\n",
    "\n",
    "        Args:\n",
    "            X (numpy.array):\n",
    "            y (numpy.array):\n",
    "            train_set_size (int):\n",
    "            val_set_size (int):\n",
    "\n",
    "        Returns:\n",
    "            dict: preprocessed data\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        data = split_train_val_sets(X, y, train_set_size, val_set_size)\n",
    "\n",
    "        # normalize images\n",
    "        data[\"X_train\"] = data[\"X_train\"].astype(\"float32\") / 255\n",
    "        data[\"X_val_seed\"] = data[\"X_val_seed\"].astype(\"float32\") / 255\n",
    "\n",
    "        # convert labels to categorical\n",
    "        data[\"y_train\"] = tf.keras.utils.to_categorical(data[\"y_train\"])\n",
    "        data[\"y_val_seed\"] = tf.keras.utils.to_categorical(data[\"y_val_seed\"])\n",
    "        return data\n",
    "    \n",
    "a=preprocess(training_data, train_labels, 500)['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug\n",
    "magnitude= 0.8472517387841256\n",
    "X_norm=a\n",
    "b=imgaug.augmenters.AddToHue(\n",
    "            (int(-45 * magnitude), int(45 * magnitude))\n",
    "        ).augment_images(\n",
    "            X_norm.astype(np.uint8)\n",
    "        )  # needs 0-1 values\n",
    "b.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a.astype(np.uint64)[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-6Yocnrq2u4F"
   ],
   "name": "25_May.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
