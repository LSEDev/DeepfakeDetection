{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /opt/conda/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.19.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.30.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (3.12.3)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (2.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (47.3.1.post20200616)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.25.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import VisualisationTools as plotting\n",
    "import pickle\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 603,778\n",
      "Trainable params: 603,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (300)\n",
    "inputs = Input(shape=input_shape)\n",
    "print('hello')\n",
    "\n",
    "t_dense1 = Dense(1024, activation='relu')(inputs)\n",
    "t_dense2 = Dense(256, activation='relu')(t_dense1)\n",
    "t_dense3 = Dense(128, activation='relu')(t_dense2)\n",
    "t_do = Dropout(0.3)(t_dense3)\n",
    "predictions = Dense(2, activation= 'softmax')(t_do)\n",
    "model = Model(inputs=inputs, outputs=predictions, name = 'simple_model')\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.0002, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import radialProfile\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(directory, batch):\n",
    "    '''Prepares train-time augmentation using given training and validations data)\n",
    "    \n",
    "    Returns train_data, val_data'''\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=True,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=True,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            )\n",
    "\n",
    "    # Classes give the folders storing the two different categories\n",
    "    train_data = datagen.flow_from_directory(directory + '/train',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    val_data = datagen.flow_from_directory(directory + '/validation',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def featurevectorise(img):\n",
    "    #img = color.rgb2gray(img)\n",
    "    img = rgb2gray(img)\n",
    "    h = int(img.shape[1]/3)\n",
    "    w = int(img.shape[2]/3)\n",
    "    img = img[0,h:-h,w:-w]\n",
    "\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift += epsilon\n",
    "\n",
    "\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psd1D = radialProfile.azimuthalAverage(magnitude_spectrum)\n",
    "    points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n",
    "    xi = np.linspace(0,N,num=N) # coordinates for interpolation\n",
    "\n",
    "    interpolated = griddata(points,psd1D,xi,method='cubic')\n",
    "    interpolated /= interpolated[0]\n",
    "    \n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 113928 images belonging to 2 classes.\n",
      "Found 21291 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch = 1\n",
    "train_data, val_data = augment_data('/home/jupyter/all_faces_disk/home/jupyter/forensics_split', batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {}\n",
    "epsilon = 1e-8\n",
    "N = 300\n",
    "y = []\n",
    "error = []\n",
    "\n",
    "\n",
    "number_iter = 1000\n",
    "val_length = 100\n",
    "\n",
    "psd1D_total = np.zeros([number_iter, N])\n",
    "label_total = np.zeros([number_iter, 2])\n",
    "\n",
    "X_test = np.zeros([val_length, N])\n",
    "Y_test = np.zeros([val_length, 2])\n",
    "cont = 0\n",
    "\n",
    "for image in train_data:\n",
    "    psd1D_total[cont,:] = featurevectorise(image[0])             \n",
    "    label_total[cont,:] = image[1]\n",
    "    cont+=1\n",
    "    if cont == number_iter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 300)\n",
      "(100, 300)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "cont2 = 0\n",
    "for image in val_data:\n",
    "    X_test[cont2,:] = featurevectorise(image[0])             \n",
    "    Y_test[cont2,:] = image[1]\n",
    "    cont2+=1\n",
    "    if cont2 == val_length:\n",
    "        break\n",
    "print(psd1D_total.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = psd1D_total\n",
    "Y_train = label_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.7790 - val_loss: 0.4811 - val_accuracy: 0.7900\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5030 - accuracy: 0.7790 - val_loss: 0.4808 - val_accuracy: 0.7900\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5011 - accuracy: 0.7790 - val_loss: 0.4798 - val_accuracy: 0.7900\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.7790 - val_loss: 0.4915 - val_accuracy: 0.7900\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4945 - accuracy: 0.7790 - val_loss: 0.4800 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5011 - accuracy: 0.7790 - val_loss: 0.4809 - val_accuracy: 0.7900\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4970 - accuracy: 0.7790 - val_loss: 0.4801 - val_accuracy: 0.7900\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.7790 - val_loss: 0.4799 - val_accuracy: 0.7900\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4936 - accuracy: 0.7790 - val_loss: 0.4771 - val_accuracy: 0.7900\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4956 - accuracy: 0.7790 - val_loss: 0.4824 - val_accuracy: 0.7900\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4958 - accuracy: 0.7790 - val_loss: 0.4751 - val_accuracy: 0.7900\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4950 - accuracy: 0.7790 - val_loss: 0.4762 - val_accuracy: 0.7900\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4925 - accuracy: 0.7790 - val_loss: 0.4772 - val_accuracy: 0.7900\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.7790 - val_loss: 0.4740 - val_accuracy: 0.7900\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4912 - accuracy: 0.7790 - val_loss: 0.4751 - val_accuracy: 0.7900\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4959 - accuracy: 0.7790 - val_loss: 0.4728 - val_accuracy: 0.7900\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4911 - accuracy: 0.7790 - val_loss: 0.4755 - val_accuracy: 0.7900\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.7790 - val_loss: 0.4740 - val_accuracy: 0.7900\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4902 - accuracy: 0.7790 - val_loss: 0.4744 - val_accuracy: 0.7900\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4879 - accuracy: 0.7790 - val_loss: 0.4774 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fde43de2910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "#X_train = psd1D_total\n",
    "Y_train = label_total\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
