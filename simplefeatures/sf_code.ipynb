{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "import math\n",
    "\n",
    "import radialProfile\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20')\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout, lr_rate, vector_length = 300):\n",
    "    \"\"\"Buil a model of just four layers, with an\n",
    "    Adam optimiser.\"\"\"\n",
    "\n",
    "    input_shape = (vector_length)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    t_dense1 = Dense(1024, activation='relu')(inputs)\n",
    "    t_dense2 = Dense(256, activation='relu')(t_dense1)\n",
    "    t_dense3 = Dense(128, activation='relu')(t_dense2)\n",
    "    t_do = Dropout(dropout)(t_dense3)\n",
    "    predictions = Dense(2, activation= 'softmax')(t_do)\n",
    "    model = Model(inputs=inputs, outputs=predictions, name = 'simple_model')\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate= lr_rate, decay=1e-6)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(directory, batch):\n",
    "    '''Prepares train-time augmentation using given training and validations data\n",
    "    \n",
    "    Returns train_data, val_data'''\n",
    "\n",
    "    data_aug = tf.keras.preprocessing.image.ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "            \n",
    "    # Classes give the folders storing the two different categories\n",
    "    train_data = data_aug.flow_from_directory(directory + '/train',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    val_data = data_aug.flow_from_directory(directory + '/validation',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    \"\"\"Gray-scale an image.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurevectorise(img, N = 300):\n",
    "    \"\"\"Turn an image into its feature vector. First, the Fourier Transformer\n",
    "    is carried out. Then this output is Azimuthally averaged. \n",
    "    img is an image, N is the length of the feature vector to be calculated. \n",
    "    \"\"\"\n",
    "    epsilon = 1e-8\n",
    "    img = rgb2gray(img)\n",
    "    h = int(img.shape[1]/3)\n",
    "    w = int(img.shape[2]/3)\n",
    "    img = img[0,h:-h,w:-w]\n",
    "\n",
    "    f = np.fft.fft2(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    fshift += epsilon\n",
    "\n",
    "\n",
    "    magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psd1D = radialProfile.azimuthalAverage(magnitude_spectrum)\n",
    "    points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n",
    "    xi = np.linspace(0,N,num=N) # coordinates for interpolation\n",
    "\n",
    "    interpolated = griddata(points,psd1D,xi,method='cubic')\n",
    "    interpolated /= interpolated[0]\n",
    "    \n",
    "    return interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, number_of_images = 1000, N = 300):\n",
    "    \"\"\"Preprocess a specified number of images, with\n",
    "    a specified length of the feature vector.\"\"\"\n",
    "    X = np.zeros([number_of_images, N])\n",
    "    Y = np.zeros([number_of_images, 2])\n",
    "    \n",
    "    cont = 0\n",
    "    start_time = time.time()\n",
    "    for image in data:\n",
    "        X[cont,:] = featurevectorise(image[0], N)             \n",
    "        Y[cont,:] = image[1]\n",
    "        cont+=1\n",
    "        if cont == number_of_images:\n",
    "            break\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_data):\n",
    "    '''Calculates class weights that weight the data based on the imbalance.\n",
    "    Allows for better analysis in the case of imbalanced data - has no effect\n",
    "    if data is balanced since the weights are then equal for each class.\n",
    "    Use the generator obtained from the flow_from_directory method to obtain\n",
    "    the class_weights.\n",
    "    \n",
    "    Input:\n",
    "    train_data: the generator obtained during augmentation\n",
    "    \n",
    "    Returns a dictionary with class weights, required format for training'''\n",
    "    \n",
    "    # Calculate class weights which are required to fully balance the classes\n",
    "    # Compares frequencies of appearence for each distinct label\n",
    "    \n",
    "    # The line of code below can be used on a generator to find the index labels\n",
    "    print('Ensure class weights function corresponds to these class indices:',\n",
    "          train_data.class_indices)\n",
    "    \n",
    "    counter = Counter(train_data.classes)                          \n",
    "    max_val = float(max(counter.values()))       \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train, X_test, Y_test, class_weights, epochs = 50, batch_size = 64):\n",
    "    '''Trains a provided model.\n",
    "    Takes 6 arguments:\n",
    "    \n",
    "    1. model: a built model with an architecture specified in the build function\n",
    "    2. train_data: augmented data obtained from the augment_data function\n",
    "    3. val_data: validation data obtained from the augment_data function\n",
    "    4. epochs -- number of epochs\n",
    "    5. class weights -- a dictionary with weights (equal for balanced data so\n",
    "    no negative impact)\n",
    "    6. architecture: can choose vgg, xception, resnet50, mobilenet or efficientnet\n",
    "    7. lr_rate: initial learning rate\n",
    "    8. last_epoch: if training fails, pick up from the most recent epoch\n",
    "    '''\n",
    "    \n",
    "    # Make a trained_models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models')\n",
    "    \n",
    "    # Make a weights folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights')\n",
    "        \n",
    "    # Make a weights folder for the architecture if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights/{}'.format(config_file)):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights/{}'.format(config_file))\n",
    "\n",
    "    # Below saves on file - the weights with the highest validation accuracy\n",
    "    filepath1=\"../all_faces_bucket/trained_models/weights/{}/highest_val_acc.hdf5\".format(config_file)\n",
    "    filepath2=\"../all_faces_bucket/trained_models/weights/{}/last_epoch.hdf5\".format(config_file)\n",
    "    checkpoint = ModelCheckpoint(filepath1, monitor='val_accuracy', \n",
    "                                verbose=1, save_best_only=True, mode='max')\n",
    "    last_epoch_checkpoint = ModelCheckpoint(filepath2, monitor='val_accuracy', \n",
    "                                verbose=1, save_best_only=False, mode='max')\n",
    "    \n",
    "    # Make a folder to store training accuracies if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/training_accuracies'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/training_accuracies')\n",
    "    \n",
    "    # Callback to save training accuracies after each epoch\n",
    "    csv_logger = CSVLogger('../all_faces_bucket/trained_models/training_accuracies/{}.csv'.format(config_file),\n",
    "                           separator=',', append=True)\n",
    "                          \n",
    "    # Load previous weights from training if there are any\n",
    "    #load_model_weights(model, architecture)\n",
    "    \n",
    "    cb = [plot_losses, checkpoint, last_epoch_checkpoint, csv_logger]\n",
    "\n",
    "    history = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              class_weight = class_weights,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              max_queue_size=100,                # maximum size for the generator queue\n",
    "              workers=16,                        # maximum number of processes to spin up when using process-based threading\n",
    "              use_multiprocessing=False)\n",
    "    \n",
    "    # Make a saved models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/saved_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/saved_models')\n",
    "        \n",
    "    model.save_weights('../all_faces_bucket/trained_models/weights/{}/lastepoch.hdf5'.format(config_file)) \n",
    "    model.save('../all_faces_bucket/trained_models/saved_models/{}.h5'.format(config_file))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model, pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(0.5, 0.002, 300)\n",
    "BATCH = 1\n",
    "train_data, val_data = augment_data('../ff-alldata/home/jupyter/forensics_split', BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = preprocess_data(train_data, 113928, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = preprocess_data(val_data, 21291, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "class_weights = calculate_class_weights(train_data)\n",
    "config_file = 'simplefeatures300alldata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, X_train, Y_train, X_test, Y_test, class_weights, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set predictions\n",
    "The code below is from the testing code. Ignore until the final cell if you're familiar with this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "af_dir = '../all_faces_bucket/'\n",
    "configname = 'simplefeatures300alldata'\n",
    "model = tf.keras.models.load_model(af_dir + 'trained_models/saved_models/' + configname + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23054 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
    "generator = datagen.flow_from_directory('../ff-alldata/home/jupyter/forensics_split/validation', target_size=(224, 224),\n",
    "                                            shuffle = False, batch_size=1)\n",
    "filenames = generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "generator.reset() # figure out this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 212.59035062789917 seconds ---\n"
     ]
    }
   ],
   "source": [
    "X_Test, Y_Test = preprocess_data(generator,23054,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23054/23054 [==============================] - 24s 1ms/sample\n"
     ]
    }
   ],
   "source": [
    "multidim_predictions = model.predict(X_Test, steps = nb_samples, verbose=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_predictions(arr, soft=True):\n",
    "    '''Obtains image predictions.\n",
    "    soft: a true value returns probabilities as opposed to hard predictions.'''\n",
    "\n",
    "    if soft:\n",
    "        # probability of belonging to fake (second) class,\n",
    "        # hence return second value for each element in the list\n",
    "        return [el[1] for el in arr]\n",
    "    # returns a list of 0's and 1's\n",
    "    return np.argmax(arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['authentic/Original_000_0150.png', 'authentic/Original_000_0165.png', 'authentic/Original_000_0180.png']\n",
      "[0.5722804, 0.24326812, 0.15801273]\n"
     ]
    }
   ],
   "source": [
    "predictions = get_image_predictions(multidim_predictions, soft=True)\n",
    "print(filenames[10:13])\n",
    "print(predictions[10:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(filenames):\n",
    "    index = range(len(filenames))\n",
    "    df = pd.DataFrame(index = index, columns = ['method', 'video', 'image', 'test/train', 'true label',\n",
    "                                                  'probability', 'predicted label', 'acc'])\n",
    "    df = df.fillna(0)\n",
    "    methods = [el[el.find('/')+1: el.find('_')] for el in filenames]\n",
    "    video_numbers = [el[el.find('_')+1: el.rfind('_')] for el in filenames]\n",
    "    # video_numbers = [re.search(\"_(.*?)\\_\", el).group(1) for el in filenames] # older version -- does not include second video name for fake videos\n",
    "    image_numbers = [el[el.find('_')+1: el.find('.')][4:] for el in filenames]\n",
    "    true_labels = [0 if el[0] == 'a' else 1 for el in filenames]\n",
    "    \n",
    "    df['method'] = methods\n",
    "    df['video'] =  video_numbers\n",
    "    df['image'] =  image_numbers\n",
    "    df['true label'] = true_labels\n",
    "    df['test/train'] = ['test']*len(filenames)\n",
    "    df['probability'] = predictions\n",
    "    df['predicted label'] = ['-']*len(filenames)\n",
    "    df['acc'] = ['-']*len(filenames)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>video</th>\n",
       "      <th>image</th>\n",
       "      <th>test/train</th>\n",
       "      <th>true label</th>\n",
       "      <th>probability</th>\n",
       "      <th>predicted label</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0150</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.572280</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0165</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243268</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0180</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158013</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method video image test/train  true label  probability predicted label  \\\n",
       "10  Original   000  0150       test           0     0.572280               -   \n",
       "11  Original   000  0165       test           0     0.243268               -   \n",
       "12  Original   000  0180       test           0     0.158013               -   \n",
       "\n",
       "   acc  \n",
       "10   -  \n",
       "11   -  \n",
       "12   -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = build_dataframe(filenames)\n",
    "display(data[10:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_of_a_fraction(lst, fraction = 1.0):\n",
    "    '''Takes in a list and outputs a mean of the fraction of the largest\n",
    "    elements for that list (by default (fraction is 1) == consider all predictions)\n",
    "        \n",
    "    if fraction equals to 1, the output is simply a mean.\n",
    "        \n",
    "    This mimics considering only the top third highest probabilities for\n",
    "    images for a given video to classify that video. The main idea is\n",
    "    that if a given video has only a fraction of it being manipulated\n",
    "    (unknown information) then it's likely to be wrongly classfied as original\n",
    "    if we average all associated probabilities, however, if we take only a\n",
    "    certain number of highest proabilities that will be much more representative\n",
    "    and overall robust.'''\n",
    "        \n",
    "    sorted_lst = sorted(lst)[::-1] if type(lst) == list else [lst]\n",
    "    sliced_lst = sorted_lst[0:math.ceil(len(lst)*fraction)] if fraction != (1 or 1.0) else sorted_lst\n",
    "    return np.mean(sliced_lst)\n",
    "\n",
    "def get_mean_with_confident_strategy(lst, fraction = 0.75, t = 0.5):\n",
    "    '''Confident strategy is implemented from first-place solution in DFDC.\n",
    "    \n",
    "    The main idea is that if there are a lot of predictions for one class,\n",
    "    then the average is taken of those predictions only. If that's not the\n",
    "    case, then a simple mean is outputted.\n",
    "    \n",
    "    Inputs:\n",
    "    1. list of predictions (converted to a list if it's a single prediction)\n",
    "    2. fraction -- (between 0 and 1) what fraction of the list should predict\n",
    "    the same class for other predictions to be disregarded when taking a mean\n",
    "    3. t -- threshold cutoff value between two classes (note: whole notebook\n",
    "    is structured for a binary classification problem only)'''\n",
    "    \n",
    "    lst = np.array(lst)\n",
    "    num_pred = len(lst)\n",
    "    num_fakes = np.count_nonzero(lst >= t)\n",
    "    num_authentic = num_pred - num_fakes\n",
    "\n",
    "    # if number of fakes is more that 75% of all predictions \n",
    "    if num_fakes > int(num_pred * fraction):\n",
    "        # take predictions which are greater than threshold and average them\n",
    "        return np.mean(lst[lst >= t])\n",
    "\n",
    "    # else if number of predictions below threshold value t is more that 75%\n",
    "    # of all predictions\n",
    "    elif num_authentic > int(num_pred * fraction):\n",
    "        # take these predictions and return their mean\n",
    "        return np.mean(lst[lst < t])\n",
    "  \n",
    "    else: # simple mean\n",
    "        return np.mean(lst)\n",
    "    \n",
    "def get_mean_of_transformed_predictions(lst):\n",
    "    '''Takes a list of predictions, transforms them by individually\n",
    "    pushing the values away from the centre (0.5) closer towards the\n",
    "    extremes (0.0 and 1.0). The visualisation is included below.\n",
    "    \n",
    "    Returns a mean of transformed predictions.'''\n",
    "\n",
    "    if type(lst) != list: lst = [lst]\n",
    "    weights = np.power([abs(el -0.5) for el in lst], 1.0) + 1e-4\n",
    "    return float((lst * weights).sum() / weights.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions(df, threshold = 0.5, option = None, fraction = 0.33):\n",
    "    ''' Takes in a dataframe, regroups by videos (collecting all predictions\n",
    "    for a video in one nested list) then (optionally modifies by one of the three\n",
    "    methods) returning a mean prediction for each video. Lastly, an accuracy\n",
    "    column is filled by comparing a true label with the predicted one (a mean\n",
    "    probability is convered into a label subject to threshold value).\n",
    "    \n",
    "    Inputs:\n",
    "    1. df -- dataframe\n",
    "    2. threshold -- cutoff probability value between classes (by default 0.5)\n",
    "    3. option -- (by default None) choices are 'transform', 'confident strategy'\n",
    "    or 'fraction'; correspond to possible list manipulations\n",
    "    \n",
    "    Note: if you feed option = 'fraction', then you need to also specify fraction\n",
    "    value (1.0 means a simple mean, 0.33 means taking top third, et cetera)\n",
    "    \n",
    "    if option is not speficied or not among choices then a simple mean is calculated\n",
    "    4. fraction (= 0.33) -- value for 'fraction' option '''\n",
    "\n",
    "    # regroup based on method, video title, and test/train category\n",
    "    df = df.groupby(['method', 'video','test/train', 'true label', 'predicted label'])\\\n",
    "                    ['probability'].apply(list).reset_index()\n",
    "    \n",
    "    collected_labels_pred = list(df['probability']) # get the nested list\n",
    "    \n",
    "    # next, we apply one of the three methods to get means\n",
    "    \n",
    "    if option == 'transform':\n",
    "        mean_labels_pred = [get_mean_of_transformed_predictions(el) for el in collected_labels_pred]\n",
    "        \n",
    "    elif option == 'confident strategy':\n",
    "        mean_labels_pred = [get_mean_with_confident_strategy(el) for el in collected_labels_pred]\n",
    "    \n",
    "    elif option == 'fraction':\n",
    "        mean_labels_pred = [get_mean_of_a_fraction(el, fraction) for el in collected_labels_pred]\n",
    "        \n",
    "    else: # if no option is chosen (or not from the list), output a simple mean per video\n",
    "        mean_labels_pred = [np.mean(el) for el in collected_labels_pred]\n",
    "\n",
    "    labels_pred = [0 if el <= threshold else 1 for el in mean_labels_pred]\n",
    "    df['predicted label'] = labels_pred\n",
    "\n",
    "    # produce accuraacy values for each video (0 if classification is wrong and\n",
    "    # 1 if classicification is correct)\n",
    "    df['acc'] = [1 if df['true label'][i] == df['predicted label'][i]\n",
    "                            else 0 for i in range(len(df['true label']))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(df):\n",
    "    acc_per_method = df.groupby(['test/train', 'method'])['acc'].mean()\n",
    "    acc_total = df.groupby(['test/train'])['acc'].mean()\n",
    "    display(acc_per_method)\n",
    "    display(acc_total)\n",
    "    return acc_per_method, acc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################\n",
      "Option: transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.978571\n",
       "            Face2Face         0.585714\n",
       "            FaceSwap          1.000000\n",
       "            NeuralTextures    0.828571\n",
       "            Original          0.828571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.844286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: confident strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.971429\n",
       "            Face2Face         0.514286\n",
       "            FaceSwap          1.000000\n",
       "            NeuralTextures    0.814286\n",
       "            Original          0.878571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.835714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: fraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         1.000000\n",
       "            Face2Face         0.814286\n",
       "            FaceSwap          1.000000\n",
       "            NeuralTextures    0.942857\n",
       "            Original          0.592857\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.87\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.971429\n",
       "            Face2Face         0.514286\n",
       "            FaceSwap          1.000000\n",
       "            NeuralTextures    0.814286\n",
       "            Original          0.878571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.835714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = build_dataframe(filenames)\n",
    "print('\\n')\n",
    "for option in ['transform', 'confident strategy', 'fraction', 'None']:\n",
    "    print('#'*38)\n",
    "    print(\"Option:\", option)\n",
    "    new = convert_predictions(data, option = option)\n",
    "    acc_per_method, acc_total = show_accuracy(new)\n",
    "    print('#'*38)\n",
    "    if option != 'None': print('\\n')\n",
    "print('#'*61)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
