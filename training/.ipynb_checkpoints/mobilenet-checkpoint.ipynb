{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udRhv-d-2i8l"
   },
   "source": [
    "# Train preliminary models - Xception, ResNet, EfficentNet etc.\n",
    "       -- built for FF+ dataset with file structure as required by Keras' flow_from_directory method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t7E1CjC9fqhq",
    "outputId": "abdef6eb-823c-4fb1-ad28-7521345d04fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 14 10:02:48 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    30W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# See available GPU RAM \n",
    "!nvidia-smi # can also be run from linux shell while GPU is training\n",
    "# !nvidia-smi dmon # this will stream memory utilisation\n",
    "# !watch -n0.1 nvidia-smi # better way to see GPU utilisation\n",
    "# !htop # cpu threads and if they're all working\n",
    "# !pip3 install --no-cache-dir -I tensorflow==2.2 #Â use if no gpu is attached so code will run \n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CMake in /opt/conda/lib/python3.7/site-packages (3.17.3)\n",
      "Requirement already satisfied: dlib in /opt/conda/lib/python3.7/site-packages (19.20.0)\n",
      "Requirement already satisfied: face_recognition in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from face_recognition) (7.2.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (19.20.0)\n",
      "Requirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from face_recognition) (1.19.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from face_recognition) (0.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Augmentation installations\n",
    "!pip install CMake\n",
    "!pip install dlib\n",
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Llx-HRnYiWQU",
    "outputId": "6e6a3556-fbb1-4972-b046-8586183f768a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.1-dlenv_tfe\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/augmentations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20')\n",
    "\n",
    "# # Augmentation libraries\n",
    "# import face_recognition\n",
    "# import cutout_augmentation as ca\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "3DRA3QPDgLLR",
    "outputId": "ed171b89-378d-469d-a254-c291be71af4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/efficientnet\n",
      "  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-3gxwxnlm\n",
      "  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-3gxwxnlm\n",
      "Requirement already satisfied (use --upgrade to upgrade): efficientnet==1.1.0 from git+https://github.com/qubvel/efficientnet in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.17.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2020.7.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\n",
      "Building wheels for collected packages: efficientnet\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.0-py3-none-any.whl size=18397 sha256=99d5495731d8868e6334bec81ab0954b90e3d967f5b1e0a7cdb34e0972c4e33d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wab6g944/wheels/11/69/85/814d64d694c96db0eef17b718042d644a1e54f113920481920\n",
      "Successfully built efficientnet\n"
     ]
    }
   ],
   "source": [
    "# Required for EfficientNet\n",
    "!pip install git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtO5vELz8i3-"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ7mWThq32JA"
   },
   "outputs": [],
   "source": [
    "def build_model(dropout, lr_rate, architecture):\n",
    "    '''Builds a specified network with the selected dropout after the last dense layer.\n",
    "\n",
    "    Architectures that can be selected are:\n",
    "    vgg, xception, resnet50, mobilenet, efficientnet, densenet\n",
    "    \n",
    "    Optimiser is Adam, with a provided learning rate (lr_rate) and fixed\n",
    "    decay 1e-6, loss is traditionally categorical_crossentropy.'''\n",
    "\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "    if architecture=='xception':\n",
    "        from tensorflow.keras.applications.xception import Xception\n",
    "        conv_base = Xception(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture=='vgg':\n",
    "        from tensorflow.keras.applications.vgg16 import VGG16\n",
    "        conv_base = VGG16(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "      \n",
    "    elif architecture=='resnet50':\n",
    "        from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "        conv_base = ResNet50(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "      \n",
    "    elif architecture=='mobilenet':\n",
    "        from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        conv_base = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture== 'efficientnet':\n",
    "        # EfficientNetB7 has the highest top-1 accuracy on imagenet\n",
    "        # among EfficientNextB{0:7}\n",
    "        from efficientnet.tfkeras import EfficientNetB0\n",
    "        conv_base = EfficientNetB0(weights='noisy-student', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "        \n",
    "    elif architecture== 'densenet':\n",
    "        from tensorflow.keras.applications.densenet import DenseNet201\n",
    "        conv_base = DenseNet201(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture not in ['vgg', 'xception', 'resnet50',\n",
    "                              'mobilenet', 'efficientnet', 'densenet']:\n",
    "        return \"An unknown network is specified\"\n",
    "    \n",
    "\n",
    "    outputconv_base = conv_base.output\n",
    "    t_flat = Flatten()(outputconv_base)\n",
    "#     t_dense1 = Dense(1024, activation='relu')(t_flat)\n",
    "#     t_dense2 = Dense(256, activation='relu')(t_dense1)\n",
    "#     t_dense3 = Dense(128, activation='relu')(t_dense2)\n",
    "#     t_do = Dropout(dropout)(t_dense3)\n",
    "    t_dense1 = Dense(256, activation='relu')(t_flat)\n",
    "    t_dense2 = Dense(128, activation='relu')(t_dense1)\n",
    "    t_do = Dropout(dropout)(t_dense2)\n",
    "    predictions = Dense(2, activation= 'softmax')(t_do)\n",
    "\n",
    "    model = Model(inputs=conv_base.input, outputs=predictions, name = 'model')\n",
    "\n",
    "    conv_base.trainable = False # freeze the convolutional base\n",
    "    \n",
    "    # # Code below trains all layers without using any pretrained weights\n",
    "    #for layer in conv_base.layers:\n",
    "    #  layer.trainable = True\n",
    "\n",
    "#     opt = tf.keras.optimizers.Adam(learning_rate= lr_rate, decay=1e-6)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_rate)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.01),\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(directory, batch):\n",
    "    '''Prepares train-time augmentation using given training and validations data)\n",
    "    \n",
    "    Returns train_data, val_data'''\n",
    "\n",
    "    datagen_train = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=True,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=True,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "#             width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "#             height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            brightness_range=[0.6, 1.4],\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            )\n",
    "    \n",
    "    datagen_test = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "    # Classes give the folders storing the two different categories\n",
    "    train_data = datagen_train.flow_from_directory(directory + '/train',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    val_data = datagen_test.flow_from_directory(directory + '/validation',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary train time functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_data):\n",
    "    '''Calculates class weights that weight the data based on the imbalance.\n",
    "    Allows for better analysis in the case of imbalanced data - has no effect\n",
    "    if data is balanced since the weights are then equal for each class.\n",
    "    Use the generator obtained from the flow_from_directory method to obtain\n",
    "    the class_weights.\n",
    "    \n",
    "    Input:\n",
    "    train_data: the generator obtained during augmentation\n",
    "    \n",
    "    Returns a dictionary with class weights, required format for training'''\n",
    "    \n",
    "    # Calculate class weights which are required to fully balance the classes\n",
    "    # Compares frequencies of appearence for each distinct label\n",
    "    \n",
    "    # The line of code below can be used on a generator to find the index labels\n",
    "    print('Ensure class weights function corresponds to these class indices:',\n",
    "          train_data.class_indices)\n",
    "    \n",
    "    counter = Counter(train_data.classes)                          \n",
    "    max_val = float(max(counter.values()))       \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "    return class_weights\n",
    "\n",
    "def load_model_weights(model, architecture):\n",
    "    '''An alternative to training if there are already some generated weights\n",
    "    \n",
    "    Takes a built model (and its architecture type) and loads the weights\n",
    "    with the highest validation accuracy.\n",
    "    \n",
    "    If there are no saved weights, a message is printed. '''\n",
    "\n",
    "    path_to_weights = \"../all_faces_bucket/trained_models/weights/mob_dense_test\"\n",
    "    # get all the weights file names in a list\n",
    "    if os.path.exists(path_to_weights):\n",
    "        all_weights = sorted(os.listdir(path_to_weights + '/'))\n",
    "    # if there is at least one file\n",
    "        if len(all_weights) >= 1:\n",
    "            # pick out accuracies out of file names\n",
    "            acc = [el[len(el)-10 : len(el)-5] for el in all_weights]\n",
    "            # get index of the first maximum accuracy\n",
    "            optimal_index = acc.index(max(acc))\n",
    "            # get the name of the file with optimal weights, load corresponding weights\n",
    "            optimal_weights = all_weights[optimal_index]\n",
    "            print(\"Loading\", path_to_weights + '/' + optimal_weights)\n",
    "            model.load_weights(path_to_weights + '/' + optimal_weights)\n",
    "            \n",
    "        else: # otherwise warn that no weights were loaded\n",
    "            print(\"There are no weights stored. Training model from scratch:\")   \n",
    "    \n",
    "    else: # otherwise warn that no weights were loaded\n",
    "        print(\"There are no weights stored. Training model from scratch:\")   \n",
    "        \n",
    "def save_model_from_best_weights(dropout, lr_rate, architecture):\n",
    "    '''Takes the weights with the highest val accuracy and saves the corresponding model.'''\n",
    "    model = build_model(dropout, lr_rate, architecture)\n",
    "    load_model_weights(model, architecture)\n",
    "    model.save('../all_faces_bucket/trained_models/saved_models/mob_dense_test_model.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, val_data, epochs, class_weights, architecture):\n",
    "    '''Trains a provided model.\n",
    "    Takes 6 arguments:\n",
    "    \n",
    "    1. model: a built model with an architecture specified in the build function\n",
    "    2. train_data: augmented data obtained from the augment_data function\n",
    "    3. val_data: validation data obtained from the augment_data function\n",
    "    4. epochs -- number of epochs\n",
    "    5. class weights -- a dictionary with weights (equal for balanced data so\n",
    "    no negative impact)\n",
    "    6. architecture: can choose vgg, xception, resnet50, mobilenet or efficientnet\n",
    "    '''\n",
    "    \n",
    "    # Make a trained_models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models')\n",
    "    \n",
    "    # Make a weights folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights')\n",
    "        \n",
    "    # Make a weights folder for the architecture if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights/mob_dense_test'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights/mob_dense_test')\n",
    "\n",
    "    # Save weights - below saves every epoch where there is improvement\n",
    "    # filepath=\"../all_faces_bucket/trained_models/weights/\" + architecture + \"/epochs:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5\"\n",
    "    # Below saves on file - the weights with the highest validation accuracy\n",
    "    filepath=\"../all_faces_bucket/trained_models/weights/mob_dense_test/highest_val_acc.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
    "                                verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    # Make a folder to store training accuracies if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/training_accuracies'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/training_accuracies')\n",
    "    \n",
    "    # Callback to save training accuracies after each epoch\n",
    "    csv_logger = CSVLogger('../all_faces_bucket/trained_models/training_accuracies/mob_dense_test.csv',\n",
    "                           separator=',', append=True)\n",
    "    \n",
    "    # Stop after 3 epochs if val_accuracy doesn't improve\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "                          \n",
    "    # Load previous weights from training if there are any\n",
    "    load_model_weights(model, architecture)\n",
    "    \n",
    "    # Set learning rate config \n",
    "    sample_count = 60000 # number of training samples\n",
    "    epochs = 50 # total epochs - affects total steps (and hence speed of decay)\n",
    "    warmup_epoch = 3 # number of warmup epochs\n",
    "    batch_size = train_data.batch_size\n",
    "    learning_rate_base = 0.0002\n",
    "    total_steps = int(epochs * sample_count / batch_size)\n",
    "    warmup_steps = int(warmup_epoch * sample_count / batch_size)\n",
    "    \n",
    "    warm_up_lr = hp.WarmUpCosineDecayScheduler(learning_rate_base=learning_rate_base,\n",
    "                                        total_steps=total_steps,\n",
    "                                        warmup_learning_rate=0.0,\n",
    "                                        warmup_steps=warmup_steps,\n",
    "                                        hold_base_rate_steps=2,\n",
    "                                        verbose=0)\n",
    "\n",
    "    history = model.fit(train_data, epochs=epochs, shuffle=True,\n",
    "              steps_per_epoch = train_data.n//train_data.batch_size,\n",
    "              validation_data = val_data, \n",
    "              validation_steps = val_data.n//val_data.batch_size,\n",
    "              class_weight=class_weights,\n",
    "              callbacks=[plot_losses, checkpoint, csv_logger, es, warm_up_lr],\n",
    "              initial_epoch=0,                    # start training epoch - useful if continuing training\n",
    "              verbose=1,\n",
    "              max_queue_size=100,                # maximum size for the generator queue\n",
    "              workers=16,                        # maximum number of processes to spin up when using process-based threading\n",
    "              use_multiprocessing=False)\n",
    "    \n",
    "    # Make a saved models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/saved_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/saved_models')\n",
    "        \n",
    "    model.save_weights('../all_faces_bucket/trained_models/weights/mob_dense_testlastepoch.hdf5') \n",
    "    model.save('../all_faces_bucket/trained_models/saved_models/mob_dense_testlastepoch.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIUZirJoxsdx"
   },
   "source": [
    "## Unifying Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYFsNbZMqYTv"
   },
   "outputs": [],
   "source": [
    "def run_training(dropout = 0.5, lr_rate = 0.0001, architecture = 'vgg', \n",
    "                 batch = 32, epochs = 50):\n",
    "\n",
    "    '''Builds a model based on the specified architecture, augments training\n",
    "    data (reserving a fraction for validation), then computes class weights to\n",
    "    balance data and trains the model.\n",
    "    \n",
    "    Inputs:\n",
    "    1. dropout  -- for the model\n",
    "    2. lr_rate\n",
    "    3. architecture -- a choice of vgg, resnet50, mobilenet, xception and efficientnet\n",
    "    4. batch -- batch size\n",
    "    5. epochs -- number of epochs\n",
    "    '''\n",
    "\n",
    "    # Build a model, augment data, get class_weights and train the model\n",
    "    # Strategy scope allows us to leverage multiple GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    \n",
    "    with strategy.scope(): # Allows for parallel GPUs\n",
    "        model = build_model(dropout, lr_rate, architecture)\n",
    "    train_data, val_data = augment_data('../all_faces_disk/home/jupyter/forensics_split', batch)\n",
    "    class_weights = calculate_class_weights(train_data)\n",
    "    trained_model = train_model(model, train_data, val_data, epochs, class_weights, architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "in8HHH594qtA"
   },
   "source": [
    "## Train Various Model Architectures\n",
    "Note: Make sure CPUs have enough memory for each batch eg. 1 core with 3.75GB RAM cant take batches larger than 32.  \n",
    "8 CPUs with 30GB RAM typically works well for batches of 256.\n",
    "\n",
    "In this model: 4 cores/8GB and T4 used - took approx 8 hours to train top dense layers and fine tune. \n",
    "\n",
    "Also note that while multiprocessing speeds up training, it interacts badly with Tensorflow and leads to deadlocks. To be on the safe side, set use_multiprocessing to False when training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gz0ilB_F8F4g"
   },
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "id": "_GZwsiNC7rkK",
    "outputId": "7b0348f4-e292-4cb7-af8f-49af0eda2638"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77340\n",
      "3560/3560 [==============================] - 571s 160ms/step - loss: 0.6676 - accuracy: 0.7997 - val_loss: 0.8113 - val_accuracy: 0.7687\n",
      "Epoch 3/50\n",
      "\n",
      "Batch 07121: setting learning rate to 0.0001998583853160962.\n",
      "   1/3560 [..............................] - ETA: 1:51:55 - loss: 0.6101 - accuracy: 0.7812\n",
      "Batch 07122: setting learning rate to 0.00019985819559255953.\n",
      "   2/3560 [..............................] - ETA: 57:40 - loss: 0.6006 - accuracy: 0.8125  \n",
      "Batch 07123: setting learning rate to 0.00019985800574211023.\n",
      "   3/3560 [..............................] - ETA: 40:52 - loss: 0.5593 - accuracy: 0.8333\n",
      "Batch 07124: setting learning rate to 0.00019985781576474854.\n",
      "   4/3560 [..............................] - ETA: 31:36 - loss: 0.5488 - accuracy: 0.8281\n",
      "Batch 07125: setting learning rate to 0.00019985762566047466.\n",
      "   5/3560 [..............................] - ETA: 26:03 - loss: 0.5299 - accuracy: 0.8313\n",
      "Batch 07126: setting learning rate to 0.00019985743542928885.\n",
      "   6/3560 [..............................] - ETA: 22:17 - loss: 0.5427 - accuracy: 0.8281\n",
      "Batch 07127: setting learning rate to 0.00019985724507119138.\n",
      "   7/3560 [..............................] - ETA: 20:09 - loss: 0.5427 - accuracy: 0.8348\n",
      "Batch 07128: setting learning rate to 0.00019985705458618245.\n",
      "   8/3560 [..............................] - ETA: 18:05 - loss: 0.5381 - accuracy: 0.8281\n",
      "Batch 07129: setting learning rate to 0.0001998568639742623.\n",
      "   9/3560 [..............................] - ETA: 16:26 - loss: 0.5641 - accuracy: 0.8264\n",
      "Batch 07130: setting learning rate to 0.00019985667323543124.\n",
      "  10/3560 [..............................] - ETA: 15:07 - loss: 0.5460 - accuracy: 0.8344\n",
      "Batch 07131: setting learning rate to 0.00019985648236968943.\n",
      "  11/3560 [..............................] - ETA: 14:02 - loss: 0.5437 - accuracy: 0.8324\n",
      "Batch 07132: setting learning rate to 0.00019985629137703715.\n",
      "  12/3560 [..............................] - ETA: 13:06 - loss: 0.5390 - accuracy: 0.8359\n",
      "Batch 07133: setting learning rate to 0.00019985610025747468.\n",
      "  13/3560 [..............................] - ETA: 12:21 - loss: 0.5441 - accuracy: 0.8413\n",
      "Batch 07134: setting learning rate to 0.00019985590901100216.\n",
      "  14/3560 [..............................] - ETA: 11:41 - loss: 0.5265 - accuracy: 0.8460\n",
      "Batch 07135: setting learning rate to 0.00019985571763761993.\n",
      "  15/3560 [..............................] - ETA: 11:06 - loss: 0.5266 - accuracy: 0.8500\n",
      "Batch 07136: setting learning rate to 0.0001998555261373282.\n",
      "\n",
      "Batch 07137: setting learning rate to 0.0001998553345101272.\n",
      "  17/3560 [..............................] - ETA: 12:09 - loss: 0.5235 - accuracy: 0.8529\n",
      "Batch 07138: setting learning rate to 0.00019985514275601722.\n",
      "  18/3560 [..............................] - ETA: 11:39 - loss: 0.5298 - accuracy: 0.8438\n",
      "Batch 07139: setting learning rate to 0.00019985495087499844.\n",
      "\n",
      "Batch 07140: setting learning rate to 0.0001998547588670711.\n",
      "  20/3560 [..............................] - ETA: 11:00 - loss: 0.5320 - accuracy: 0.8438\n",
      "Batch 07141: setting learning rate to 0.00019985456673223554.\n",
      "  21/3560 [..............................] - ETA: 11:01 - loss: 0.5414 - accuracy: 0.8423\n",
      "Batch 07142: setting learning rate to 0.00019985437447049193.\n",
      "  22/3560 [..............................] - ETA: 10:40 - loss: 0.5686 - accuracy: 0.8395\n",
      "Batch 07143: setting learning rate to 0.00019985418208184053.\n",
      "  23/3560 [..............................] - ETA: 10:20 - loss: 0.6003 - accuracy: 0.8356\n",
      "Batch 07144: setting learning rate to 0.00019985398956628156.\n",
      "  24/3560 [..............................] - ETA: 10:02 - loss: 0.5931 - accuracy: 0.8398\n",
      "Batch 07145: setting learning rate to 0.00019985379692381527.\n",
      "  25/3560 [..............................] - ETA: 9:47 - loss: 0.5822 - accuracy: 0.8438 \n",
      "Batch 07146: setting learning rate to 0.00019985360415444197.\n",
      "  26/3560 [..............................] - ETA: 9:32 - loss: 0.5783 - accuracy: 0.8450\n",
      "Batch 07147: setting learning rate to 0.00019985341125816183.\n",
      "  27/3560 [..............................] - ETA: 9:18 - loss: 0.5886 - accuracy: 0.8438\n",
      "Batch 07148: setting learning rate to 0.0001998532182349751.\n",
      "  28/3560 [..............................] - ETA: 9:04 - loss: 0.6014 - accuracy: 0.8393\n",
      "Batch 07149: setting learning rate to 0.00019985302508488206.\n",
      "\n",
      "Batch 07150: setting learning rate to 0.00019985283180788295.\n",
      "  30/3560 [..............................] - ETA: 8:39 - loss: 0.6166 - accuracy: 0.8260\n",
      "Batch 07151: setting learning rate to 0.00019985263840397802.\n",
      "\n",
      "Batch 07152: setting learning rate to 0.00019985244487316748.\n",
      "  32/3560 [..............................] - ETA: 8:40 - loss: 0.6098 - accuracy: 0.8213\n",
      "Batch 07153: setting learning rate to 0.0001998522512154516.\n",
      "  33/3560 [..............................] - ETA: 10:06 - loss: 0.6110 - accuracy: 0.8182\n",
      "Batch 07154: setting learning rate to 0.00019985205743083064.\n",
      "  34/3560 [..............................] - ETA: 9:53 - loss: 0.6083 - accuracy: 0.8180 \n",
      "Batch 07155: setting learning rate to 0.0001998518635193048.\n",
      "\n",
      "Batch 07156: setting learning rate to 0.0001998516694808744.\n",
      "  36/3560 [..............................] - ETA: 9:30 - loss: 0.6124 - accuracy: 0.8186\n",
      "Batch 07157: setting learning rate to 0.0001998514753155396.\n",
      "  37/3560 [..............................] - ETA: 9:20 - loss: 0.6100 - accuracy: 0.8184\n",
      "Batch 07158: setting learning rate to 0.00019985128102330073.\n",
      "  38/3560 [..............................] - ETA: 9:10 - loss: 0.6118 - accuracy: 0.8207\n",
      "Batch 07159: setting learning rate to 0.00019985108660415798.\n",
      "\n",
      "Batch 07160: setting learning rate to 0.0001998508920581116.\n",
      "  40/3560 [..............................] - ETA: 8:53 - loss: 0.6126 - accuracy: 0.8227\n",
      "Batch 07161: setting learning rate to 0.00019985069738516189.\n",
      "  41/3560 [..............................] - ETA: 8:45 - loss: 0.6067 - accuracy: 0.8247\n",
      "Batch 07162: setting learning rate to 0.00019985050258530902.\n",
      "  42/3560 [..............................] - ETA: 8:37 - loss: 0.6060 - accuracy: 0.8259\n",
      "Batch 07163: setting learning rate to 0.00019985030765855332.\n",
      "  43/3560 [..............................] - ETA: 8:29 - loss: 0.6082 - accuracy: 0.8249\n",
      "Batch 07164: setting learning rate to 0.00019985011260489498.\n",
      "  44/3560 [..............................] - ETA: 8:21 - loss: 0.6022 - accuracy: 0.8267\n",
      "Batch 07165: setting learning rate to 0.00019984991742433425.\n",
      "\n",
      "Batch 07166: setting learning rate to 0.00019984972211687136.\n",
      "  46/3560 [..............................] - ETA: 8:11 - loss: 0.5940 - accuracy: 0.8268\n",
      "Batch 07167: setting learning rate to 0.00019984952668250663.\n",
      "\n",
      "Batch 07168: setting learning rate to 0.00019984933112124028.\n",
      "  48/3560 [..............................] - ETA: 8:23 - loss: 0.5976 - accuracy: 0.8281\n",
      "Batch 07169: setting learning rate to 0.00019984913543307252.\n",
      "  49/3560 [..............................] - ETA: 8:49 - loss: 0.6035 - accuracy: 0.8259\n",
      "Batch 07170: setting learning rate to 0.0001998489396180036.\n",
      "  50/3560 [..............................] - ETA: 8:48 - loss: 0.6069 - accuracy: 0.8244\n",
      "Batch 07171: setting learning rate to 0.00019984874367603387.\n",
      "  51/3560 [..............................] - ETA: 8:41 - loss: 0.6108 - accuracy: 0.8241\n",
      "Batch 07172: setting learning rate to 0.00019984854760716342.\n",
      "  52/3560 [..............................] - ETA: 8:35 - loss: 0.6068 - accuracy: 0.8251\n",
      "Batch 07173: setting learning rate to 0.00019984835141139264.\n",
      "  53/3560 [..............................] - ETA: 8:29 - loss: 0.6105 - accuracy: 0.8243\n",
      "Batch 07174: setting learning rate to 0.0001998481550887217.\n",
      "\n",
      "Batch 07175: setting learning rate to 0.0001998479586391509.\n",
      "  55/3560 [..............................] - ETA: 8:17 - loss: 0.6040 - accuracy: 0.8256\n",
      "Batch 07176: setting learning rate to 0.00019984776206268041.\n",
      "  56/3560 [..............................] - ETA: 8:12 - loss: 0.6049 - accuracy: 0.8253\n",
      "Batch 07177: setting learning rate to 0.00019984756535931054.\n",
      "  57/3560 [..............................] - ETA: 8:19 - loss: 0.6065 - accuracy: 0.8251\n",
      "Batch 07178: setting learning rate to 0.00019984736852904155.\n",
      "  58/3560 [..............................] - ETA: 8:13 - loss: 0.6039 - accuracy: 0.8254\n",
      "Batch 07179: setting learning rate to 0.00019984717157187366.\n",
      "  59/3560 [..............................] - ETA: 8:08 - loss: 0.6058 - accuracy: 0.8247\n",
      "Batch 07180: setting learning rate to 0.00019984697448780715.\n",
      "  60/3560 [..............................] - ETA: 8:03 - loss: 0.6079 - accuracy: 0.8240\n",
      "Batch 07181: setting learning rate to 0.00019984677727684225.\n",
      "  61/3560 [..............................] - ETA: 7:58 - loss: 0.6045 - accuracy: 0.8248\n",
      "Batch 07182: setting learning rate to 0.00019984657993897916.\n",
      "  62/3560 [..............................] - ETA: 7:53 - loss: 0.6054 - accuracy: 0.8241\n",
      "Batch 07183: setting learning rate to 0.00019984638247421823.\n",
      "\n",
      "Batch 07184: setting learning rate to 0.00019984618488255967.\n",
      "  64/3560 [..............................] - ETA: 8:08 - loss: 0.5990 - accuracy: 0.8247\n",
      "Batch 07185: setting learning rate to 0.0001998459871640037.\n",
      "  65/3560 [..............................] - ETA: 8:24 - loss: 0.5961 - accuracy: 0.8260\n",
      "Batch 07186: setting learning rate to 0.00019984578931855063.\n",
      "  66/3560 [..............................] - ETA: 8:24 - loss: 0.5956 - accuracy: 0.8267\n",
      "Batch 07187: setting learning rate to 0.00019984559134620064.\n",
      "  67/3560 [..............................] - ETA: 8:19 - loss: 0.5986 - accuracy: 0.8274\n",
      "Batch 07188: setting learning rate to 0.00019984539324695402.\n",
      "  68/3560 [..............................] - ETA: 8:15 - loss: 0.6047 - accuracy: 0.8263\n",
      "Batch 07189: setting learning rate to 0.00019984519502081103.\n",
      "  69/3560 [..............................] - ETA: 8:10 - loss: 0.6016 - accuracy: 0.8284\n",
      "Batch 07190: setting learning rate to 0.00019984499666777193.\n",
      "  70/3560 [..............................] - ETA: 8:06 - loss: 0.6003 - accuracy: 0.8286\n",
      "Batch 07191: setting learning rate to 0.00019984479818783694.\n",
      "\n",
      "Batch 07192: setting learning rate to 0.0001998445995810063.\n",
      "  72/3560 [..............................] - ETA: 7:57 - loss: 0.5994 - accuracy: 0.8268\n",
      "Batch 07193: setting learning rate to 0.00019984440084728033.\n",
      "\n",
      "Batch 07194: setting learning rate to 0.00019984420198665922.\n",
      "  74/3560 [..............................] - ETA: 7:48 - loss: 0.5978 - accuracy: 0.8260\n",
      "Batch 07195: setting learning rate to 0.00019984400299914324.\n",
      "\n",
      "Batch 07196: setting learning rate to 0.00019984380388473268.\n",
      "  76/3560 [..............................] - ETA: 7:40 - loss: 0.5981 - accuracy: 0.8257\n",
      "Batch 07197: setting learning rate to 0.00019984360464342775.\n",
      "  77/3560 [..............................] - ETA: 7:37 - loss: 0.5996 - accuracy: 0.8255\n",
      "Batch 07198: setting learning rate to 0.00019984340527522872.\n",
      "  78/3560 [..............................] - ETA: 7:33 - loss: 0.5983 - accuracy: 0.8257\n",
      "Batch 07199: setting learning rate to 0.00019984320578013583.\n",
      "\n",
      "Batch 07200: setting learning rate to 0.00019984300615814933.\n",
      "  80/3560 [..............................] - ETA: 7:49 - loss: 0.6001 - accuracy: 0.8234\n",
      "Batch 07201: setting learning rate to 0.00019984280640926948.\n",
      "  81/3560 [..............................] - ETA: 8:08 - loss: 0.6000 - accuracy: 0.8237\n",
      "Batch 07202: setting learning rate to 0.00019984260653349654.\n",
      "  82/3560 [..............................] - ETA: 8:04 - loss: 0.6005 - accuracy: 0.8228\n",
      "Batch 07203: setting learning rate to 0.00019984240653083077.\n",
      "  83/3560 [..............................] - ETA: 8:01 - loss: 0.5962 - accuracy: 0.8242\n",
      "Batch 07204: setting learning rate to 0.00019984220640127242.\n",
      "  84/3560 [..............................] - ETA: 7:57 - loss: 0.5970 - accuracy: 0.8240\n",
      "Batch 07205: setting learning rate to 0.00019984200614482175.\n",
      "  85/3560 [..............................] - ETA: 7:53 - loss: 0.5958 - accuracy: 0.8250\n",
      "Batch 07206: setting learning rate to 0.000199841805761479.\n",
      "  86/3560 [..............................] - ETA: 7:50 - loss: 0.6008 - accuracy: 0.8249\n",
      "Batch 07207: setting learning rate to 0.00019984160525124441.\n",
      "  87/3560 [..............................] - ETA: 7:47 - loss: 0.5988 - accuracy: 0.8261\n",
      "Batch 07208: setting learning rate to 0.00019984140461411828.\n",
      "  88/3560 [..............................] - ETA: 7:44 - loss: 0.5951 - accuracy: 0.8271\n",
      "Batch 07209: setting learning rate to 0.00019984120385010083.\n",
      "  89/3560 [..............................] - ETA: 7:41 - loss: 0.5932 - accuracy: 0.8283\n",
      "Batch 07210: setting learning rate to 0.00019984100295919233.\n",
      "  90/3560 [..............................] - ETA: 7:38 - loss: 0.5909 - accuracy: 0.8281\n",
      "Batch 07211: setting learning rate to 0.000199840801941393.\n",
      "  91/3560 [..............................] - ETA: 7:34 - loss: 0.5910 - accuracy: 0.8286\n",
      "Batch 07212: setting learning rate to 0.00019984060079670317.\n",
      "\n",
      "Batch 07213: setting learning rate to 0.00019984039952512304.\n",
      "  93/3560 [..............................] - ETA: 7:28 - loss: 0.5973 - accuracy: 0.8286\n",
      "Batch 07214: setting learning rate to 0.00019984019812665287.\n",
      "  94/3560 [..............................] - ETA: 7:25 - loss: 0.5966 - accuracy: 0.8285\n",
      "Batch 07215: setting learning rate to 0.00019983999660129294.\n",
      "  95/3560 [..............................] - ETA: 7:28 - loss: 0.5935 - accuracy: 0.8293\n",
      "Batch 07216: setting learning rate to 0.00019983979494904346.\n",
      "  96/3560 [..............................] - ETA: 7:45 - loss: 0.5960 - accuracy: 0.8301\n",
      "Batch 07217: setting learning rate to 0.00019983959316990474.\n",
      "  97/3560 [..............................] - ETA: 7:47 - loss: 0.5953 - accuracy: 0.8302\n",
      "Batch 07218: setting learning rate to 0.000199839391263877.\n",
      "  98/3560 [..............................] - ETA: 7:44 - loss: 0.5950 - accuracy: 0.8310\n",
      "Batch 07219: setting learning rate to 0.00019983918923096049.\n",
      "\n",
      "Batch 07220: setting learning rate to 0.00019983898707115553.\n",
      " 100/3560 [..............................] - ETA: 7:44 - loss: 0.5919 - accuracy: 0.8303\n",
      "Batch 07221: setting learning rate to 0.0001998387847844623.\n",
      " 101/3560 [..............................] - ETA: 7:41 - loss: 0.5925 - accuracy: 0.8314\n",
      "Batch 07222: setting learning rate to 0.0001998385823708811.\n",
      "\n",
      "Batch 07223: setting learning rate to 0.0001998383798304122.\n",
      " 103/3560 [..............................] - ETA: 7:37 - loss: 0.5947 - accuracy: 0.8304\n",
      "Batch 07224: setting learning rate to 0.0001998381771630558.\n",
      " 104/3560 [..............................] - ETA: 7:34 - loss: 0.5930 - accuracy: 0.8311\n",
      "Batch 07225: setting learning rate to 0.0001998379743688122.\n",
      " 105/3560 [..............................] - ETA: 7:31 - loss: 0.5930 - accuracy: 0.8315\n",
      "Batch 07226: setting learning rate to 0.00019983777144768166.\n",
      " 106/3560 [..............................] - ETA: 7:29 - loss: 0.5939 - accuracy: 0.8311\n",
      "Batch 07227: setting learning rate to 0.0001998375683996644.\n",
      " 107/3560 [..............................] - ETA: 7:26 - loss: 0.5924 - accuracy: 0.8315\n",
      "Batch 07228: setting learning rate to 0.00019983736522476074.\n",
      " 108/3560 [..............................] - ETA: 7:24 - loss: 0.5908 - accuracy: 0.8322\n",
      "Batch 07229: setting learning rate to 0.00019983716192297087.\n",
      " 109/3560 [..............................] - ETA: 7:21 - loss: 0.5884 - accuracy: 0.8331\n",
      "Batch 07230: setting learning rate to 0.00019983695849429514.\n",
      "\n",
      "Batch 07231: setting learning rate to 0.0001998367549387337.\n",
      " 111/3560 [..............................] - ETA: 7:25 - loss: 0.5866 - accuracy: 0.8333\n",
      "Batch 07232: setting learning rate to 0.00019983655125628688.\n",
      " 112/3560 [..............................] - ETA: 7:31 - loss: 0.5845 - accuracy: 0.8340\n",
      "Batch 07233: setting learning rate to 0.0001998363474469549.\n",
      " 113/3560 [..............................] - ETA: 7:36 - loss: 0.5883 - accuracy: 0.8330\n",
      "Batch 07234: setting learning rate to 0.00019983614351073804.\n",
      " 114/3560 [..............................] - ETA: 7:34 - loss: 0.5885 - accuracy: 0.8328\n",
      "Batch 07235: setting learning rate to 0.00019983593944763656.\n",
      " 115/3560 [..............................] - ETA: 7:32 - loss: 0.5882 - accuracy: 0.8329\n",
      "Batch 07236: setting learning rate to 0.00019983573525765073.\n",
      " 116/3560 [..............................] - ETA: 7:34 - loss: 0.5873 - accuracy: 0.8327\n",
      "Batch 07237: setting learning rate to 0.0001998355309407808.\n",
      " 117/3560 [..............................] - ETA: 7:32 - loss: 0.5863 - accuracy: 0.8328\n",
      "Batch 07238: setting learning rate to 0.00019983532649702702.\n",
      " 118/3560 [..............................] - ETA: 7:32 - loss: 0.5881 - accuracy: 0.8326\n",
      "Batch 07239: setting learning rate to 0.00019983512192638965.\n",
      "\n",
      "Batch 07240: setting learning rate to 0.00019983491722886895.\n",
      " 120/3560 [>.............................] - ETA: 7:27 - loss: 0.5829 - accuracy: 0.8349\n",
      "Batch 07241: setting learning rate to 0.0001998347124044652.\n",
      " 121/3560 [>.............................] - ETA: 7:25 - loss: 0.5820 - accuracy: 0.8357\n",
      "Batch 07242: setting learning rate to 0.00019983450745317862.\n",
      " 122/3560 [>.............................] - ETA: 7:22 - loss: 0.5795 - accuracy: 0.8363\n",
      "Batch 07243: setting learning rate to 0.0001998343023750095.\n",
      " 123/3560 [>.............................] - ETA: 7:20 - loss: 0.5795 - accuracy: 0.8364\n",
      "Batch 07244: setting learning rate to 0.0001998340971699581.\n",
      " 124/3560 [>.............................] - ETA: 7:18 - loss: 0.5792 - accuracy: 0.8362\n",
      "Batch 07245: setting learning rate to 0.0001998338918380247.\n",
      " 125/3560 [>.............................] - ETA: 7:16 - loss: 0.5789 - accuracy: 0.8360\n",
      "Batch 07246: setting learning rate to 0.0001998336863792095.\n",
      "\n",
      "Batch 07247: setting learning rate to 0.00019983348079351284.\n",
      " 127/3560 [>.............................] - ETA: 7:19 - loss: 0.5783 - accuracy: 0.8361\n",
      "Batch 07248: setting learning rate to 0.0001998332750809349.\n",
      " 128/3560 [>.............................] - ETA: 7:26 - loss: 0.5768 - accuracy: 0.8364\n",
      "Batch 07249: setting learning rate to 0.000199833069241476.\n",
      " 129/3560 [>.............................] - ETA: 7:24 - loss: 0.5760 - accuracy: 0.8360\n",
      "Batch 07250: setting learning rate to 0.00019983286327513643.\n",
      " 130/3560 [>.............................] - ETA: 7:24 - loss: 0.5766 - accuracy: 0.8363\n",
      "Batch 07251: setting learning rate to 0.00019983265718191633.\n",
      " 131/3560 [>.............................] - ETA: 7:22 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 07252: setting learning rate to 0.0001998324509618161.\n",
      " 132/3560 [>.............................] - ETA: 7:20 - loss: 0.5769 - accuracy: 0.8374\n",
      "Batch 07253: setting learning rate to 0.00019983224461483587.\n",
      "\n",
      "Batch 07254: setting learning rate to 0.00019983203814097605.\n",
      " 134/3560 [>.............................] - ETA: 7:18 - loss: 0.5776 - accuracy: 0.8368\n",
      "Batch 07255: setting learning rate to 0.00019983183154023676.\n",
      " 135/3560 [>.............................] - ETA: 7:18 - loss: 0.5789 - accuracy: 0.8368\n",
      "Batch 07256: setting learning rate to 0.00019983162481261837.\n",
      " 136/3560 [>.............................] - ETA: 7:17 - loss: 0.5786 - accuracy: 0.8366\n",
      "Batch 07257: setting learning rate to 0.00019983141795812105.\n",
      " 137/3560 [>.............................] - ETA: 7:18 - loss: 0.5790 - accuracy: 0.8367\n",
      "Batch 07258: setting learning rate to 0.00019983121097674517.\n",
      " 138/3560 [>.............................] - ETA: 7:17 - loss: 0.5792 - accuracy: 0.8367\n",
      "Batch 07259: setting learning rate to 0.00019983100386849093.\n",
      " 139/3560 [>.............................] - ETA: 7:17 - loss: 0.5821 - accuracy: 0.8361\n",
      "Batch 07260: setting learning rate to 0.00019983079663335858.\n",
      " 140/3560 [>.............................] - ETA: 7:15 - loss: 0.5823 - accuracy: 0.8350\n",
      "Batch 07261: setting learning rate to 0.0001998305892713484.\n",
      "\n",
      "Batch 07262: setting learning rate to 0.00019983038178246064.\n",
      " 142/3560 [>.............................] - ETA: 7:12 - loss: 0.5818 - accuracy: 0.8341\n",
      "Batch 07263: setting learning rate to 0.0001998301741666956.\n",
      " 143/3560 [>.............................] - ETA: 7:15 - loss: 0.5801 - accuracy: 0.8348\n",
      "Batch 07264: setting learning rate to 0.00019982996642405352.\n",
      " 144/3560 [>.............................] - ETA: 7:16 - loss: 0.5800 - accuracy: 0.8344\n",
      "Batch 07265: setting learning rate to 0.00019982975855453464.\n",
      " 145/3560 [>.............................] - ETA: 7:19 - loss: 0.5792 - accuracy: 0.8347\n",
      "Batch 07266: setting learning rate to 0.0001998295505581393.\n",
      " 146/3560 [>.............................] - ETA: 7:17 - loss: 0.5806 - accuracy: 0.8345\n",
      "Batch 07267: setting learning rate to 0.0001998293424348677.\n",
      " 147/3560 [>.............................] - ETA: 7:15 - loss: 0.5790 - accuracy: 0.8346\n",
      "Batch 07268: setting learning rate to 0.0001998291341847201.\n",
      " 148/3560 [>.............................] - ETA: 7:13 - loss: 0.5793 - accuracy: 0.8349\n",
      "Batch 07269: setting learning rate to 0.00019982892580769682.\n",
      " 149/3560 [>.............................] - ETA: 7:11 - loss: 0.5794 - accuracy: 0.8349\n",
      "Batch 07270: setting learning rate to 0.00019982871730379808.\n",
      " 150/3560 [>.............................] - ETA: 7:10 - loss: 0.5784 - accuracy: 0.8354\n",
      "Batch 07271: setting learning rate to 0.00019982850867302415.\n",
      " 151/3560 [>.............................] - ETA: 7:20 - loss: 0.5778 - accuracy: 0.8355\n",
      "Batch 07272: setting learning rate to 0.0001998282999153753.\n",
      " 152/3560 [>.............................] - ETA: 7:19 - loss: 0.5762 - accuracy: 0.8361\n",
      "Batch 07273: setting learning rate to 0.00019982809103085176.\n",
      " 153/3560 [>.............................] - ETA: 7:17 - loss: 0.5762 - accuracy: 0.8364\n",
      "Batch 07274: setting learning rate to 0.00019982788201945386.\n",
      " 154/3560 [>.............................] - ETA: 7:15 - loss: 0.5780 - accuracy: 0.8366\n",
      "Batch 07275: setting learning rate to 0.0001998276728811818.\n",
      " 155/3560 [>.............................] - ETA: 7:13 - loss: 0.5773 - accuracy: 0.8363\n",
      "Batch 07276: setting learning rate to 0.00019982746361603594.\n",
      "\n",
      "Batch 07277: setting learning rate to 0.00019982725422401648.\n",
      " 157/3560 [>.............................] - ETA: 7:12 - loss: 0.5784 - accuracy: 0.8364\n",
      "Batch 07278: setting learning rate to 0.0001998270447051237.\n",
      " 158/3560 [>.............................] - ETA: 7:10 - loss: 0.5781 - accuracy: 0.8362\n",
      "Batch 07279: setting learning rate to 0.00019982683505935782.\n",
      " 159/3560 [>.............................] - ETA: 7:09 - loss: 0.5799 - accuracy: 0.8357\n",
      "Batch 07280: setting learning rate to 0.0001998266252867192.\n",
      " 160/3560 [>.............................] - ETA: 7:09 - loss: 0.5790 - accuracy: 0.8361\n",
      "Batch 07281: setting learning rate to 0.00019982641538720798.\n",
      " 161/3560 [>.............................] - ETA: 7:14 - loss: 0.5799 - accuracy: 0.8364\n",
      "Batch 07282: setting learning rate to 0.00019982620536082457.\n",
      "\n",
      "Batch 07283: setting learning rate to 0.00019982599520756912.\n",
      " 163/3560 [>.............................] - ETA: 7:20 - loss: 0.5798 - accuracy: 0.8359\n",
      "Batch 07284: setting learning rate to 0.000199825784927442.\n",
      " 164/3560 [>.............................] - ETA: 7:19 - loss: 0.5798 - accuracy: 0.8354\n",
      "Batch 07285: setting learning rate to 0.00019982557452044336.\n",
      " 165/3560 [>.............................] - ETA: 7:17 - loss: 0.5796 - accuracy: 0.8354\n",
      "Batch 07286: setting learning rate to 0.00019982536398657357.\n",
      " 166/3560 [>.............................] - ETA: 7:15 - loss: 0.5806 - accuracy: 0.8341\n",
      "Batch 07287: setting learning rate to 0.00019982515332583284.\n",
      " 167/3560 [>.............................] - ETA: 7:16 - loss: 0.5814 - accuracy: 0.8344\n",
      "Batch 07288: setting learning rate to 0.00019982494253822147.\n",
      "\n",
      "Batch 07289: setting learning rate to 0.0001998247316237397.\n",
      " 169/3560 [>.............................] - ETA: 7:13 - loss: 0.5811 - accuracy: 0.8338\n",
      "Batch 07290: setting learning rate to 0.00019982452058238777.\n",
      "\n",
      "Batch 07291: setting learning rate to 0.00019982430941416606.\n",
      " 171/3560 [>.............................] - ETA: 7:09 - loss: 0.5818 - accuracy: 0.8341\n",
      "Batch 07292: setting learning rate to 0.00019982409811907474.\n",
      " 172/3560 [>.............................] - ETA: 7:08 - loss: 0.5825 - accuracy: 0.8343\n",
      "Batch 07293: setting learning rate to 0.0001998238866971141.\n",
      " 173/3560 [>.............................] - ETA: 7:06 - loss: 0.5821 - accuracy: 0.8338\n",
      "Batch 07294: setting learning rate to 0.0001998236751482844.\n",
      " 174/3560 [>.............................] - ETA: 7:05 - loss: 0.5811 - accuracy: 0.8341\n",
      "Batch 07295: setting learning rate to 0.00019982346347258593.\n",
      " 175/3560 [>.............................] - ETA: 7:04 - loss: 0.5807 - accuracy: 0.8341\n",
      "Batch 07296: setting learning rate to 0.00019982325167001896.\n",
      "\n",
      "Batch 07297: setting learning rate to 0.00019982303974058375.\n",
      " 177/3560 [>.............................] - ETA: 7:03 - loss: 0.5814 - accuracy: 0.8339\n",
      "Batch 07298: setting learning rate to 0.00019982282768428057.\n",
      " 178/3560 [>.............................] - ETA: 7:02 - loss: 0.5801 - accuracy: 0.8344\n",
      "Batch 07299: setting learning rate to 0.00019982261550110971.\n",
      " 179/3560 [>.............................] - ETA: 7:04 - loss: 0.5804 - accuracy: 0.8348\n",
      "Batch 07300: setting learning rate to 0.0001998224031910714.\n",
      " 180/3560 [>.............................] - ETA: 7:06 - loss: 0.5807 - accuracy: 0.8349\n",
      "Batch 07301: setting learning rate to 0.00019982219075416593.\n",
      "\n",
      "Batch 07302: setting learning rate to 0.00019982197819039358.\n",
      " 182/3560 [>.............................] - ETA: 7:03 - loss: 0.5809 - accuracy: 0.8345\n",
      "Batch 07303: setting learning rate to 0.0001998217654997546.\n",
      " 183/3560 [>.............................] - ETA: 7:04 - loss: 0.5799 - accuracy: 0.8345\n",
      "Batch 07304: setting learning rate to 0.00019982155268224926.\n",
      " 184/3560 [>.............................] - ETA: 7:03 - loss: 0.5797 - accuracy: 0.8353\n",
      "Batch 07305: setting learning rate to 0.00019982133973787787.\n",
      " 185/3560 [>.............................] - ETA: 7:06 - loss: 0.5792 - accuracy: 0.8353\n",
      "Batch 07306: setting learning rate to 0.00019982112666664065.\n",
      " 186/3560 [>.............................] - ETA: 7:09 - loss: 0.5803 - accuracy: 0.8348\n",
      "Batch 07307: setting learning rate to 0.00019982091346853787.\n",
      "\n",
      "Batch 07308: setting learning rate to 0.00019982070014356985.\n",
      " 188/3560 [>.............................] - ETA: 7:06 - loss: 0.5789 - accuracy: 0.8349\n",
      "Batch 07309: setting learning rate to 0.00019982048669173685.\n",
      " 189/3560 [>.............................] - ETA: 7:05 - loss: 0.5787 - accuracy: 0.8348\n",
      "Batch 07310: setting learning rate to 0.0001998202731130391.\n",
      " 190/3560 [>.............................] - ETA: 7:03 - loss: 0.5783 - accuracy: 0.8344\n",
      "Batch 07311: setting learning rate to 0.0001998200594074769.\n",
      " 191/3560 [>.............................] - ETA: 7:02 - loss: 0.5787 - accuracy: 0.8344\n",
      "Batch 07312: setting learning rate to 0.00019981984557505052.\n",
      " 192/3560 [>.............................] - ETA: 7:00 - loss: 0.5782 - accuracy: 0.8346\n",
      "Batch 07313: setting learning rate to 0.00019981963161576021.\n",
      "\n",
      "Batch 07314: setting learning rate to 0.0001998194175296063.\n",
      " 194/3560 [>.............................] - ETA: 6:58 - loss: 0.5791 - accuracy: 0.8341\n",
      "Batch 07315: setting learning rate to 0.00019981920331658902.\n",
      " 195/3560 [>.............................] - ETA: 7:04 - loss: 0.5792 - accuracy: 0.8343\n",
      "Batch 07316: setting learning rate to 0.00019981898897670862.\n",
      " 196/3560 [>.............................] - ETA: 7:03 - loss: 0.5808 - accuracy: 0.8345\n",
      "Batch 07317: setting learning rate to 0.00019981877450996543.\n",
      " 197/3560 [>.............................] - ETA: 7:02 - loss: 0.5819 - accuracy: 0.8344\n",
      "Batch 07318: setting learning rate to 0.00019981855991635966.\n",
      " 198/3560 [>.............................] - ETA: 7:03 - loss: 0.5817 - accuracy: 0.8344\n",
      "Batch 07319: setting learning rate to 0.0001998183451958916.\n",
      " 199/3560 [>.............................] - ETA: 7:03 - loss: 0.5824 - accuracy: 0.8339\n",
      "Batch 07320: setting learning rate to 0.0001998181303485616.\n",
      " 200/3560 [>.............................] - ETA: 7:02 - loss: 0.5817 - accuracy: 0.8341\n",
      "Batch 07321: setting learning rate to 0.00019981791537436984.\n",
      " 201/3560 [>.............................] - ETA: 7:03 - loss: 0.5817 - accuracy: 0.8336\n",
      "Batch 07322: setting learning rate to 0.0001998177002733166.\n",
      " 202/3560 [>.............................] - ETA: 7:02 - loss: 0.5832 - accuracy: 0.8332\n",
      "Batch 07323: setting learning rate to 0.0001998174850454022.\n",
      " 203/3560 [>.............................] - ETA: 7:01 - loss: 0.5826 - accuracy: 0.8334\n",
      "Batch 07324: setting learning rate to 0.0001998172696906269.\n",
      "\n",
      "Batch 07325: setting learning rate to 0.00019981705420899095.\n",
      " 205/3560 [>.............................] - ETA: 7:05 - loss: 0.5830 - accuracy: 0.8331\n",
      "Batch 07326: setting learning rate to 0.00019981683860049464.\n",
      " 206/3560 [>.............................] - ETA: 7:03 - loss: 0.5829 - accuracy: 0.8328\n",
      "Batch 07327: setting learning rate to 0.00019981662286513822.\n",
      " 207/3560 [>.............................] - ETA: 7:02 - loss: 0.5817 - accuracy: 0.8330\n",
      "Batch 07328: setting learning rate to 0.00019981640700292205.\n",
      " 208/3560 [>.............................] - ETA: 7:01 - loss: 0.5802 - accuracy: 0.8334\n",
      "Batch 07329: setting learning rate to 0.00019981619101384625.\n",
      "\n",
      "Batch 07330: setting learning rate to 0.00019981597489791123.\n",
      " 210/3560 [>.............................] - ETA: 6:58 - loss: 0.5782 - accuracy: 0.8339\n",
      "Batch 07331: setting learning rate to 0.00019981575865511724.\n",
      " 211/3560 [>.............................] - ETA: 6:57 - loss: 0.5799 - accuracy: 0.8335\n",
      "Batch 07332: setting learning rate to 0.00019981554228546452.\n",
      "\n",
      "Batch 07333: setting learning rate to 0.00019981532578895335.\n",
      " 213/3560 [>.............................] - ETA: 6:55 - loss: 0.5809 - accuracy: 0.8339\n",
      "Batch 07334: setting learning rate to 0.000199815109165584.\n",
      "\n",
      "Batch 07335: setting learning rate to 0.0001998148924153568.\n",
      " 215/3560 [>.............................] - ETA: 7:00 - loss: 0.5814 - accuracy: 0.8339\n",
      "Batch 07336: setting learning rate to 0.00019981467553827195.\n",
      " 216/3560 [>.............................] - ETA: 6:59 - loss: 0.5810 - accuracy: 0.8345\n",
      "Batch 07337: setting learning rate to 0.0001998144585343298.\n",
      " 217/3560 [>.............................] - ETA: 6:57 - loss: 0.5802 - accuracy: 0.8350\n",
      "Batch 07338: setting learning rate to 0.00019981424140353053.\n",
      " 218/3560 [>.............................] - ETA: 6:56 - loss: 0.5808 - accuracy: 0.8347\n",
      "Batch 07339: setting learning rate to 0.00019981402414587454.\n",
      " 219/3560 [>.............................] - ETA: 7:00 - loss: 0.5808 - accuracy: 0.8343\n",
      "Batch 07340: setting learning rate to 0.00019981380676136197.\n",
      " 220/3560 [>.............................] - ETA: 6:58 - loss: 0.5809 - accuracy: 0.8342\n",
      "Batch 07341: setting learning rate to 0.0001998135892499932.\n",
      " 221/3560 [>.............................] - ETA: 6:57 - loss: 0.5822 - accuracy: 0.8339\n",
      "Batch 07342: setting learning rate to 0.00019981337161176848.\n",
      "\n",
      "Batch 07343: setting learning rate to 0.00019981315384668807.\n",
      " 223/3560 [>.............................] - ETA: 6:56 - loss: 0.5820 - accuracy: 0.8337\n",
      "Batch 07344: setting learning rate to 0.00019981293595475226.\n",
      " 224/3560 [>.............................] - ETA: 6:55 - loss: 0.5825 - accuracy: 0.8333\n",
      "Batch 07345: setting learning rate to 0.0001998127179359613.\n",
      " 225/3560 [>.............................] - ETA: 6:53 - loss: 0.5823 - accuracy: 0.8335\n",
      "Batch 07346: setting learning rate to 0.0001998124997903155.\n",
      " 226/3560 [>.............................] - ETA: 6:52 - loss: 0.5821 - accuracy: 0.8335\n",
      "Batch 07347: setting learning rate to 0.0001998122815178151.\n",
      " 227/3560 [>.............................] - ETA: 6:56 - loss: 0.5818 - accuracy: 0.8334\n",
      "Batch 07348: setting learning rate to 0.00019981206311846047.\n",
      "\n",
      "Batch 07349: setting learning rate to 0.00019981184459225178.\n",
      " 229/3560 [>.............................] - ETA: 6:53 - loss: 0.5816 - accuracy: 0.8337\n",
      "Batch 07350: setting learning rate to 0.00019981162593918933.\n",
      " 230/3560 [>.............................] - ETA: 6:52 - loss: 0.5831 - accuracy: 0.8333\n",
      "Batch 07351: setting learning rate to 0.00019981140715927346.\n",
      " 231/3560 [>.............................] - ETA: 6:52 - loss: 0.5827 - accuracy: 0.8331\n",
      "Batch 07352: setting learning rate to 0.0001998111882525044.\n",
      " 232/3560 [>.............................] - ETA: 6:51 - loss: 0.5822 - accuracy: 0.8334\n",
      "Batch 07353: setting learning rate to 0.0001998109692188824.\n",
      " 233/3560 [>.............................] - ETA: 6:52 - loss: 0.5813 - accuracy: 0.8336\n",
      "Batch 07354: setting learning rate to 0.0001998107500584078.\n",
      " 234/3560 [>.............................] - ETA: 6:52 - loss: 0.5808 - accuracy: 0.8337\n",
      "Batch 07355: setting learning rate to 0.00019981053077108084.\n",
      " 235/3560 [>.............................] - ETA: 6:51 - loss: 0.5812 - accuracy: 0.8338\n",
      "Batch 07356: setting learning rate to 0.00019981031135690177.\n",
      " 236/3560 [>.............................] - ETA: 6:58 - loss: 0.5810 - accuracy: 0.8337\n",
      "Batch 07357: setting learning rate to 0.00019981009181587096.\n",
      " 237/3560 [>.............................] - ETA: 6:57 - loss: 0.5816 - accuracy: 0.8337\n",
      "Batch 07358: setting learning rate to 0.00019980987214798863.\n",
      " 238/3560 [=>............................] - ETA: 6:56 - loss: 0.5806 - accuracy: 0.8342\n",
      "Batch 07359: setting learning rate to 0.00019980965235325506.\n",
      " 239/3560 [=>............................] - ETA: 6:55 - loss: 0.5807 - accuracy: 0.8342\n",
      "Batch 07360: setting learning rate to 0.0001998094324316705.\n",
      " 240/3560 [=>............................] - ETA: 6:53 - loss: 0.5804 - accuracy: 0.8345\n",
      "Batch 07361: setting learning rate to 0.0001998092123832353.\n",
      " 241/3560 [=>............................] - ETA: 6:53 - loss: 0.5805 - accuracy: 0.8347\n",
      "Batch 07362: setting learning rate to 0.00019980899220794972.\n",
      " 242/3560 [=>............................] - ETA: 6:51 - loss: 0.5817 - accuracy: 0.8346\n",
      "Batch 07363: setting learning rate to 0.00019980877190581403.\n",
      "\n",
      "Batch 07364: setting learning rate to 0.00019980855147682847.\n",
      " 244/3560 [=>............................] - ETA: 6:49 - loss: 0.5814 - accuracy: 0.8347\n",
      "Batch 07365: setting learning rate to 0.00019980833092099335.\n",
      " 245/3560 [=>............................] - ETA: 6:48 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 07366: setting learning rate to 0.00019980811023830895.\n",
      "\n",
      "Batch 07367: setting learning rate to 0.0001998078894287756.\n",
      " 247/3560 [=>............................] - ETA: 6:50 - loss: 0.5794 - accuracy: 0.8357\n",
      "Batch 07368: setting learning rate to 0.0001998076684923935.\n",
      " 248/3560 [=>............................] - ETA: 6:49 - loss: 0.5804 - accuracy: 0.8356\n",
      "Batch 07369: setting learning rate to 0.00019980744742916295.\n",
      " 249/3560 [=>............................] - ETA: 6:48 - loss: 0.5810 - accuracy: 0.8356\n",
      "Batch 07370: setting learning rate to 0.0001998072262390843.\n",
      "\n",
      "Batch 07371: setting learning rate to 0.00019980700492215774.\n",
      " 251/3560 [=>............................] - ETA: 6:47 - loss: 0.5817 - accuracy: 0.8357\n",
      "Batch 07372: setting learning rate to 0.0001998067834783836.\n",
      " 252/3560 [=>............................] - ETA: 6:50 - loss: 0.5813 - accuracy: 0.8358\n",
      "Batch 07373: setting learning rate to 0.00019980656190776215.\n",
      " 253/3560 [=>............................] - ETA: 6:49 - loss: 0.5811 - accuracy: 0.8357\n",
      "Batch 07374: setting learning rate to 0.00019980634021029368.\n",
      "\n",
      "Batch 07375: setting learning rate to 0.00019980611838597845.\n",
      " 255/3560 [=>............................] - ETA: 6:49 - loss: 0.5818 - accuracy: 0.8349\n",
      "Batch 07376: setting learning rate to 0.00019980589643481676.\n",
      " 256/3560 [=>............................] - ETA: 6:48 - loss: 0.5823 - accuracy: 0.8347\n",
      "Batch 07377: setting learning rate to 0.0001998056743568089.\n",
      " 257/3560 [=>............................] - ETA: 6:49 - loss: 0.5829 - accuracy: 0.8346\n",
      "Batch 07378: setting learning rate to 0.00019980545215195515.\n",
      " 258/3560 [=>............................] - ETA: 6:49 - loss: 0.5831 - accuracy: 0.8342\n",
      "Batch 07379: setting learning rate to 0.00019980522982025574.\n",
      " 259/3560 [=>............................] - ETA: 6:48 - loss: 0.5824 - accuracy: 0.8343\n",
      "Batch 07380: setting learning rate to 0.00019980500736171104.\n",
      " 260/3560 [=>............................] - ETA: 6:47 - loss: 0.5840 - accuracy: 0.8341\n",
      "Batch 07381: setting learning rate to 0.00019980478477632125.\n",
      " 261/3560 [=>............................] - ETA: 6:48 - loss: 0.5837 - accuracy: 0.8341\n",
      "Batch 07382: setting learning rate to 0.00019980456206408672.\n",
      " 262/3560 [=>............................] - ETA: 6:47 - loss: 0.5836 - accuracy: 0.8342\n",
      "Batch 07383: setting learning rate to 0.0001998043392250077.\n",
      " 263/3560 [=>............................] - ETA: 6:46 - loss: 0.5831 - accuracy: 0.8342\n",
      "Batch 07384: setting learning rate to 0.00019980411625908446.\n",
      " 264/3560 [=>............................] - ETA: 6:45 - loss: 0.5825 - accuracy: 0.8343\n",
      "Batch 07385: setting learning rate to 0.00019980389316631733.\n",
      " 265/3560 [=>............................] - ETA: 6:48 - loss: 0.5825 - accuracy: 0.8341\n",
      "Batch 07386: setting learning rate to 0.00019980366994670653.\n",
      "\n",
      "Batch 07387: setting learning rate to 0.0001998034466002524.\n",
      " 267/3560 [=>............................] - ETA: 6:45 - loss: 0.5817 - accuracy: 0.8345\n",
      "Batch 07388: setting learning rate to 0.0001998032231269552.\n",
      " 268/3560 [=>............................] - ETA: 6:51 - loss: 0.5806 - accuracy: 0.8345\n",
      "Batch 07389: setting learning rate to 0.00019980299952681522.\n",
      " 269/3560 [=>............................] - ETA: 6:51 - loss: 0.5801 - accuracy: 0.8349\n",
      "Batch 07390: setting learning rate to 0.00019980277579983272.\n",
      " 270/3560 [=>............................] - ETA: 6:50 - loss: 0.5795 - accuracy: 0.8353\n",
      "Batch 07391: setting learning rate to 0.00019980255194600806.\n",
      " 271/3560 [=>............................] - ETA: 6:49 - loss: 0.5785 - accuracy: 0.8357\n",
      "Batch 07392: setting learning rate to 0.00019980232796534142.\n",
      "\n",
      "Batch 07393: setting learning rate to 0.00019980210385783312.\n",
      " 273/3560 [=>............................] - ETA: 6:48 - loss: 0.5772 - accuracy: 0.8364\n",
      "Batch 07394: setting learning rate to 0.0001998018796234835.\n",
      " 274/3560 [=>............................] - ETA: 6:47 - loss: 0.5773 - accuracy: 0.8367\n",
      "Batch 07395: setting learning rate to 0.00019980165526229277.\n",
      "\n",
      "Batch 07396: setting learning rate to 0.00019980143077426128.\n",
      " 276/3560 [=>............................] - ETA: 6:47 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 07397: setting learning rate to 0.00019980120615938928.\n",
      " 277/3560 [=>............................] - ETA: 6:46 - loss: 0.5764 - accuracy: 0.8373\n",
      "Batch 07398: setting learning rate to 0.00019980098141767703.\n",
      " 278/3560 [=>............................] - ETA: 6:45 - loss: 0.5756 - accuracy: 0.8376\n",
      "Batch 07399: setting learning rate to 0.00019980075654912487.\n",
      "\n",
      "Batch 07400: setting learning rate to 0.00019980053155373305.\n",
      " 280/3560 [=>............................] - ETA: 6:43 - loss: 0.5760 - accuracy: 0.8374\n",
      "Batch 07401: setting learning rate to 0.00019980030643150187.\n",
      " 281/3560 [=>............................] - ETA: 6:42 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 07402: setting learning rate to 0.0001998000811824316.\n",
      " 282/3560 [=>............................] - ETA: 6:43 - loss: 0.5766 - accuracy: 0.8368\n",
      "Batch 07403: setting learning rate to 0.00019979985580652256.\n",
      " 283/3560 [=>............................] - ETA: 6:43 - loss: 0.5775 - accuracy: 0.8365\n",
      "Batch 07404: setting learning rate to 0.000199799630303775.\n",
      "\n",
      "Batch 07405: setting learning rate to 0.00019979940467418925.\n",
      " 285/3560 [=>............................] - ETA: 6:43 - loss: 0.5766 - accuracy: 0.8365\n",
      "Batch 07406: setting learning rate to 0.00019979917891776557.\n",
      " 286/3560 [=>............................] - ETA: 6:42 - loss: 0.5767 - accuracy: 0.8364\n",
      "Batch 07407: setting learning rate to 0.00019979895303450423.\n",
      " 287/3560 [=>............................] - ETA: 6:42 - loss: 0.5763 - accuracy: 0.8365\n",
      "Batch 07408: setting learning rate to 0.0001997987270244055.\n",
      " 288/3560 [=>............................] - ETA: 6:42 - loss: 0.5787 - accuracy: 0.8359\n",
      "Batch 07409: setting learning rate to 0.00019979850088746974.\n",
      " 289/3560 [=>............................] - ETA: 6:44 - loss: 0.5790 - accuracy: 0.8357\n",
      "Batch 07410: setting learning rate to 0.00019979827462369718.\n",
      " 290/3560 [=>............................] - ETA: 6:43 - loss: 0.5796 - accuracy: 0.8355\n",
      "Batch 07411: setting learning rate to 0.00019979804823308815.\n",
      " 291/3560 [=>............................] - ETA: 6:42 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 07412: setting learning rate to 0.0001997978217156429.\n",
      " 292/3560 [=>............................] - ETA: 6:43 - loss: 0.5801 - accuracy: 0.8354\n",
      "Batch 07413: setting learning rate to 0.00019979759507136172.\n",
      "\n",
      "Batch 07414: setting learning rate to 0.00019979736830024491.\n",
      " 294/3560 [=>............................] - ETA: 6:42 - loss: 0.5816 - accuracy: 0.8348\n",
      "Batch 07415: setting learning rate to 0.00019979714140229277.\n",
      " 295/3560 [=>............................] - ETA: 6:42 - loss: 0.5812 - accuracy: 0.8350\n",
      "Batch 07416: setting learning rate to 0.00019979691437750557.\n",
      " 296/3560 [=>............................] - ETA: 6:41 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 07417: setting learning rate to 0.0001997966872258836.\n",
      " 297/3560 [=>............................] - ETA: 6:43 - loss: 0.5804 - accuracy: 0.8350\n",
      "Batch 07418: setting learning rate to 0.00019979645994742715.\n",
      " 298/3560 [=>............................] - ETA: 6:42 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 07419: setting learning rate to 0.00019979623254213653.\n",
      " 299/3560 [=>............................] - ETA: 6:41 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 07420: setting learning rate to 0.000199796005010012.\n",
      " 300/3560 [=>............................] - ETA: 6:42 - loss: 0.5799 - accuracy: 0.8352\n",
      "Batch 07421: setting learning rate to 0.00019979577735105384.\n",
      " 301/3560 [=>............................] - ETA: 6:41 - loss: 0.5804 - accuracy: 0.8351\n",
      "Batch 07422: setting learning rate to 0.00019979554956526236.\n",
      " 302/3560 [=>............................] - ETA: 6:40 - loss: 0.5797 - accuracy: 0.8351\n",
      "Batch 07423: setting learning rate to 0.00019979532165263788.\n",
      "\n",
      "Batch 07424: setting learning rate to 0.00019979509361318066.\n",
      " 304/3560 [=>............................] - ETA: 6:43 - loss: 0.5793 - accuracy: 0.8352\n",
      "Batch 07425: setting learning rate to 0.00019979486544689096.\n",
      " 305/3560 [=>............................] - ETA: 6:47 - loss: 0.5788 - accuracy: 0.8352\n",
      "Batch 07426: setting learning rate to 0.0001997946371537691.\n",
      " 306/3560 [=>............................] - ETA: 6:46 - loss: 0.5783 - accuracy: 0.8356\n",
      "Batch 07427: setting learning rate to 0.0001997944087338154.\n",
      " 307/3560 [=>............................] - ETA: 6:46 - loss: 0.5786 - accuracy: 0.8355\n",
      "Batch 07428: setting learning rate to 0.00019979418018703008.\n",
      " 308/3560 [=>............................] - ETA: 6:45 - loss: 0.5783 - accuracy: 0.8356\n",
      "Batch 07429: setting learning rate to 0.0001997939515134135.\n",
      " 309/3560 [=>............................] - ETA: 6:44 - loss: 0.5778 - accuracy: 0.8358\n",
      "Batch 07430: setting learning rate to 0.0001997937227129659.\n",
      " 310/3560 [=>............................] - ETA: 6:43 - loss: 0.5782 - accuracy: 0.8357\n",
      "Batch 07431: setting learning rate to 0.00019979349378568758.\n",
      " 311/3560 [=>............................] - ETA: 6:42 - loss: 0.5779 - accuracy: 0.8357\n",
      "Batch 07432: setting learning rate to 0.00019979326473157887.\n",
      " 312/3560 [=>............................] - ETA: 6:41 - loss: 0.5771 - accuracy: 0.8359\n",
      "Batch 07433: setting learning rate to 0.00019979303555064002.\n",
      " 313/3560 [=>............................] - ETA: 6:40 - loss: 0.5763 - accuracy: 0.8363\n",
      "Batch 07434: setting learning rate to 0.00019979280624287133.\n",
      " 314/3560 [=>............................] - ETA: 6:40 - loss: 0.5758 - accuracy: 0.8364\n",
      "Batch 07435: setting learning rate to 0.0001997925768082731.\n",
      " 315/3560 [=>............................] - ETA: 6:39 - loss: 0.5764 - accuracy: 0.8365\n",
      "Batch 07436: setting learning rate to 0.0001997923472468456.\n",
      " 316/3560 [=>............................] - ETA: 6:39 - loss: 0.5761 - accuracy: 0.8366\n",
      "Batch 07437: setting learning rate to 0.00019979211755858915.\n",
      "\n",
      "Batch 07438: setting learning rate to 0.00019979188774350406.\n",
      " 318/3560 [=>............................] - ETA: 6:39 - loss: 0.5765 - accuracy: 0.8372\n",
      "Batch 07439: setting learning rate to 0.00019979165780159054.\n",
      " 319/3560 [=>............................] - ETA: 6:38 - loss: 0.5775 - accuracy: 0.8368\n",
      "Batch 07440: setting learning rate to 0.00019979142773284898.\n",
      " 320/3560 [=>............................] - ETA: 6:42 - loss: 0.5779 - accuracy: 0.8367\n",
      "Batch 07441: setting learning rate to 0.0001997911975372796.\n",
      " 321/3560 [=>............................] - ETA: 6:41 - loss: 0.5778 - accuracy: 0.8368\n",
      "Batch 07442: setting learning rate to 0.00019979096721488274.\n",
      " 322/3560 [=>............................] - ETA: 6:41 - loss: 0.5773 - accuracy: 0.8368\n",
      "Batch 07443: setting learning rate to 0.00019979073676565866.\n",
      " 323/3560 [=>............................] - ETA: 6:40 - loss: 0.5780 - accuracy: 0.8362\n",
      "Batch 07444: setting learning rate to 0.00019979050618960765.\n",
      " 324/3560 [=>............................] - ETA: 6:43 - loss: 0.5798 - accuracy: 0.8357\n",
      "Batch 07445: setting learning rate to 0.00019979027548673006.\n",
      " 325/3560 [=>............................] - ETA: 6:42 - loss: 0.5803 - accuracy: 0.8355\n",
      "Batch 07446: setting learning rate to 0.0001997900446570261.\n",
      " 326/3560 [=>............................] - ETA: 6:41 - loss: 0.5801 - accuracy: 0.8355\n",
      "Batch 07447: setting learning rate to 0.00019978981370049614.\n",
      " 327/3560 [=>............................] - ETA: 6:40 - loss: 0.5794 - accuracy: 0.8356\n",
      "Batch 07448: setting learning rate to 0.0001997895826171404.\n",
      " 328/3560 [=>............................] - ETA: 6:40 - loss: 0.5790 - accuracy: 0.8359\n",
      "Batch 07449: setting learning rate to 0.00019978935140695924.\n",
      " 329/3560 [=>............................] - ETA: 6:39 - loss: 0.5789 - accuracy: 0.8358\n",
      "Batch 07450: setting learning rate to 0.00019978912006995292.\n",
      " 330/3560 [=>............................] - ETA: 6:38 - loss: 0.5799 - accuracy: 0.8350\n",
      "Batch 07451: setting learning rate to 0.00019978888860612174.\n",
      " 331/3560 [=>............................] - ETA: 6:37 - loss: 0.5800 - accuracy: 0.8347\n",
      "Batch 07452: setting learning rate to 0.000199788657015466.\n",
      " 332/3560 [=>............................] - ETA: 6:36 - loss: 0.5801 - accuracy: 0.8344\n",
      "Batch 07453: setting learning rate to 0.000199788425297986.\n",
      " 333/3560 [=>............................] - ETA: 6:36 - loss: 0.5800 - accuracy: 0.8345\n",
      "Batch 07454: setting learning rate to 0.00019978819345368198.\n",
      " 334/3560 [=>............................] - ETA: 6:39 - loss: 0.5806 - accuracy: 0.8343\n",
      "Batch 07455: setting learning rate to 0.00019978796148255432.\n",
      " 335/3560 [=>............................] - ETA: 6:39 - loss: 0.5805 - accuracy: 0.8342\n",
      "Batch 07456: setting learning rate to 0.00019978772938460324.\n",
      " 336/3560 [=>............................] - ETA: 6:38 - loss: 0.5797 - accuracy: 0.8346\n",
      "Batch 07457: setting learning rate to 0.00019978749715982908.\n",
      " 337/3560 [=>............................] - ETA: 6:37 - loss: 0.5792 - accuracy: 0.8347\n",
      "Batch 07458: setting learning rate to 0.00019978726480823214.\n",
      " 338/3560 [=>............................] - ETA: 6:38 - loss: 0.5792 - accuracy: 0.8349\n",
      "Batch 07459: setting learning rate to 0.00019978703232981267.\n",
      " 339/3560 [=>............................] - ETA: 6:39 - loss: 0.5784 - accuracy: 0.8350\n",
      "Batch 07460: setting learning rate to 0.000199786799724571.\n",
      "\n",
      "Batch 07461: setting learning rate to 0.00019978656699250742.\n",
      " 341/3560 [=>............................] - ETA: 6:39 - loss: 0.5789 - accuracy: 0.8345\n",
      "Batch 07462: setting learning rate to 0.00019978633413362225.\n",
      " 342/3560 [=>............................] - ETA: 6:38 - loss: 0.5786 - accuracy: 0.8347\n",
      "Batch 07463: setting learning rate to 0.00019978610114791573.\n",
      "\n",
      "Batch 07464: setting learning rate to 0.0001997858680353882.\n",
      " 344/3560 [=>............................] - ETA: 6:37 - loss: 0.5785 - accuracy: 0.8349\n",
      "Batch 07465: setting learning rate to 0.00019978563479603994.\n",
      "\n",
      "Batch 07466: setting learning rate to 0.00019978540142987126.\n",
      " 346/3560 [=>............................] - ETA: 6:35 - loss: 0.5781 - accuracy: 0.8349\n",
      "Batch 07467: setting learning rate to 0.00019978516793688243.\n",
      "\n",
      "Batch 07468: setting learning rate to 0.00019978493431707376.\n",
      " 348/3560 [=>............................] - ETA: 6:34 - loss: 0.5773 - accuracy: 0.8352\n",
      "Batch 07469: setting learning rate to 0.0001997847005704456.\n",
      " 349/3560 [=>............................] - ETA: 6:33 - loss: 0.5773 - accuracy: 0.8352\n",
      "Batch 07470: setting learning rate to 0.00019978446669699813.\n",
      "\n",
      "Batch 07471: setting learning rate to 0.00019978423269673175.\n",
      " 351/3560 [=>............................] - ETA: 6:34 - loss: 0.5773 - accuracy: 0.8350\n",
      "Batch 07472: setting learning rate to 0.0001997839985696467.\n",
      "\n",
      "Batch 07473: setting learning rate to 0.00019978376431574333.\n",
      " 353/3560 [=>............................] - ETA: 6:33 - loss: 0.5772 - accuracy: 0.8351\n",
      "Batch 07474: setting learning rate to 0.00019978352993502187.\n",
      " 354/3560 [=>............................] - ETA: 6:37 - loss: 0.5768 - accuracy: 0.8353\n",
      "Batch 07475: setting learning rate to 0.00019978329542748267.\n",
      " 355/3560 [=>............................] - ETA: 6:36 - loss: 0.5761 - accuracy: 0.8355\n",
      "Batch 07476: setting learning rate to 0.00019978306079312602.\n",
      "\n",
      "Batch 07477: setting learning rate to 0.00019978282603195222.\n",
      " 357/3560 [==>...........................] - ETA: 6:35 - loss: 0.5756 - accuracy: 0.8354\n",
      "Batch 07478: setting learning rate to 0.00019978259114396155.\n",
      " 358/3560 [==>...........................] - ETA: 6:34 - loss: 0.5753 - accuracy: 0.8355\n",
      "Batch 07479: setting learning rate to 0.0001997823561291543.\n",
      " 359/3560 [==>...........................] - ETA: 6:34 - loss: 0.5752 - accuracy: 0.8353\n",
      "Batch 07480: setting learning rate to 0.0001997821209875308.\n",
      " 360/3560 [==>...........................] - ETA: 6:33 - loss: 0.5759 - accuracy: 0.8353\n",
      "Batch 07481: setting learning rate to 0.00019978188571909136.\n",
      " 361/3560 [==>...........................] - ETA: 6:33 - loss: 0.5761 - accuracy: 0.8355\n",
      "Batch 07482: setting learning rate to 0.0001997816503238362.\n",
      " 362/3560 [==>...........................] - ETA: 6:35 - loss: 0.5773 - accuracy: 0.8355\n",
      "Batch 07483: setting learning rate to 0.00019978141480176572.\n",
      " 363/3560 [==>...........................] - ETA: 6:34 - loss: 0.5779 - accuracy: 0.8355\n",
      "Batch 07484: setting learning rate to 0.00019978117915288017.\n",
      " 364/3560 [==>...........................] - ETA: 6:33 - loss: 0.5787 - accuracy: 0.8355\n",
      "Batch 07485: setting learning rate to 0.00019978094337717983.\n",
      " 365/3560 [==>...........................] - ETA: 6:33 - loss: 0.5784 - accuracy: 0.8353\n",
      "Batch 07486: setting learning rate to 0.00019978070747466502.\n",
      " 366/3560 [==>...........................] - ETA: 6:32 - loss: 0.5787 - accuracy: 0.8351\n",
      "Batch 07487: setting learning rate to 0.00019978047144533605.\n",
      "\n",
      "Batch 07488: setting learning rate to 0.00019978023528919323.\n",
      " 368/3560 [==>...........................] - ETA: 6:32 - loss: 0.5780 - accuracy: 0.8352\n",
      "Batch 07489: setting learning rate to 0.00019977999900623684.\n",
      " 369/3560 [==>...........................] - ETA: 6:31 - loss: 0.5783 - accuracy: 0.8351\n",
      "Batch 07490: setting learning rate to 0.00019977976259646715.\n",
      " 370/3560 [==>...........................] - ETA: 6:34 - loss: 0.5787 - accuracy: 0.8352\n",
      "Batch 07491: setting learning rate to 0.00019977952605988454.\n",
      "\n",
      "Batch 07492: setting learning rate to 0.0001997792893964892.\n",
      " 372/3560 [==>...........................] - ETA: 6:34 - loss: 0.5783 - accuracy: 0.8353\n",
      "Batch 07493: setting learning rate to 0.00019977905260628153.\n",
      " 373/3560 [==>...........................] - ETA: 6:33 - loss: 0.5782 - accuracy: 0.8355\n",
      "Batch 07494: setting learning rate to 0.0001997788156892618.\n",
      " 374/3560 [==>...........................] - ETA: 6:33 - loss: 0.5777 - accuracy: 0.8357\n",
      "Batch 07495: setting learning rate to 0.0001997785786454303.\n",
      " 375/3560 [==>...........................] - ETA: 6:33 - loss: 0.5780 - accuracy: 0.8356\n",
      "Batch 07496: setting learning rate to 0.00019977834147478737.\n",
      " 376/3560 [==>...........................] - ETA: 6:32 - loss: 0.5782 - accuracy: 0.8355\n",
      "Batch 07497: setting learning rate to 0.00019977810417733322.\n",
      "\n",
      "Batch 07498: setting learning rate to 0.00019977786675306827.\n",
      " 378/3560 [==>...........................] - ETA: 6:30 - loss: 0.5775 - accuracy: 0.8356\n",
      "Batch 07499: setting learning rate to 0.0001997776292019927.\n",
      " 379/3560 [==>...........................] - ETA: 6:30 - loss: 0.5771 - accuracy: 0.8358\n",
      "Batch 07500: setting learning rate to 0.00019977739152410694.\n",
      "\n",
      "Batch 07501: setting learning rate to 0.00019977715371941116.\n",
      " 381/3560 [==>...........................] - ETA: 6:30 - loss: 0.5765 - accuracy: 0.8360\n",
      "Batch 07502: setting learning rate to 0.00019977691578790575.\n",
      " 382/3560 [==>...........................] - ETA: 6:29 - loss: 0.5762 - accuracy: 0.8360\n",
      "Batch 07503: setting learning rate to 0.00019977667772959104.\n",
      " 383/3560 [==>...........................] - ETA: 6:30 - loss: 0.5759 - accuracy: 0.8360\n",
      "Batch 07504: setting learning rate to 0.00019977643954446724.\n",
      " 384/3560 [==>...........................] - ETA: 6:30 - loss: 0.5787 - accuracy: 0.8360\n",
      "Batch 07505: setting learning rate to 0.00019977620123253468.\n",
      " 385/3560 [==>...........................] - ETA: 6:30 - loss: 0.5785 - accuracy: 0.8360\n",
      "Batch 07506: setting learning rate to 0.0001997759627937937.\n",
      " 386/3560 [==>...........................] - ETA: 6:33 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 07507: setting learning rate to 0.00019977572422824459.\n",
      " 387/3560 [==>...........................] - ETA: 6:32 - loss: 0.5792 - accuracy: 0.8354\n",
      "Batch 07508: setting learning rate to 0.00019977548553588764.\n",
      " 388/3560 [==>...........................] - ETA: 6:31 - loss: 0.5790 - accuracy: 0.8355\n",
      "Batch 07509: setting learning rate to 0.00019977524671672313.\n",
      " 389/3560 [==>...........................] - ETA: 6:31 - loss: 0.5795 - accuracy: 0.8355\n",
      "Batch 07510: setting learning rate to 0.00019977500777075143.\n",
      "\n",
      "Batch 07511: setting learning rate to 0.0001997747686979728.\n",
      " 391/3560 [==>...........................] - ETA: 6:30 - loss: 0.5798 - accuracy: 0.8353\n",
      "Batch 07512: setting learning rate to 0.00019977452949838752.\n",
      " 392/3560 [==>...........................] - ETA: 6:30 - loss: 0.5797 - accuracy: 0.8353\n",
      "Batch 07513: setting learning rate to 0.00019977429017199597.\n",
      " 393/3560 [==>...........................] - ETA: 6:29 - loss: 0.5804 - accuracy: 0.8350\n",
      "Batch 07514: setting learning rate to 0.00019977405071879839.\n",
      "\n",
      "Batch 07515: setting learning rate to 0.0001997738111387951.\n",
      " 395/3560 [==>...........................] - ETA: 6:30 - loss: 0.5806 - accuracy: 0.8347\n",
      "Batch 07516: setting learning rate to 0.00019977357143198638.\n",
      " 396/3560 [==>...........................] - ETA: 6:29 - loss: 0.5808 - accuracy: 0.8347\n",
      "Batch 07517: setting learning rate to 0.00019977333159837258.\n",
      " 397/3560 [==>...........................] - ETA: 6:28 - loss: 0.5806 - accuracy: 0.8346\n",
      "Batch 07518: setting learning rate to 0.00019977309163795402.\n",
      " 398/3560 [==>...........................] - ETA: 6:28 - loss: 0.5804 - accuracy: 0.8346\n",
      "Batch 07519: setting learning rate to 0.00019977285155073094.\n",
      " 399/3560 [==>...........................] - ETA: 6:27 - loss: 0.5799 - accuracy: 0.8348\n",
      "Batch 07520: setting learning rate to 0.00019977261133670364.\n",
      " 400/3560 [==>...........................] - ETA: 6:27 - loss: 0.5797 - accuracy: 0.8348\n",
      "Batch 07521: setting learning rate to 0.0001997723709958725.\n",
      " 401/3560 [==>...........................] - ETA: 6:27 - loss: 0.5793 - accuracy: 0.8350\n",
      "Batch 07522: setting learning rate to 0.0001997721305282378.\n",
      " 402/3560 [==>...........................] - ETA: 6:31 - loss: 0.5789 - accuracy: 0.8350\n",
      "Batch 07523: setting learning rate to 0.00019977188993379984.\n",
      " 403/3560 [==>...........................] - ETA: 6:30 - loss: 0.5798 - accuracy: 0.8349\n",
      "Batch 07524: setting learning rate to 0.00019977164921255888.\n",
      " 404/3560 [==>...........................] - ETA: 6:29 - loss: 0.5798 - accuracy: 0.8350\n",
      "Batch 07525: setting learning rate to 0.00019977140836451528.\n",
      " 405/3560 [==>...........................] - ETA: 6:29 - loss: 0.5803 - accuracy: 0.8349\n",
      "Batch 07526: setting learning rate to 0.00019977116738966935.\n",
      " 406/3560 [==>...........................] - ETA: 6:28 - loss: 0.5814 - accuracy: 0.8349\n",
      "Batch 07527: setting learning rate to 0.00019977092628802135.\n",
      " 407/3560 [==>...........................] - ETA: 6:27 - loss: 0.5809 - accuracy: 0.8350\n",
      "Batch 07528: setting learning rate to 0.00019977068505957162.\n",
      " 408/3560 [==>...........................] - ETA: 6:27 - loss: 0.5812 - accuracy: 0.8350\n",
      "Batch 07529: setting learning rate to 0.00019977044370432046.\n",
      " 409/3560 [==>...........................] - ETA: 6:26 - loss: 0.5814 - accuracy: 0.8350\n",
      "Batch 07530: setting learning rate to 0.00019977020222226817.\n",
      " 410/3560 [==>...........................] - ETA: 6:28 - loss: 0.5819 - accuracy: 0.8349\n",
      "Batch 07531: setting learning rate to 0.0001997699606134151.\n",
      "\n",
      "Batch 07532: setting learning rate to 0.00019976971887776147.\n",
      " 412/3560 [==>...........................] - ETA: 6:28 - loss: 0.5823 - accuracy: 0.8353\n",
      "Batch 07533: setting learning rate to 0.00019976947701530766.\n",
      " 413/3560 [==>...........................] - ETA: 6:28 - loss: 0.5828 - accuracy: 0.8354\n",
      "Batch 07534: setting learning rate to 0.00019976923502605396.\n",
      " 414/3560 [==>...........................] - ETA: 6:27 - loss: 0.5837 - accuracy: 0.8351\n",
      "Batch 07535: setting learning rate to 0.00019976899291000065.\n",
      " 415/3560 [==>...........................] - ETA: 6:26 - loss: 0.5845 - accuracy: 0.8346\n",
      "Batch 07536: setting learning rate to 0.0001997687506671481.\n",
      " 416/3560 [==>...........................] - ETA: 6:26 - loss: 0.5850 - accuracy: 0.8341\n",
      "Batch 07537: setting learning rate to 0.00019976850829749653.\n",
      " 417/3560 [==>...........................] - ETA: 6:26 - loss: 0.5854 - accuracy: 0.8339\n",
      "Batch 07538: setting learning rate to 0.00019976826580104634.\n",
      " 418/3560 [==>...........................] - ETA: 6:26 - loss: 0.5861 - accuracy: 0.8337\n",
      "Batch 07539: setting learning rate to 0.00019976802317779778.\n",
      " 419/3560 [==>...........................] - ETA: 6:26 - loss: 0.5864 - accuracy: 0.8332\n",
      "Batch 07540: setting learning rate to 0.00019976778042775115.\n",
      " 420/3560 [==>...........................] - ETA: 6:26 - loss: 0.5867 - accuracy: 0.8332\n",
      "Batch 07541: setting learning rate to 0.0001997675375509068.\n",
      " 421/3560 [==>...........................] - ETA: 6:26 - loss: 0.5868 - accuracy: 0.8331\n",
      "Batch 07542: setting learning rate to 0.00019976729454726502.\n",
      " 422/3560 [==>...........................] - ETA: 6:25 - loss: 0.5872 - accuracy: 0.8327\n",
      "Batch 07543: setting learning rate to 0.00019976705141682612.\n",
      " 423/3560 [==>...........................] - ETA: 6:24 - loss: 0.5870 - accuracy: 0.8326\n",
      "Batch 07544: setting learning rate to 0.0001997668081595904.\n",
      " 424/3560 [==>...........................] - ETA: 6:24 - loss: 0.5870 - accuracy: 0.8325\n",
      "Batch 07545: setting learning rate to 0.00019976656477555817.\n",
      " 425/3560 [==>...........................] - ETA: 6:24 - loss: 0.5871 - accuracy: 0.8325\n",
      "Batch 07546: setting learning rate to 0.00019976632126472978.\n",
      " 426/3560 [==>...........................] - ETA: 6:24 - loss: 0.5864 - accuracy: 0.8327\n",
      "Batch 07547: setting learning rate to 0.0001997660776271055.\n",
      " 427/3560 [==>...........................] - ETA: 6:24 - loss: 0.5861 - accuracy: 0.8328\n",
      "Batch 07548: setting learning rate to 0.0001997658338626856.\n",
      "\n",
      "Batch 07549: setting learning rate to 0.00019976558997147046.\n",
      " 429/3560 [==>...........................] - ETA: 6:24 - loss: 0.5868 - accuracy: 0.8330\n",
      "Batch 07550: setting learning rate to 0.0001997653459534604.\n",
      " 430/3560 [==>...........................] - ETA: 6:24 - loss: 0.5861 - accuracy: 0.8332\n",
      "Batch 07551: setting learning rate to 0.00019976510180865563.\n",
      " 431/3560 [==>...........................] - ETA: 6:23 - loss: 0.5859 - accuracy: 0.8334\n",
      "Batch 07552: setting learning rate to 0.0001997648575370566.\n",
      " 432/3560 [==>...........................] - ETA: 6:23 - loss: 0.5859 - accuracy: 0.8336\n",
      "Batch 07553: setting learning rate to 0.0001997646131386635.\n",
      " 433/3560 [==>...........................] - ETA: 6:23 - loss: 0.5863 - accuracy: 0.8333\n",
      "Batch 07554: setting learning rate to 0.00019976436861347666.\n",
      " 434/3560 [==>...........................] - ETA: 6:24 - loss: 0.5862 - accuracy: 0.8335\n",
      "Batch 07555: setting learning rate to 0.00019976412396149646.\n",
      " 435/3560 [==>...........................] - ETA: 6:24 - loss: 0.5856 - accuracy: 0.8338\n",
      "Batch 07556: setting learning rate to 0.00019976387918272317.\n",
      " 436/3560 [==>...........................] - ETA: 6:24 - loss: 0.5855 - accuracy: 0.8337\n",
      "Batch 07557: setting learning rate to 0.00019976363427715707.\n",
      " 437/3560 [==>...........................] - ETA: 6:24 - loss: 0.5849 - accuracy: 0.8340\n",
      "Batch 07558: setting learning rate to 0.00019976338924479855.\n",
      " 438/3560 [==>...........................] - ETA: 6:23 - loss: 0.5845 - accuracy: 0.8343\n",
      "Batch 07559: setting learning rate to 0.00019976314408564784.\n",
      " 439/3560 [==>...........................] - ETA: 6:23 - loss: 0.5856 - accuracy: 0.8341\n",
      "Batch 07560: setting learning rate to 0.0001997628987997053.\n",
      " 440/3560 [==>...........................] - ETA: 6:23 - loss: 0.5857 - accuracy: 0.8340\n",
      "Batch 07561: setting learning rate to 0.0001997626533869712.\n",
      "\n",
      "Batch 07562: setting learning rate to 0.00019976240784744587.\n",
      " 442/3560 [==>...........................] - ETA: 6:24 - loss: 0.5847 - accuracy: 0.8345\n",
      "Batch 07563: setting learning rate to 0.00019976216218112964.\n",
      " 443/3560 [==>...........................] - ETA: 6:23 - loss: 0.5843 - accuracy: 0.8347\n",
      "Batch 07564: setting learning rate to 0.00019976191638802285.\n",
      " 444/3560 [==>...........................] - ETA: 6:23 - loss: 0.5840 - accuracy: 0.8349\n",
      "Batch 07565: setting learning rate to 0.00019976167046812572.\n",
      " 445/3560 [==>...........................] - ETA: 6:22 - loss: 0.5836 - accuracy: 0.8350\n",
      "Batch 07566: setting learning rate to 0.00019976142442143865.\n",
      " 446/3560 [==>...........................] - ETA: 6:21 - loss: 0.5840 - accuracy: 0.8347\n",
      "Batch 07567: setting learning rate to 0.0001997611782479619.\n",
      "\n",
      "Batch 07568: setting learning rate to 0.0001997609319476958.\n",
      " 448/3560 [==>...........................] - ETA: 6:22 - loss: 0.5847 - accuracy: 0.8345\n",
      "Batch 07569: setting learning rate to 0.00019976068552064069.\n",
      " 449/3560 [==>...........................] - ETA: 6:21 - loss: 0.5847 - accuracy: 0.8346\n",
      "Batch 07570: setting learning rate to 0.00019976043896679686.\n",
      " 450/3560 [==>...........................] - ETA: 6:22 - loss: 0.5842 - accuracy: 0.8349\n",
      "Batch 07571: setting learning rate to 0.00019976019228616458.\n",
      " 451/3560 [==>...........................] - ETA: 6:22 - loss: 0.5842 - accuracy: 0.8350\n",
      "Batch 07572: setting learning rate to 0.00019975994547874427.\n",
      "\n",
      "Batch 07573: setting learning rate to 0.0001997596985445361.\n",
      " 453/3560 [==>...........................] - ETA: 6:20 - loss: 0.5841 - accuracy: 0.8348\n",
      "Batch 07574: setting learning rate to 0.0001997594514835405.\n",
      " 454/3560 [==>...........................] - ETA: 6:21 - loss: 0.5852 - accuracy: 0.8345\n",
      "Batch 07575: setting learning rate to 0.00019975920429575776.\n",
      "\n",
      "Batch 07576: setting learning rate to 0.0001997589569811882.\n",
      " 456/3560 [==>...........................] - ETA: 6:20 - loss: 0.5857 - accuracy: 0.8345\n",
      "Batch 07577: setting learning rate to 0.00019975870953983207.\n",
      " 457/3560 [==>...........................] - ETA: 6:20 - loss: 0.5857 - accuracy: 0.8345\n",
      "Batch 07578: setting learning rate to 0.00019975846197168974.\n",
      " 458/3560 [==>...........................] - ETA: 6:20 - loss: 0.5858 - accuracy: 0.8343\n",
      "Batch 07579: setting learning rate to 0.0001997582142767615.\n",
      " 459/3560 [==>...........................] - ETA: 6:21 - loss: 0.5861 - accuracy: 0.8342\n",
      "Batch 07580: setting learning rate to 0.00019975796645504772.\n",
      " 460/3560 [==>...........................] - ETA: 6:20 - loss: 0.5861 - accuracy: 0.8340\n",
      "Batch 07581: setting learning rate to 0.00019975771850654864.\n",
      " 461/3560 [==>...........................] - ETA: 6:19 - loss: 0.5857 - accuracy: 0.8341\n",
      "Batch 07582: setting learning rate to 0.00019975747043126461.\n",
      " 462/3560 [==>...........................] - ETA: 6:19 - loss: 0.5864 - accuracy: 0.8339\n",
      "Batch 07583: setting learning rate to 0.000199757222229196.\n",
      " 463/3560 [==>...........................] - ETA: 6:19 - loss: 0.5865 - accuracy: 0.8340\n",
      "Batch 07584: setting learning rate to 0.000199756973900343.\n",
      " 464/3560 [==>...........................] - ETA: 6:19 - loss: 0.5869 - accuracy: 0.8339\n",
      "Batch 07585: setting learning rate to 0.00019975672544470606.\n",
      " 465/3560 [==>...........................] - ETA: 6:19 - loss: 0.5870 - accuracy: 0.8337\n",
      "Batch 07586: setting learning rate to 0.00019975647686228535.\n",
      " 466/3560 [==>...........................] - ETA: 6:19 - loss: 0.5870 - accuracy: 0.8339\n",
      "Batch 07587: setting learning rate to 0.00019975622815308132.\n",
      " 467/3560 [==>...........................] - ETA: 6:19 - loss: 0.5868 - accuracy: 0.8339\n",
      "Batch 07588: setting learning rate to 0.00019975597931709424.\n",
      " 468/3560 [==>...........................] - ETA: 6:20 - loss: 0.5872 - accuracy: 0.8337\n",
      "Batch 07589: setting learning rate to 0.0001997557303543244.\n",
      " 469/3560 [==>...........................] - ETA: 6:19 - loss: 0.5875 - accuracy: 0.8338\n",
      "Batch 07590: setting learning rate to 0.00019975548126477215.\n",
      " 470/3560 [==>...........................] - ETA: 6:19 - loss: 0.5872 - accuracy: 0.8338\n",
      "Batch 07591: setting learning rate to 0.00019975523204843778.\n",
      "\n",
      "Batch 07592: setting learning rate to 0.00019975498270532162.\n",
      " 472/3560 [==>...........................] - ETA: 6:19 - loss: 0.5876 - accuracy: 0.8338\n",
      "Batch 07593: setting learning rate to 0.00019975473323542397.\n",
      "\n",
      "Batch 07594: setting learning rate to 0.0001997544836387452.\n",
      " 474/3560 [==>...........................] - ETA: 6:19 - loss: 0.5882 - accuracy: 0.8333\n",
      "Batch 07595: setting learning rate to 0.0001997542339152856.\n",
      " 475/3560 [===>..........................] - ETA: 6:18 - loss: 0.5881 - accuracy: 0.8332\n",
      "Batch 07596: setting learning rate to 0.00019975398406504543.\n",
      " 476/3560 [===>..........................] - ETA: 6:18 - loss: 0.5884 - accuracy: 0.8329\n",
      "Batch 07597: setting learning rate to 0.00019975373408802506.\n",
      " 477/3560 [===>..........................] - ETA: 6:17 - loss: 0.5881 - accuracy: 0.8329\n",
      "Batch 07598: setting learning rate to 0.00019975348398422482.\n",
      "\n",
      "Batch 07599: setting learning rate to 0.00019975323375364502.\n",
      " 479/3560 [===>..........................] - ETA: 6:19 - loss: 0.5883 - accuracy: 0.8329\n",
      "Batch 07600: setting learning rate to 0.00019975298339628593.\n",
      " 480/3560 [===>..........................] - ETA: 6:18 - loss: 0.5885 - accuracy: 0.8329\n",
      "Batch 07601: setting learning rate to 0.00019975273291214797.\n",
      "\n",
      "Batch 07602: setting learning rate to 0.00019975248230123135.\n",
      " 482/3560 [===>..........................] - ETA: 6:17 - loss: 0.5881 - accuracy: 0.8329\n",
      "Batch 07603: setting learning rate to 0.00019975223156353647.\n",
      " 483/3560 [===>..........................] - ETA: 6:18 - loss: 0.5880 - accuracy: 0.8328\n",
      "Batch 07604: setting learning rate to 0.0001997519806990636.\n",
      " 484/3560 [===>..........................] - ETA: 6:17 - loss: 0.5883 - accuracy: 0.8326\n",
      "Batch 07605: setting learning rate to 0.00019975172970781305.\n",
      "\n",
      "Batch 07606: setting learning rate to 0.00019975147858978514.\n",
      " 486/3560 [===>..........................] - ETA: 6:17 - loss: 0.5880 - accuracy: 0.8328\n",
      "Batch 07607: setting learning rate to 0.00019975122734498024.\n",
      " 487/3560 [===>..........................] - ETA: 6:16 - loss: 0.5879 - accuracy: 0.8330\n",
      "Batch 07608: setting learning rate to 0.00019975097597339865.\n",
      " 488/3560 [===>..........................] - ETA: 6:17 - loss: 0.5873 - accuracy: 0.8332\n",
      "Batch 07609: setting learning rate to 0.00019975072447504067.\n",
      " 489/3560 [===>..........................] - ETA: 6:17 - loss: 0.5875 - accuracy: 0.8334\n",
      "Batch 07610: setting learning rate to 0.0001997504728499066.\n",
      " 490/3560 [===>..........................] - ETA: 6:17 - loss: 0.5876 - accuracy: 0.8335\n",
      "Batch 07611: setting learning rate to 0.00019975022109799685.\n",
      " 491/3560 [===>..........................] - ETA: 6:19 - loss: 0.5874 - accuracy: 0.8335\n",
      "Batch 07612: setting learning rate to 0.00019974996921931165.\n",
      " 492/3560 [===>..........................] - ETA: 6:19 - loss: 0.5872 - accuracy: 0.8336\n",
      "Batch 07613: setting learning rate to 0.00019974971721385134.\n",
      " 493/3560 [===>..........................] - ETA: 6:18 - loss: 0.5876 - accuracy: 0.8335\n",
      "Batch 07614: setting learning rate to 0.00019974946508161622.\n",
      " 494/3560 [===>..........................] - ETA: 6:17 - loss: 0.5869 - accuracy: 0.8337\n",
      "Batch 07615: setting learning rate to 0.00019974921282260667.\n",
      "\n",
      "Batch 07616: setting learning rate to 0.00019974896043682298.\n",
      " 496/3560 [===>..........................] - ETA: 6:16 - loss: 0.5876 - accuracy: 0.8339\n",
      "Batch 07617: setting learning rate to 0.00019974870792426549.\n",
      " 497/3560 [===>..........................] - ETA: 6:16 - loss: 0.5881 - accuracy: 0.8339\n",
      "Batch 07618: setting learning rate to 0.00019974845528493445.\n",
      " 498/3560 [===>..........................] - ETA: 6:16 - loss: 0.5887 - accuracy: 0.8338\n",
      "Batch 07619: setting learning rate to 0.0001997482025188303.\n",
      " 499/3560 [===>..........................] - ETA: 6:15 - loss: 0.5884 - accuracy: 0.8338\n",
      "Batch 07620: setting learning rate to 0.00019974794962595321.\n",
      "\n",
      "Batch 07621: setting learning rate to 0.00019974769660630363.\n",
      " 501/3560 [===>..........................] - ETA: 6:14 - loss: 0.5881 - accuracy: 0.8339\n",
      "Batch 07622: setting learning rate to 0.00019974744345988184.\n",
      " 502/3560 [===>..........................] - ETA: 6:14 - loss: 0.5879 - accuracy: 0.8339\n",
      "Batch 07623: setting learning rate to 0.00019974719018668816.\n",
      " 503/3560 [===>..........................] - ETA: 6:14 - loss: 0.5878 - accuracy: 0.8339\n",
      "Batch 07624: setting learning rate to 0.0001997469367867229.\n",
      " 504/3560 [===>..........................] - ETA: 6:16 - loss: 0.5876 - accuracy: 0.8340\n",
      "Batch 07625: setting learning rate to 0.0001997466832599864.\n",
      " 505/3560 [===>..........................] - ETA: 6:16 - loss: 0.5872 - accuracy: 0.8340\n",
      "Batch 07626: setting learning rate to 0.00019974642960647897.\n",
      " 506/3560 [===>..........................] - ETA: 6:15 - loss: 0.5871 - accuracy: 0.8341\n",
      "Batch 07627: setting learning rate to 0.00019974617582620092.\n",
      " 507/3560 [===>..........................] - ETA: 6:15 - loss: 0.5867 - accuracy: 0.8341\n",
      "Batch 07628: setting learning rate to 0.0001997459219191526.\n",
      " 508/3560 [===>..........................] - ETA: 6:14 - loss: 0.5862 - accuracy: 0.8343\n",
      "Batch 07629: setting learning rate to 0.00019974566788533436.\n",
      " 509/3560 [===>..........................] - ETA: 6:15 - loss: 0.5860 - accuracy: 0.8343\n",
      "Batch 07630: setting learning rate to 0.00019974541372474644.\n",
      " 510/3560 [===>..........................] - ETA: 6:15 - loss: 0.5864 - accuracy: 0.8340\n",
      "Batch 07631: setting learning rate to 0.00019974515943738921.\n",
      " 511/3560 [===>..........................] - ETA: 6:15 - loss: 0.5865 - accuracy: 0.8338\n",
      "Batch 07632: setting learning rate to 0.000199744905023263.\n",
      " 512/3560 [===>..........................] - ETA: 6:15 - loss: 0.5867 - accuracy: 0.8339\n",
      "Batch 07633: setting learning rate to 0.00019974465048236813.\n",
      " 513/3560 [===>..........................] - ETA: 6:14 - loss: 0.5873 - accuracy: 0.8337\n",
      "Batch 07634: setting learning rate to 0.0001997443958147049.\n",
      " 514/3560 [===>..........................] - ETA: 6:16 - loss: 0.5879 - accuracy: 0.8335\n",
      "Batch 07635: setting learning rate to 0.00019974414102027366.\n",
      " 515/3560 [===>..........................] - ETA: 6:15 - loss: 0.5881 - accuracy: 0.8335\n",
      "Batch 07636: setting learning rate to 0.00019974388609907476.\n",
      " 516/3560 [===>..........................] - ETA: 6:14 - loss: 0.5877 - accuracy: 0.8337\n",
      "Batch 07637: setting learning rate to 0.00019974363105110845.\n",
      " 517/3560 [===>..........................] - ETA: 6:14 - loss: 0.5875 - accuracy: 0.8337\n",
      "Batch 07638: setting learning rate to 0.00019974337587637508.\n",
      " 518/3560 [===>..........................] - ETA: 6:13 - loss: 0.5883 - accuracy: 0.8335\n",
      "Batch 07639: setting learning rate to 0.000199743120574875.\n",
      " 519/3560 [===>..........................] - ETA: 6:13 - loss: 0.5884 - accuracy: 0.8335\n",
      "Batch 07640: setting learning rate to 0.00019974286514660853.\n",
      " 520/3560 [===>..........................] - ETA: 6:13 - loss: 0.5887 - accuracy: 0.8334\n",
      "Batch 07641: setting learning rate to 0.00019974260959157602.\n",
      " 521/3560 [===>..........................] - ETA: 6:16 - loss: 0.5889 - accuracy: 0.8333\n",
      "Batch 07642: setting learning rate to 0.00019974235390977772.\n",
      " 522/3560 [===>..........................] - ETA: 6:16 - loss: 0.5891 - accuracy: 0.8332\n",
      "Batch 07643: setting learning rate to 0.00019974209810121401.\n",
      " 523/3560 [===>..........................] - ETA: 6:15 - loss: 0.5893 - accuracy: 0.8332\n",
      "Batch 07644: setting learning rate to 0.00019974184216588518.\n",
      " 524/3560 [===>..........................] - ETA: 6:15 - loss: 0.5888 - accuracy: 0.8333\n",
      "Batch 07645: setting learning rate to 0.00019974158610379158.\n",
      " 525/3560 [===>..........................] - ETA: 6:14 - loss: 0.5886 - accuracy: 0.8335\n",
      "Batch 07646: setting learning rate to 0.00019974132991493356.\n",
      " 526/3560 [===>..........................] - ETA: 6:14 - loss: 0.5890 - accuracy: 0.8334\n",
      "Batch 07647: setting learning rate to 0.0001997410735993114.\n",
      " 527/3560 [===>..........................] - ETA: 6:14 - loss: 0.5890 - accuracy: 0.8333\n",
      "Batch 07648: setting learning rate to 0.00019974081715692544.\n",
      " 528/3560 [===>..........................] - ETA: 6:14 - loss: 0.5889 - accuracy: 0.8332\n",
      "Batch 07649: setting learning rate to 0.00019974056058777605.\n",
      " 529/3560 [===>..........................] - ETA: 6:13 - loss: 0.5887 - accuracy: 0.8332\n",
      "Batch 07650: setting learning rate to 0.00019974030389186348.\n",
      "\n",
      "Batch 07651: setting learning rate to 0.0001997400470691881.\n",
      " 531/3560 [===>..........................] - ETA: 6:12 - loss: 0.5881 - accuracy: 0.8335\n",
      "Batch 07652: setting learning rate to 0.0001997397901197502.\n",
      " 532/3560 [===>..........................] - ETA: 6:13 - loss: 0.5882 - accuracy: 0.8333\n",
      "Batch 07653: setting learning rate to 0.00019973953304355018.\n",
      " 533/3560 [===>..........................] - ETA: 6:13 - loss: 0.5876 - accuracy: 0.8335\n",
      "Batch 07654: setting learning rate to 0.0001997392758405883.\n",
      " 534/3560 [===>..........................] - ETA: 6:12 - loss: 0.5869 - accuracy: 0.8337\n",
      "Batch 07655: setting learning rate to 0.0001997390185108649.\n",
      "\n",
      "Batch 07656: setting learning rate to 0.00019973876105438033.\n",
      " 536/3560 [===>..........................] - ETA: 6:13 - loss: 0.5872 - accuracy: 0.8338\n",
      "Batch 07657: setting learning rate to 0.0001997385034711349.\n",
      " 537/3560 [===>..........................] - ETA: 6:13 - loss: 0.5868 - accuracy: 0.8340\n",
      "Batch 07658: setting learning rate to 0.00019973824576112893.\n",
      " 538/3560 [===>..........................] - ETA: 6:12 - loss: 0.5865 - accuracy: 0.8342\n",
      "Batch 07659: setting learning rate to 0.00019973798792436275.\n",
      "\n",
      "Batch 07660: setting learning rate to 0.00019973772996083672.\n",
      " 540/3560 [===>..........................] - ETA: 6:12 - loss: 0.5866 - accuracy: 0.8342\n",
      "Batch 07661: setting learning rate to 0.00019973747187055114.\n",
      " 541/3560 [===>..........................] - ETA: 6:11 - loss: 0.5861 - accuracy: 0.8343\n",
      "Batch 07662: setting learning rate to 0.00019973721365350633.\n",
      " 542/3560 [===>..........................] - ETA: 6:13 - loss: 0.5857 - accuracy: 0.8344\n",
      "Batch 07663: setting learning rate to 0.00019973695530970265.\n",
      " 543/3560 [===>..........................] - ETA: 6:13 - loss: 0.5854 - accuracy: 0.8345\n",
      "Batch 07664: setting learning rate to 0.00019973669683914037.\n",
      " 544/3560 [===>..........................] - ETA: 6:13 - loss: 0.5851 - accuracy: 0.8346\n",
      "Batch 07665: setting learning rate to 0.0001997364382418199.\n",
      "\n",
      "Batch 07666: setting learning rate to 0.0001997361795177415.\n",
      " 546/3560 [===>..........................] - ETA: 6:12 - loss: 0.5855 - accuracy: 0.8342\n",
      "Batch 07667: setting learning rate to 0.00019973592066690552.\n",
      " 547/3560 [===>..........................] - ETA: 6:11 - loss: 0.5849 - accuracy: 0.8346\n",
      "Batch 07668: setting learning rate to 0.0001997356616893123.\n",
      " 548/3560 [===>..........................] - ETA: 6:11 - loss: 0.5851 - accuracy: 0.8346\n",
      "Batch 07669: setting learning rate to 0.00019973540258496218.\n",
      " 549/3560 [===>..........................] - ETA: 6:10 - loss: 0.5848 - accuracy: 0.8348\n",
      "Batch 07670: setting learning rate to 0.00019973514335385544.\n",
      " 550/3560 [===>..........................] - ETA: 6:10 - loss: 0.5844 - accuracy: 0.8349\n",
      "Batch 07671: setting learning rate to 0.00019973488399599245.\n",
      " 551/3560 [===>..........................] - ETA: 6:09 - loss: 0.5847 - accuracy: 0.8348\n",
      "Batch 07672: setting learning rate to 0.00019973462451137355.\n",
      " 552/3560 [===>..........................] - ETA: 6:10 - loss: 0.5843 - accuracy: 0.8349\n",
      "Batch 07673: setting learning rate to 0.00019973436489999902.\n",
      " 553/3560 [===>..........................] - ETA: 6:10 - loss: 0.5842 - accuracy: 0.8350\n",
      "Batch 07674: setting learning rate to 0.00019973410516186923.\n",
      " 554/3560 [===>..........................] - ETA: 6:10 - loss: 0.5839 - accuracy: 0.8350\n",
      "Batch 07675: setting learning rate to 0.0001997338452969845.\n",
      "\n",
      "Batch 07676: setting learning rate to 0.00019973358530534516.\n",
      " 556/3560 [===>..........................] - ETA: 6:10 - loss: 0.5844 - accuracy: 0.8349\n",
      "Batch 07677: setting learning rate to 0.00019973332518695156.\n",
      " 557/3560 [===>..........................] - ETA: 6:10 - loss: 0.5853 - accuracy: 0.8346\n",
      "Batch 07678: setting learning rate to 0.000199733064941804.\n",
      " 558/3560 [===>..........................] - ETA: 6:12 - loss: 0.5853 - accuracy: 0.8345\n",
      "Batch 07679: setting learning rate to 0.00019973280456990283.\n",
      "\n",
      "Batch 07680: setting learning rate to 0.00019973254407124836.\n",
      " 560/3560 [===>..........................] - ETA: 6:11 - loss: 0.5853 - accuracy: 0.8345\n",
      "Batch 07681: setting learning rate to 0.00019973228344584093.\n",
      " 561/3560 [===>..........................] - ETA: 6:11 - loss: 0.5853 - accuracy: 0.8346\n",
      "Batch 07682: setting learning rate to 0.00019973202269368088.\n",
      " 562/3560 [===>..........................] - ETA: 6:10 - loss: 0.5856 - accuracy: 0.8344\n",
      "Batch 07683: setting learning rate to 0.00019973176181476852.\n",
      " 563/3560 [===>..........................] - ETA: 6:10 - loss: 0.5857 - accuracy: 0.8344\n",
      "Batch 07684: setting learning rate to 0.0001997315008091042.\n",
      " 564/3560 [===>..........................] - ETA: 6:09 - loss: 0.5855 - accuracy: 0.8343\n",
      "Batch 07685: setting learning rate to 0.0001997312396766883.\n",
      " 565/3560 [===>..........................] - ETA: 6:09 - loss: 0.5855 - accuracy: 0.8342\n",
      "Batch 07686: setting learning rate to 0.00019973097841752106.\n",
      " 566/3560 [===>..........................] - ETA: 6:08 - loss: 0.5854 - accuracy: 0.8342\n",
      "Batch 07687: setting learning rate to 0.00019973071703160286.\n",
      "\n",
      "Batch 07688: setting learning rate to 0.00019973045551893403.\n",
      " 568/3560 [===>..........................] - ETA: 6:09 - loss: 0.5852 - accuracy: 0.8340\n",
      "Batch 07689: setting learning rate to 0.00019973019387951491.\n",
      " 569/3560 [===>..........................] - ETA: 6:09 - loss: 0.5856 - accuracy: 0.8338\n",
      "Batch 07690: setting learning rate to 0.00019972993211334582.\n",
      " 570/3560 [===>..........................] - ETA: 6:08 - loss: 0.5862 - accuracy: 0.8338\n",
      "Batch 07691: setting learning rate to 0.00019972967022042706.\n",
      "\n",
      "Batch 07692: setting learning rate to 0.00019972940820075903.\n",
      " 572/3560 [===>..........................] - ETA: 6:09 - loss: 0.5864 - accuracy: 0.8338\n",
      "Batch 07693: setting learning rate to 0.000199729146054342.\n",
      " 573/3560 [===>..........................] - ETA: 6:09 - loss: 0.5859 - accuracy: 0.8339\n",
      "Batch 07694: setting learning rate to 0.00019972888378117634.\n",
      " 574/3560 [===>..........................] - ETA: 6:08 - loss: 0.5857 - accuracy: 0.8340\n",
      "Batch 07695: setting learning rate to 0.0001997286213812624.\n",
      " 575/3560 [===>..........................] - ETA: 6:10 - loss: 0.5862 - accuracy: 0.8339\n",
      "Batch 07696: setting learning rate to 0.00019972835885460048.\n",
      " 576/3560 [===>..........................] - ETA: 6:09 - loss: 0.5858 - accuracy: 0.8340\n",
      "Batch 07697: setting learning rate to 0.00019972809620119093.\n",
      " 577/3560 [===>..........................] - ETA: 6:11 - loss: 0.5856 - accuracy: 0.8340\n",
      "Batch 07698: setting learning rate to 0.00019972783342103406.\n",
      " 578/3560 [===>..........................] - ETA: 6:11 - loss: 0.5857 - accuracy: 0.8341\n",
      "Batch 07699: setting learning rate to 0.00019972757051413024.\n",
      " 579/3560 [===>..........................] - ETA: 6:10 - loss: 0.5859 - accuracy: 0.8340\n",
      "Batch 07700: setting learning rate to 0.00019972730748047976.\n",
      " 580/3560 [===>..........................] - ETA: 6:10 - loss: 0.5853 - accuracy: 0.8343\n",
      "Batch 07701: setting learning rate to 0.000199727044320083.\n",
      " 581/3560 [===>..........................] - ETA: 6:09 - loss: 0.5852 - accuracy: 0.8344\n",
      "Batch 07702: setting learning rate to 0.00019972678103294026.\n",
      " 582/3560 [===>..........................] - ETA: 6:09 - loss: 0.5861 - accuracy: 0.8341\n",
      "Batch 07703: setting learning rate to 0.0001997265176190519.\n",
      " 583/3560 [===>..........................] - ETA: 6:08 - loss: 0.5864 - accuracy: 0.8340\n",
      "Batch 07704: setting learning rate to 0.00019972625407841825.\n",
      " 584/3560 [===>..........................] - ETA: 6:08 - loss: 0.5862 - accuracy: 0.8342\n",
      "Batch 07705: setting learning rate to 0.0001997259904110396.\n",
      "\n",
      "Batch 07706: setting learning rate to 0.00019972572661691636.\n",
      " 586/3560 [===>..........................] - ETA: 6:07 - loss: 0.5861 - accuracy: 0.8342\n",
      "Batch 07707: setting learning rate to 0.00019972546269604884.\n",
      " 587/3560 [===>..........................] - ETA: 6:06 - loss: 0.5862 - accuracy: 0.8342\n",
      "Batch 07708: setting learning rate to 0.00019972519864843732.\n",
      " 588/3560 [===>..........................] - ETA: 6:06 - loss: 0.5858 - accuracy: 0.8344\n",
      "Batch 07709: setting learning rate to 0.00019972493447408224.\n",
      " 589/3560 [===>..........................] - ETA: 6:09 - loss: 0.5862 - accuracy: 0.8344\n",
      "Batch 07710: setting learning rate to 0.00019972467017298379.\n",
      " 590/3560 [===>..........................] - ETA: 6:09 - loss: 0.5865 - accuracy: 0.8344\n",
      "Batch 07711: setting learning rate to 0.00019972440574514245.\n",
      " 591/3560 [===>..........................] - ETA: 6:08 - loss: 0.5862 - accuracy: 0.8344\n",
      "Batch 07712: setting learning rate to 0.00019972414119055849.\n",
      " 592/3560 [===>..........................] - ETA: 6:08 - loss: 0.5862 - accuracy: 0.8344\n",
      "Batch 07713: setting learning rate to 0.00019972387650923226.\n",
      " 593/3560 [===>..........................] - ETA: 6:07 - loss: 0.5860 - accuracy: 0.8344\n",
      "Batch 07714: setting learning rate to 0.00019972361170116407.\n",
      " 594/3560 [====>.........................] - ETA: 6:07 - loss: 0.5860 - accuracy: 0.8344\n",
      "Batch 07715: setting learning rate to 0.0001997233467663543.\n",
      " 595/3560 [====>.........................] - ETA: 6:06 - loss: 0.5861 - accuracy: 0.8345\n",
      "Batch 07716: setting learning rate to 0.00019972308170480325.\n",
      " 596/3560 [====>.........................] - ETA: 6:06 - loss: 0.5864 - accuracy: 0.8342\n",
      "Batch 07717: setting learning rate to 0.00019972281651651125.\n",
      " 597/3560 [====>.........................] - ETA: 6:05 - loss: 0.5863 - accuracy: 0.8342\n",
      "Batch 07718: setting learning rate to 0.0001997225512014787.\n",
      " 598/3560 [====>.........................] - ETA: 6:05 - loss: 0.5862 - accuracy: 0.8341\n",
      "Batch 07719: setting learning rate to 0.00019972228575970585.\n",
      " 599/3560 [====>.........................] - ETA: 6:04 - loss: 0.5858 - accuracy: 0.8343\n",
      "Batch 07720: setting learning rate to 0.00019972202019119311.\n",
      " 600/3560 [====>.........................] - ETA: 6:04 - loss: 0.5858 - accuracy: 0.8342\n",
      "Batch 07721: setting learning rate to 0.0001997217544959408.\n",
      "\n",
      "Batch 07722: setting learning rate to 0.00019972148867394921.\n",
      " 602/3560 [====>.........................] - ETA: 6:03 - loss: 0.5854 - accuracy: 0.8341\n",
      "Batch 07723: setting learning rate to 0.00019972122272521876.\n",
      " 603/3560 [====>.........................] - ETA: 6:04 - loss: 0.5860 - accuracy: 0.8339\n",
      "Batch 07724: setting learning rate to 0.0001997209566497497.\n",
      " 604/3560 [====>.........................] - ETA: 6:04 - loss: 0.5864 - accuracy: 0.8337\n",
      "Batch 07725: setting learning rate to 0.00019972069044754242.\n",
      " 605/3560 [====>.........................] - ETA: 6:05 - loss: 0.5862 - accuracy: 0.8338\n",
      "Batch 07726: setting learning rate to 0.00019972042411859725.\n",
      " 606/3560 [====>.........................] - ETA: 6:05 - loss: 0.5872 - accuracy: 0.8337\n",
      "Batch 07727: setting learning rate to 0.00019972015766291454.\n",
      " 607/3560 [====>.........................] - ETA: 6:05 - loss: 0.5870 - accuracy: 0.8337\n",
      "Batch 07728: setting learning rate to 0.00019971989108049463.\n",
      " 608/3560 [====>.........................] - ETA: 6:05 - loss: 0.5871 - accuracy: 0.8336\n",
      "Batch 07729: setting learning rate to 0.0001997196243713378.\n",
      " 609/3560 [====>.........................] - ETA: 6:05 - loss: 0.5872 - accuracy: 0.8334\n",
      "Batch 07730: setting learning rate to 0.00019971935753544448.\n",
      " 610/3560 [====>.........................] - ETA: 6:06 - loss: 0.5869 - accuracy: 0.8336\n",
      "Batch 07731: setting learning rate to 0.00019971909057281496.\n",
      " 611/3560 [====>.........................] - ETA: 6:05 - loss: 0.5870 - accuracy: 0.8336\n",
      "Batch 07732: setting learning rate to 0.00019971882348344955.\n",
      " 612/3560 [====>.........................] - ETA: 6:05 - loss: 0.5871 - accuracy: 0.8336\n",
      "Batch 07733: setting learning rate to 0.00019971855626734866.\n",
      " 613/3560 [====>.........................] - ETA: 6:04 - loss: 0.5872 - accuracy: 0.8336\n",
      "Batch 07734: setting learning rate to 0.00019971828892451256.\n",
      " 614/3560 [====>.........................] - ETA: 6:04 - loss: 0.5874 - accuracy: 0.8336\n",
      "Batch 07735: setting learning rate to 0.00019971802145494162.\n",
      " 615/3560 [====>.........................] - ETA: 6:04 - loss: 0.5872 - accuracy: 0.8337\n",
      "Batch 07736: setting learning rate to 0.0001997177538586362.\n",
      " 616/3560 [====>.........................] - ETA: 6:03 - loss: 0.5867 - accuracy: 0.8338\n",
      "Batch 07737: setting learning rate to 0.0001997174861355966.\n",
      " 617/3560 [====>.........................] - ETA: 6:03 - loss: 0.5869 - accuracy: 0.8336\n",
      "Batch 07738: setting learning rate to 0.00019971721828582323.\n",
      "\n",
      "Batch 07739: setting learning rate to 0.00019971695030931633.\n",
      " 619/3560 [====>.........................] - ETA: 6:02 - loss: 0.5868 - accuracy: 0.8338\n",
      "Batch 07740: setting learning rate to 0.0001997166822060763.\n",
      "\n",
      "Batch 07741: setting learning rate to 0.0001997164139761035.\n",
      " 621/3560 [====>.........................] - ETA: 6:04 - loss: 0.5874 - accuracy: 0.8336\n",
      "Batch 07742: setting learning rate to 0.00019971614561939822.\n",
      " 622/3560 [====>.........................] - ETA: 6:03 - loss: 0.5874 - accuracy: 0.8336\n",
      "Batch 07743: setting learning rate to 0.00019971587713596084.\n",
      " 623/3560 [====>.........................] - ETA: 6:05 - loss: 0.5872 - accuracy: 0.8336\n",
      "Batch 07744: setting learning rate to 0.00019971560852579168.\n",
      " 624/3560 [====>.........................] - ETA: 6:05 - loss: 0.5871 - accuracy: 0.8336\n",
      "Batch 07745: setting learning rate to 0.00019971533978889108.\n",
      " 625/3560 [====>.........................] - ETA: 6:04 - loss: 0.5876 - accuracy: 0.8335\n",
      "Batch 07746: setting learning rate to 0.0001997150709252594.\n",
      " 626/3560 [====>.........................] - ETA: 6:04 - loss: 0.5880 - accuracy: 0.8334\n",
      "Batch 07747: setting learning rate to 0.00019971480193489697.\n",
      " 627/3560 [====>.........................] - ETA: 6:03 - loss: 0.5876 - accuracy: 0.8335\n",
      "Batch 07748: setting learning rate to 0.00019971453281780415.\n",
      " 628/3560 [====>.........................] - ETA: 6:03 - loss: 0.5873 - accuracy: 0.8336\n",
      "Batch 07749: setting learning rate to 0.00019971426357398125.\n",
      " 629/3560 [====>.........................] - ETA: 6:02 - loss: 0.5869 - accuracy: 0.8337\n",
      "Batch 07750: setting learning rate to 0.0001997139942034286.\n",
      " 630/3560 [====>.........................] - ETA: 6:02 - loss: 0.5865 - accuracy: 0.8337\n",
      "Batch 07751: setting learning rate to 0.0001997137247061466.\n",
      " 631/3560 [====>.........................] - ETA: 6:02 - loss: 0.5862 - accuracy: 0.8338\n",
      "Batch 07752: setting learning rate to 0.00019971345508213557.\n",
      " 632/3560 [====>.........................] - ETA: 6:01 - loss: 0.5864 - accuracy: 0.8338\n",
      "Batch 07753: setting learning rate to 0.00019971318533139584.\n",
      "\n",
      "Batch 07754: setting learning rate to 0.00019971291545392775.\n",
      " 634/3560 [====>.........................] - ETA: 6:00 - loss: 0.5860 - accuracy: 0.8340\n",
      "Batch 07755: setting learning rate to 0.00019971264544973164.\n",
      " 635/3560 [====>.........................] - ETA: 6:00 - loss: 0.5859 - accuracy: 0.8340\n",
      "Batch 07756: setting learning rate to 0.00019971237531880788.\n",
      "\n",
      "Batch 07757: setting learning rate to 0.0001997121050611568.\n",
      " 637/3560 [====>.........................] - ETA: 6:01 - loss: 0.5861 - accuracy: 0.8340\n",
      "Batch 07758: setting learning rate to 0.00019971183467677872.\n",
      " 638/3560 [====>.........................] - ETA: 6:00 - loss: 0.5860 - accuracy: 0.8340\n",
      "Batch 07759: setting learning rate to 0.00019971156416567402.\n",
      " 639/3560 [====>.........................] - ETA: 6:00 - loss: 0.5863 - accuracy: 0.8339\n",
      "Batch 07760: setting learning rate to 0.00019971129352784302.\n",
      " 640/3560 [====>.........................] - ETA: 6:00 - loss: 0.5864 - accuracy: 0.8339\n",
      "Batch 07761: setting learning rate to 0.0001997110227632861.\n",
      " 641/3560 [====>.........................] - ETA: 6:00 - loss: 0.5862 - accuracy: 0.8340\n",
      "Batch 07762: setting learning rate to 0.0001997107518720035.\n",
      " 642/3560 [====>.........................] - ETA: 6:00 - loss: 0.5858 - accuracy: 0.8341\n",
      "Batch 07763: setting learning rate to 0.00019971048085399572.\n",
      " 643/3560 [====>.........................] - ETA: 6:01 - loss: 0.5858 - accuracy: 0.8341\n",
      "Batch 07764: setting learning rate to 0.000199710209709263.\n",
      " 644/3560 [====>.........................] - ETA: 6:00 - loss: 0.5858 - accuracy: 0.8339\n",
      "Batch 07765: setting learning rate to 0.0001997099384378057.\n",
      " 645/3560 [====>.........................] - ETA: 6:01 - loss: 0.5853 - accuracy: 0.8342\n",
      "Batch 07766: setting learning rate to 0.0001997096670396242.\n",
      " 646/3560 [====>.........................] - ETA: 6:00 - loss: 0.5854 - accuracy: 0.8342\n",
      "Batch 07767: setting learning rate to 0.0001997093955147188.\n",
      " 647/3560 [====>.........................] - ETA: 6:00 - loss: 0.5851 - accuracy: 0.8344\n",
      "Batch 07768: setting learning rate to 0.00019970912386308985.\n",
      " 648/3560 [====>.........................] - ETA: 5:59 - loss: 0.5851 - accuracy: 0.8343\n",
      "Batch 07769: setting learning rate to 0.00019970885208473775.\n",
      " 649/3560 [====>.........................] - ETA: 5:59 - loss: 0.5848 - accuracy: 0.8344\n",
      "Batch 07770: setting learning rate to 0.00019970858017966277.\n",
      " 650/3560 [====>.........................] - ETA: 5:59 - loss: 0.5846 - accuracy: 0.8344\n",
      "Batch 07771: setting learning rate to 0.0001997083081478653.\n",
      " 651/3560 [====>.........................] - ETA: 5:58 - loss: 0.5853 - accuracy: 0.8344\n",
      "Batch 07772: setting learning rate to 0.0001997080359893457.\n",
      "\n",
      "Batch 07773: setting learning rate to 0.00019970776370410425.\n",
      " 653/3560 [====>.........................] - ETA: 5:59 - loss: 0.5855 - accuracy: 0.8345\n",
      "Batch 07774: setting learning rate to 0.00019970749129214136.\n",
      "\n",
      "Batch 07775: setting learning rate to 0.00019970721875345736.\n",
      " 655/3560 [====>.........................] - ETA: 5:58 - loss: 0.5856 - accuracy: 0.8345\n",
      "Batch 07776: setting learning rate to 0.00019970694608805256.\n",
      " 656/3560 [====>.........................] - ETA: 5:58 - loss: 0.5852 - accuracy: 0.8346\n",
      "Batch 07777: setting learning rate to 0.00019970667329592735.\n",
      " 657/3560 [====>.........................] - ETA: 5:57 - loss: 0.5852 - accuracy: 0.8346\n",
      "Batch 07778: setting learning rate to 0.00019970640037708212.\n",
      " 658/3560 [====>.........................] - ETA: 5:58 - loss: 0.5849 - accuracy: 0.8347\n",
      "Batch 07779: setting learning rate to 0.0001997061273315171.\n",
      "\n",
      "Batch 07780: setting learning rate to 0.0001997058541592327.\n",
      " 660/3560 [====>.........................] - ETA: 5:58 - loss: 0.5849 - accuracy: 0.8347\n",
      "Batch 07781: setting learning rate to 0.00019970558086022927.\n",
      " 661/3560 [====>.........................] - ETA: 5:58 - loss: 0.5848 - accuracy: 0.8346\n",
      "Batch 07782: setting learning rate to 0.00019970530743450716.\n",
      " 662/3560 [====>.........................] - ETA: 5:58 - loss: 0.5850 - accuracy: 0.8346\n",
      "Batch 07783: setting learning rate to 0.00019970503388206675.\n",
      " 663/3560 [====>.........................] - ETA: 5:58 - loss: 0.5852 - accuracy: 0.8344\n",
      "Batch 07784: setting learning rate to 0.00019970476020290828.\n",
      " 664/3560 [====>.........................] - ETA: 5:57 - loss: 0.5851 - accuracy: 0.8343\n",
      "Batch 07785: setting learning rate to 0.0001997044863970322.\n",
      " 665/3560 [====>.........................] - ETA: 5:57 - loss: 0.5850 - accuracy: 0.8342\n",
      "Batch 07786: setting learning rate to 0.00019970421246443882.\n",
      " 666/3560 [====>.........................] - ETA: 5:56 - loss: 0.5846 - accuracy: 0.8343\n",
      "Batch 07787: setting learning rate to 0.0001997039384051285.\n",
      " 667/3560 [====>.........................] - ETA: 5:56 - loss: 0.5846 - accuracy: 0.8342\n",
      "Batch 07788: setting learning rate to 0.00019970366421910156.\n",
      "\n",
      "Batch 07789: setting learning rate to 0.00019970338990635836.\n",
      " 669/3560 [====>.........................] - ETA: 5:55 - loss: 0.5842 - accuracy: 0.8341\n",
      "Batch 07790: setting learning rate to 0.00019970311546689928.\n",
      " 670/3560 [====>.........................] - ETA: 5:56 - loss: 0.5842 - accuracy: 0.8340\n",
      "Batch 07791: setting learning rate to 0.00019970284090072463.\n",
      " 671/3560 [====>.........................] - ETA: 5:55 - loss: 0.5841 - accuracy: 0.8342\n",
      "Batch 07792: setting learning rate to 0.0001997025662078348.\n",
      " 672/3560 [====>.........................] - ETA: 5:57 - loss: 0.5837 - accuracy: 0.8344\n",
      "Batch 07793: setting learning rate to 0.0001997022913882301.\n",
      " 673/3560 [====>.........................] - ETA: 5:56 - loss: 0.5839 - accuracy: 0.8343\n",
      "Batch 07794: setting learning rate to 0.00019970201644191088.\n",
      " 674/3560 [====>.........................] - ETA: 5:56 - loss: 0.5838 - accuracy: 0.8343\n",
      "Batch 07795: setting learning rate to 0.00019970174136887755.\n",
      " 675/3560 [====>.........................] - ETA: 5:56 - loss: 0.5833 - accuracy: 0.8344\n",
      "Batch 07796: setting learning rate to 0.00019970146616913033.\n",
      " 676/3560 [====>.........................] - ETA: 5:57 - loss: 0.5834 - accuracy: 0.8345\n",
      "Batch 07797: setting learning rate to 0.00019970119084266973.\n",
      " 677/3560 [====>.........................] - ETA: 5:56 - loss: 0.5831 - accuracy: 0.8347\n",
      "Batch 07798: setting learning rate to 0.00019970091538949598.\n",
      " 678/3560 [====>.........................] - ETA: 5:56 - loss: 0.5828 - accuracy: 0.8348\n",
      "Batch 07799: setting learning rate to 0.00019970063980960946.\n",
      " 679/3560 [====>.........................] - ETA: 5:55 - loss: 0.5827 - accuracy: 0.8347\n",
      "Batch 07800: setting learning rate to 0.00019970036410301057.\n",
      " 680/3560 [====>.........................] - ETA: 5:55 - loss: 0.5826 - accuracy: 0.8347\n",
      "Batch 07801: setting learning rate to 0.0001997000882696996.\n",
      " 681/3560 [====>.........................] - ETA: 5:55 - loss: 0.5824 - accuracy: 0.8349\n",
      "Batch 07802: setting learning rate to 0.00019969981230967695.\n",
      " 682/3560 [====>.........................] - ETA: 5:54 - loss: 0.5826 - accuracy: 0.8350\n",
      "Batch 07803: setting learning rate to 0.00019969953622294293.\n",
      "\n",
      "Batch 07804: setting learning rate to 0.0001996992600094979.\n",
      " 684/3560 [====>.........................] - ETA: 5:54 - loss: 0.5819 - accuracy: 0.8352\n",
      "Batch 07805: setting learning rate to 0.00019969898366934219.\n",
      " 685/3560 [====>.........................] - ETA: 5:53 - loss: 0.5820 - accuracy: 0.8352\n",
      "Batch 07806: setting learning rate to 0.0001996987072024762.\n",
      " 686/3560 [====>.........................] - ETA: 5:53 - loss: 0.5819 - accuracy: 0.8351\n",
      "Batch 07807: setting learning rate to 0.0001996984306089003.\n",
      "\n",
      "Batch 07808: setting learning rate to 0.0001996981538886147.\n",
      " 688/3560 [====>.........................] - ETA: 5:53 - loss: 0.5819 - accuracy: 0.8351\n",
      "Batch 07809: setting learning rate to 0.00019969787704161992.\n",
      " 689/3560 [====>.........................] - ETA: 5:54 - loss: 0.5818 - accuracy: 0.8350\n",
      "Batch 07810: setting learning rate to 0.00019969760006791626.\n",
      " 690/3560 [====>.........................] - ETA: 5:54 - loss: 0.5816 - accuracy: 0.8351\n",
      "Batch 07811: setting learning rate to 0.00019969732296750404.\n",
      " 691/3560 [====>.........................] - ETA: 5:54 - loss: 0.5815 - accuracy: 0.8352\n",
      "Batch 07812: setting learning rate to 0.0001996970457403836.\n",
      " 692/3560 [====>.........................] - ETA: 5:54 - loss: 0.5812 - accuracy: 0.8353\n",
      "Batch 07813: setting learning rate to 0.00019969676838655533.\n",
      " 693/3560 [====>.........................] - ETA: 5:54 - loss: 0.5811 - accuracy: 0.8353\n",
      "Batch 07814: setting learning rate to 0.00019969649090601958.\n",
      " 694/3560 [====>.........................] - ETA: 5:54 - loss: 0.5814 - accuracy: 0.8353\n",
      "Batch 07815: setting learning rate to 0.0001996962132987767.\n",
      " 695/3560 [====>.........................] - ETA: 5:55 - loss: 0.5820 - accuracy: 0.8353\n",
      "Batch 07816: setting learning rate to 0.00019969593556482703.\n",
      " 696/3560 [====>.........................] - ETA: 5:55 - loss: 0.5815 - accuracy: 0.8354\n",
      "Batch 07817: setting learning rate to 0.00019969565770417097.\n",
      " 697/3560 [====>.........................] - ETA: 5:54 - loss: 0.5819 - accuracy: 0.8352\n",
      "Batch 07818: setting learning rate to 0.00019969537971680878.\n",
      " 698/3560 [====>.........................] - ETA: 5:54 - loss: 0.5822 - accuracy: 0.8351\n",
      "Batch 07819: setting learning rate to 0.0001996951016027409.\n",
      " 699/3560 [====>.........................] - ETA: 5:53 - loss: 0.5821 - accuracy: 0.8351\n",
      "Batch 07820: setting learning rate to 0.00019969482336196762.\n",
      " 700/3560 [====>.........................] - ETA: 5:53 - loss: 0.5816 - accuracy: 0.8353\n",
      "Batch 07821: setting learning rate to 0.00019969454499448936.\n",
      " 701/3560 [====>.........................] - ETA: 5:53 - loss: 0.5823 - accuracy: 0.8350\n",
      "Batch 07822: setting learning rate to 0.0001996942665003064.\n",
      " 702/3560 [====>.........................] - ETA: 5:52 - loss: 0.5821 - accuracy: 0.8351\n",
      "Batch 07823: setting learning rate to 0.00019969398787941916.\n",
      " 703/3560 [====>.........................] - ETA: 5:52 - loss: 0.5816 - accuracy: 0.8352\n",
      "Batch 07824: setting learning rate to 0.00019969370913182797.\n",
      " 704/3560 [====>.........................] - ETA: 5:51 - loss: 0.5815 - accuracy: 0.8352\n",
      "Batch 07825: setting learning rate to 0.00019969343025753316.\n",
      "\n",
      "Batch 07826: setting learning rate to 0.00019969315125653513.\n",
      " 706/3560 [====>.........................] - ETA: 5:51 - loss: 0.5813 - accuracy: 0.8353\n",
      "Batch 07827: setting learning rate to 0.00019969287212883417.\n",
      " 707/3560 [====>.........................] - ETA: 5:52 - loss: 0.5820 - accuracy: 0.8352\n",
      "Batch 07828: setting learning rate to 0.00019969259287443069.\n",
      "\n",
      "Batch 07829: setting learning rate to 0.00019969231349332503.\n",
      " 709/3560 [====>.........................] - ETA: 5:52 - loss: 0.5821 - accuracy: 0.8352\n",
      "Batch 07830: setting learning rate to 0.00019969203398551756.\n",
      " 710/3560 [====>.........................] - ETA: 5:52 - loss: 0.5817 - accuracy: 0.8353\n",
      "Batch 07831: setting learning rate to 0.00019969175435100863.\n",
      " 711/3560 [====>.........................] - ETA: 5:51 - loss: 0.5819 - accuracy: 0.8352\n",
      "Batch 07832: setting learning rate to 0.00019969147458979855.\n",
      "\n",
      "Batch 07833: setting learning rate to 0.00019969119470188772.\n",
      " 713/3560 [=====>........................] - ETA: 5:51 - loss: 0.5820 - accuracy: 0.8351\n",
      "Batch 07834: setting learning rate to 0.00019969091468727653.\n",
      " 714/3560 [=====>........................] - ETA: 5:50 - loss: 0.5815 - accuracy: 0.8353\n",
      "Batch 07835: setting learning rate to 0.0001996906345459652.\n",
      "\n",
      "Batch 07836: setting learning rate to 0.00019969035427795426.\n",
      " 716/3560 [=====>........................] - ETA: 5:50 - loss: 0.5820 - accuracy: 0.8350\n",
      "Batch 07837: setting learning rate to 0.00019969007388324396.\n",
      " 717/3560 [=====>........................] - ETA: 5:50 - loss: 0.5819 - accuracy: 0.8350\n",
      "Batch 07838: setting learning rate to 0.0001996897933618347.\n",
      "\n",
      "Batch 07839: setting learning rate to 0.00019968951271372677.\n",
      " 719/3560 [=====>........................] - ETA: 5:50 - loss: 0.5822 - accuracy: 0.8350\n",
      "Batch 07840: setting learning rate to 0.00019968923193892062.\n",
      "\n",
      "Batch 07841: setting learning rate to 0.00019968895103741652.\n",
      " 721/3560 [=====>........................] - ETA: 5:49 - loss: 0.5820 - accuracy: 0.8349\n",
      "Batch 07842: setting learning rate to 0.0001996886700092149.\n",
      " 722/3560 [=====>........................] - ETA: 5:49 - loss: 0.5821 - accuracy: 0.8349\n",
      "Batch 07843: setting learning rate to 0.00019968838885431607.\n",
      " 723/3560 [=====>........................] - ETA: 5:50 - loss: 0.5821 - accuracy: 0.8348\n",
      "Batch 07844: setting learning rate to 0.0001996881075727204.\n",
      " 724/3560 [=====>........................] - ETA: 5:50 - loss: 0.5822 - accuracy: 0.8348\n",
      "Batch 07845: setting learning rate to 0.00019968782616442825.\n",
      " 725/3560 [=====>........................] - ETA: 5:50 - loss: 0.5819 - accuracy: 0.8348\n",
      "Batch 07846: setting learning rate to 0.00019968754462944.\n",
      " 726/3560 [=====>........................] - ETA: 5:50 - loss: 0.5820 - accuracy: 0.8346\n",
      "Batch 07847: setting learning rate to 0.00019968726296775598.\n",
      "\n",
      "Batch 07848: setting learning rate to 0.00019968698117937652.\n",
      " 728/3560 [=====>........................] - ETA: 5:49 - loss: 0.5817 - accuracy: 0.8349\n",
      "Batch 07849: setting learning rate to 0.00019968669926430203.\n",
      " 729/3560 [=====>........................] - ETA: 5:49 - loss: 0.5822 - accuracy: 0.8347\n",
      "Batch 07850: setting learning rate to 0.00019968641722253286.\n",
      " 730/3560 [=====>........................] - ETA: 5:49 - loss: 0.5823 - accuracy: 0.8348\n",
      "Batch 07851: setting learning rate to 0.00019968613505406935.\n",
      " 731/3560 [=====>........................] - ETA: 5:48 - loss: 0.5821 - accuracy: 0.8349\n",
      "Batch 07852: setting learning rate to 0.00019968585275891186.\n",
      "\n",
      "Batch 07853: setting learning rate to 0.00019968557033706077.\n",
      " 733/3560 [=====>........................] - ETA: 5:48 - loss: 0.5820 - accuracy: 0.8350\n",
      "Batch 07854: setting learning rate to 0.00019968528778851642.\n",
      " 734/3560 [=====>........................] - ETA: 5:48 - loss: 0.5825 - accuracy: 0.8348\n",
      "Batch 07855: setting learning rate to 0.00019968500511327917.\n",
      "\n",
      "Batch 07856: setting learning rate to 0.00019968472231134937.\n",
      " 736/3560 [=====>........................] - ETA: 5:47 - loss: 0.5823 - accuracy: 0.8349\n",
      "Batch 07857: setting learning rate to 0.0001996844393827274.\n",
      "\n",
      "Batch 07858: setting learning rate to 0.00019968415632741363.\n",
      " 738/3560 [=====>........................] - ETA: 5:47 - loss: 0.5825 - accuracy: 0.8348\n",
      "Batch 07859: setting learning rate to 0.00019968387314540838.\n",
      " 739/3560 [=====>........................] - ETA: 5:48 - loss: 0.5823 - accuracy: 0.8347\n",
      "Batch 07860: setting learning rate to 0.00019968358983671203.\n",
      " 740/3560 [=====>........................] - ETA: 5:48 - loss: 0.5824 - accuracy: 0.8348\n",
      "Batch 07861: setting learning rate to 0.00019968330640132494.\n",
      " 741/3560 [=====>........................] - ETA: 5:48 - loss: 0.5823 - accuracy: 0.8348\n",
      "Batch 07862: setting learning rate to 0.00019968302283924748.\n",
      " 742/3560 [=====>........................] - ETA: 5:48 - loss: 0.5822 - accuracy: 0.8348\n",
      "Batch 07863: setting learning rate to 0.00019968273915048004.\n",
      " 743/3560 [=====>........................] - ETA: 5:47 - loss: 0.5826 - accuracy: 0.8348\n",
      "Batch 07864: setting learning rate to 0.0001996824553350229.\n",
      " 744/3560 [=====>........................] - ETA: 5:47 - loss: 0.5826 - accuracy: 0.8349\n",
      "Batch 07865: setting learning rate to 0.00019968217139287647.\n",
      " 745/3560 [=====>........................] - ETA: 5:47 - loss: 0.5826 - accuracy: 0.8348\n",
      "Batch 07866: setting learning rate to 0.0001996818873240411.\n",
      " 746/3560 [=====>........................] - ETA: 5:47 - loss: 0.5827 - accuracy: 0.8349\n",
      "Batch 07867: setting learning rate to 0.00019968160312851716.\n",
      " 747/3560 [=====>........................] - ETA: 5:46 - loss: 0.5827 - accuracy: 0.8348\n",
      "Batch 07868: setting learning rate to 0.000199681318806305.\n",
      " 748/3560 [=====>........................] - ETA: 5:46 - loss: 0.5825 - accuracy: 0.8349\n",
      "Batch 07869: setting learning rate to 0.00019968103435740502.\n",
      "\n",
      "Batch 07870: setting learning rate to 0.0001996807497818175.\n",
      " 750/3560 [=====>........................] - ETA: 5:45 - loss: 0.5827 - accuracy: 0.8348\n",
      "Batch 07871: setting learning rate to 0.00019968046507954287.\n",
      " 751/3560 [=====>........................] - ETA: 5:46 - loss: 0.5830 - accuracy: 0.8347\n",
      "Batch 07872: setting learning rate to 0.00019968018025058148.\n",
      " 752/3560 [=====>........................] - ETA: 5:45 - loss: 0.5829 - accuracy: 0.8348\n",
      "Batch 07873: setting learning rate to 0.0001996798952949337.\n",
      "\n",
      "Batch 07874: setting learning rate to 0.00019967961021259987.\n",
      " 754/3560 [=====>........................] - ETA: 5:45 - loss: 0.5826 - accuracy: 0.8348\n",
      "Batch 07875: setting learning rate to 0.00019967932500358033.\n",
      " 755/3560 [=====>........................] - ETA: 5:46 - loss: 0.5825 - accuracy: 0.8349\n",
      "Batch 07876: setting learning rate to 0.00019967903966787548.\n",
      " 756/3560 [=====>........................] - ETA: 5:45 - loss: 0.5824 - accuracy: 0.8350\n",
      "Batch 07877: setting learning rate to 0.0001996787542054857.\n",
      " 757/3560 [=====>........................] - ETA: 5:46 - loss: 0.5823 - accuracy: 0.8350\n",
      "Batch 07878: setting learning rate to 0.0001996784686164113.\n",
      " 758/3560 [=====>........................] - ETA: 5:46 - loss: 0.5825 - accuracy: 0.8349\n",
      "Batch 07879: setting learning rate to 0.0001996781829006527.\n",
      "\n",
      "Batch 07880: setting learning rate to 0.0001996778970582102.\n",
      " 760/3560 [=====>........................] - ETA: 5:46 - loss: 0.5821 - accuracy: 0.8350\n",
      "Batch 07881: setting learning rate to 0.0001996776110890842.\n",
      " 761/3560 [=====>........................] - ETA: 5:46 - loss: 0.5820 - accuracy: 0.8350\n",
      "Batch 07882: setting learning rate to 0.0001996773249932751.\n",
      " 762/3560 [=====>........................] - ETA: 5:46 - loss: 0.5819 - accuracy: 0.8351\n",
      "Batch 07883: setting learning rate to 0.00019967703877078318.\n",
      " 763/3560 [=====>........................] - ETA: 5:45 - loss: 0.5822 - accuracy: 0.8351\n",
      "Batch 07884: setting learning rate to 0.00019967675242160885.\n",
      " 764/3560 [=====>........................] - ETA: 5:45 - loss: 0.5826 - accuracy: 0.8350\n",
      "Batch 07885: setting learning rate to 0.0001996764659457525.\n",
      " 765/3560 [=====>........................] - ETA: 5:44 - loss: 0.5825 - accuracy: 0.8350\n",
      "Batch 07886: setting learning rate to 0.00019967617934321446.\n",
      " 766/3560 [=====>........................] - ETA: 5:44 - loss: 0.5826 - accuracy: 0.8350\n",
      "Batch 07887: setting learning rate to 0.00019967589261399508.\n",
      " 767/3560 [=====>........................] - ETA: 5:44 - loss: 0.5827 - accuracy: 0.8350\n",
      "Batch 07888: setting learning rate to 0.00019967560575809477.\n",
      " 768/3560 [=====>........................] - ETA: 5:44 - loss: 0.5825 - accuracy: 0.8350\n",
      "Batch 07889: setting learning rate to 0.00019967531877551384.\n",
      "\n",
      "Batch 07890: setting learning rate to 0.0001996750316662527.\n",
      " 770/3560 [=====>........................] - ETA: 5:43 - loss: 0.5825 - accuracy: 0.8351\n",
      "Batch 07891: setting learning rate to 0.00019967474443031172.\n",
      " 771/3560 [=====>........................] - ETA: 5:43 - loss: 0.5823 - accuracy: 0.8352\n",
      "Batch 07892: setting learning rate to 0.00019967445706769118.\n",
      " 772/3560 [=====>........................] - ETA: 5:44 - loss: 0.5824 - accuracy: 0.8352\n",
      "Batch 07893: setting learning rate to 0.00019967416957839156.\n",
      " 773/3560 [=====>........................] - ETA: 5:44 - loss: 0.5825 - accuracy: 0.8352\n",
      "Batch 07894: setting learning rate to 0.00019967388196241313.\n",
      " 774/3560 [=====>........................] - ETA: 5:44 - loss: 0.5824 - accuracy: 0.8352\n",
      "Batch 07895: setting learning rate to 0.00019967359421975636.\n",
      " 775/3560 [=====>........................] - ETA: 5:44 - loss: 0.5829 - accuracy: 0.8351\n",
      "Batch 07896: setting learning rate to 0.00019967330635042152.\n",
      " 776/3560 [=====>........................] - ETA: 5:44 - loss: 0.5827 - accuracy: 0.8352\n",
      "Batch 07897: setting learning rate to 0.00019967301835440901.\n",
      " 777/3560 [=====>........................] - ETA: 5:44 - loss: 0.5826 - accuracy: 0.8351\n",
      "Batch 07898: setting learning rate to 0.00019967273023171922.\n",
      " 778/3560 [=====>........................] - ETA: 5:43 - loss: 0.5834 - accuracy: 0.8349\n",
      "Batch 07899: setting learning rate to 0.00019967244198235249.\n",
      " 779/3560 [=====>........................] - ETA: 5:43 - loss: 0.5834 - accuracy: 0.8349\n",
      "Batch 07900: setting learning rate to 0.00019967215360630917.\n",
      "\n",
      "Batch 07901: setting learning rate to 0.00019967186510358963.\n",
      " 781/3560 [=====>........................] - ETA: 5:42 - loss: 0.5834 - accuracy: 0.8348\n",
      "Batch 07902: setting learning rate to 0.0001996715764741943.\n",
      " 782/3560 [=====>........................] - ETA: 5:42 - loss: 0.5834 - accuracy: 0.8347\n",
      "Batch 07903: setting learning rate to 0.00019967128771812345.\n",
      " 783/3560 [=====>........................] - ETA: 5:43 - loss: 0.5833 - accuracy: 0.8347\n",
      "Batch 07904: setting learning rate to 0.00019967099883537754.\n",
      " 784/3560 [=====>........................] - ETA: 5:42 - loss: 0.5834 - accuracy: 0.8346\n",
      "Batch 07905: setting learning rate to 0.00019967070982595687.\n",
      " 785/3560 [=====>........................] - ETA: 5:42 - loss: 0.5832 - accuracy: 0.8346\n",
      "Batch 07906: setting learning rate to 0.00019967042068986184.\n",
      " 786/3560 [=====>........................] - ETA: 5:42 - loss: 0.5835 - accuracy: 0.8345\n",
      "Batch 07907: setting learning rate to 0.00019967013142709278.\n",
      "\n",
      "Batch 07908: setting learning rate to 0.00019966984203765014.\n",
      " 788/3560 [=====>........................] - ETA: 5:41 - loss: 0.5832 - accuracy: 0.8347\n",
      "Batch 07909: setting learning rate to 0.0001996695525215342.\n",
      " 789/3560 [=====>........................] - ETA: 5:42 - loss: 0.5829 - accuracy: 0.8348\n",
      "Batch 07910: setting learning rate to 0.00019966926287874536.\n",
      " 790/3560 [=====>........................] - ETA: 5:42 - loss: 0.5828 - accuracy: 0.8348\n",
      "Batch 07911: setting learning rate to 0.000199668973109284.\n",
      " 791/3560 [=====>........................] - ETA: 5:41 - loss: 0.5830 - accuracy: 0.8347\n",
      "Batch 07912: setting learning rate to 0.00019966868321315046.\n",
      " 792/3560 [=====>........................] - ETA: 5:41 - loss: 0.5827 - accuracy: 0.8348\n",
      "Batch 07913: setting learning rate to 0.00019966839319034515.\n",
      " 793/3560 [=====>........................] - ETA: 5:41 - loss: 0.5827 - accuracy: 0.8348\n",
      "Batch 07914: setting learning rate to 0.0001996681030408684.\n",
      " 794/3560 [=====>........................] - ETA: 5:41 - loss: 0.5826 - accuracy: 0.8348\n",
      "Batch 07915: setting learning rate to 0.00019966781276472062.\n",
      " 795/3560 [=====>........................] - ETA: 5:41 - loss: 0.5827 - accuracy: 0.8347\n",
      "Batch 07916: setting learning rate to 0.00019966752236190213.\n",
      " 796/3560 [=====>........................] - ETA: 5:40 - loss: 0.5829 - accuracy: 0.8348\n",
      "Batch 07917: setting learning rate to 0.00019966723183241332.\n",
      "\n",
      "Batch 07918: setting learning rate to 0.00019966694117625456.\n",
      " 798/3560 [=====>........................] - ETA: 5:40 - loss: 0.5826 - accuracy: 0.8349\n",
      "Batch 07919: setting learning rate to 0.00019966665039342622.\n",
      " 799/3560 [=====>........................] - ETA: 5:40 - loss: 0.5826 - accuracy: 0.8349\n",
      "Batch 07920: setting learning rate to 0.00019966635948392872.\n",
      " 800/3560 [=====>........................] - ETA: 5:40 - loss: 0.5827 - accuracy: 0.8349\n",
      "Batch 07921: setting learning rate to 0.00019966606844776233.\n",
      "\n",
      "Batch 07922: setting learning rate to 0.00019966577728492747.\n",
      " 802/3560 [=====>........................] - ETA: 5:39 - loss: 0.5829 - accuracy: 0.8348\n",
      "Batch 07923: setting learning rate to 0.0001996654859954245.\n",
      " 803/3560 [=====>........................] - ETA: 5:40 - loss: 0.5829 - accuracy: 0.8347\n",
      "Batch 07924: setting learning rate to 0.00019966519457925383.\n",
      " 804/3560 [=====>........................] - ETA: 5:39 - loss: 0.5828 - accuracy: 0.8348\n",
      "Batch 07925: setting learning rate to 0.0001996649030364158.\n",
      " 805/3560 [=====>........................] - ETA: 5:39 - loss: 0.5830 - accuracy: 0.8348\n",
      "Batch 07926: setting learning rate to 0.00019966461136691077.\n",
      "\n",
      "Batch 07927: setting learning rate to 0.00019966431957073913.\n",
      " 807/3560 [=====>........................] - ETA: 5:39 - loss: 0.5829 - accuracy: 0.8348\n",
      "Batch 07928: setting learning rate to 0.00019966402764790123.\n",
      " 808/3560 [=====>........................] - ETA: 5:40 - loss: 0.5826 - accuracy: 0.8349\n",
      "Batch 07929: setting learning rate to 0.00019966373559839745.\n",
      " 809/3560 [=====>........................] - ETA: 5:40 - loss: 0.5829 - accuracy: 0.8347\n",
      "Batch 07930: setting learning rate to 0.00019966344342222815.\n",
      " 810/3560 [=====>........................] - ETA: 5:39 - loss: 0.5828 - accuracy: 0.8346\n",
      "Batch 07931: setting learning rate to 0.0001996631511193938.\n",
      " 811/3560 [=====>........................] - ETA: 5:39 - loss: 0.5830 - accuracy: 0.8345\n",
      "Batch 07932: setting learning rate to 0.00019966285868989458.\n",
      " 812/3560 [=====>........................] - ETA: 5:39 - loss: 0.5830 - accuracy: 0.8346\n",
      "Batch 07933: setting learning rate to 0.00019966256613373101.\n",
      " 813/3560 [=====>........................] - ETA: 5:38 - loss: 0.5832 - accuracy: 0.8345\n",
      "Batch 07934: setting learning rate to 0.00019966227345090344.\n",
      " 814/3560 [=====>........................] - ETA: 5:38 - loss: 0.5834 - accuracy: 0.8345\n",
      "Batch 07935: setting learning rate to 0.00019966198064141222.\n",
      " 815/3560 [=====>........................] - ETA: 5:39 - loss: 0.5835 - accuracy: 0.8344\n",
      "Batch 07936: setting learning rate to 0.00019966168770525772.\n",
      " 816/3560 [=====>........................] - ETA: 5:38 - loss: 0.5833 - accuracy: 0.8344\n",
      "Batch 07937: setting learning rate to 0.0001996613946424403.\n",
      " 817/3560 [=====>........................] - ETA: 5:38 - loss: 0.5834 - accuracy: 0.8343\n",
      "Batch 07938: setting learning rate to 0.00019966110145296036.\n",
      " 818/3560 [=====>........................] - ETA: 5:38 - loss: 0.5832 - accuracy: 0.8343\n",
      "Batch 07939: setting learning rate to 0.00019966080813681826.\n",
      " 819/3560 [=====>........................] - ETA: 5:38 - loss: 0.5829 - accuracy: 0.8343\n",
      "Batch 07940: setting learning rate to 0.0001996605146940144.\n",
      " 820/3560 [=====>........................] - ETA: 5:37 - loss: 0.5828 - accuracy: 0.8343\n",
      "Batch 07941: setting learning rate to 0.00019966022112454911.\n",
      " 821/3560 [=====>........................] - ETA: 5:37 - loss: 0.5827 - accuracy: 0.8342\n",
      "Batch 07942: setting learning rate to 0.00019965992742842278.\n",
      " 822/3560 [=====>........................] - ETA: 5:37 - loss: 0.5830 - accuracy: 0.8342\n",
      "Batch 07943: setting learning rate to 0.00019965963360563577.\n",
      " 823/3560 [=====>........................] - ETA: 5:37 - loss: 0.5828 - accuracy: 0.8342\n",
      "Batch 07944: setting learning rate to 0.00019965933965618852.\n",
      " 824/3560 [=====>........................] - ETA: 5:37 - loss: 0.5827 - accuracy: 0.8342\n",
      "Batch 07945: setting learning rate to 0.0001996590455800813.\n",
      "\n",
      "Batch 07946: setting learning rate to 0.00019965875137731453.\n",
      " 826/3560 [=====>........................] - ETA: 5:37 - loss: 0.5825 - accuracy: 0.8343\n",
      "Batch 07947: setting learning rate to 0.00019965845704788865.\n",
      " 827/3560 [=====>........................] - ETA: 5:37 - loss: 0.5829 - accuracy: 0.8343\n",
      "Batch 07948: setting learning rate to 0.00019965816259180392.\n",
      "\n",
      "Batch 07949: setting learning rate to 0.00019965786800906076.\n",
      " 829/3560 [=====>........................] - ETA: 5:37 - loss: 0.5826 - accuracy: 0.8345\n",
      "Batch 07950: setting learning rate to 0.0001996575732996596.\n",
      " 830/3560 [=====>........................] - ETA: 5:36 - loss: 0.5826 - accuracy: 0.8345\n",
      "Batch 07951: setting learning rate to 0.00019965727846360073.\n",
      " 831/3560 [======>.......................] - ETA: 5:36 - loss: 0.5824 - accuracy: 0.8345\n",
      "Batch 07952: setting learning rate to 0.0001996569835008846.\n",
      " 832/3560 [======>.......................] - ETA: 5:36 - loss: 0.5823 - accuracy: 0.8345\n",
      "Batch 07953: setting learning rate to 0.00019965668841151149.\n",
      " 833/3560 [======>.......................] - ETA: 5:36 - loss: 0.5824 - accuracy: 0.8346\n",
      "Batch 07954: setting learning rate to 0.00019965639319548183.\n",
      " 834/3560 [======>.......................] - ETA: 5:36 - loss: 0.5823 - accuracy: 0.8346\n",
      "Batch 07955: setting learning rate to 0.00019965609785279606.\n",
      " 835/3560 [======>.......................] - ETA: 5:35 - loss: 0.5821 - accuracy: 0.8347\n",
      "Batch 07956: setting learning rate to 0.00019965580238345444.\n",
      " 836/3560 [======>.......................] - ETA: 5:35 - loss: 0.5819 - accuracy: 0.8347\n",
      "Batch 07957: setting learning rate to 0.00019965550678745743.\n",
      "\n",
      "Batch 07958: setting learning rate to 0.00019965521106480533.\n",
      " 838/3560 [======>.......................] - ETA: 5:36 - loss: 0.5822 - accuracy: 0.8347\n",
      "Batch 07959: setting learning rate to 0.00019965491521549858.\n",
      " 839/3560 [======>.......................] - ETA: 5:36 - loss: 0.5819 - accuracy: 0.8348\n",
      "Batch 07960: setting learning rate to 0.00019965461923953756.\n",
      "\n",
      "Batch 07961: setting learning rate to 0.0001996543231369226.\n",
      " 841/3560 [======>.......................] - ETA: 5:35 - loss: 0.5817 - accuracy: 0.8348\n",
      "Batch 07962: setting learning rate to 0.00019965402690765412.\n",
      " 842/3560 [======>.......................] - ETA: 5:35 - loss: 0.5815 - accuracy: 0.8347\n",
      "Batch 07963: setting learning rate to 0.00019965373055173244.\n",
      " 843/3560 [======>.......................] - ETA: 5:34 - loss: 0.5815 - accuracy: 0.8347\n",
      "Batch 07964: setting learning rate to 0.000199653434069158.\n",
      "\n",
      "Batch 07965: setting learning rate to 0.00019965313745993113.\n",
      " 845/3560 [======>.......................] - ETA: 5:34 - loss: 0.5813 - accuracy: 0.8348\n",
      "Batch 07966: setting learning rate to 0.00019965284072405223.\n",
      " 846/3560 [======>.......................] - ETA: 5:34 - loss: 0.5811 - accuracy: 0.8349\n",
      "Batch 07967: setting learning rate to 0.00019965254386152166.\n",
      " 847/3560 [======>.......................] - ETA: 5:34 - loss: 0.5810 - accuracy: 0.8349\n",
      "Batch 07968: setting learning rate to 0.0001996522468723398.\n",
      "\n",
      "Batch 07969: setting learning rate to 0.00019965194975650707.\n",
      " 849/3560 [======>.......................] - ETA: 5:34 - loss: 0.5807 - accuracy: 0.8349\n",
      "Batch 07970: setting learning rate to 0.00019965165251402381.\n",
      "\n",
      "Batch 07971: setting learning rate to 0.00019965135514489037.\n",
      " 851/3560 [======>.......................] - ETA: 5:33 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 07972: setting learning rate to 0.00019965105764910718.\n",
      "\n",
      "Batch 07973: setting learning rate to 0.0001996507600266746.\n",
      " 853/3560 [======>.......................] - ETA: 5:33 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 07974: setting learning rate to 0.000199650462277593.\n",
      " 854/3560 [======>.......................] - ETA: 5:33 - loss: 0.5801 - accuracy: 0.8353\n",
      "Batch 07975: setting learning rate to 0.00019965016440186278.\n",
      " 855/3560 [======>.......................] - ETA: 5:34 - loss: 0.5798 - accuracy: 0.8354\n",
      "Batch 07976: setting learning rate to 0.00019964986639948426.\n",
      " 856/3560 [======>.......................] - ETA: 5:33 - loss: 0.5799 - accuracy: 0.8354\n",
      "Batch 07977: setting learning rate to 0.0001996495682704579.\n",
      " 857/3560 [======>.......................] - ETA: 5:33 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 07978: setting learning rate to 0.000199649270014784.\n",
      " 858/3560 [======>.......................] - ETA: 5:33 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 07979: setting learning rate to 0.00019964897163246304.\n",
      " 859/3560 [======>.......................] - ETA: 5:32 - loss: 0.5810 - accuracy: 0.8352\n",
      "Batch 07980: setting learning rate to 0.0001996486731234953.\n",
      " 860/3560 [======>.......................] - ETA: 5:32 - loss: 0.5812 - accuracy: 0.8351\n",
      "Batch 07981: setting learning rate to 0.0001996483744878812.\n",
      " 861/3560 [======>.......................] - ETA: 5:32 - loss: 0.5810 - accuracy: 0.8351\n",
      "Batch 07982: setting learning rate to 0.00019964807572562114.\n",
      " 862/3560 [======>.......................] - ETA: 5:32 - loss: 0.5812 - accuracy: 0.8352\n",
      "Batch 07983: setting learning rate to 0.00019964777683671546.\n",
      "\n",
      "Batch 07984: setting learning rate to 0.00019964747782116456.\n",
      " 864/3560 [======>.......................] - ETA: 5:32 - loss: 0.5812 - accuracy: 0.8351\n",
      "Batch 07985: setting learning rate to 0.00019964717867896882.\n",
      " 865/3560 [======>.......................] - ETA: 5:32 - loss: 0.5811 - accuracy: 0.8351\n",
      "Batch 07986: setting learning rate to 0.0001996468794101286.\n",
      "\n",
      "Batch 07987: setting learning rate to 0.00019964658001464432.\n",
      " 867/3560 [======>.......................] - ETA: 5:33 - loss: 0.5809 - accuracy: 0.8351\n",
      "Batch 07988: setting learning rate to 0.00019964628049251633.\n",
      " 868/3560 [======>.......................] - ETA: 5:32 - loss: 0.5811 - accuracy: 0.8350\n",
      "Batch 07989: setting learning rate to 0.00019964598084374501.\n",
      "\n",
      "Batch 07990: setting learning rate to 0.00019964568106833078.\n",
      " 870/3560 [======>.......................] - ETA: 5:32 - loss: 0.5809 - accuracy: 0.8352\n",
      "Batch 07991: setting learning rate to 0.00019964538116627395.\n",
      " 871/3560 [======>.......................] - ETA: 5:32 - loss: 0.5811 - accuracy: 0.8353\n",
      "Batch 07992: setting learning rate to 0.00019964508113757496.\n",
      " 872/3560 [======>.......................] - ETA: 5:32 - loss: 0.5809 - accuracy: 0.8354\n",
      "Batch 07993: setting learning rate to 0.0001996447809822342.\n",
      "\n",
      "Batch 07994: setting learning rate to 0.000199644480700252.\n",
      " 874/3560 [======>.......................] - ETA: 5:31 - loss: 0.5809 - accuracy: 0.8353\n",
      "Batch 07995: setting learning rate to 0.00019964418029162876.\n",
      " 875/3560 [======>.......................] - ETA: 5:31 - loss: 0.5808 - accuracy: 0.8352\n",
      "Batch 07996: setting learning rate to 0.00019964387975636484.\n",
      " 876/3560 [======>.......................] - ETA: 5:31 - loss: 0.5810 - accuracy: 0.8352\n",
      "Batch 07997: setting learning rate to 0.00019964357909446072.\n",
      "\n",
      "Batch 07998: setting learning rate to 0.00019964327830591664.\n",
      " 878/3560 [======>.......................] - ETA: 5:30 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 07999: setting learning rate to 0.0001996429773907331.\n",
      " 879/3560 [======>.......................] - ETA: 5:30 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 08000: setting learning rate to 0.00019964267634891046.\n",
      "\n",
      "Batch 08001: setting learning rate to 0.00019964237518044903.\n",
      " 881/3560 [======>.......................] - ETA: 5:30 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08002: setting learning rate to 0.00019964207388534927.\n",
      "\n",
      "Batch 08003: setting learning rate to 0.00019964177246361154.\n",
      " 883/3560 [======>.......................] - ETA: 5:30 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 08004: setting learning rate to 0.0001996414709152362.\n",
      " 884/3560 [======>.......................] - ETA: 5:29 - loss: 0.5801 - accuracy: 0.8353\n",
      "Batch 08005: setting learning rate to 0.00019964116924022364.\n",
      " 885/3560 [======>.......................] - ETA: 5:30 - loss: 0.5805 - accuracy: 0.8353\n",
      "Batch 08006: setting learning rate to 0.00019964086743857426.\n",
      " 886/3560 [======>.......................] - ETA: 5:31 - loss: 0.5805 - accuracy: 0.8352\n",
      "Batch 08007: setting learning rate to 0.00019964056551028848.\n",
      " 887/3560 [======>.......................] - ETA: 5:30 - loss: 0.5811 - accuracy: 0.8352\n",
      "Batch 08008: setting learning rate to 0.0001996402634553666.\n",
      " 888/3560 [======>.......................] - ETA: 5:30 - loss: 0.5810 - accuracy: 0.8353\n",
      "Batch 08009: setting learning rate to 0.00019963996127380905.\n",
      "\n",
      "Batch 08010: setting learning rate to 0.0001996396589656162.\n",
      " 890/3560 [======>.......................] - ETA: 5:30 - loss: 0.5808 - accuracy: 0.8354\n",
      "Batch 08011: setting learning rate to 0.00019963935653078847.\n",
      "\n",
      "Batch 08012: setting learning rate to 0.0001996390539693262.\n",
      " 892/3560 [======>.......................] - ETA: 5:29 - loss: 0.5808 - accuracy: 0.8353\n",
      "Batch 08013: setting learning rate to 0.00019963875128122983.\n",
      " 893/3560 [======>.......................] - ETA: 5:29 - loss: 0.5810 - accuracy: 0.8353\n",
      "Batch 08014: setting learning rate to 0.00019963844846649967.\n",
      " 894/3560 [======>.......................] - ETA: 5:29 - loss: 0.5810 - accuracy: 0.8353\n",
      "Batch 08015: setting learning rate to 0.00019963814552513616.\n",
      "\n",
      "Batch 08016: setting learning rate to 0.00019963784245713965.\n",
      " 896/3560 [======>.......................] - ETA: 5:28 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08017: setting learning rate to 0.00019963753926251055.\n",
      " 897/3560 [======>.......................] - ETA: 5:28 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08018: setting learning rate to 0.00019963723594124927.\n",
      "\n",
      "Batch 08019: setting learning rate to 0.00019963693249335613.\n",
      " 899/3560 [======>.......................] - ETA: 5:28 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08020: setting learning rate to 0.00019963662891883156.\n",
      " 900/3560 [======>.......................] - ETA: 5:28 - loss: 0.5803 - accuracy: 0.8355\n",
      "Batch 08021: setting learning rate to 0.00019963632521767592.\n",
      " 901/3560 [======>.......................] - ETA: 5:28 - loss: 0.5802 - accuracy: 0.8355\n",
      "Batch 08022: setting learning rate to 0.00019963602138988964.\n",
      " 902/3560 [======>.......................] - ETA: 5:29 - loss: 0.5804 - accuracy: 0.8354\n",
      "Batch 08023: setting learning rate to 0.00019963571743547307.\n",
      " 903/3560 [======>.......................] - ETA: 5:29 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 08024: setting learning rate to 0.0001996354133544266.\n",
      " 904/3560 [======>.......................] - ETA: 5:28 - loss: 0.5806 - accuracy: 0.8353\n",
      "Batch 08025: setting learning rate to 0.00019963510914675062.\n",
      " 905/3560 [======>.......................] - ETA: 5:28 - loss: 0.5806 - accuracy: 0.8353\n",
      "Batch 08026: setting learning rate to 0.0001996348048124455.\n",
      " 906/3560 [======>.......................] - ETA: 5:28 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08027: setting learning rate to 0.00019963450035151165.\n",
      " 907/3560 [======>.......................] - ETA: 5:27 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08028: setting learning rate to 0.00019963419576394945.\n",
      " 908/3560 [======>.......................] - ETA: 5:27 - loss: 0.5805 - accuracy: 0.8352\n",
      "Batch 08029: setting learning rate to 0.00019963389104975932.\n",
      " 909/3560 [======>.......................] - ETA: 5:28 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 08030: setting learning rate to 0.00019963358620894158.\n",
      " 910/3560 [======>.......................] - ETA: 5:27 - loss: 0.5805 - accuracy: 0.8352\n",
      "Batch 08031: setting learning rate to 0.00019963328124149668.\n",
      "\n",
      "Batch 08032: setting learning rate to 0.00019963297614742498.\n",
      " 912/3560 [======>.......................] - ETA: 5:27 - loss: 0.5799 - accuracy: 0.8354\n",
      "Batch 08033: setting learning rate to 0.00019963267092672684.\n",
      " 913/3560 [======>.......................] - ETA: 5:27 - loss: 0.5804 - accuracy: 0.8355\n",
      "Batch 08034: setting learning rate to 0.00019963236557940268.\n",
      " 914/3560 [======>.......................] - ETA: 5:27 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08035: setting learning rate to 0.0001996320601054529.\n",
      " 915/3560 [======>.......................] - ETA: 5:27 - loss: 0.5807 - accuracy: 0.8355\n",
      "Batch 08036: setting learning rate to 0.00019963175450487785.\n",
      " 916/3560 [======>.......................] - ETA: 5:27 - loss: 0.5809 - accuracy: 0.8354\n",
      "Batch 08037: setting learning rate to 0.00019963144877767797.\n",
      "\n",
      "Batch 08038: setting learning rate to 0.00019963114292385358.\n",
      " 918/3560 [======>.......................] - ETA: 5:28 - loss: 0.5809 - accuracy: 0.8354\n",
      "Batch 08039: setting learning rate to 0.00019963083694340514.\n",
      " 919/3560 [======>.......................] - ETA: 5:27 - loss: 0.5809 - accuracy: 0.8354\n",
      "Batch 08040: setting learning rate to 0.00019963053083633302.\n",
      " 920/3560 [======>.......................] - ETA: 5:27 - loss: 0.5808 - accuracy: 0.8354\n",
      "Batch 08041: setting learning rate to 0.00019963022460263755.\n",
      " 921/3560 [======>.......................] - ETA: 5:27 - loss: 0.5811 - accuracy: 0.8352\n",
      "Batch 08042: setting learning rate to 0.0001996299182423192.\n",
      " 922/3560 [======>.......................] - ETA: 5:27 - loss: 0.5812 - accuracy: 0.8351\n",
      "Batch 08043: setting learning rate to 0.0001996296117553783.\n",
      " 923/3560 [======>.......................] - ETA: 5:26 - loss: 0.5810 - accuracy: 0.8350\n",
      "Batch 08044: setting learning rate to 0.0001996293051418153.\n",
      " 924/3560 [======>.......................] - ETA: 5:26 - loss: 0.5808 - accuracy: 0.8351\n",
      "Batch 08045: setting learning rate to 0.00019962899840163053.\n",
      " 925/3560 [======>.......................] - ETA: 5:26 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08046: setting learning rate to 0.0001996286915348244.\n",
      "\n",
      "Batch 08047: setting learning rate to 0.00019962838454139732.\n",
      " 927/3560 [======>.......................] - ETA: 5:25 - loss: 0.5809 - accuracy: 0.8350\n",
      "Batch 08048: setting learning rate to 0.00019962807742134964.\n",
      " 928/3560 [======>.......................] - ETA: 5:25 - loss: 0.5808 - accuracy: 0.8351\n",
      "Batch 08049: setting learning rate to 0.00019962777017468178.\n",
      " 929/3560 [======>.......................] - ETA: 5:25 - loss: 0.5808 - accuracy: 0.8351\n",
      "Batch 08050: setting learning rate to 0.00019962746280139412.\n",
      " 930/3560 [======>.......................] - ETA: 5:25 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08051: setting learning rate to 0.00019962715530148705.\n",
      " 931/3560 [======>.......................] - ETA: 5:26 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08052: setting learning rate to 0.00019962684767496102.\n",
      " 932/3560 [======>.......................] - ETA: 5:25 - loss: 0.5811 - accuracy: 0.8351\n",
      "Batch 08053: setting learning rate to 0.0001996265399218163.\n",
      " 933/3560 [======>.......................] - ETA: 5:25 - loss: 0.5811 - accuracy: 0.8351\n",
      "Batch 08054: setting learning rate to 0.0001996262320420534.\n",
      " 934/3560 [======>.......................] - ETA: 5:26 - loss: 0.5809 - accuracy: 0.8352\n",
      "Batch 08055: setting learning rate to 0.00019962592403567262.\n",
      " 935/3560 [======>.......................] - ETA: 5:26 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08056: setting learning rate to 0.00019962561590267442.\n",
      " 936/3560 [======>.......................] - ETA: 5:26 - loss: 0.5805 - accuracy: 0.8353\n",
      "Batch 08057: setting learning rate to 0.0001996253076430591.\n",
      " 937/3560 [======>.......................] - ETA: 5:26 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 08058: setting learning rate to 0.00019962499925682718.\n",
      " 938/3560 [======>.......................] - ETA: 5:25 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 08059: setting learning rate to 0.000199624690743979.\n",
      " 939/3560 [======>.......................] - ETA: 5:25 - loss: 0.5800 - accuracy: 0.8354\n",
      "Batch 08060: setting learning rate to 0.00019962438210451486.\n",
      " 940/3560 [======>.......................] - ETA: 5:25 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08061: setting learning rate to 0.00019962407333843528.\n",
      " 941/3560 [======>.......................] - ETA: 5:24 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08062: setting learning rate to 0.0001996237644457406.\n",
      "\n",
      "Batch 08063: setting learning rate to 0.00019962345542643122.\n",
      " 943/3560 [======>.......................] - ETA: 5:24 - loss: 0.5805 - accuracy: 0.8353\n",
      "Batch 08064: setting learning rate to 0.00019962314628050752.\n",
      " 944/3560 [======>.......................] - ETA: 5:24 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08065: setting learning rate to 0.0001996228370079699.\n",
      " 945/3560 [======>.......................] - ETA: 5:24 - loss: 0.5804 - accuracy: 0.8354\n",
      "Batch 08066: setting learning rate to 0.00019962252760881874.\n",
      " 946/3560 [======>.......................] - ETA: 5:23 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08067: setting learning rate to 0.00019962221808305448.\n",
      " 947/3560 [======>.......................] - ETA: 5:23 - loss: 0.5804 - accuracy: 0.8355\n",
      "Batch 08068: setting learning rate to 0.00019962190843067745.\n",
      " 948/3560 [======>.......................] - ETA: 5:23 - loss: 0.5803 - accuracy: 0.8354\n",
      "Batch 08069: setting learning rate to 0.0001996215986516881.\n",
      " 949/3560 [======>.......................] - ETA: 5:23 - loss: 0.5801 - accuracy: 0.8355\n",
      "Batch 08070: setting learning rate to 0.00019962128874608678.\n",
      " 950/3560 [=======>......................] - ETA: 5:24 - loss: 0.5803 - accuracy: 0.8354\n",
      "Batch 08071: setting learning rate to 0.0001996209787138739.\n",
      " 951/3560 [=======>......................] - ETA: 5:24 - loss: 0.5806 - accuracy: 0.8354\n",
      "Batch 08072: setting learning rate to 0.00019962066855504985.\n",
      " 952/3560 [=======>......................] - ETA: 5:24 - loss: 0.5807 - accuracy: 0.8353\n",
      "Batch 08073: setting learning rate to 0.00019962035826961506.\n",
      " 953/3560 [=======>......................] - ETA: 5:23 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 08074: setting learning rate to 0.00019962004785756987.\n",
      " 954/3560 [=======>......................] - ETA: 5:23 - loss: 0.5807 - accuracy: 0.8350\n",
      "Batch 08075: setting learning rate to 0.00019961973731891472.\n",
      " 955/3560 [=======>......................] - ETA: 5:23 - loss: 0.5809 - accuracy: 0.8349\n",
      "Batch 08076: setting learning rate to 0.00019961942665364996.\n",
      " 956/3560 [=======>......................] - ETA: 5:22 - loss: 0.5809 - accuracy: 0.8349\n",
      "Batch 08077: setting learning rate to 0.000199619115861776.\n",
      " 957/3560 [=======>......................] - ETA: 5:22 - loss: 0.5809 - accuracy: 0.8349\n",
      "Batch 08078: setting learning rate to 0.0001996188049432933.\n",
      "\n",
      "Batch 08079: setting learning rate to 0.00019961849389820216.\n",
      " 959/3560 [=======>......................] - ETA: 5:23 - loss: 0.5808 - accuracy: 0.8348\n",
      "Batch 08080: setting learning rate to 0.000199618182726503.\n",
      " 960/3560 [=======>......................] - ETA: 5:22 - loss: 0.5809 - accuracy: 0.8348\n",
      "Batch 08081: setting learning rate to 0.00019961787142819623.\n",
      " 961/3560 [=======>......................] - ETA: 5:22 - loss: 0.5811 - accuracy: 0.8349\n",
      "Batch 08082: setting learning rate to 0.00019961756000328227.\n",
      " 962/3560 [=======>......................] - ETA: 5:22 - loss: 0.5814 - accuracy: 0.8349\n",
      "Batch 08083: setting learning rate to 0.00019961724845176147.\n",
      " 963/3560 [=======>......................] - ETA: 5:21 - loss: 0.5815 - accuracy: 0.8349\n",
      "Batch 08084: setting learning rate to 0.00019961693677363426.\n",
      " 964/3560 [=======>......................] - ETA: 5:21 - loss: 0.5813 - accuracy: 0.8348\n",
      "Batch 08085: setting learning rate to 0.00019961662496890102.\n",
      " 965/3560 [=======>......................] - ETA: 5:21 - loss: 0.5813 - accuracy: 0.8348\n",
      "Batch 08086: setting learning rate to 0.00019961631303756213.\n",
      " 966/3560 [=======>......................] - ETA: 5:22 - loss: 0.5813 - accuracy: 0.8349\n",
      "Batch 08087: setting learning rate to 0.00019961600097961803.\n",
      " 967/3560 [=======>......................] - ETA: 5:21 - loss: 0.5810 - accuracy: 0.8350\n",
      "Batch 08088: setting learning rate to 0.0001996156887950691.\n",
      " 968/3560 [=======>......................] - ETA: 5:21 - loss: 0.5808 - accuracy: 0.8351\n",
      "Batch 08089: setting learning rate to 0.0001996153764839157.\n",
      "\n",
      "Batch 08090: setting learning rate to 0.00019961506404615826.\n",
      " 970/3560 [=======>......................] - ETA: 5:21 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08091: setting learning rate to 0.0001996147514817972.\n",
      " 971/3560 [=======>......................] - ETA: 5:20 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08092: setting learning rate to 0.00019961443879083285.\n",
      " 972/3560 [=======>......................] - ETA: 5:20 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08093: setting learning rate to 0.00019961412597326568.\n",
      " 973/3560 [=======>......................] - ETA: 5:20 - loss: 0.5806 - accuracy: 0.8350\n",
      "Batch 08094: setting learning rate to 0.00019961381302909605.\n",
      "\n",
      "Batch 08095: setting learning rate to 0.00019961349995832435.\n",
      " 975/3560 [=======>......................] - ETA: 5:19 - loss: 0.5805 - accuracy: 0.8351\n",
      "Batch 08096: setting learning rate to 0.000199613186760951.\n",
      " 976/3560 [=======>......................] - ETA: 5:19 - loss: 0.5804 - accuracy: 0.8351\n",
      "Batch 08097: setting learning rate to 0.0001996128734369764.\n",
      " 977/3560 [=======>......................] - ETA: 5:20 - loss: 0.5804 - accuracy: 0.8351\n",
      "Batch 08098: setting learning rate to 0.00019961255998640092.\n",
      " 978/3560 [=======>......................] - ETA: 5:19 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08099: setting learning rate to 0.00019961224640922497.\n",
      " 979/3560 [=======>......................] - ETA: 5:19 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08100: setting learning rate to 0.00019961193270544896.\n",
      "\n",
      "Batch 08101: setting learning rate to 0.0001996116188750733.\n",
      " 981/3560 [=======>......................] - ETA: 5:19 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08102: setting learning rate to 0.00019961130491809835.\n",
      " 982/3560 [=======>......................] - ETA: 5:19 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08103: setting learning rate to 0.00019961099083452456.\n",
      " 983/3560 [=======>......................] - ETA: 5:19 - loss: 0.5808 - accuracy: 0.8351\n",
      "Batch 08104: setting learning rate to 0.00019961067662435224.\n",
      " 984/3560 [=======>......................] - ETA: 5:19 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 08105: setting learning rate to 0.0001996103622875819.\n",
      "\n",
      "Batch 08106: setting learning rate to 0.00019961004782421388.\n",
      " 986/3560 [=======>......................] - ETA: 5:19 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08107: setting learning rate to 0.00019960973323424858.\n",
      " 987/3560 [=======>......................] - ETA: 5:18 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08108: setting learning rate to 0.0001996094185176864.\n",
      " 988/3560 [=======>......................] - ETA: 5:18 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08109: setting learning rate to 0.00019960910367452776.\n",
      " 989/3560 [=======>......................] - ETA: 5:18 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 08110: setting learning rate to 0.00019960878870477306.\n",
      " 990/3560 [=======>......................] - ETA: 5:18 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 08111: setting learning rate to 0.00019960847360842268.\n",
      " 991/3560 [=======>......................] - ETA: 5:17 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 08112: setting learning rate to 0.000199608158385477.\n",
      " 992/3560 [=======>......................] - ETA: 5:18 - loss: 0.5799 - accuracy: 0.8353\n",
      "Batch 08113: setting learning rate to 0.0001996078430359365.\n",
      " 993/3560 [=======>......................] - ETA: 5:18 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08114: setting learning rate to 0.0001996075275598015.\n",
      " 994/3560 [=======>......................] - ETA: 5:18 - loss: 0.5803 - accuracy: 0.8351\n",
      "Batch 08115: setting learning rate to 0.00019960721195707242.\n",
      " 995/3560 [=======>......................] - ETA: 5:18 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08116: setting learning rate to 0.0001996068962277497.\n",
      "\n",
      "Batch 08117: setting learning rate to 0.0001996065803718337.\n",
      " 997/3560 [=======>......................] - ETA: 5:17 - loss: 0.5803 - accuracy: 0.8352\n",
      "Batch 08118: setting learning rate to 0.00019960626438932485.\n",
      " 998/3560 [=======>......................] - ETA: 5:17 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08119: setting learning rate to 0.0001996059482802235.\n",
      " 999/3560 [=======>......................] - ETA: 5:17 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08120: setting learning rate to 0.0001996056320445301.\n",
      "1000/3560 [=======>......................] - ETA: 5:17 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08121: setting learning rate to 0.00019960531568224504.\n",
      "1001/3560 [=======>......................] - ETA: 5:16 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08122: setting learning rate to 0.00019960499919336876.\n",
      "1002/3560 [=======>......................] - ETA: 5:16 - loss: 0.5802 - accuracy: 0.8354\n",
      "Batch 08123: setting learning rate to 0.0001996046825779016.\n",
      "1003/3560 [=======>......................] - ETA: 5:17 - loss: 0.5799 - accuracy: 0.8354\n",
      "Batch 08124: setting learning rate to 0.00019960436583584397.\n",
      "1004/3560 [=======>......................] - ETA: 5:16 - loss: 0.5801 - accuracy: 0.8354\n",
      "Batch 08125: setting learning rate to 0.0001996040489671963.\n",
      "1005/3560 [=======>......................] - ETA: 5:16 - loss: 0.5798 - accuracy: 0.8354\n",
      "Batch 08126: setting learning rate to 0.00019960373197195898.\n",
      "1006/3560 [=======>......................] - ETA: 5:16 - loss: 0.5798 - accuracy: 0.8354\n",
      "Batch 08127: setting learning rate to 0.00019960341485013246.\n",
      "\n",
      "Batch 08128: setting learning rate to 0.00019960309760171704.\n",
      "1008/3560 [=======>......................] - ETA: 5:16 - loss: 0.5798 - accuracy: 0.8354\n",
      "Batch 08129: setting learning rate to 0.0001996027802267132.\n",
      "1009/3560 [=======>......................] - ETA: 5:16 - loss: 0.5799 - accuracy: 0.8353\n",
      "Batch 08130: setting learning rate to 0.00019960246272512133.\n",
      "1010/3560 [=======>......................] - ETA: 5:16 - loss: 0.5800 - accuracy: 0.8352\n",
      "Batch 08131: setting learning rate to 0.00019960214509694182.\n",
      "\n",
      "Batch 08132: setting learning rate to 0.0001996018273421751.\n",
      "1012/3560 [=======>......................] - ETA: 5:16 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08133: setting learning rate to 0.00019960150946082155.\n",
      "1013/3560 [=======>......................] - ETA: 5:16 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 08134: setting learning rate to 0.00019960119145288156.\n",
      "1014/3560 [=======>......................] - ETA: 5:15 - loss: 0.5800 - accuracy: 0.8352\n",
      "Batch 08135: setting learning rate to 0.00019960087331835557.\n",
      "1015/3560 [=======>......................] - ETA: 5:15 - loss: 0.5801 - accuracy: 0.8352\n",
      "Batch 08136: setting learning rate to 0.00019960055505724396.\n",
      "1016/3560 [=======>......................] - ETA: 5:15 - loss: 0.5803 - accuracy: 0.8352\n",
      "Batch 08137: setting learning rate to 0.00019960023666954713.\n",
      "1017/3560 [=======>......................] - ETA: 5:15 - loss: 0.5805 - accuracy: 0.8352\n",
      "Batch 08138: setting learning rate to 0.0001995999181552655.\n",
      "1018/3560 [=======>......................] - ETA: 5:14 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08139: setting learning rate to 0.0001995995995143995.\n",
      "1019/3560 [=======>......................] - ETA: 5:15 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 08140: setting learning rate to 0.00019959928074694952.\n",
      "1020/3560 [=======>......................] - ETA: 5:15 - loss: 0.5803 - accuracy: 0.8352\n",
      "Batch 08141: setting learning rate to 0.00019959896185291591.\n",
      "1021/3560 [=======>......................] - ETA: 5:14 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08142: setting learning rate to 0.00019959864283229913.\n",
      "1022/3560 [=======>......................] - ETA: 5:14 - loss: 0.5803 - accuracy: 0.8352\n",
      "Batch 08143: setting learning rate to 0.00019959832368509958.\n",
      "\n",
      "Batch 08144: setting learning rate to 0.00019959800441131766.\n",
      "1024/3560 [=======>......................] - ETA: 5:14 - loss: 0.5806 - accuracy: 0.8351\n",
      "Batch 08145: setting learning rate to 0.00019959768501095378.\n",
      "1025/3560 [=======>......................] - ETA: 5:13 - loss: 0.5805 - accuracy: 0.8351\n",
      "Batch 08146: setting learning rate to 0.00019959736548400833.\n",
      "1026/3560 [=======>......................] - ETA: 5:13 - loss: 0.5804 - accuracy: 0.8351\n",
      "Batch 08147: setting learning rate to 0.00019959704583048172.\n",
      "1027/3560 [=======>......................] - ETA: 5:14 - loss: 0.5800 - accuracy: 0.8352\n",
      "Batch 08148: setting learning rate to 0.00019959672605037435.\n",
      "1028/3560 [=======>......................] - ETA: 5:13 - loss: 0.5800 - accuracy: 0.8352\n",
      "Batch 08149: setting learning rate to 0.00019959640614368665.\n",
      "1029/3560 [=======>......................] - ETA: 5:13 - loss: 0.5797 - accuracy: 0.8352\n",
      "Batch 08150: setting learning rate to 0.00019959608611041905.\n",
      "1030/3560 [=======>......................] - ETA: 5:14 - loss: 0.5801 - accuracy: 0.8353\n",
      "Batch 08151: setting learning rate to 0.0001995957659505719.\n",
      "1031/3560 [=======>......................] - ETA: 5:13 - loss: 0.5801 - accuracy: 0.8354\n",
      "Batch 08152: setting learning rate to 0.00019959544566414562.\n",
      "1032/3560 [=======>......................] - ETA: 5:13 - loss: 0.5799 - accuracy: 0.8355\n",
      "Batch 08153: setting learning rate to 0.00019959512525114062.\n",
      "1033/3560 [=======>......................] - ETA: 5:13 - loss: 0.5800 - accuracy: 0.8355\n",
      "Batch 08154: setting learning rate to 0.00019959480471155733.\n",
      "1034/3560 [=======>......................] - ETA: 5:12 - loss: 0.5798 - accuracy: 0.8356\n",
      "Batch 08155: setting learning rate to 0.00019959448404539615.\n",
      "1035/3560 [=======>......................] - ETA: 5:12 - loss: 0.5796 - accuracy: 0.8356\n",
      "Batch 08156: setting learning rate to 0.00019959416325265745.\n",
      "1036/3560 [=======>......................] - ETA: 5:12 - loss: 0.5796 - accuracy: 0.8357\n",
      "Batch 08157: setting learning rate to 0.00019959384233334172.\n",
      "\n",
      "Batch 08158: setting learning rate to 0.00019959352128744927.\n",
      "1038/3560 [=======>......................] - ETA: 5:11 - loss: 0.5793 - accuracy: 0.8359\n",
      "Batch 08159: setting learning rate to 0.00019959320011498055.\n",
      "\n",
      "Batch 08160: setting learning rate to 0.00019959287881593597.\n",
      "1040/3560 [=======>......................] - ETA: 5:12 - loss: 0.5790 - accuracy: 0.8360\n",
      "Batch 08161: setting learning rate to 0.00019959255739031596.\n",
      "\n",
      "Batch 08162: setting learning rate to 0.0001995922358381209.\n",
      "1042/3560 [=======>......................] - ETA: 5:12 - loss: 0.5790 - accuracy: 0.8360\n",
      "Batch 08163: setting learning rate to 0.00019959191415935118.\n",
      "\n",
      "Batch 08164: setting learning rate to 0.00019959159235400726.\n",
      "1044/3560 [=======>......................] - ETA: 5:11 - loss: 0.5790 - accuracy: 0.8361\n",
      "Batch 08165: setting learning rate to 0.00019959127042208953.\n",
      "1045/3560 [=======>......................] - ETA: 5:11 - loss: 0.5791 - accuracy: 0.8360\n",
      "Batch 08166: setting learning rate to 0.00019959094836359838.\n",
      "1046/3560 [=======>......................] - ETA: 5:11 - loss: 0.5790 - accuracy: 0.8361\n",
      "Batch 08167: setting learning rate to 0.00019959062617853424.\n",
      "1047/3560 [=======>......................] - ETA: 5:10 - loss: 0.5790 - accuracy: 0.8361\n",
      "Batch 08168: setting learning rate to 0.0001995903038668975.\n",
      "1048/3560 [=======>......................] - ETA: 5:10 - loss: 0.5791 - accuracy: 0.8360\n",
      "Batch 08169: setting learning rate to 0.00019958998142868858.\n",
      "1049/3560 [=======>......................] - ETA: 5:10 - loss: 0.5789 - accuracy: 0.8360\n",
      "Batch 08170: setting learning rate to 0.0001995896588639079.\n",
      "1050/3560 [=======>......................] - ETA: 5:10 - loss: 0.5789 - accuracy: 0.8360\n",
      "Batch 08171: setting learning rate to 0.00019958933617255587.\n",
      "1051/3560 [=======>......................] - ETA: 5:10 - loss: 0.5793 - accuracy: 0.8360\n",
      "Batch 08172: setting learning rate to 0.00019958901335463287.\n",
      "1052/3560 [=======>......................] - ETA: 5:09 - loss: 0.5794 - accuracy: 0.8360\n",
      "Batch 08173: setting learning rate to 0.00019958869041013935.\n",
      "1053/3560 [=======>......................] - ETA: 5:09 - loss: 0.5792 - accuracy: 0.8360\n",
      "Batch 08174: setting learning rate to 0.0001995883673390757.\n",
      "1054/3560 [=======>......................] - ETA: 5:09 - loss: 0.5792 - accuracy: 0.8360\n",
      "Batch 08175: setting learning rate to 0.00019958804414144232.\n",
      "1055/3560 [=======>......................] - ETA: 5:09 - loss: 0.5791 - accuracy: 0.8361\n",
      "Batch 08176: setting learning rate to 0.00019958772081723965.\n",
      "\n",
      "Batch 08177: setting learning rate to 0.00019958739736646806.\n",
      "1057/3560 [=======>......................] - ETA: 5:09 - loss: 0.5789 - accuracy: 0.8362\n",
      "Batch 08178: setting learning rate to 0.000199587073789128.\n",
      "1058/3560 [=======>......................] - ETA: 5:10 - loss: 0.5788 - accuracy: 0.8363\n",
      "Batch 08179: setting learning rate to 0.00019958675008521984.\n",
      "\n",
      "Batch 08180: setting learning rate to 0.0001995864262547441.\n",
      "1060/3560 [=======>......................] - ETA: 5:09 - loss: 0.5787 - accuracy: 0.8363\n",
      "Batch 08181: setting learning rate to 0.00019958610229770104.\n",
      "\n",
      "Batch 08182: setting learning rate to 0.00019958577821409116.\n",
      "1062/3560 [=======>......................] - ETA: 5:09 - loss: 0.5783 - accuracy: 0.8364\n",
      "Batch 08183: setting learning rate to 0.00019958545400391482.\n",
      "1063/3560 [=======>......................] - ETA: 5:08 - loss: 0.5783 - accuracy: 0.8364\n",
      "Batch 08184: setting learning rate to 0.00019958512966717251.\n",
      "1064/3560 [=======>......................] - ETA: 5:08 - loss: 0.5782 - accuracy: 0.8364\n",
      "Batch 08185: setting learning rate to 0.00019958480520386457.\n",
      "1065/3560 [=======>......................] - ETA: 5:08 - loss: 0.5780 - accuracy: 0.8365\n",
      "Batch 08186: setting learning rate to 0.00019958448061399144.\n",
      "1066/3560 [=======>......................] - ETA: 5:08 - loss: 0.5782 - accuracy: 0.8365\n",
      "Batch 08187: setting learning rate to 0.00019958415589755357.\n",
      "1067/3560 [=======>......................] - ETA: 5:08 - loss: 0.5782 - accuracy: 0.8365\n",
      "Batch 08188: setting learning rate to 0.0001995838310545513.\n",
      "1068/3560 [========>.....................] - ETA: 5:08 - loss: 0.5782 - accuracy: 0.8366\n",
      "Batch 08189: setting learning rate to 0.00019958350608498507.\n",
      "1069/3560 [========>.....................] - ETA: 5:07 - loss: 0.5784 - accuracy: 0.8366\n",
      "Batch 08190: setting learning rate to 0.0001995831809888553.\n",
      "1070/3560 [========>.....................] - ETA: 5:07 - loss: 0.5787 - accuracy: 0.8365\n",
      "Batch 08191: setting learning rate to 0.00019958285576616246.\n",
      "\n",
      "Batch 08192: setting learning rate to 0.00019958253041690686.\n",
      "1072/3560 [========>.....................] - ETA: 5:07 - loss: 0.5785 - accuracy: 0.8366\n",
      "Batch 08193: setting learning rate to 0.00019958220494108896.\n",
      "1073/3560 [========>.....................] - ETA: 5:07 - loss: 0.5785 - accuracy: 0.8365\n",
      "Batch 08194: setting learning rate to 0.0001995818793387092.\n",
      "1074/3560 [========>.....................] - ETA: 5:08 - loss: 0.5784 - accuracy: 0.8365\n",
      "Batch 08195: setting learning rate to 0.00019958155360976794.\n",
      "1075/3560 [========>.....................] - ETA: 5:08 - loss: 0.5786 - accuracy: 0.8365\n",
      "Batch 08196: setting learning rate to 0.00019958122775426561.\n",
      "1076/3560 [========>.....................] - ETA: 5:07 - loss: 0.5789 - accuracy: 0.8363\n",
      "Batch 08197: setting learning rate to 0.00019958090177220268.\n",
      "1077/3560 [========>.....................] - ETA: 5:07 - loss: 0.5791 - accuracy: 0.8361\n",
      "Batch 08198: setting learning rate to 0.00019958057566357948.\n",
      "1078/3560 [========>.....................] - ETA: 5:07 - loss: 0.5792 - accuracy: 0.8361\n",
      "Batch 08199: setting learning rate to 0.00019958024942839649.\n",
      "1079/3560 [========>.....................] - ETA: 5:07 - loss: 0.5791 - accuracy: 0.8361\n",
      "Batch 08200: setting learning rate to 0.00019957992306665409.\n",
      "1080/3560 [========>.....................] - ETA: 5:06 - loss: 0.5791 - accuracy: 0.8361\n",
      "Batch 08201: setting learning rate to 0.0001995795965783527.\n",
      "1081/3560 [========>.....................] - ETA: 5:06 - loss: 0.5792 - accuracy: 0.8360\n",
      "Batch 08202: setting learning rate to 0.00019957926996349277.\n",
      "1082/3560 [========>.....................] - ETA: 5:06 - loss: 0.5792 - accuracy: 0.8360\n",
      "Batch 08203: setting learning rate to 0.00019957894322207467.\n",
      "1083/3560 [========>.....................] - ETA: 5:06 - loss: 0.5795 - accuracy: 0.8360\n",
      "Batch 08204: setting learning rate to 0.00019957861635409881.\n",
      "1084/3560 [========>.....................] - ETA: 5:05 - loss: 0.5794 - accuracy: 0.8359\n",
      "Batch 08205: setting learning rate to 0.00019957828935956564.\n",
      "1085/3560 [========>.....................] - ETA: 5:05 - loss: 0.5794 - accuracy: 0.8358\n",
      "Batch 08206: setting learning rate to 0.00019957796223847555.\n",
      "1086/3560 [========>.....................] - ETA: 5:05 - loss: 0.5796 - accuracy: 0.8358\n",
      "Batch 08207: setting learning rate to 0.00019957763499082898.\n",
      "1087/3560 [========>.....................] - ETA: 5:05 - loss: 0.5797 - accuracy: 0.8358\n",
      "Batch 08208: setting learning rate to 0.00019957730761662633.\n",
      "1088/3560 [========>.....................] - ETA: 5:05 - loss: 0.5798 - accuracy: 0.8358\n",
      "Batch 08209: setting learning rate to 0.00019957698011586802.\n",
      "1089/3560 [========>.....................] - ETA: 5:05 - loss: 0.5799 - accuracy: 0.8357\n",
      "Batch 08210: setting learning rate to 0.00019957665248855445.\n",
      "1090/3560 [========>.....................] - ETA: 5:06 - loss: 0.5797 - accuracy: 0.8357\n",
      "Batch 08211: setting learning rate to 0.00019957632473468608.\n",
      "1091/3560 [========>.....................] - ETA: 5:06 - loss: 0.5800 - accuracy: 0.8356\n",
      "Batch 08212: setting learning rate to 0.0001995759968542633.\n",
      "1092/3560 [========>.....................] - ETA: 5:05 - loss: 0.5802 - accuracy: 0.8355\n",
      "Batch 08213: setting learning rate to 0.0001995756688472865.\n",
      "1093/3560 [========>.....................] - ETA: 5:05 - loss: 0.5802 - accuracy: 0.8356\n",
      "Batch 08214: setting learning rate to 0.00019957534071375613.\n",
      "1094/3560 [========>.....................] - ETA: 5:05 - loss: 0.5801 - accuracy: 0.8356\n",
      "Batch 08215: setting learning rate to 0.00019957501245367257.\n",
      "1095/3560 [========>.....................] - ETA: 5:04 - loss: 0.5801 - accuracy: 0.8356\n",
      "Batch 08216: setting learning rate to 0.00019957468406703633.\n",
      "\n",
      "Batch 08217: setting learning rate to 0.00019957435555384773.\n",
      "1097/3560 [========>.....................] - ETA: 5:04 - loss: 0.5803 - accuracy: 0.8355\n",
      "Batch 08218: setting learning rate to 0.00019957402691410717.\n",
      "1098/3560 [========>.....................] - ETA: 5:04 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08219: setting learning rate to 0.00019957369814781518.\n",
      "1099/3560 [========>.....................] - ETA: 5:04 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08220: setting learning rate to 0.0001995733692549721.\n",
      "1100/3560 [========>.....................] - ETA: 5:03 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08221: setting learning rate to 0.00019957304023557833.\n",
      "1101/3560 [========>.....................] - ETA: 5:03 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08222: setting learning rate to 0.00019957271108963438.\n",
      "1102/3560 [========>.....................] - ETA: 5:03 - loss: 0.5805 - accuracy: 0.8355\n",
      "Batch 08223: setting learning rate to 0.0001995723818171406.\n",
      "1103/3560 [========>.....................] - ETA: 5:03 - loss: 0.5808 - accuracy: 0.8355\n",
      "Batch 08224: setting learning rate to 0.0001995720524180974.\n",
      "1104/3560 [========>.....................] - ETA: 5:03 - loss: 0.5809 - accuracy: 0.8355\n",
      "Batch 08225: setting learning rate to 0.00019957172289250522.\n",
      "1105/3560 [========>.....................] - ETA: 5:03 - loss: 0.5808 - accuracy: 0.8355\n",
      "Batch 08226: setting learning rate to 0.00019957139324036448.\n",
      "1106/3560 [========>.....................] - ETA: 5:02 - loss: 0.5807 - accuracy: 0.8355\n",
      "Batch 08227: setting learning rate to 0.0001995710634616756.\n",
      "1107/3560 [========>.....................] - ETA: 5:02 - loss: 0.5807 - accuracy: 0.8355\n",
      "Batch 08228: setting learning rate to 0.00019957073355643897.\n",
      "1108/3560 [========>.....................] - ETA: 5:03 - loss: 0.5807 - accuracy: 0.8355\n",
      "Batch 08229: setting learning rate to 0.00019957040352465506.\n",
      "1109/3560 [========>.....................] - ETA: 5:03 - loss: 0.5807 - accuracy: 0.8356\n",
      "Batch 08230: setting learning rate to 0.00019957007336632426.\n",
      "1110/3560 [========>.....................] - ETA: 5:02 - loss: 0.5809 - accuracy: 0.8355\n",
      "Batch 08231: setting learning rate to 0.000199569743081447.\n",
      "1111/3560 [========>.....................] - ETA: 5:02 - loss: 0.5805 - accuracy: 0.8356\n",
      "Batch 08232: setting learning rate to 0.00019956941267002364.\n",
      "1112/3560 [========>.....................] - ETA: 5:02 - loss: 0.5805 - accuracy: 0.8357\n",
      "Batch 08233: setting learning rate to 0.0001995690821320547.\n",
      "1113/3560 [========>.....................] - ETA: 5:02 - loss: 0.5808 - accuracy: 0.8356\n",
      "Batch 08234: setting learning rate to 0.00019956875146754058.\n",
      "1114/3560 [========>.....................] - ETA: 5:02 - loss: 0.5806 - accuracy: 0.8355\n",
      "Batch 08235: setting learning rate to 0.00019956842067648162.\n",
      "1115/3560 [========>.....................] - ETA: 5:01 - loss: 0.5806 - accuracy: 0.8355\n",
      "Batch 08236: setting learning rate to 0.00019956808975887832.\n",
      "1116/3560 [========>.....................] - ETA: 5:01 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08237: setting learning rate to 0.00019956775871473107.\n",
      "1117/3560 [========>.....................] - ETA: 5:01 - loss: 0.5808 - accuracy: 0.8354\n",
      "Batch 08238: setting learning rate to 0.0001995674275440403.\n",
      "1118/3560 [========>.....................] - ETA: 5:01 - loss: 0.5808 - accuracy: 0.8353\n",
      "Batch 08239: setting learning rate to 0.00019956709624680642.\n",
      "\n",
      "Batch 08240: setting learning rate to 0.00019956676482302984.\n",
      "1120/3560 [========>.....................] - ETA: 5:01 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08241: setting learning rate to 0.000199566433272711.\n",
      "1121/3560 [========>.....................] - ETA: 5:01 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08242: setting learning rate to 0.0001995661015958503.\n",
      "1122/3560 [========>.....................] - ETA: 5:01 - loss: 0.5806 - accuracy: 0.8355\n",
      "Batch 08243: setting learning rate to 0.00019956576979244823.\n",
      "\n",
      "Batch 08244: setting learning rate to 0.00019956543786250514.\n",
      "1124/3560 [========>.....................] - ETA: 5:01 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08245: setting learning rate to 0.0001995651058060215.\n",
      "\n",
      "Batch 08246: setting learning rate to 0.00019956477362299767.\n",
      "1126/3560 [========>.....................] - ETA: 5:00 - loss: 0.5811 - accuracy: 0.8352\n",
      "Batch 08247: setting learning rate to 0.0001995644413134341.\n",
      "1127/3560 [========>.....................] - ETA: 5:00 - loss: 0.5810 - accuracy: 0.8352\n",
      "Batch 08248: setting learning rate to 0.00019956410887733125.\n",
      "1128/3560 [========>.....................] - ETA: 5:00 - loss: 0.5808 - accuracy: 0.8353\n",
      "Batch 08249: setting learning rate to 0.0001995637763146895.\n",
      "1129/3560 [========>.....................] - ETA: 5:00 - loss: 0.5808 - accuracy: 0.8354\n",
      "Batch 08250: setting learning rate to 0.0001995634436255093.\n",
      "1130/3560 [========>.....................] - ETA: 5:00 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08251: setting learning rate to 0.00019956311080979107.\n",
      "1131/3560 [========>.....................] - ETA: 4:59 - loss: 0.5806 - accuracy: 0.8355\n",
      "Batch 08252: setting learning rate to 0.0001995627778675352.\n",
      "1132/3560 [========>.....................] - ETA: 5:00 - loss: 0.5807 - accuracy: 0.8354\n",
      "Batch 08253: setting learning rate to 0.00019956244479874213.\n",
      "1133/3560 [========>.....................] - ETA: 4:59 - loss: 0.5804 - accuracy: 0.8354\n",
      "Batch 08254: setting learning rate to 0.0001995621116034123.\n",
      "1134/3560 [========>.....................] - ETA: 4:59 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08255: setting learning rate to 0.00019956177828154613.\n",
      "\n",
      "Batch 08256: setting learning rate to 0.000199561444833144.\n",
      "1136/3560 [========>.....................] - ETA: 4:59 - loss: 0.5806 - accuracy: 0.8354\n",
      "Batch 08257: setting learning rate to 0.0001995611112582064.\n",
      "1137/3560 [========>.....................] - ETA: 4:59 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08258: setting learning rate to 0.0001995607775567337.\n",
      "1138/3560 [========>.....................] - ETA: 4:59 - loss: 0.5804 - accuracy: 0.8353\n",
      "Batch 08259: setting learning rate to 0.00019956044372872636.\n",
      "\n",
      "Batch 08260: setting learning rate to 0.00019956010977418477.\n",
      "1140/3560 [========>.....................] - ETA: 4:58 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 08261: setting learning rate to 0.0001995597756931094.\n",
      "1141/3560 [========>.....................] - ETA: 4:58 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 08262: setting learning rate to 0.00019955944148550067.\n",
      "1142/3560 [========>.....................] - ETA: 4:58 - loss: 0.5800 - accuracy: 0.8353\n",
      "Batch 08263: setting learning rate to 0.00019955910715135897.\n",
      "1143/3560 [========>.....................] - ETA: 4:58 - loss: 0.5799 - accuracy: 0.8354\n",
      "Batch 08264: setting learning rate to 0.00019955877269068473.\n",
      "1144/3560 [========>.....................] - ETA: 4:58 - loss: 0.5797 - accuracy: 0.8354\n",
      "Batch 08265: setting learning rate to 0.0001995584381034784.\n",
      "1145/3560 [========>.....................] - ETA: 4:58 - loss: 0.5796 - accuracy: 0.8355\n",
      "Batch 08266: setting learning rate to 0.00019955810338974036.\n",
      "1146/3560 [========>.....................] - ETA: 4:58 - loss: 0.5799 - accuracy: 0.8354\n",
      "Batch 08267: setting learning rate to 0.00019955776854947108.\n",
      "\n",
      "Batch 08268: setting learning rate to 0.00019955743358267101.\n",
      "1148/3560 [========>.....................] - ETA: 4:57 - loss: 0.5802 - accuracy: 0.8354\n",
      "Batch 08269: setting learning rate to 0.0001995570984893405.\n",
      "1149/3560 [========>.....................] - ETA: 4:57 - loss: 0.5806 - accuracy: 0.8354\n",
      "Batch 08270: setting learning rate to 0.00019955676326948.\n",
      "1150/3560 [========>.....................] - ETA: 4:57 - loss: 0.5805 - accuracy: 0.8354\n",
      "Batch 08271: setting learning rate to 0.00019955642792308996.\n",
      "1151/3560 [========>.....................] - ETA: 4:57 - loss: 0.5803 - accuracy: 0.8354\n",
      "Batch 08272: setting learning rate to 0.0001995560924501708.\n",
      "1152/3560 [========>.....................] - ETA: 4:57 - loss: 0.5805 - accuracy: 0.8352\n",
      "Batch 08273: setting learning rate to 0.00019955575685072296.\n",
      "1153/3560 [========>.....................] - ETA: 4:57 - loss: 0.5807 - accuracy: 0.8352\n",
      "Batch 08274: setting learning rate to 0.00019955542112474683.\n",
      "1154/3560 [========>.....................] - ETA: 4:57 - loss: 0.5807 - accuracy: 0.8351\n",
      "Batch 08275: setting learning rate to 0.00019955508527224285.\n",
      "1155/3560 [========>.....................] - ETA: 4:57 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08276: setting learning rate to 0.00019955474929321144.\n",
      "1156/3560 [========>.....................] - ETA: 4:56 - loss: 0.5806 - accuracy: 0.8352\n",
      "Batch 08277: setting learning rate to 0.00019955441318765307.\n",
      "1157/3560 [========>.....................] - ETA: 4:56 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08278: setting learning rate to 0.00019955407695556812.\n",
      "1158/3560 [========>.....................] - ETA: 4:56 - loss: 0.5805 - accuracy: 0.8351\n",
      "Batch 08279: setting learning rate to 0.00019955374059695704.\n",
      "1159/3560 [========>.....................] - ETA: 4:56 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08280: setting learning rate to 0.00019955340411182025.\n",
      "1160/3560 [========>.....................] - ETA: 4:57 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08281: setting learning rate to 0.00019955306750015815.\n",
      "1161/3560 [========>.....................] - ETA: 4:56 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08282: setting learning rate to 0.00019955273076197123.\n",
      "\n",
      "Batch 08283: setting learning rate to 0.0001995523938972599.\n",
      "1163/3560 [========>.....................] - ETA: 4:56 - loss: 0.5803 - accuracy: 0.8351\n",
      "Batch 08284: setting learning rate to 0.00019955205690602452.\n",
      "1164/3560 [========>.....................] - ETA: 4:56 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08285: setting learning rate to 0.0001995517197882656.\n",
      "1165/3560 [========>.....................] - ETA: 4:56 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08286: setting learning rate to 0.00019955138254398354.\n",
      "1166/3560 [========>.....................] - ETA: 4:55 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08287: setting learning rate to 0.00019955104517317874.\n",
      "1167/3560 [========>.....................] - ETA: 4:55 - loss: 0.5800 - accuracy: 0.8351\n",
      "Batch 08288: setting learning rate to 0.0001995507076758517.\n",
      "\n",
      "Batch 08289: setting learning rate to 0.00019955037005200277.\n",
      "1169/3560 [========>.....................] - ETA: 4:55 - loss: 0.5804 - accuracy: 0.8351\n",
      "Batch 08290: setting learning rate to 0.00019955003230163242.\n",
      "1170/3560 [========>.....................] - ETA: 4:55 - loss: 0.5805 - accuracy: 0.8350\n",
      "Batch 08291: setting learning rate to 0.0001995496944247411.\n",
      "1171/3560 [========>.....................] - ETA: 4:55 - loss: 0.5805 - accuracy: 0.8350\n",
      "Batch 08292: setting learning rate to 0.0001995493564213292.\n",
      "1172/3560 [========>.....................] - ETA: 4:54 - loss: 0.5803 - accuracy: 0.8351\n",
      "Batch 08293: setting learning rate to 0.00019954901829139713.\n",
      "1173/3560 [========>.....................] - ETA: 4:54 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08294: setting learning rate to 0.0001995486800349454.\n",
      "1174/3560 [========>.....................] - ETA: 4:54 - loss: 0.5802 - accuracy: 0.8351\n",
      "Batch 08295: setting learning rate to 0.0001995483416519744.\n",
      "\n",
      "Batch 08296: setting learning rate to 0.00019954800314248453.\n",
      "1176/3560 [========>.....................] - ETA: 4:54 - loss: 0.5803 - accuracy: 0.8352\n",
      "Batch 08297: setting learning rate to 0.00019954766450647622.\n",
      "1177/3560 [========>.....................] - ETA: 4:54 - loss: 0.5803 - accuracy: 0.8351\n",
      "Batch 08298: setting learning rate to 0.0001995473257439499.\n",
      "1178/3560 [========>.....................] - ETA: 4:54 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08299: setting learning rate to 0.0001995469868549061.\n",
      "1179/3560 [========>.....................] - ETA: 4:55 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08300: setting learning rate to 0.00019954664783934515.\n",
      "1180/3560 [========>.....................] - ETA: 4:54 - loss: 0.5804 - accuracy: 0.8352\n",
      "Batch 08301: setting learning rate to 0.00019954630869726747.\n",
      "1181/3560 [========>.....................] - ETA: 4:54 - loss: 0.5803 - accuracy: 0.8353\n",
      "Batch 08302: setting learning rate to 0.00019954596942867357.\n",
      "1182/3560 [========>.....................] - ETA: 4:54 - loss: 0.5802 - accuracy: 0.8353\n",
      "Batch 08303: setting learning rate to 0.00019954563003356381.\n",
      "1183/3560 [========>.....................] - ETA: 4:54 - loss: 0.5802 - accuracy: 0.8352\n",
      "Batch 08304: setting learning rate to 0.00019954529051193864.\n",
      "1184/3560 [========>.....................] - ETA: 4:53 - loss: 0.5799 - accuracy: 0.8353\n",
      "Batch 08305: setting learning rate to 0.00019954495086379852.\n",
      "1185/3560 [========>.....................] - ETA: 4:53 - loss: 0.5797 - accuracy: 0.8353\n",
      "Batch 08306: setting learning rate to 0.00019954461108914387.\n",
      "1186/3560 [========>.....................] - ETA: 4:53 - loss: 0.5798 - accuracy: 0.8353\n",
      "Batch 08307: setting learning rate to 0.00019954427118797508.\n",
      "\n",
      "Batch 08308: setting learning rate to 0.00019954393116029264.\n",
      "1188/3560 [=========>....................] - ETA: 4:53 - loss: 0.5800 - accuracy: 0.8352\n",
      "Batch 08309: setting learning rate to 0.00019954359100609695.\n",
      "1189/3560 [=========>....................] - ETA: 4:53 - loss: 0.5801 - accuracy: 0.8351\n",
      "Batch 08310: setting learning rate to 0.00019954325072538845.\n",
      "1190/3560 [=========>....................] - ETA: 4:53 - loss: 0.5799 - accuracy: 0.8352\n",
      "Batch 08311: setting learning rate to 0.0001995429103181676.\n",
      "1191/3560 [=========>....................] - ETA: 4:52 - loss: 0.5797 - accuracy: 0.8353\n",
      "Batch 08312: setting learning rate to 0.00019954256978443478.\n",
      "1192/3560 [=========>....................] - ETA: 4:52 - loss: 0.5796 - accuracy: 0.8353\n",
      "Batch 08313: setting learning rate to 0.00019954222912419044.\n",
      "1193/3560 [=========>....................] - ETA: 4:52 - loss: 0.5796 - accuracy: 0.8353\n",
      "Batch 08314: setting learning rate to 0.00019954188833743502.\n",
      "1194/3560 [=========>....................] - ETA: 4:52 - loss: 0.5797 - accuracy: 0.8352\n",
      "Batch 08315: setting learning rate to 0.00019954154742416895.\n",
      "1195/3560 [=========>....................] - ETA: 4:52 - loss: 0.5797 - accuracy: 0.8352\n",
      "Batch 08316: setting learning rate to 0.00019954120638439272.\n",
      "1196/3560 [=========>....................] - ETA: 4:52 - loss: 0.5796 - accuracy: 0.8353\n",
      "Batch 08317: setting learning rate to 0.00019954086521810664.\n",
      "\n",
      "Batch 08318: setting learning rate to 0.00019954052392531123.\n",
      "1198/3560 [=========>....................] - ETA: 4:51 - loss: 0.5794 - accuracy: 0.8353\n",
      "Batch 08319: setting learning rate to 0.00019954018250600695.\n",
      "1199/3560 [=========>....................] - ETA: 4:51 - loss: 0.5793 - accuracy: 0.8353\n",
      "Batch 08320: setting learning rate to 0.00019953984096019416.\n",
      "1200/3560 [=========>....................] - ETA: 4:51 - loss: 0.5792 - accuracy: 0.8354\n",
      "Batch 08321: setting learning rate to 0.00019953949928787332.\n",
      "1201/3560 [=========>....................] - ETA: 4:51 - loss: 0.5792 - accuracy: 0.8354\n",
      "Batch 08322: setting learning rate to 0.00019953915748904488.\n",
      "1202/3560 [=========>....................] - ETA: 4:51 - loss: 0.5791 - accuracy: 0.8355\n",
      "Batch 08323: setting learning rate to 0.00019953881556370929.\n",
      "1203/3560 [=========>....................] - ETA: 4:51 - loss: 0.5789 - accuracy: 0.8356\n",
      "Batch 08324: setting learning rate to 0.00019953847351186692.\n",
      "1204/3560 [=========>....................] - ETA: 4:50 - loss: 0.5790 - accuracy: 0.8356\n",
      "Batch 08325: setting learning rate to 0.00019953813133351828.\n",
      "1205/3560 [=========>....................] - ETA: 4:51 - loss: 0.5794 - accuracy: 0.8357\n",
      "Batch 08326: setting learning rate to 0.00019953778902866373.\n",
      "1206/3560 [=========>....................] - ETA: 4:51 - loss: 0.5792 - accuracy: 0.8358\n",
      "Batch 08327: setting learning rate to 0.00019953744659730375.\n",
      "1207/3560 [=========>....................] - ETA: 4:51 - loss: 0.5790 - accuracy: 0.8359\n",
      "Batch 08328: setting learning rate to 0.0001995371040394388.\n",
      "\n",
      "Batch 08329: setting learning rate to 0.00019953676135506926.\n",
      "1209/3560 [=========>....................] - ETA: 4:50 - loss: 0.5793 - accuracy: 0.8359\n",
      "Batch 08330: setting learning rate to 0.0001995364185441956.\n",
      "\n",
      "Batch 08331: setting learning rate to 0.00019953607560681827.\n",
      "1211/3560 [=========>....................] - ETA: 4:50 - loss: 0.5791 - accuracy: 0.8360\n",
      "Batch 08332: setting learning rate to 0.00019953573254293764.\n",
      "\n",
      "Batch 08333: setting learning rate to 0.0001995353893525542.\n",
      "1213/3560 [=========>....................] - ETA: 4:49 - loss: 0.5790 - accuracy: 0.8359\n",
      "Batch 08334: setting learning rate to 0.00019953504603566837.\n",
      "1214/3560 [=========>....................] - ETA: 4:49 - loss: 0.5792 - accuracy: 0.8358\n",
      "Batch 08335: setting learning rate to 0.0001995347025922806.\n",
      "\n",
      "Batch 08336: setting learning rate to 0.00019953435902239132.\n",
      "1216/3560 [=========>....................] - ETA: 4:49 - loss: 0.5793 - accuracy: 0.8357\n",
      "Batch 08337: setting learning rate to 0.00019953401532600093.\n",
      "1217/3560 [=========>....................] - ETA: 4:49 - loss: 0.5793 - accuracy: 0.8358\n",
      "Batch 08338: setting learning rate to 0.00019953367150310993.\n",
      "1218/3560 [=========>....................] - ETA: 4:49 - loss: 0.5794 - accuracy: 0.8357\n",
      "Batch 08339: setting learning rate to 0.00019953332755371874.\n",
      "1219/3560 [=========>....................] - ETA: 4:49 - loss: 0.5794 - accuracy: 0.8357\n",
      "Batch 08340: setting learning rate to 0.00019953298347782775.\n",
      "1220/3560 [=========>....................] - ETA: 4:48 - loss: 0.5793 - accuracy: 0.8357\n",
      "Batch 08341: setting learning rate to 0.00019953263927543745.\n",
      "1221/3560 [=========>....................] - ETA: 4:49 - loss: 0.5793 - accuracy: 0.8356\n",
      "Batch 08342: setting learning rate to 0.00019953229494654826.\n",
      "1222/3560 [=========>....................] - ETA: 4:49 - loss: 0.5791 - accuracy: 0.8357\n",
      "Batch 08343: setting learning rate to 0.00019953195049116063.\n",
      "\n",
      "Batch 08344: setting learning rate to 0.00019953160590927495.\n",
      "1224/3560 [=========>....................] - ETA: 4:49 - loss: 0.5790 - accuracy: 0.8358\n",
      "Batch 08345: setting learning rate to 0.00019953126120089172.\n",
      "1225/3560 [=========>....................] - ETA: 4:49 - loss: 0.5789 - accuracy: 0.8358\n",
      "Batch 08346: setting learning rate to 0.00019953091636601132.\n",
      "1226/3560 [=========>....................] - ETA: 4:48 - loss: 0.5790 - accuracy: 0.8359\n",
      "Batch 08347: setting learning rate to 0.00019953057140463426.\n",
      "1227/3560 [=========>....................] - ETA: 4:48 - loss: 0.5791 - accuracy: 0.8358\n",
      "Batch 08348: setting learning rate to 0.00019953022631676091.\n",
      "1228/3560 [=========>....................] - ETA: 4:48 - loss: 0.5792 - accuracy: 0.8358\n",
      "Batch 08349: setting learning rate to 0.00019952988110239175.\n",
      "1229/3560 [=========>....................] - ETA: 4:48 - loss: 0.5792 - accuracy: 0.8357\n",
      "Batch 08350: setting learning rate to 0.00019952953576152718.\n",
      "1230/3560 [=========>....................] - ETA: 4:47 - loss: 0.5791 - accuracy: 0.8357\n",
      "Batch 08351: setting learning rate to 0.00019952919029416768.\n",
      "1231/3560 [=========>....................] - ETA: 4:47 - loss: 0.5790 - accuracy: 0.8357\n",
      "Batch 08352: setting learning rate to 0.0001995288447003137.\n",
      "1232/3560 [=========>....................] - ETA: 4:47 - loss: 0.5790 - accuracy: 0.8357\n",
      "Batch 08353: setting learning rate to 0.0001995284989799656.\n",
      "1233/3560 [=========>....................] - ETA: 4:47 - loss: 0.5790 - accuracy: 0.8357\n",
      "Batch 08354: setting learning rate to 0.0001995281531331239.\n",
      "1234/3560 [=========>....................] - ETA: 4:47 - loss: 0.5791 - accuracy: 0.8357\n",
      "Batch 08355: setting learning rate to 0.00019952780715978897.\n",
      "1235/3560 [=========>....................] - ETA: 4:47 - loss: 0.5791 - accuracy: 0.8356\n",
      "Batch 08356: setting learning rate to 0.00019952746105996133.\n",
      "\n",
      "Batch 08357: setting learning rate to 0.0001995271148336414.\n",
      "1237/3560 [=========>....................] - ETA: 4:47 - loss: 0.5788 - accuracy: 0.8357\n",
      "Batch 08358: setting learning rate to 0.00019952676848082956.\n",
      "1238/3560 [=========>....................] - ETA: 4:47 - loss: 0.5786 - accuracy: 0.8358\n",
      "Batch 08359: setting learning rate to 0.0001995264220015263.\n",
      "1239/3560 [=========>....................] - ETA: 4:47 - loss: 0.5785 - accuracy: 0.8358\n",
      "Batch 08360: setting learning rate to 0.00019952607539573208.\n",
      "1240/3560 [=========>....................] - ETA: 4:47 - loss: 0.5786 - accuracy: 0.8358\n",
      "Batch 08361: setting learning rate to 0.00019952572866344727.\n",
      "1241/3560 [=========>....................] - ETA: 4:47 - loss: 0.5786 - accuracy: 0.8358\n",
      "Batch 08362: setting learning rate to 0.00019952538180467236.\n",
      "1242/3560 [=========>....................] - ETA: 4:46 - loss: 0.5787 - accuracy: 0.8359\n",
      "Batch 08363: setting learning rate to 0.0001995250348194078.\n",
      "1243/3560 [=========>....................] - ETA: 4:46 - loss: 0.5786 - accuracy: 0.8359\n",
      "Batch 08364: setting learning rate to 0.000199524687707654.\n",
      "1244/3560 [=========>....................] - ETA: 4:46 - loss: 0.5785 - accuracy: 0.8360\n",
      "Batch 08365: setting learning rate to 0.00019952434046941142.\n",
      "1245/3560 [=========>....................] - ETA: 4:46 - loss: 0.5788 - accuracy: 0.8360\n",
      "Batch 08366: setting learning rate to 0.00019952399310468048.\n",
      "1246/3560 [=========>....................] - ETA: 4:46 - loss: 0.5787 - accuracy: 0.8360\n",
      "Batch 08367: setting learning rate to 0.00019952364561346165.\n",
      "1247/3560 [=========>....................] - ETA: 4:45 - loss: 0.5788 - accuracy: 0.8360\n",
      "Batch 08368: setting learning rate to 0.00019952329799575538.\n",
      "1248/3560 [=========>....................] - ETA: 4:45 - loss: 0.5789 - accuracy: 0.8360\n",
      "Batch 08369: setting learning rate to 0.00019952295025156208.\n",
      "1249/3560 [=========>....................] - ETA: 4:45 - loss: 0.5789 - accuracy: 0.8360\n",
      "Batch 08370: setting learning rate to 0.00019952260238088217.\n",
      "1250/3560 [=========>....................] - ETA: 4:46 - loss: 0.5788 - accuracy: 0.8360\n",
      "Batch 08371: setting learning rate to 0.00019952225438371618.\n",
      "1251/3560 [=========>....................] - ETA: 4:46 - loss: 0.5787 - accuracy: 0.8360\n",
      "Batch 08372: setting learning rate to 0.00019952190626006447.\n",
      "1252/3560 [=========>....................] - ETA: 4:46 - loss: 0.5788 - accuracy: 0.8359\n",
      "Batch 08373: setting learning rate to 0.0001995215580099275.\n",
      "1253/3560 [=========>....................] - ETA: 4:46 - loss: 0.5790 - accuracy: 0.8358\n",
      "Batch 08374: setting learning rate to 0.00019952120963330573.\n",
      "1254/3560 [=========>....................] - ETA: 4:45 - loss: 0.5788 - accuracy: 0.8359\n",
      "Batch 08375: setting learning rate to 0.00019952086113019958.\n",
      "1255/3560 [=========>....................] - ETA: 4:45 - loss: 0.5787 - accuracy: 0.8359\n",
      "Batch 08376: setting learning rate to 0.00019952051250060954.\n",
      "\n",
      "Batch 08377: setting learning rate to 0.00019952016374453598.\n",
      "1257/3560 [=========>....................] - ETA: 4:45 - loss: 0.5787 - accuracy: 0.8359\n",
      "Batch 08378: setting learning rate to 0.0001995198148619794.\n",
      "1258/3560 [=========>....................] - ETA: 4:45 - loss: 0.5785 - accuracy: 0.8359\n",
      "Batch 08379: setting learning rate to 0.0001995194658529403.\n",
      "1259/3560 [=========>....................] - ETA: 4:45 - loss: 0.5785 - accuracy: 0.8360\n",
      "Batch 08380: setting learning rate to 0.00019951911671741893.\n",
      "1260/3560 [=========>....................] - ETA: 4:45 - loss: 0.5785 - accuracy: 0.8360\n",
      "Batch 08381: setting learning rate to 0.00019951876745541593.\n",
      "1261/3560 [=========>....................] - ETA: 4:44 - loss: 0.5785 - accuracy: 0.8360\n",
      "Batch 08382: setting learning rate to 0.00019951841806693167.\n",
      "1262/3560 [=========>....................] - ETA: 4:44 - loss: 0.5784 - accuracy: 0.8361\n",
      "Batch 08383: setting learning rate to 0.00019951806855196655.\n",
      "1263/3560 [=========>....................] - ETA: 4:44 - loss: 0.5783 - accuracy: 0.8361\n",
      "Batch 08384: setting learning rate to 0.00019951771891052111.\n",
      "\n",
      "Batch 08385: setting learning rate to 0.0001995173691425957.\n",
      "1265/3560 [=========>....................] - ETA: 4:44 - loss: 0.5781 - accuracy: 0.8361\n",
      "Batch 08386: setting learning rate to 0.00019951701924819082.\n",
      "1266/3560 [=========>....................] - ETA: 4:44 - loss: 0.5783 - accuracy: 0.8361\n",
      "Batch 08387: setting learning rate to 0.0001995166692273069.\n",
      "\n",
      "Batch 08388: setting learning rate to 0.00019951631907994438.\n",
      "1268/3560 [=========>....................] - ETA: 4:44 - loss: 0.5784 - accuracy: 0.8362\n",
      "Batch 08389: setting learning rate to 0.00019951596880610372.\n",
      "1269/3560 [=========>....................] - ETA: 4:44 - loss: 0.5787 - accuracy: 0.8361\n",
      "Batch 08390: setting learning rate to 0.00019951561840578536.\n",
      "\n",
      "Batch 08391: setting learning rate to 0.00019951526787898973.\n",
      "1271/3560 [=========>....................] - ETA: 4:43 - loss: 0.5784 - accuracy: 0.8362\n",
      "Batch 08392: setting learning rate to 0.0001995149172257173.\n",
      "1272/3560 [=========>....................] - ETA: 4:44 - loss: 0.5783 - accuracy: 0.8362\n",
      "Batch 08393: setting learning rate to 0.00019951456644596847.\n",
      "1273/3560 [=========>....................] - ETA: 4:43 - loss: 0.5787 - accuracy: 0.8361\n",
      "Batch 08394: setting learning rate to 0.00019951421553974377.\n",
      "\n",
      "Batch 08395: setting learning rate to 0.00019951386450704357.\n",
      "1275/3560 [=========>....................] - ETA: 4:43 - loss: 0.5787 - accuracy: 0.8361\n",
      "Batch 08396: setting learning rate to 0.00019951351334786832.\n",
      "1276/3560 [=========>....................] - ETA: 4:43 - loss: 0.5787 - accuracy: 0.8361\n",
      "Batch 08397: setting learning rate to 0.0001995131620622185.\n",
      "1277/3560 [=========>....................] - ETA: 4:43 - loss: 0.5785 - accuracy: 0.8361\n",
      "Batch 08398: setting learning rate to 0.00019951281065009455.\n",
      "1278/3560 [=========>....................] - ETA: 4:43 - loss: 0.5787 - accuracy: 0.8359\n",
      "Batch 08399: setting learning rate to 0.00019951245911149692.\n",
      "1279/3560 [=========>....................] - ETA: 4:42 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 08400: setting learning rate to 0.00019951210744642602.\n",
      "\n",
      "Batch 08401: setting learning rate to 0.00019951175565488234.\n",
      "1281/3560 [=========>....................] - ETA: 4:42 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 08402: setting learning rate to 0.0001995114037368663.\n",
      "1282/3560 [=========>....................] - ETA: 4:43 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 08403: setting learning rate to 0.00019951105169237839.\n",
      "1283/3560 [=========>....................] - ETA: 4:42 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 08404: setting learning rate to 0.00019951069952141897.\n",
      "\n",
      "Batch 08405: setting learning rate to 0.00019951034722398857.\n",
      "1285/3560 [=========>....................] - ETA: 4:42 - loss: 0.5786 - accuracy: 0.8359\n",
      "Batch 08406: setting learning rate to 0.00019950999480008763.\n",
      "\n",
      "Batch 08407: setting learning rate to 0.00019950964224971655.\n",
      "1287/3560 [=========>....................] - ETA: 4:42 - loss: 0.5785 - accuracy: 0.8359\n",
      "Batch 08408: setting learning rate to 0.0001995092895728758.\n",
      "\n",
      "Batch 08409: setting learning rate to 0.00019950893676956585.\n",
      "1289/3560 [=========>....................] - ETA: 4:41 - loss: 0.5787 - accuracy: 0.8358\n",
      "Batch 08410: setting learning rate to 0.00019950858383978716.\n",
      "1290/3560 [=========>....................] - ETA: 4:41 - loss: 0.5786 - accuracy: 0.8359\n",
      "Batch 08411: setting learning rate to 0.00019950823078354013.\n",
      "1291/3560 [=========>....................] - ETA: 4:41 - loss: 0.5783 - accuracy: 0.8360\n",
      "Batch 08412: setting learning rate to 0.00019950787760082523.\n",
      "1292/3560 [=========>....................] - ETA: 4:41 - loss: 0.5782 - accuracy: 0.8361\n",
      "Batch 08413: setting learning rate to 0.00019950752429164287.\n",
      "\n",
      "Batch 08414: setting learning rate to 0.0001995071708559936.\n",
      "1294/3560 [=========>....................] - ETA: 4:41 - loss: 0.5781 - accuracy: 0.8361\n",
      "Batch 08415: setting learning rate to 0.0001995068172938778.\n",
      "1295/3560 [=========>....................] - ETA: 4:40 - loss: 0.5780 - accuracy: 0.8361\n",
      "Batch 08416: setting learning rate to 0.0001995064636052959.\n",
      "1296/3560 [=========>....................] - ETA: 4:40 - loss: 0.5779 - accuracy: 0.8362\n",
      "Batch 08417: setting learning rate to 0.00019950610979024838.\n",
      "1297/3560 [=========>....................] - ETA: 4:40 - loss: 0.5778 - accuracy: 0.8362\n",
      "Batch 08418: setting learning rate to 0.0001995057558487357.\n",
      "\n",
      "Batch 08419: setting learning rate to 0.00019950540178075826.\n",
      "1299/3560 [=========>....................] - ETA: 4:40 - loss: 0.5778 - accuracy: 0.8363\n",
      "Batch 08420: setting learning rate to 0.00019950504758631658.\n",
      "1300/3560 [=========>....................] - ETA: 4:40 - loss: 0.5779 - accuracy: 0.8363\n",
      "Batch 08421: setting learning rate to 0.00019950469326541107.\n",
      "1301/3560 [=========>....................] - ETA: 4:40 - loss: 0.5778 - accuracy: 0.8363\n",
      "Batch 08422: setting learning rate to 0.00019950433881804218.\n",
      "1302/3560 [=========>....................] - ETA: 4:40 - loss: 0.5780 - accuracy: 0.8363\n",
      "Batch 08423: setting learning rate to 0.00019950398424421038.\n",
      "1303/3560 [=========>....................] - ETA: 4:40 - loss: 0.5779 - accuracy: 0.8363\n",
      "Batch 08424: setting learning rate to 0.0001995036295439161.\n",
      "1304/3560 [=========>....................] - ETA: 4:40 - loss: 0.5777 - accuracy: 0.8364\n",
      "Batch 08425: setting learning rate to 0.0001995032747171598.\n",
      "\n",
      "Batch 08426: setting learning rate to 0.00019950291976394193.\n",
      "1306/3560 [==========>...................] - ETA: 4:39 - loss: 0.5776 - accuracy: 0.8364\n",
      "Batch 08427: setting learning rate to 0.00019950256468426295.\n",
      "\n",
      "Batch 08428: setting learning rate to 0.00019950220947812327.\n",
      "1308/3560 [==========>...................] - ETA: 4:39 - loss: 0.5773 - accuracy: 0.8365\n",
      "Batch 08429: setting learning rate to 0.0001995018541455234.\n",
      "1309/3560 [==========>...................] - ETA: 4:39 - loss: 0.5772 - accuracy: 0.8366\n",
      "Batch 08430: setting learning rate to 0.00019950149868646375.\n",
      "1310/3560 [==========>...................] - ETA: 4:39 - loss: 0.5773 - accuracy: 0.8366\n",
      "Batch 08431: setting learning rate to 0.00019950114310094476.\n",
      "\n",
      "Batch 08432: setting learning rate to 0.00019950078738896696.\n",
      "1312/3560 [==========>...................] - ETA: 4:39 - loss: 0.5772 - accuracy: 0.8365\n",
      "Batch 08433: setting learning rate to 0.00019950043155053074.\n",
      "1313/3560 [==========>...................] - ETA: 4:38 - loss: 0.5771 - accuracy: 0.8366\n",
      "Batch 08434: setting learning rate to 0.00019950007558563654.\n",
      "1314/3560 [==========>...................] - ETA: 4:38 - loss: 0.5771 - accuracy: 0.8366\n",
      "Batch 08435: setting learning rate to 0.00019949971949428485.\n",
      "1315/3560 [==========>...................] - ETA: 4:38 - loss: 0.5770 - accuracy: 0.8366\n",
      "Batch 08436: setting learning rate to 0.0001994993632764761.\n",
      "1316/3560 [==========>...................] - ETA: 4:38 - loss: 0.5769 - accuracy: 0.8367\n",
      "Batch 08437: setting learning rate to 0.00019949900693221078.\n",
      "1317/3560 [==========>...................] - ETA: 4:38 - loss: 0.5769 - accuracy: 0.8367\n",
      "Batch 08438: setting learning rate to 0.00019949865046148927.\n",
      "1318/3560 [==========>...................] - ETA: 4:38 - loss: 0.5768 - accuracy: 0.8367\n",
      "Batch 08439: setting learning rate to 0.00019949829386431208.\n",
      "1319/3560 [==========>...................] - ETA: 4:38 - loss: 0.5768 - accuracy: 0.8367\n",
      "Batch 08440: setting learning rate to 0.00019949793714067968.\n",
      "1320/3560 [==========>...................] - ETA: 4:38 - loss: 0.5771 - accuracy: 0.8367\n",
      "Batch 08441: setting learning rate to 0.00019949758029059246.\n",
      "1321/3560 [==========>...................] - ETA: 4:37 - loss: 0.5770 - accuracy: 0.8367\n",
      "Batch 08442: setting learning rate to 0.0001994972233140509.\n",
      "1322/3560 [==========>...................] - ETA: 4:37 - loss: 0.5769 - accuracy: 0.8367\n",
      "Batch 08443: setting learning rate to 0.00019949686621105548.\n",
      "\n",
      "Batch 08444: setting learning rate to 0.00019949650898160663.\n",
      "1324/3560 [==========>...................] - ETA: 4:37 - loss: 0.5773 - accuracy: 0.8366\n",
      "Batch 08445: setting learning rate to 0.00019949615162570482.\n",
      "1325/3560 [==========>...................] - ETA: 4:37 - loss: 0.5772 - accuracy: 0.8366\n",
      "Batch 08446: setting learning rate to 0.00019949579414335047.\n",
      "1326/3560 [==========>...................] - ETA: 4:37 - loss: 0.5774 - accuracy: 0.8367\n",
      "Batch 08447: setting learning rate to 0.00019949543653454405.\n",
      "1327/3560 [==========>...................] - ETA: 4:37 - loss: 0.5775 - accuracy: 0.8367\n",
      "Batch 08448: setting learning rate to 0.00019949507879928605.\n",
      "1328/3560 [==========>...................] - ETA: 4:37 - loss: 0.5775 - accuracy: 0.8366\n",
      "Batch 08449: setting learning rate to 0.00019949472093757687.\n",
      "\n",
      "Batch 08450: setting learning rate to 0.00019949436294941698.\n",
      "1330/3560 [==========>...................] - ETA: 4:37 - loss: 0.5780 - accuracy: 0.8364\n",
      "Batch 08451: setting learning rate to 0.00019949400483480688.\n",
      "1331/3560 [==========>...................] - ETA: 4:36 - loss: 0.5780 - accuracy: 0.8364\n",
      "Batch 08452: setting learning rate to 0.000199493646593747.\n",
      "1332/3560 [==========>...................] - ETA: 4:36 - loss: 0.5779 - accuracy: 0.8363\n",
      "Batch 08453: setting learning rate to 0.00019949328822623774.\n",
      "1333/3560 [==========>...................] - ETA: 4:36 - loss: 0.5778 - accuracy: 0.8364\n",
      "Batch 08454: setting learning rate to 0.00019949292973227962.\n",
      "1334/3560 [==========>...................] - ETA: 4:36 - loss: 0.5778 - accuracy: 0.8363\n",
      "Batch 08455: setting learning rate to 0.0001994925711118731.\n",
      "1335/3560 [==========>...................] - ETA: 4:36 - loss: 0.5776 - accuracy: 0.8364\n",
      "Batch 08456: setting learning rate to 0.00019949221236501862.\n",
      "1336/3560 [==========>...................] - ETA: 4:36 - loss: 0.5776 - accuracy: 0.8363\n",
      "Batch 08457: setting learning rate to 0.00019949185349171658.\n",
      "1337/3560 [==========>...................] - ETA: 4:36 - loss: 0.5775 - accuracy: 0.8363\n",
      "Batch 08458: setting learning rate to 0.00019949149449196752.\n",
      "1338/3560 [==========>...................] - ETA: 4:36 - loss: 0.5775 - accuracy: 0.8362\n",
      "Batch 08459: setting learning rate to 0.00019949113536577183.\n",
      "1339/3560 [==========>...................] - ETA: 4:36 - loss: 0.5772 - accuracy: 0.8363\n",
      "Batch 08460: setting learning rate to 0.00019949077611313004.\n",
      "1340/3560 [==========>...................] - ETA: 4:35 - loss: 0.5771 - accuracy: 0.8363\n",
      "Batch 08461: setting learning rate to 0.0001994904167340425.\n",
      "1341/3560 [==========>...................] - ETA: 4:35 - loss: 0.5772 - accuracy: 0.8363\n",
      "Batch 08462: setting learning rate to 0.0001994900572285098.\n",
      "1342/3560 [==========>...................] - ETA: 4:35 - loss: 0.5772 - accuracy: 0.8363\n",
      "Batch 08463: setting learning rate to 0.00019948969759653228.\n",
      "1343/3560 [==========>...................] - ETA: 4:35 - loss: 0.5776 - accuracy: 0.8363\n",
      "Batch 08464: setting learning rate to 0.00019948933783811045.\n",
      "\n",
      "Batch 08465: setting learning rate to 0.0001994889779532448.\n",
      "1345/3560 [==========>...................] - ETA: 4:35 - loss: 0.5776 - accuracy: 0.8363\n",
      "Batch 08466: setting learning rate to 0.0001994886179419357.\n",
      "1346/3560 [==========>...................] - ETA: 4:35 - loss: 0.5776 - accuracy: 0.8363\n",
      "Batch 08467: setting learning rate to 0.0001994882578041837.\n",
      "1347/3560 [==========>...................] - ETA: 4:34 - loss: 0.5777 - accuracy: 0.8363\n",
      "Batch 08468: setting learning rate to 0.0001994878975399892.\n",
      "1348/3560 [==========>...................] - ETA: 4:34 - loss: 0.5776 - accuracy: 0.8364\n",
      "Batch 08469: setting learning rate to 0.00019948753714935268.\n",
      "\n",
      "Batch 08470: setting learning rate to 0.00019948717663227457.\n",
      "1350/3560 [==========>...................] - ETA: 4:34 - loss: 0.5775 - accuracy: 0.8365\n",
      "Batch 08471: setting learning rate to 0.00019948681598875535.\n",
      "\n",
      "Batch 08472: setting learning rate to 0.0001994864552187955.\n",
      "1352/3560 [==========>...................] - ETA: 4:34 - loss: 0.5775 - accuracy: 0.8364\n",
      "Batch 08473: setting learning rate to 0.00019948609432239543.\n",
      "1353/3560 [==========>...................] - ETA: 4:34 - loss: 0.5773 - accuracy: 0.8365\n",
      "Batch 08474: setting learning rate to 0.00019948573329955563.\n",
      "1354/3560 [==========>...................] - ETA: 4:34 - loss: 0.5773 - accuracy: 0.8364\n",
      "Batch 08475: setting learning rate to 0.00019948537215027656.\n",
      "1355/3560 [==========>...................] - ETA: 4:33 - loss: 0.5772 - accuracy: 0.8365\n",
      "Batch 08476: setting learning rate to 0.00019948501087455864.\n",
      "1356/3560 [==========>...................] - ETA: 4:33 - loss: 0.5772 - accuracy: 0.8365\n",
      "Batch 08477: setting learning rate to 0.0001994846494724024.\n",
      "1357/3560 [==========>...................] - ETA: 4:33 - loss: 0.5773 - accuracy: 0.8364\n",
      "Batch 08478: setting learning rate to 0.00019948428794380827.\n",
      "1358/3560 [==========>...................] - ETA: 4:33 - loss: 0.5772 - accuracy: 0.8365\n",
      "Batch 08479: setting learning rate to 0.00019948392628877667.\n",
      "1359/3560 [==========>...................] - ETA: 4:33 - loss: 0.5771 - accuracy: 0.8366\n",
      "Batch 08480: setting learning rate to 0.0001994835645073081.\n",
      "1360/3560 [==========>...................] - ETA: 4:33 - loss: 0.5771 - accuracy: 0.8366\n",
      "Batch 08481: setting learning rate to 0.000199483202599403.\n",
      "1361/3560 [==========>...................] - ETA: 4:33 - loss: 0.5768 - accuracy: 0.8367\n",
      "Batch 08482: setting learning rate to 0.00019948284056506185.\n",
      "1362/3560 [==========>...................] - ETA: 4:33 - loss: 0.5773 - accuracy: 0.8365\n",
      "Batch 08483: setting learning rate to 0.0001994824784042851.\n",
      "1363/3560 [==========>...................] - ETA: 4:33 - loss: 0.5772 - accuracy: 0.8366\n",
      "Batch 08484: setting learning rate to 0.00019948211611707322.\n",
      "1364/3560 [==========>...................] - ETA: 4:33 - loss: 0.5772 - accuracy: 0.8366\n",
      "Batch 08485: setting learning rate to 0.00019948175370342663.\n",
      "1365/3560 [==========>...................] - ETA: 4:33 - loss: 0.5771 - accuracy: 0.8367\n",
      "Batch 08486: setting learning rate to 0.00019948139116334585.\n",
      "\n",
      "Batch 08487: setting learning rate to 0.0001994810284968313.\n",
      "1367/3560 [==========>...................] - ETA: 4:32 - loss: 0.5770 - accuracy: 0.8367\n",
      "Batch 08488: setting learning rate to 0.00019948066570388346.\n",
      "1368/3560 [==========>...................] - ETA: 4:32 - loss: 0.5772 - accuracy: 0.8367\n",
      "Batch 08489: setting learning rate to 0.00019948030278450277.\n",
      "1369/3560 [==========>...................] - ETA: 4:32 - loss: 0.5771 - accuracy: 0.8367\n",
      "Batch 08490: setting learning rate to 0.00019947993973868972.\n",
      "1370/3560 [==========>...................] - ETA: 4:32 - loss: 0.5772 - accuracy: 0.8367\n",
      "Batch 08491: setting learning rate to 0.00019947957656644473.\n",
      "1371/3560 [==========>...................] - ETA: 4:32 - loss: 0.5771 - accuracy: 0.8367\n",
      "Batch 08492: setting learning rate to 0.00019947921326776832.\n",
      "1372/3560 [==========>...................] - ETA: 4:31 - loss: 0.5770 - accuracy: 0.8366\n",
      "Batch 08493: setting learning rate to 0.00019947884984266093.\n",
      "\n",
      "Batch 08494: setting learning rate to 0.000199478486291123.\n",
      "1374/3560 [==========>...................] - ETA: 4:31 - loss: 0.5768 - accuracy: 0.8367\n",
      "Batch 08495: setting learning rate to 0.00019947812261315496.\n",
      "1375/3560 [==========>...................] - ETA: 4:31 - loss: 0.5771 - accuracy: 0.8367\n",
      "Batch 08496: setting learning rate to 0.00019947775880875735.\n",
      "1376/3560 [==========>...................] - ETA: 4:31 - loss: 0.5770 - accuracy: 0.8367\n",
      "Batch 08497: setting learning rate to 0.00019947739487793058.\n",
      "\n",
      "Batch 08498: setting learning rate to 0.00019947703082067516.\n",
      "1378/3560 [==========>...................] - ETA: 4:31 - loss: 0.5767 - accuracy: 0.8368\n",
      "Batch 08499: setting learning rate to 0.00019947666663699148.\n",
      "1379/3560 [==========>...................] - ETA: 4:31 - loss: 0.5767 - accuracy: 0.8368\n",
      "Batch 08500: setting learning rate to 0.0001994763023268801.\n",
      "1380/3560 [==========>...................] - ETA: 4:31 - loss: 0.5765 - accuracy: 0.8369\n",
      "Batch 08501: setting learning rate to 0.00019947593789034138.\n",
      "1381/3560 [==========>...................] - ETA: 4:31 - loss: 0.5764 - accuracy: 0.8369\n",
      "Batch 08502: setting learning rate to 0.00019947557332737587.\n",
      "1382/3560 [==========>...................] - ETA: 4:31 - loss: 0.5763 - accuracy: 0.8370\n",
      "Batch 08503: setting learning rate to 0.000199475208637984.\n",
      "1383/3560 [==========>...................] - ETA: 4:30 - loss: 0.5765 - accuracy: 0.8369\n",
      "Batch 08504: setting learning rate to 0.0001994748438221662.\n",
      "1384/3560 [==========>...................] - ETA: 4:30 - loss: 0.5767 - accuracy: 0.8369\n",
      "Batch 08505: setting learning rate to 0.00019947447887992296.\n",
      "1385/3560 [==========>...................] - ETA: 4:30 - loss: 0.5767 - accuracy: 0.8369\n",
      "Batch 08506: setting learning rate to 0.00019947411381125477.\n",
      "1386/3560 [==========>...................] - ETA: 4:30 - loss: 0.5767 - accuracy: 0.8369\n",
      "Batch 08507: setting learning rate to 0.00019947374861616207.\n",
      "1387/3560 [==========>...................] - ETA: 4:30 - loss: 0.5766 - accuracy: 0.8369\n",
      "Batch 08508: setting learning rate to 0.0001994733832946453.\n",
      "\n",
      "Batch 08509: setting learning rate to 0.00019947301784670497.\n",
      "1389/3560 [==========>...................] - ETA: 4:29 - loss: 0.5765 - accuracy: 0.8369\n",
      "Batch 08510: setting learning rate to 0.00019947265227234152.\n",
      "\n",
      "Batch 08511: setting learning rate to 0.0001994722865715554.\n",
      "1391/3560 [==========>...................] - ETA: 4:29 - loss: 0.5764 - accuracy: 0.8370\n",
      "Batch 08512: setting learning rate to 0.00019947192074434714.\n",
      "1392/3560 [==========>...................] - ETA: 4:29 - loss: 0.5762 - accuracy: 0.8370\n",
      "Batch 08513: setting learning rate to 0.0001994715547907171.\n",
      "1393/3560 [==========>...................] - ETA: 4:29 - loss: 0.5761 - accuracy: 0.8370\n",
      "Batch 08514: setting learning rate to 0.00019947118871066583.\n",
      "1394/3560 [==========>...................] - ETA: 4:29 - loss: 0.5765 - accuracy: 0.8370\n",
      "Batch 08515: setting learning rate to 0.00019947082250419378.\n",
      "1395/3560 [==========>...................] - ETA: 4:29 - loss: 0.5767 - accuracy: 0.8370\n",
      "Batch 08516: setting learning rate to 0.00019947045617130138.\n",
      "\n",
      "Batch 08517: setting learning rate to 0.00019947008971198913.\n",
      "1397/3560 [==========>...................] - ETA: 4:29 - loss: 0.5766 - accuracy: 0.8371\n",
      "Batch 08518: setting learning rate to 0.0001994697231262575.\n",
      "1398/3560 [==========>...................] - ETA: 4:29 - loss: 0.5768 - accuracy: 0.8371\n",
      "Batch 08519: setting learning rate to 0.0001994693564141069.\n",
      "1399/3560 [==========>...................] - ETA: 4:29 - loss: 0.5766 - accuracy: 0.8371\n",
      "Batch 08520: setting learning rate to 0.00019946898957553787.\n",
      "1400/3560 [==========>...................] - ETA: 4:29 - loss: 0.5765 - accuracy: 0.8371\n",
      "Batch 08521: setting learning rate to 0.00019946862261055082.\n",
      "1401/3560 [==========>...................] - ETA: 4:28 - loss: 0.5763 - accuracy: 0.8371\n",
      "Batch 08522: setting learning rate to 0.00019946825551914627.\n",
      "1402/3560 [==========>...................] - ETA: 4:28 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08523: setting learning rate to 0.00019946788830132466.\n",
      "1403/3560 [==========>...................] - ETA: 4:28 - loss: 0.5761 - accuracy: 0.8371\n",
      "Batch 08524: setting learning rate to 0.00019946752095708644.\n",
      "1404/3560 [==========>...................] - ETA: 4:28 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08525: setting learning rate to 0.00019946715348643208.\n",
      "1405/3560 [==========>...................] - ETA: 4:28 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08526: setting learning rate to 0.00019946678588936205.\n",
      "1406/3560 [==========>...................] - ETA: 4:28 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 08527: setting learning rate to 0.00019946641816587682.\n",
      "1407/3560 [==========>...................] - ETA: 4:28 - loss: 0.5765 - accuracy: 0.8371\n",
      "Batch 08528: setting learning rate to 0.00019946605031597687.\n",
      "\n",
      "Batch 08529: setting learning rate to 0.0001994656823396627.\n",
      "1409/3560 [==========>...................] - ETA: 4:27 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 08530: setting learning rate to 0.0001994653142369347.\n",
      "1410/3560 [==========>...................] - ETA: 4:27 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 08531: setting learning rate to 0.00019946494600779334.\n",
      "1411/3560 [==========>...................] - ETA: 4:27 - loss: 0.5763 - accuracy: 0.8371\n",
      "Batch 08532: setting learning rate to 0.00019946457765223917.\n",
      "1412/3560 [==========>...................] - ETA: 4:27 - loss: 0.5761 - accuracy: 0.8372\n",
      "Batch 08533: setting learning rate to 0.0001994642091702726.\n",
      "1413/3560 [==========>...................] - ETA: 4:27 - loss: 0.5761 - accuracy: 0.8372\n",
      "Batch 08534: setting learning rate to 0.0001994638405618941.\n",
      "1414/3560 [==========>...................] - ETA: 4:27 - loss: 0.5761 - accuracy: 0.8372\n",
      "Batch 08535: setting learning rate to 0.00019946347182710417.\n",
      "1415/3560 [==========>...................] - ETA: 4:27 - loss: 0.5759 - accuracy: 0.8372\n",
      "Batch 08536: setting learning rate to 0.00019946310296590323.\n",
      "1416/3560 [==========>...................] - ETA: 4:26 - loss: 0.5758 - accuracy: 0.8372\n",
      "Batch 08537: setting learning rate to 0.0001994627339782918.\n",
      "1417/3560 [==========>...................] - ETA: 4:26 - loss: 0.5757 - accuracy: 0.8373\n",
      "Batch 08538: setting learning rate to 0.0001994623648642703.\n",
      "1418/3560 [==========>...................] - ETA: 4:27 - loss: 0.5759 - accuracy: 0.8373\n",
      "Batch 08539: setting learning rate to 0.00019946199562383924.\n",
      "1419/3560 [==========>...................] - ETA: 4:27 - loss: 0.5761 - accuracy: 0.8373\n",
      "Batch 08540: setting learning rate to 0.00019946162625699904.\n",
      "1420/3560 [==========>...................] - ETA: 4:27 - loss: 0.5761 - accuracy: 0.8372\n",
      "Batch 08541: setting learning rate to 0.00019946125676375022.\n",
      "1421/3560 [==========>...................] - ETA: 4:26 - loss: 0.5766 - accuracy: 0.8372\n",
      "Batch 08542: setting learning rate to 0.00019946088714409323.\n",
      "1422/3560 [==========>...................] - ETA: 4:26 - loss: 0.5764 - accuracy: 0.8372\n",
      "Batch 08543: setting learning rate to 0.00019946051739802855.\n",
      "1423/3560 [==========>...................] - ETA: 4:26 - loss: 0.5763 - accuracy: 0.8372\n",
      "Batch 08544: setting learning rate to 0.00019946014752555665.\n",
      "1424/3560 [===========>..................] - ETA: 4:26 - loss: 0.5764 - accuracy: 0.8372\n",
      "Batch 08545: setting learning rate to 0.00019945977752667797.\n",
      "1425/3560 [===========>..................] - ETA: 4:26 - loss: 0.5764 - accuracy: 0.8371\n",
      "Batch 08546: setting learning rate to 0.000199459407401393.\n",
      "\n",
      "Batch 08547: setting learning rate to 0.0001994590371497022.\n",
      "1427/3560 [===========>..................] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.8371\n",
      "Batch 08548: setting learning rate to 0.0001994586667716061.\n",
      "1428/3560 [===========>..................] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.8371\n",
      "Batch 08549: setting learning rate to 0.00019945829626710507.\n",
      "1429/3560 [===========>..................] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.8371\n",
      "Batch 08550: setting learning rate to 0.00019945792563619969.\n",
      "1430/3560 [===========>..................] - ETA: 4:25 - loss: 0.5761 - accuracy: 0.8371\n",
      "Batch 08551: setting learning rate to 0.00019945755487889034.\n",
      "1431/3560 [===========>..................] - ETA: 4:25 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08552: setting learning rate to 0.00019945718399517752.\n",
      "1432/3560 [===========>..................] - ETA: 4:24 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08553: setting learning rate to 0.0001994568129850617.\n",
      "\n",
      "Batch 08554: setting learning rate to 0.00019945644184854339.\n",
      "1434/3560 [===========>..................] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.8370\n",
      "Batch 08555: setting learning rate to 0.00019945607058562302.\n",
      "1435/3560 [===========>..................] - ETA: 4:25 - loss: 0.5763 - accuracy: 0.8370\n",
      "Batch 08556: setting learning rate to 0.00019945569919630106.\n",
      "1436/3560 [===========>..................] - ETA: 4:24 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08557: setting learning rate to 0.000199455327680578.\n",
      "1437/3560 [===========>..................] - ETA: 4:24 - loss: 0.5762 - accuracy: 0.8371\n",
      "Batch 08558: setting learning rate to 0.0001994549560384543.\n",
      "1438/3560 [===========>..................] - ETA: 4:24 - loss: 0.5761 - accuracy: 0.8371\n",
      "Batch 08559: setting learning rate to 0.00019945458426993046.\n",
      "1439/3560 [===========>..................] - ETA: 4:24 - loss: 0.5760 - accuracy: 0.8371\n",
      "Batch 08560: setting learning rate to 0.0001994542123750069.\n",
      "1440/3560 [===========>..................] - ETA: 4:24 - loss: 0.5758 - accuracy: 0.8371\n",
      "Batch 08561: setting learning rate to 0.00019945384035368412.\n",
      "1441/3560 [===========>..................] - ETA: 4:24 - loss: 0.5757 - accuracy: 0.8372\n",
      "Batch 08562: setting learning rate to 0.00019945346820596265.\n",
      "1442/3560 [===========>..................] - ETA: 4:23 - loss: 0.5758 - accuracy: 0.8372\n",
      "Batch 08563: setting learning rate to 0.00019945309593184286.\n",
      "1443/3560 [===========>..................] - ETA: 4:24 - loss: 0.5759 - accuracy: 0.8371\n",
      "Batch 08564: setting learning rate to 0.0001994527235313253.\n",
      "1444/3560 [===========>..................] - ETA: 4:24 - loss: 0.5759 - accuracy: 0.8372\n",
      "Batch 08565: setting learning rate to 0.0001994523510044104.\n",
      "1445/3560 [===========>..................] - ETA: 4:24 - loss: 0.5759 - accuracy: 0.8372\n",
      "Batch 08566: setting learning rate to 0.00019945197835109866.\n",
      "1446/3560 [===========>..................] - ETA: 4:23 - loss: 0.5758 - accuracy: 0.8372\n",
      "Batch 08567: setting learning rate to 0.00019945160557139054.\n",
      "1447/3560 [===========>..................] - ETA: 4:23 - loss: 0.5757 - accuracy: 0.8373\n",
      "Batch 08568: setting learning rate to 0.00019945123266528652.\n",
      "1448/3560 [===========>..................] - ETA: 4:23 - loss: 0.5757 - accuracy: 0.8373\n",
      "Batch 08569: setting learning rate to 0.00019945085963278704.\n",
      "1449/3560 [===========>..................] - ETA: 4:23 - loss: 0.5756 - accuracy: 0.8374\n",
      "Batch 08570: setting learning rate to 0.00019945048647389263.\n",
      "1450/3560 [===========>..................] - ETA: 4:23 - loss: 0.5756 - accuracy: 0.8374\n",
      "Batch 08571: setting learning rate to 0.00019945011318860375.\n",
      "1451/3560 [===========>..................] - ETA: 4:23 - loss: 0.5754 - accuracy: 0.8374\n",
      "Batch 08572: setting learning rate to 0.00019944973977692088.\n",
      "1452/3560 [===========>..................] - ETA: 4:23 - loss: 0.5757 - accuracy: 0.8374\n",
      "Batch 08573: setting learning rate to 0.00019944936623884446.\n",
      "1453/3560 [===========>..................] - ETA: 4:23 - loss: 0.5760 - accuracy: 0.8375\n",
      "Batch 08574: setting learning rate to 0.00019944899257437495.\n",
      "1454/3560 [===========>..................] - ETA: 4:23 - loss: 0.5761 - accuracy: 0.8375\n",
      "Batch 08575: setting learning rate to 0.0001994486187835129.\n",
      "1455/3560 [===========>..................] - ETA: 4:22 - loss: 0.5760 - accuracy: 0.8375\n",
      "Batch 08576: setting learning rate to 0.00019944824486625872.\n",
      "1456/3560 [===========>..................] - ETA: 4:22 - loss: 0.5760 - accuracy: 0.8375\n",
      "Batch 08577: setting learning rate to 0.0001994478708226129.\n",
      "1457/3560 [===========>..................] - ETA: 4:22 - loss: 0.5761 - accuracy: 0.8374\n",
      "Batch 08578: setting learning rate to 0.00019944749665257595.\n",
      "1458/3560 [===========>..................] - ETA: 4:22 - loss: 0.5760 - accuracy: 0.8374\n",
      "Batch 08579: setting learning rate to 0.0001994471223561483.\n",
      "1459/3560 [===========>..................] - ETA: 4:22 - loss: 0.5760 - accuracy: 0.8374\n",
      "Batch 08580: setting learning rate to 0.00019944674793333044.\n",
      "1460/3560 [===========>..................] - ETA: 4:22 - loss: 0.5759 - accuracy: 0.8374\n",
      "Batch 08581: setting learning rate to 0.0001994463733841229.\n",
      "1461/3560 [===========>..................] - ETA: 4:22 - loss: 0.5758 - accuracy: 0.8374\n",
      "Batch 08582: setting learning rate to 0.00019944599870852606.\n",
      "1462/3560 [===========>..................] - ETA: 4:21 - loss: 0.5758 - accuracy: 0.8373\n",
      "Batch 08583: setting learning rate to 0.00019944562390654044.\n",
      "1463/3560 [===========>..................] - ETA: 4:21 - loss: 0.5758 - accuracy: 0.8373\n",
      "Batch 08584: setting learning rate to 0.00019944524897816653.\n",
      "1464/3560 [===========>..................] - ETA: 4:21 - loss: 0.5756 - accuracy: 0.8374\n",
      "Batch 08585: setting learning rate to 0.00019944487392340482.\n",
      "1465/3560 [===========>..................] - ETA: 4:21 - loss: 0.5755 - accuracy: 0.8375\n",
      "Batch 08586: setting learning rate to 0.00019944449874225573.\n",
      "1466/3560 [===========>..................] - ETA: 4:21 - loss: 0.5755 - accuracy: 0.8375\n",
      "Batch 08587: setting learning rate to 0.00019944412343471976.\n",
      "\n",
      "Batch 08588: setting learning rate to 0.00019944374800079742.\n",
      "1468/3560 [===========>..................] - ETA: 4:21 - loss: 0.5756 - accuracy: 0.8374\n",
      "Batch 08589: setting learning rate to 0.00019944337244048917.\n",
      "\n",
      "Batch 08590: setting learning rate to 0.00019944299675379545.\n",
      "1470/3560 [===========>..................] - ETA: 4:20 - loss: 0.5756 - accuracy: 0.8374\n",
      "Batch 08591: setting learning rate to 0.0001994426209407168.\n",
      "1471/3560 [===========>..................] - ETA: 4:20 - loss: 0.5754 - accuracy: 0.8374\n",
      "Batch 08592: setting learning rate to 0.00019944224500125364.\n",
      "1472/3560 [===========>..................] - ETA: 4:20 - loss: 0.5754 - accuracy: 0.8374\n",
      "Batch 08593: setting learning rate to 0.0001994418689354065.\n",
      "1473/3560 [===========>..................] - ETA: 4:20 - loss: 0.5755 - accuracy: 0.8374\n",
      "Batch 08594: setting learning rate to 0.00019944149274317581.\n",
      "\n",
      "Batch 08595: setting learning rate to 0.00019944111642456207.\n",
      "1475/3560 [===========>..................] - ETA: 4:20 - loss: 0.5754 - accuracy: 0.8375\n",
      "Batch 08596: setting learning rate to 0.00019944073997956577.\n",
      "1476/3560 [===========>..................] - ETA: 4:20 - loss: 0.5753 - accuracy: 0.8375\n",
      "Batch 08597: setting learning rate to 0.0001994403634081874.\n",
      "1477/3560 [===========>..................] - ETA: 4:20 - loss: 0.5752 - accuracy: 0.8376\n",
      "Batch 08598: setting learning rate to 0.00019943998671042735.\n",
      "1478/3560 [===========>..................] - ETA: 4:19 - loss: 0.5751 - accuracy: 0.8376\n",
      "Batch 08599: setting learning rate to 0.0001994396098862862.\n",
      "1479/3560 [===========>..................] - ETA: 4:19 - loss: 0.5751 - accuracy: 0.8376\n",
      "Batch 08600: setting learning rate to 0.0001994392329357644.\n",
      "1480/3560 [===========>..................] - ETA: 4:19 - loss: 0.5750 - accuracy: 0.8376\n",
      "Batch 08601: setting learning rate to 0.00019943885585886243.\n",
      "1481/3560 [===========>..................] - ETA: 4:19 - loss: 0.5751 - accuracy: 0.8376\n",
      "Batch 08602: setting learning rate to 0.00019943847865558074.\n",
      "1482/3560 [===========>..................] - ETA: 4:19 - loss: 0.5751 - accuracy: 0.8375\n",
      "Batch 08603: setting learning rate to 0.00019943810132591985.\n",
      "1483/3560 [===========>..................] - ETA: 4:19 - loss: 0.5752 - accuracy: 0.8374\n",
      "Batch 08604: setting learning rate to 0.00019943772386988017.\n",
      "1484/3560 [===========>..................] - ETA: 4:19 - loss: 0.5751 - accuracy: 0.8375\n",
      "Batch 08605: setting learning rate to 0.00019943734628746228.\n",
      "\n",
      "Batch 08606: setting learning rate to 0.00019943696857866662.\n",
      "1486/3560 [===========>..................] - ETA: 4:18 - loss: 0.5750 - accuracy: 0.8375\n",
      "Batch 08607: setting learning rate to 0.0001994365907434936.\n",
      "1487/3560 [===========>..................] - ETA: 4:18 - loss: 0.5748 - accuracy: 0.8376\n",
      "Batch 08608: setting learning rate to 0.0001994362127819438.\n",
      "1488/3560 [===========>..................] - ETA: 4:18 - loss: 0.5748 - accuracy: 0.8376\n",
      "Batch 08609: setting learning rate to 0.00019943583469401768.\n",
      "1489/3560 [===========>..................] - ETA: 4:18 - loss: 0.5749 - accuracy: 0.8375\n",
      "Batch 08610: setting learning rate to 0.00019943545647971566.\n",
      "1490/3560 [===========>..................] - ETA: 4:18 - loss: 0.5747 - accuracy: 0.8375\n",
      "Batch 08611: setting learning rate to 0.00019943507813903827.\n",
      "1491/3560 [===========>..................] - ETA: 4:18 - loss: 0.5746 - accuracy: 0.8376\n",
      "Batch 08612: setting learning rate to 0.00019943469967198597.\n",
      "1492/3560 [===========>..................] - ETA: 4:18 - loss: 0.5746 - accuracy: 0.8375\n",
      "Batch 08613: setting learning rate to 0.0001994343210785593.\n",
      "1493/3560 [===========>..................] - ETA: 4:18 - loss: 0.5747 - accuracy: 0.8375\n",
      "Batch 08614: setting learning rate to 0.00019943394235875865.\n",
      "1494/3560 [===========>..................] - ETA: 4:18 - loss: 0.5748 - accuracy: 0.8375\n",
      "Batch 08615: setting learning rate to 0.00019943356351258458.\n",
      "1495/3560 [===========>..................] - ETA: 4:17 - loss: 0.5748 - accuracy: 0.8374\n",
      "Batch 08616: setting learning rate to 0.0001994331845400375.\n",
      "1496/3560 [===========>..................] - ETA: 4:17 - loss: 0.5745 - accuracy: 0.8375\n",
      "Batch 08617: setting learning rate to 0.00019943280544111795.\n",
      "1497/3560 [===========>..................] - ETA: 4:17 - loss: 0.5744 - accuracy: 0.8376\n",
      "Batch 08618: setting learning rate to 0.0001994324262158264.\n",
      "1498/3560 [===========>..................] - ETA: 4:17 - loss: 0.5744 - accuracy: 0.8376\n",
      "Batch 08619: setting learning rate to 0.00019943204686416333.\n",
      "1499/3560 [===========>..................] - ETA: 4:17 - loss: 0.5743 - accuracy: 0.8377\n",
      "Batch 08620: setting learning rate to 0.00019943166738612918.\n",
      "1500/3560 [===========>..................] - ETA: 4:16 - loss: 0.5746 - accuracy: 0.8375\n",
      "Batch 08621: setting learning rate to 0.00019943128778172447.\n",
      "1501/3560 [===========>..................] - ETA: 4:16 - loss: 0.5744 - accuracy: 0.8376\n",
      "Batch 08622: setting learning rate to 0.00019943090805094968.\n",
      "1502/3560 [===========>..................] - ETA: 4:16 - loss: 0.5744 - accuracy: 0.8376\n",
      "Batch 08623: setting learning rate to 0.00019943052819380532.\n",
      "1503/3560 [===========>..................] - ETA: 4:16 - loss: 0.5743 - accuracy: 0.8377\n",
      "Batch 08624: setting learning rate to 0.0001994301482102918.\n",
      "\n",
      "Batch 08625: setting learning rate to 0.0001994297681004097.\n",
      "1505/3560 [===========>..................] - ETA: 4:16 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08626: setting learning rate to 0.00019942938786415943.\n",
      "1506/3560 [===========>..................] - ETA: 4:16 - loss: 0.5742 - accuracy: 0.8377\n",
      "Batch 08627: setting learning rate to 0.0001994290075015415.\n",
      "1507/3560 [===========>..................] - ETA: 4:16 - loss: 0.5742 - accuracy: 0.8377\n",
      "Batch 08628: setting learning rate to 0.00019942862701255638.\n",
      "1508/3560 [===========>..................] - ETA: 4:15 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08629: setting learning rate to 0.00019942824639720454.\n",
      "1509/3560 [===========>..................] - ETA: 4:15 - loss: 0.5742 - accuracy: 0.8378\n",
      "Batch 08630: setting learning rate to 0.00019942786565548652.\n",
      "1510/3560 [===========>..................] - ETA: 4:15 - loss: 0.5744 - accuracy: 0.8377\n",
      "Batch 08631: setting learning rate to 0.00019942748478740275.\n",
      "1511/3560 [===========>..................] - ETA: 4:16 - loss: 0.5744 - accuracy: 0.8376\n",
      "Batch 08632: setting learning rate to 0.00019942710379295374.\n",
      "1512/3560 [===========>..................] - ETA: 4:15 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08633: setting learning rate to 0.00019942672267213998.\n",
      "1513/3560 [===========>..................] - ETA: 4:15 - loss: 0.5743 - accuracy: 0.8376\n",
      "Batch 08634: setting learning rate to 0.0001994263414249619.\n",
      "\n",
      "Batch 08635: setting learning rate to 0.00019942596005142007.\n",
      "1515/3560 [===========>..................] - ETA: 4:15 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08636: setting learning rate to 0.0001994255785515149.\n",
      "1516/3560 [===========>..................] - ETA: 4:15 - loss: 0.5740 - accuracy: 0.8377\n",
      "Batch 08637: setting learning rate to 0.00019942519692524692.\n",
      "1517/3560 [===========>..................] - ETA: 4:15 - loss: 0.5742 - accuracy: 0.8378\n",
      "Batch 08638: setting learning rate to 0.00019942481517261658.\n",
      "1518/3560 [===========>..................] - ETA: 4:15 - loss: 0.5741 - accuracy: 0.8378\n",
      "Batch 08639: setting learning rate to 0.00019942443329362442.\n",
      "1519/3560 [===========>..................] - ETA: 4:14 - loss: 0.5740 - accuracy: 0.8378\n",
      "Batch 08640: setting learning rate to 0.00019942405128827085.\n",
      "1520/3560 [===========>..................] - ETA: 4:14 - loss: 0.5740 - accuracy: 0.8378\n",
      "Batch 08641: setting learning rate to 0.00019942366915655642.\n",
      "1521/3560 [===========>..................] - ETA: 4:14 - loss: 0.5738 - accuracy: 0.8379\n",
      "Batch 08642: setting learning rate to 0.0001994232868984816.\n",
      "\n",
      "Batch 08643: setting learning rate to 0.00019942290451404685.\n",
      "1523/3560 [===========>..................] - ETA: 4:14 - loss: 0.5738 - accuracy: 0.8379\n",
      "Batch 08644: setting learning rate to 0.0001994225220032527.\n",
      "1524/3560 [===========>..................] - ETA: 4:13 - loss: 0.5737 - accuracy: 0.8379\n",
      "Batch 08645: setting learning rate to 0.0001994221393660996.\n",
      "1525/3560 [===========>..................] - ETA: 4:13 - loss: 0.5739 - accuracy: 0.8378\n",
      "Batch 08646: setting learning rate to 0.00019942175660258804.\n",
      "1526/3560 [===========>..................] - ETA: 4:13 - loss: 0.5741 - accuracy: 0.8378\n",
      "Batch 08647: setting learning rate to 0.00019942137371271849.\n",
      "1527/3560 [===========>..................] - ETA: 4:13 - loss: 0.5743 - accuracy: 0.8378\n",
      "Batch 08648: setting learning rate to 0.0001994209906964915.\n",
      "1528/3560 [===========>..................] - ETA: 4:14 - loss: 0.5744 - accuracy: 0.8378\n",
      "Batch 08649: setting learning rate to 0.0001994206075539075.\n",
      "\n",
      "Batch 08650: setting learning rate to 0.000199420224284967.\n",
      "1530/3560 [===========>..................] - ETA: 4:13 - loss: 0.5744 - accuracy: 0.8378\n",
      "Batch 08651: setting learning rate to 0.00019941984088967045.\n",
      "1531/3560 [===========>..................] - ETA: 4:13 - loss: 0.5745 - accuracy: 0.8378\n",
      "Batch 08652: setting learning rate to 0.00019941945736801843.\n",
      "1532/3560 [===========>..................] - ETA: 4:13 - loss: 0.5747 - accuracy: 0.8377\n",
      "Batch 08653: setting learning rate to 0.0001994190737200113.\n",
      "1533/3560 [===========>..................] - ETA: 4:13 - loss: 0.5746 - accuracy: 0.8377\n",
      "Batch 08654: setting learning rate to 0.00019941868994564964.\n",
      "1534/3560 [===========>..................] - ETA: 4:13 - loss: 0.5745 - accuracy: 0.8377\n",
      "Batch 08655: setting learning rate to 0.0001994183060449339.\n",
      "1535/3560 [===========>..................] - ETA: 4:13 - loss: 0.5745 - accuracy: 0.8377\n",
      "Batch 08656: setting learning rate to 0.0001994179220178646.\n",
      "1536/3560 [===========>..................] - ETA: 4:12 - loss: 0.5744 - accuracy: 0.8377\n",
      "Batch 08657: setting learning rate to 0.00019941753786444219.\n",
      "1537/3560 [===========>..................] - ETA: 4:12 - loss: 0.5743 - accuracy: 0.8377\n",
      "Batch 08658: setting learning rate to 0.00019941715358466717.\n",
      "1538/3560 [===========>..................] - ETA: 4:12 - loss: 0.5746 - accuracy: 0.8376\n",
      "Batch 08659: setting learning rate to 0.00019941676917854004.\n",
      "1539/3560 [===========>..................] - ETA: 4:12 - loss: 0.5745 - accuracy: 0.8376\n",
      "Batch 08660: setting learning rate to 0.00019941638464606126.\n",
      "\n",
      "Batch 08661: setting learning rate to 0.00019941599998723138.\n",
      "1541/3560 [===========>..................] - ETA: 4:11 - loss: 0.5743 - accuracy: 0.8376\n",
      "Batch 08662: setting learning rate to 0.00019941561520205086.\n",
      "1542/3560 [===========>..................] - ETA: 4:11 - loss: 0.5743 - accuracy: 0.8376\n",
      "Batch 08663: setting learning rate to 0.00019941523029052012.\n",
      "1543/3560 [============>.................] - ETA: 4:12 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08664: setting learning rate to 0.00019941484525263974.\n",
      "1544/3560 [============>.................] - ETA: 4:11 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08665: setting learning rate to 0.00019941446008841019.\n",
      "1545/3560 [============>.................] - ETA: 4:11 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08666: setting learning rate to 0.0001994140747978319.\n",
      "1546/3560 [============>.................] - ETA: 4:12 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08667: setting learning rate to 0.00019941368938090545.\n",
      "1547/3560 [============>.................] - ETA: 4:11 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08668: setting learning rate to 0.00019941330383763125.\n",
      "\n",
      "Batch 08669: setting learning rate to 0.00019941291816800988.\n",
      "1549/3560 [============>.................] - ETA: 4:11 - loss: 0.5740 - accuracy: 0.8377\n",
      "Batch 08670: setting learning rate to 0.00019941253237204174.\n",
      "1550/3560 [============>.................] - ETA: 4:11 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08671: setting learning rate to 0.00019941214644972734.\n",
      "1551/3560 [============>.................] - ETA: 4:11 - loss: 0.5742 - accuracy: 0.8376\n",
      "Batch 08672: setting learning rate to 0.0001994117604010672.\n",
      "1552/3560 [============>.................] - ETA: 4:10 - loss: 0.5741 - accuracy: 0.8376\n",
      "Batch 08673: setting learning rate to 0.00019941137422606182.\n",
      "1553/3560 [============>.................] - ETA: 4:10 - loss: 0.5740 - accuracy: 0.8377\n",
      "Batch 08674: setting learning rate to 0.00019941098792471165.\n",
      "1554/3560 [============>.................] - ETA: 4:10 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08675: setting learning rate to 0.0001994106014970172.\n",
      "1555/3560 [============>.................] - ETA: 4:10 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08676: setting learning rate to 0.000199410214942979.\n",
      "\n",
      "Batch 08677: setting learning rate to 0.00019940982826259745.\n",
      "1557/3560 [============>.................] - ETA: 4:10 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08678: setting learning rate to 0.00019940944145587308.\n",
      "1558/3560 [============>.................] - ETA: 4:10 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08679: setting learning rate to 0.0001994090545228064.\n",
      "\n",
      "Batch 08680: setting learning rate to 0.00019940866746339793.\n",
      "1560/3560 [============>.................] - ETA: 4:10 - loss: 0.5742 - accuracy: 0.8377\n",
      "Batch 08681: setting learning rate to 0.0001994082802776481.\n",
      "1561/3560 [============>.................] - ETA: 4:09 - loss: 0.5741 - accuracy: 0.8377\n",
      "Batch 08682: setting learning rate to 0.00019940789296555745.\n",
      "1562/3560 [============>.................] - ETA: 4:09 - loss: 0.5740 - accuracy: 0.8377\n",
      "Batch 08683: setting learning rate to 0.00019940750552712645.\n",
      "1563/3560 [============>.................] - ETA: 4:09 - loss: 0.5739 - accuracy: 0.8378\n",
      "Batch 08684: setting learning rate to 0.0001994071179623556.\n",
      "1564/3560 [============>.................] - ETA: 4:09 - loss: 0.5739 - accuracy: 0.8378\n",
      "Batch 08685: setting learning rate to 0.00019940673027124537.\n",
      "1565/3560 [============>.................] - ETA: 4:09 - loss: 0.5740 - accuracy: 0.8378\n",
      "Batch 08686: setting learning rate to 0.00019940634245379629.\n",
      "1566/3560 [============>.................] - ETA: 4:09 - loss: 0.5741 - accuracy: 0.8376\n",
      "Batch 08687: setting learning rate to 0.00019940595451000884.\n",
      "1567/3560 [============>.................] - ETA: 4:09 - loss: 0.5740 - accuracy: 0.8376\n",
      "Batch 08688: setting learning rate to 0.00019940556643988346.\n",
      "1568/3560 [============>.................] - ETA: 4:08 - loss: 0.5740 - accuracy: 0.8376\n",
      "Batch 08689: setting learning rate to 0.00019940517824342072.\n",
      "1569/3560 [============>.................] - ETA: 4:08 - loss: 0.5740 - accuracy: 0.8376\n",
      "Batch 08690: setting learning rate to 0.0001994047899206211.\n",
      "1570/3560 [============>.................] - ETA: 4:08 - loss: 0.5741 - accuracy: 0.8376\n",
      "Batch 08691: setting learning rate to 0.00019940440147148505.\n",
      "1571/3560 [============>.................] - ETA: 4:08 - loss: 0.5739 - accuracy: 0.8376\n",
      "Batch 08692: setting learning rate to 0.00019940401289601312.\n",
      "1572/3560 [============>.................] - ETA: 4:08 - loss: 0.5738 - accuracy: 0.8377\n",
      "Batch 08693: setting learning rate to 0.00019940362419420572.\n",
      "1573/3560 [============>.................] - ETA: 4:08 - loss: 0.5740 - accuracy: 0.8378\n",
      "Batch 08694: setting learning rate to 0.00019940323536606343.\n",
      "\n",
      "Batch 08695: setting learning rate to 0.00019940284641158673.\n",
      "1575/3560 [============>.................] - ETA: 4:07 - loss: 0.5747 - accuracy: 0.8378\n",
      "Batch 08696: setting learning rate to 0.00019940245733077606.\n",
      "1576/3560 [============>.................] - ETA: 4:07 - loss: 0.5745 - accuracy: 0.8378\n",
      "Batch 08697: setting learning rate to 0.00019940206812363198.\n",
      "1577/3560 [============>.................] - ETA: 4:07 - loss: 0.5746 - accuracy: 0.8378\n",
      "Batch 08698: setting learning rate to 0.00019940167879015495.\n",
      "\n",
      "Batch 08699: setting learning rate to 0.00019940128933034545.\n",
      "1579/3560 [============>.................] - ETA: 4:07 - loss: 0.5746 - accuracy: 0.8378\n",
      "Batch 08700: setting learning rate to 0.00019940089974420402.\n",
      "1580/3560 [============>.................] - ETA: 4:07 - loss: 0.5746 - accuracy: 0.8378\n",
      "Batch 08701: setting learning rate to 0.0001994005100317311.\n",
      "\n",
      "Batch 08702: setting learning rate to 0.00019940012019292725.\n",
      "1582/3560 [============>.................] - ETA: 4:07 - loss: 0.5744 - accuracy: 0.8378\n",
      "Batch 08703: setting learning rate to 0.00019939973022779293.\n",
      "1583/3560 [============>.................] - ETA: 4:07 - loss: 0.5745 - accuracy: 0.8377\n",
      "Batch 08704: setting learning rate to 0.00019939934013632861.\n",
      "1584/3560 [============>.................] - ETA: 4:06 - loss: 0.5745 - accuracy: 0.8377\n",
      "Batch 08705: setting learning rate to 0.00019939894991853483.\n",
      "\n",
      "Batch 08706: setting learning rate to 0.00019939855957441208.\n",
      "1586/3560 [============>.................] - ETA: 4:07 - loss: 0.5745 - accuracy: 0.8376\n",
      "Batch 08707: setting learning rate to 0.0001993981691039608.\n",
      "1587/3560 [============>.................] - ETA: 4:06 - loss: 0.5743 - accuracy: 0.8377\n",
      "Batch 08708: setting learning rate to 0.00019939777850718157.\n",
      "1588/3560 [============>.................] - ETA: 4:06 - loss: 0.5743 - accuracy: 0.8377\n",
      "Batch 08709: setting learning rate to 0.00019939738778407485.\n",
      "1589/3560 [============>.................] - ETA: 4:06 - loss: 0.5741 - accuracy: 0.8378\n",
      "Batch 08710: setting learning rate to 0.0001993969969346411.\n",
      "1590/3560 [============>.................] - ETA: 4:06 - loss: 0.5740 - accuracy: 0.8378\n",
      "Batch 08711: setting learning rate to 0.0001993966059588809.\n",
      "1591/3560 [============>.................] - ETA: 4:06 - loss: 0.5739 - accuracy: 0.8379\n",
      "Batch 08712: setting learning rate to 0.00019939621485679467.\n",
      "1592/3560 [============>.................] - ETA: 4:05 - loss: 0.5739 - accuracy: 0.8379\n",
      "Batch 08713: setting learning rate to 0.00019939582362838291.\n",
      "1593/3560 [============>.................] - ETA: 4:06 - loss: 0.5737 - accuracy: 0.8379\n",
      "Batch 08714: setting learning rate to 0.00019939543227364616.\n",
      "1594/3560 [============>.................] - ETA: 4:05 - loss: 0.5740 - accuracy: 0.8379\n",
      "Batch 08715: setting learning rate to 0.0001993950407925849.\n",
      "1595/3560 [============>.................] - ETA: 4:05 - loss: 0.5739 - accuracy: 0.8380\n",
      "Batch 08716: setting learning rate to 0.00019939464918519967.\n",
      "\n",
      "Batch 08717: setting learning rate to 0.00019939425745149088.\n",
      "1597/3560 [============>.................] - ETA: 4:05 - loss: 0.5737 - accuracy: 0.8381\n",
      "Batch 08718: setting learning rate to 0.00019939386559145907.\n",
      "1598/3560 [============>.................] - ETA: 4:05 - loss: 0.5735 - accuracy: 0.8381\n",
      "Batch 08719: setting learning rate to 0.00019939347360510475.\n",
      "1599/3560 [============>.................] - ETA: 4:05 - loss: 0.5737 - accuracy: 0.8381\n",
      "Batch 08720: setting learning rate to 0.0001993930814924284.\n",
      "1600/3560 [============>.................] - ETA: 4:05 - loss: 0.5737 - accuracy: 0.8382\n",
      "Batch 08721: setting learning rate to 0.00019939268925343054.\n",
      "1601/3560 [============>.................] - ETA: 4:05 - loss: 0.5737 - accuracy: 0.8382\n",
      "Batch 08722: setting learning rate to 0.00019939229688811165.\n",
      "1602/3560 [============>.................] - ETA: 4:04 - loss: 0.5736 - accuracy: 0.8382\n",
      "Batch 08723: setting learning rate to 0.00019939190439647225.\n",
      "1603/3560 [============>.................] - ETA: 4:04 - loss: 0.5737 - accuracy: 0.8383\n",
      "Batch 08724: setting learning rate to 0.00019939151177851279.\n",
      "1604/3560 [============>.................] - ETA: 4:04 - loss: 0.5738 - accuracy: 0.8383\n",
      "Batch 08725: setting learning rate to 0.00019939111903423382.\n",
      "1605/3560 [============>.................] - ETA: 4:04 - loss: 0.5738 - accuracy: 0.8382\n",
      "Batch 08726: setting learning rate to 0.00019939072616363581.\n",
      "1606/3560 [============>.................] - ETA: 4:04 - loss: 0.5739 - accuracy: 0.8382\n",
      "Batch 08727: setting learning rate to 0.00019939033316671928.\n",
      "1607/3560 [============>.................] - ETA: 4:04 - loss: 0.5739 - accuracy: 0.8381\n",
      "Batch 08728: setting learning rate to 0.00019938994004348474.\n",
      "\n",
      "Batch 08729: setting learning rate to 0.00019938954679393265.\n",
      "1609/3560 [============>.................] - ETA: 4:04 - loss: 0.5738 - accuracy: 0.8381\n",
      "Batch 08730: setting learning rate to 0.00019938915341806353.\n",
      "1610/3560 [============>.................] - ETA: 4:04 - loss: 0.5738 - accuracy: 0.8381\n",
      "Batch 08731: setting learning rate to 0.00019938875991587786.\n",
      "1611/3560 [============>.................] - ETA: 4:03 - loss: 0.5738 - accuracy: 0.8381\n",
      "Batch 08732: setting learning rate to 0.0001993883662873762.\n",
      "1612/3560 [============>.................] - ETA: 4:03 - loss: 0.5737 - accuracy: 0.8381\n",
      "Batch 08733: setting learning rate to 0.00019938797253255897.\n",
      "1613/3560 [============>.................] - ETA: 4:03 - loss: 0.5738 - accuracy: 0.8382\n",
      "Batch 08734: setting learning rate to 0.00019938757865142672.\n",
      "1614/3560 [============>.................] - ETA: 4:03 - loss: 0.5738 - accuracy: 0.8382\n",
      "Batch 08735: setting learning rate to 0.00019938718464397996.\n",
      "1615/3560 [============>.................] - ETA: 4:03 - loss: 0.5736 - accuracy: 0.8382\n",
      "Batch 08736: setting learning rate to 0.00019938679051021915.\n",
      "1616/3560 [============>.................] - ETA: 4:03 - loss: 0.5736 - accuracy: 0.8382\n",
      "Batch 08737: setting learning rate to 0.00019938639625014483.\n",
      "1617/3560 [============>.................] - ETA: 4:03 - loss: 0.5736 - accuracy: 0.8383\n",
      "Batch 08738: setting learning rate to 0.00019938600186375749.\n",
      "\n",
      "Batch 08739: setting learning rate to 0.0001993856073510576.\n",
      "1619/3560 [============>.................] - ETA: 4:02 - loss: 0.5734 - accuracy: 0.8384\n",
      "Batch 08740: setting learning rate to 0.00019938521271204568.\n",
      "1620/3560 [============>.................] - ETA: 4:02 - loss: 0.5733 - accuracy: 0.8384\n",
      "Batch 08741: setting learning rate to 0.00019938481794672228.\n",
      "1621/3560 [============>.................] - ETA: 4:02 - loss: 0.5734 - accuracy: 0.8384\n",
      "Batch 08742: setting learning rate to 0.00019938442305508783.\n",
      "1622/3560 [============>.................] - ETA: 4:02 - loss: 0.5733 - accuracy: 0.8384\n",
      "Batch 08743: setting learning rate to 0.00019938402803714285.\n",
      "1623/3560 [============>.................] - ETA: 4:02 - loss: 0.5733 - accuracy: 0.8385\n",
      "Batch 08744: setting learning rate to 0.00019938363289288786.\n",
      "1624/3560 [============>.................] - ETA: 4:02 - loss: 0.5732 - accuracy: 0.8385\n",
      "Batch 08745: setting learning rate to 0.00019938323762232337.\n",
      "1625/3560 [============>.................] - ETA: 4:01 - loss: 0.5733 - accuracy: 0.8385\n",
      "Batch 08746: setting learning rate to 0.00019938284222544987.\n",
      "1626/3560 [============>.................] - ETA: 4:02 - loss: 0.5732 - accuracy: 0.8384\n",
      "Batch 08747: setting learning rate to 0.00019938244670226785.\n",
      "\n",
      "Batch 08748: setting learning rate to 0.00019938205105277782.\n",
      "1628/3560 [============>.................] - ETA: 4:01 - loss: 0.5730 - accuracy: 0.8385\n",
      "Batch 08749: setting learning rate to 0.00019938165527698027.\n",
      "1629/3560 [============>.................] - ETA: 4:01 - loss: 0.5731 - accuracy: 0.8385\n",
      "Batch 08750: setting learning rate to 0.00019938125937487574.\n",
      "\n",
      "Batch 08751: setting learning rate to 0.00019938086334646472.\n",
      "1631/3560 [============>.................] - ETA: 4:01 - loss: 0.5731 - accuracy: 0.8385\n",
      "Batch 08752: setting learning rate to 0.00019938046719174767.\n",
      "1632/3560 [============>.................] - ETA: 4:01 - loss: 0.5731 - accuracy: 0.8385\n",
      "Batch 08753: setting learning rate to 0.00019938007091072516.\n",
      "1633/3560 [============>.................] - ETA: 4:00 - loss: 0.5731 - accuracy: 0.8384\n",
      "Batch 08754: setting learning rate to 0.00019937967450339768.\n",
      "1634/3560 [============>.................] - ETA: 4:01 - loss: 0.5731 - accuracy: 0.8384\n",
      "Batch 08755: setting learning rate to 0.00019937927796976568.\n",
      "1635/3560 [============>.................] - ETA: 4:01 - loss: 0.5730 - accuracy: 0.8384\n",
      "Batch 08756: setting learning rate to 0.00019937888130982972.\n",
      "\n",
      "Batch 08757: setting learning rate to 0.00019937848452359028.\n",
      "1637/3560 [============>.................] - ETA: 4:00 - loss: 0.5728 - accuracy: 0.8385\n",
      "Batch 08758: setting learning rate to 0.00019937808761104787.\n",
      "\n",
      "Batch 08759: setting learning rate to 0.00019937769057220298.\n",
      "1639/3560 [============>.................] - ETA: 4:00 - loss: 0.5730 - accuracy: 0.8385\n",
      "Batch 08760: setting learning rate to 0.00019937729340705612.\n",
      "1640/3560 [============>.................] - ETA: 4:00 - loss: 0.5729 - accuracy: 0.8385\n",
      "Batch 08761: setting learning rate to 0.00019937689611560782.\n",
      "1641/3560 [============>.................] - ETA: 4:00 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08762: setting learning rate to 0.00019937649869785856.\n",
      "1642/3560 [============>.................] - ETA: 4:00 - loss: 0.5729 - accuracy: 0.8386\n",
      "Batch 08763: setting learning rate to 0.00019937610115380888.\n",
      "1643/3560 [============>.................] - ETA: 4:00 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08764: setting learning rate to 0.0001993757034834592.\n",
      "1644/3560 [============>.................] - ETA: 3:59 - loss: 0.5730 - accuracy: 0.8386\n",
      "Batch 08765: setting learning rate to 0.00019937530568681013.\n",
      "1645/3560 [============>.................] - ETA: 3:59 - loss: 0.5729 - accuracy: 0.8386\n",
      "Batch 08766: setting learning rate to 0.00019937490776386212.\n",
      "\n",
      "Batch 08767: setting learning rate to 0.00019937450971461572.\n",
      "1647/3560 [============>.................] - ETA: 3:59 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08768: setting learning rate to 0.00019937411153907135.\n",
      "1648/3560 [============>.................] - ETA: 3:59 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08769: setting learning rate to 0.0001993737132372296.\n",
      "1649/3560 [============>.................] - ETA: 3:59 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08770: setting learning rate to 0.00019937331480909088.\n",
      "1650/3560 [============>.................] - ETA: 3:58 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08771: setting learning rate to 0.00019937291625465582.\n",
      "1651/3560 [============>.................] - ETA: 3:59 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08772: setting learning rate to 0.00019937251757392484.\n",
      "1652/3560 [============>.................] - ETA: 3:59 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08773: setting learning rate to 0.00019937211876689848.\n",
      "1653/3560 [============>.................] - ETA: 3:59 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08774: setting learning rate to 0.00019937171983357724.\n",
      "1654/3560 [============>.................] - ETA: 3:58 - loss: 0.5728 - accuracy: 0.8385\n",
      "Batch 08775: setting learning rate to 0.00019937132077396162.\n",
      "1655/3560 [============>.................] - ETA: 3:58 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08776: setting learning rate to 0.00019937092158805214.\n",
      "1656/3560 [============>.................] - ETA: 3:58 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08777: setting learning rate to 0.0001993705222758493.\n",
      "1657/3560 [============>.................] - ETA: 3:58 - loss: 0.5726 - accuracy: 0.8386\n",
      "Batch 08778: setting learning rate to 0.00019937012283735358.\n",
      "\n",
      "Batch 08779: setting learning rate to 0.00019936972327256553.\n",
      "1659/3560 [============>.................] - ETA: 3:58 - loss: 0.5726 - accuracy: 0.8387\n",
      "Batch 08780: setting learning rate to 0.00019936932358148566.\n",
      "1660/3560 [============>.................] - ETA: 3:58 - loss: 0.5727 - accuracy: 0.8386\n",
      "Batch 08781: setting learning rate to 0.00019936892376411447.\n",
      "\n",
      "Batch 08782: setting learning rate to 0.00019936852382045243.\n",
      "1662/3560 [=============>................] - ETA: 3:57 - loss: 0.5729 - accuracy: 0.8386\n",
      "Batch 08783: setting learning rate to 0.00019936812375050011.\n",
      "1663/3560 [=============>................] - ETA: 3:57 - loss: 0.5728 - accuracy: 0.8386\n",
      "Batch 08784: setting learning rate to 0.00019936772355425798.\n",
      "1664/3560 [=============>................] - ETA: 3:57 - loss: 0.5728 - accuracy: 0.8385\n",
      "Batch 08785: setting learning rate to 0.00019936732323172653.\n",
      "1665/3560 [=============>................] - ETA: 3:57 - loss: 0.5728 - accuracy: 0.8385\n",
      "Batch 08786: setting learning rate to 0.0001993669227829063.\n",
      "1666/3560 [=============>................] - ETA: 3:57 - loss: 0.5727 - accuracy: 0.8385\n",
      "Batch 08787: setting learning rate to 0.00019936652220779778.\n",
      "\n",
      "Batch 08788: setting learning rate to 0.00019936612150640154.\n",
      "1668/3560 [=============>................] - ETA: 3:56 - loss: 0.5727 - accuracy: 0.8384\n",
      "Batch 08789: setting learning rate to 0.00019936572067871802.\n",
      "1669/3560 [=============>................] - ETA: 3:56 - loss: 0.5727 - accuracy: 0.8384\n",
      "Batch 08790: setting learning rate to 0.00019936531972474772.\n",
      "\n",
      "Batch 08791: setting learning rate to 0.0001993649186444912.\n",
      "1671/3560 [=============>................] - ETA: 3:56 - loss: 0.5728 - accuracy: 0.8384\n",
      "Batch 08792: setting learning rate to 0.00019936451743794899.\n",
      "1672/3560 [=============>................] - ETA: 3:56 - loss: 0.5726 - accuracy: 0.8384\n",
      "Batch 08793: setting learning rate to 0.0001993641161051215.\n",
      "1673/3560 [=============>................] - ETA: 3:56 - loss: 0.5729 - accuracy: 0.8384\n",
      "Batch 08794: setting learning rate to 0.00019936371464600932.\n",
      "1674/3560 [=============>................] - ETA: 3:56 - loss: 0.5727 - accuracy: 0.8384\n",
      "Batch 08795: setting learning rate to 0.00019936331306061295.\n",
      "1675/3560 [=============>................] - ETA: 3:56 - loss: 0.5725 - accuracy: 0.8385\n",
      "Batch 08796: setting learning rate to 0.0001993629113489329.\n",
      "1676/3560 [=============>................] - ETA: 3:55 - loss: 0.5726 - accuracy: 0.8385\n",
      "Batch 08797: setting learning rate to 0.00019936250951096965.\n",
      "1677/3560 [=============>................] - ETA: 3:55 - loss: 0.5726 - accuracy: 0.8385\n",
      "Batch 08798: setting learning rate to 0.00019936210754672374.\n",
      "1678/3560 [=============>................] - ETA: 3:55 - loss: 0.5726 - accuracy: 0.8385\n",
      "Batch 08799: setting learning rate to 0.00019936170545619566.\n",
      "\n",
      "Batch 08800: setting learning rate to 0.00019936130323938594.\n",
      "1680/3560 [=============>................] - ETA: 3:55 - loss: 0.5724 - accuracy: 0.8386\n",
      "Batch 08801: setting learning rate to 0.00019936090089629508.\n",
      "1681/3560 [=============>................] - ETA: 3:55 - loss: 0.5723 - accuracy: 0.8386\n",
      "Batch 08802: setting learning rate to 0.0001993604984269236.\n",
      "1682/3560 [=============>................] - ETA: 3:55 - loss: 0.5724 - accuracy: 0.8386\n",
      "Batch 08803: setting learning rate to 0.00019936009583127202.\n",
      "1683/3560 [=============>................] - ETA: 3:55 - loss: 0.5723 - accuracy: 0.8386\n",
      "Batch 08804: setting learning rate to 0.00019935969310934084.\n",
      "1684/3560 [=============>................] - ETA: 3:55 - loss: 0.5724 - accuracy: 0.8386\n",
      "Batch 08805: setting learning rate to 0.00019935929026113056.\n",
      "1685/3560 [=============>................] - ETA: 3:55 - loss: 0.5724 - accuracy: 0.8386\n",
      "Batch 08806: setting learning rate to 0.00019935888728664169.\n",
      "\n",
      "Batch 08807: setting learning rate to 0.00019935848418587478.\n",
      "1687/3560 [=============>................] - ETA: 3:54 - loss: 0.5723 - accuracy: 0.8387\n",
      "Batch 08808: setting learning rate to 0.00019935808095883034.\n",
      "1688/3560 [=============>................] - ETA: 3:54 - loss: 0.5723 - accuracy: 0.8387\n",
      "Batch 08809: setting learning rate to 0.0001993576776055088.\n",
      "1689/3560 [=============>................] - ETA: 3:54 - loss: 0.5722 - accuracy: 0.8387\n",
      "Batch 08810: setting learning rate to 0.00019935727412591077.\n",
      "1690/3560 [=============>................] - ETA: 3:54 - loss: 0.5722 - accuracy: 0.8387\n",
      "Batch 08811: setting learning rate to 0.0001993568705200367.\n",
      "\n",
      "Batch 08812: setting learning rate to 0.00019935646678788716.\n",
      "1692/3560 [=============>................] - ETA: 3:54 - loss: 0.5720 - accuracy: 0.8388\n",
      "Batch 08813: setting learning rate to 0.00019935606292946262.\n",
      "1693/3560 [=============>................] - ETA: 3:54 - loss: 0.5720 - accuracy: 0.8388\n",
      "Batch 08814: setting learning rate to 0.0001993556589447636.\n",
      "1694/3560 [=============>................] - ETA: 3:53 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08815: setting learning rate to 0.00019935525483379062.\n",
      "\n",
      "Batch 08816: setting learning rate to 0.00019935485059654418.\n",
      "1696/3560 [=============>................] - ETA: 3:53 - loss: 0.5718 - accuracy: 0.8388\n",
      "Batch 08817: setting learning rate to 0.00019935444623302482.\n",
      "1697/3560 [=============>................] - ETA: 3:53 - loss: 0.5719 - accuracy: 0.8389\n",
      "Batch 08818: setting learning rate to 0.00019935404174323303.\n",
      "1698/3560 [=============>................] - ETA: 3:53 - loss: 0.5720 - accuracy: 0.8389\n",
      "Batch 08819: setting learning rate to 0.00019935363712716934.\n",
      "\n",
      "Batch 08820: setting learning rate to 0.00019935323238483426.\n",
      "1700/3560 [=============>................] - ETA: 3:53 - loss: 0.5719 - accuracy: 0.8389\n",
      "Batch 08821: setting learning rate to 0.0001993528275162283.\n",
      "1701/3560 [=============>................] - ETA: 3:52 - loss: 0.5718 - accuracy: 0.8389\n",
      "Batch 08822: setting learning rate to 0.00019935242252135197.\n",
      "1702/3560 [=============>................] - ETA: 3:53 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08823: setting learning rate to 0.0001993520174002058.\n",
      "1703/3560 [=============>................] - ETA: 3:53 - loss: 0.5718 - accuracy: 0.8389\n",
      "Batch 08824: setting learning rate to 0.0001993516121527903.\n",
      "1704/3560 [=============>................] - ETA: 3:52 - loss: 0.5717 - accuracy: 0.8389\n",
      "Batch 08825: setting learning rate to 0.000199351206779106.\n",
      "1705/3560 [=============>................] - ETA: 3:52 - loss: 0.5717 - accuracy: 0.8389\n",
      "Batch 08826: setting learning rate to 0.00019935080127915335.\n",
      "\n",
      "Batch 08827: setting learning rate to 0.00019935039565293294.\n",
      "1707/3560 [=============>................] - ETA: 3:52 - loss: 0.5715 - accuracy: 0.8390\n",
      "Batch 08828: setting learning rate to 0.00019934998990044526.\n",
      "1708/3560 [=============>................] - ETA: 3:52 - loss: 0.5715 - accuracy: 0.8390\n",
      "Batch 08829: setting learning rate to 0.00019934958402169082.\n",
      "\n",
      "Batch 08830: setting learning rate to 0.00019934917801667012.\n",
      "1710/3560 [=============>................] - ETA: 3:52 - loss: 0.5716 - accuracy: 0.8390\n",
      "Batch 08831: setting learning rate to 0.0001993487718853837.\n",
      "1711/3560 [=============>................] - ETA: 3:51 - loss: 0.5715 - accuracy: 0.8390\n",
      "Batch 08832: setting learning rate to 0.0001993483656278321.\n",
      "1712/3560 [=============>................] - ETA: 3:51 - loss: 0.5717 - accuracy: 0.8390\n",
      "Batch 08833: setting learning rate to 0.0001993479592440158.\n",
      "1713/3560 [=============>................] - ETA: 3:51 - loss: 0.5716 - accuracy: 0.8390\n",
      "Batch 08834: setting learning rate to 0.0001993475527339353.\n",
      "1714/3560 [=============>................] - ETA: 3:51 - loss: 0.5717 - accuracy: 0.8390\n",
      "Batch 08835: setting learning rate to 0.00019934714609759117.\n",
      "\n",
      "Batch 08836: setting learning rate to 0.00019934673933498387.\n",
      "1716/3560 [=============>................] - ETA: 3:51 - loss: 0.5715 - accuracy: 0.8390\n",
      "Batch 08837: setting learning rate to 0.00019934633244611397.\n",
      "1717/3560 [=============>................] - ETA: 3:51 - loss: 0.5718 - accuracy: 0.8389\n",
      "Batch 08838: setting learning rate to 0.00019934592543098192.\n",
      "\n",
      "Batch 08839: setting learning rate to 0.00019934551828958833.\n",
      "1719/3560 [=============>................] - ETA: 3:50 - loss: 0.5715 - accuracy: 0.8390\n",
      "Batch 08840: setting learning rate to 0.00019934511102193364.\n",
      "1720/3560 [=============>................] - ETA: 3:50 - loss: 0.5716 - accuracy: 0.8390\n",
      "Batch 08841: setting learning rate to 0.00019934470362801838.\n",
      "1721/3560 [=============>................] - ETA: 3:50 - loss: 0.5718 - accuracy: 0.8390\n",
      "Batch 08842: setting learning rate to 0.00019934429610784311.\n",
      "1722/3560 [=============>................] - ETA: 3:50 - loss: 0.5717 - accuracy: 0.8390\n",
      "Batch 08843: setting learning rate to 0.0001993438884614083.\n",
      "1723/3560 [=============>................] - ETA: 3:50 - loss: 0.5718 - accuracy: 0.8389\n",
      "Batch 08844: setting learning rate to 0.0001993434806887145.\n",
      "1724/3560 [=============>................] - ETA: 3:49 - loss: 0.5718 - accuracy: 0.8389\n",
      "Batch 08845: setting learning rate to 0.00019934307278976222.\n",
      "1725/3560 [=============>................] - ETA: 3:50 - loss: 0.5719 - accuracy: 0.8389\n",
      "Batch 08846: setting learning rate to 0.00019934266476455195.\n",
      "1726/3560 [=============>................] - ETA: 3:50 - loss: 0.5720 - accuracy: 0.8388\n",
      "Batch 08847: setting learning rate to 0.00019934225661308425.\n",
      "\n",
      "Batch 08848: setting learning rate to 0.00019934184833535963.\n",
      "1728/3560 [=============>................] - ETA: 3:49 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08849: setting learning rate to 0.00019934143993137856.\n",
      "1729/3560 [=============>................] - ETA: 3:49 - loss: 0.5718 - accuracy: 0.8388\n",
      "Batch 08850: setting learning rate to 0.00019934103140114163.\n",
      "1730/3560 [=============>................] - ETA: 3:49 - loss: 0.5718 - accuracy: 0.8388\n",
      "Batch 08851: setting learning rate to 0.00019934062274464936.\n",
      "1731/3560 [=============>................] - ETA: 3:49 - loss: 0.5717 - accuracy: 0.8388\n",
      "Batch 08852: setting learning rate to 0.00019934021396190218.\n",
      "1732/3560 [=============>................] - ETA: 3:49 - loss: 0.5718 - accuracy: 0.8388\n",
      "Batch 08853: setting learning rate to 0.00019933980505290074.\n",
      "\n",
      "Batch 08854: setting learning rate to 0.00019933939601764542.\n",
      "1734/3560 [=============>................] - ETA: 3:49 - loss: 0.5720 - accuracy: 0.8387\n",
      "Batch 08855: setting learning rate to 0.00019933898685613684.\n",
      "1735/3560 [=============>................] - ETA: 3:48 - loss: 0.5720 - accuracy: 0.8387\n",
      "Batch 08856: setting learning rate to 0.00019933857756837547.\n",
      "1736/3560 [=============>................] - ETA: 3:48 - loss: 0.5720 - accuracy: 0.8388\n",
      "Batch 08857: setting learning rate to 0.00019933816815436185.\n",
      "1737/3560 [=============>................] - ETA: 3:48 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08858: setting learning rate to 0.0001993377586140965.\n",
      "1738/3560 [=============>................] - ETA: 3:48 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08859: setting learning rate to 0.00019933734894757996.\n",
      "1739/3560 [=============>................] - ETA: 3:48 - loss: 0.5719 - accuracy: 0.8388\n",
      "Batch 08860: setting learning rate to 0.0001993369391548127.\n",
      "1740/3560 [=============>................] - ETA: 3:48 - loss: 0.5719 - accuracy: 0.8387\n",
      "Batch 08861: setting learning rate to 0.0001993365292357953.\n",
      "1741/3560 [=============>................] - ETA: 3:48 - loss: 0.5718 - accuracy: 0.8388\n",
      "Batch 08862: setting learning rate to 0.0001993361191905282.\n",
      "1742/3560 [=============>................] - ETA: 3:48 - loss: 0.5718 - accuracy: 0.8387\n",
      "Batch 08863: setting learning rate to 0.00019933570901901201.\n",
      "1743/3560 [=============>................] - ETA: 3:47 - loss: 0.5717 - accuracy: 0.8387\n",
      "Batch 08864: setting learning rate to 0.0001993352987212472.\n",
      "1744/3560 [=============>................] - ETA: 3:47 - loss: 0.5715 - accuracy: 0.8388\n",
      "Batch 08865: setting learning rate to 0.0001993348882972343.\n",
      "1745/3560 [=============>................] - ETA: 3:47 - loss: 0.5714 - accuracy: 0.8388\n",
      "Batch 08866: setting learning rate to 0.00019933447774697386.\n",
      "1746/3560 [=============>................] - ETA: 3:47 - loss: 0.5714 - accuracy: 0.8389\n",
      "Batch 08867: setting learning rate to 0.00019933406707046638.\n",
      "\n",
      "Batch 08868: setting learning rate to 0.00019933365626771234.\n",
      "1748/3560 [=============>................] - ETA: 3:47 - loss: 0.5713 - accuracy: 0.8389\n",
      "Batch 08869: setting learning rate to 0.00019933324533871237.\n",
      "1749/3560 [=============>................] - ETA: 3:47 - loss: 0.5712 - accuracy: 0.8389\n",
      "Batch 08870: setting learning rate to 0.00019933283428346686.\n",
      "1750/3560 [=============>................] - ETA: 3:46 - loss: 0.5712 - accuracy: 0.8389\n",
      "Batch 08871: setting learning rate to 0.00019933242310197642.\n",
      "1751/3560 [=============>................] - ETA: 3:47 - loss: 0.5711 - accuracy: 0.8390\n",
      "Batch 08872: setting learning rate to 0.00019933201179424154.\n",
      "1752/3560 [=============>................] - ETA: 3:46 - loss: 0.5710 - accuracy: 0.8390\n",
      "Batch 08873: setting learning rate to 0.00019933160036026277.\n",
      "\n",
      "Batch 08874: setting learning rate to 0.0001993311888000406.\n",
      "1754/3560 [=============>................] - ETA: 3:46 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08875: setting learning rate to 0.00019933077711357556.\n",
      "1755/3560 [=============>................] - ETA: 3:46 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08876: setting learning rate to 0.0001993303653008682.\n",
      "1756/3560 [=============>................] - ETA: 3:46 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08877: setting learning rate to 0.00019932995336191902.\n",
      "1757/3560 [=============>................] - ETA: 3:46 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08878: setting learning rate to 0.00019932954129672857.\n",
      "\n",
      "Batch 08879: setting learning rate to 0.0001993291291052973.\n",
      "1759/3560 [=============>................] - ETA: 3:46 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08880: setting learning rate to 0.00019932871678762584.\n",
      "1760/3560 [=============>................] - ETA: 3:45 - loss: 0.5706 - accuracy: 0.8393\n",
      "Batch 08881: setting learning rate to 0.00019932830434371464.\n",
      "1761/3560 [=============>................] - ETA: 3:45 - loss: 0.5706 - accuracy: 0.8392\n",
      "Batch 08882: setting learning rate to 0.0001993278917735642.\n",
      "\n",
      "Batch 08883: setting learning rate to 0.00019932747907717513.\n",
      "1763/3560 [=============>................] - ETA: 3:45 - loss: 0.5712 - accuracy: 0.8391\n",
      "Batch 08884: setting learning rate to 0.00019932706625454795.\n",
      "1764/3560 [=============>................] - ETA: 3:45 - loss: 0.5711 - accuracy: 0.8392\n",
      "Batch 08885: setting learning rate to 0.0001993266533056831.\n",
      "1765/3560 [=============>................] - ETA: 3:45 - loss: 0.5711 - accuracy: 0.8392\n",
      "Batch 08886: setting learning rate to 0.00019932624023058116.\n",
      "1766/3560 [=============>................] - ETA: 3:44 - loss: 0.5710 - accuracy: 0.8392\n",
      "Batch 08887: setting learning rate to 0.00019932582702924262.\n",
      "\n",
      "Batch 08888: setting learning rate to 0.00019932541370166806.\n",
      "1768/3560 [=============>................] - ETA: 3:44 - loss: 0.5710 - accuracy: 0.8392\n",
      "Batch 08889: setting learning rate to 0.00019932500024785797.\n",
      "\n",
      "Batch 08890: setting learning rate to 0.0001993245866678129.\n",
      "1770/3560 [=============>................] - ETA: 3:44 - loss: 0.5712 - accuracy: 0.8392\n",
      "Batch 08891: setting learning rate to 0.00019932417296153335.\n",
      "1771/3560 [=============>................] - ETA: 3:44 - loss: 0.5712 - accuracy: 0.8392\n",
      "Batch 08892: setting learning rate to 0.00019932375912901985.\n",
      "1772/3560 [=============>................] - ETA: 3:44 - loss: 0.5711 - accuracy: 0.8392\n",
      "Batch 08893: setting learning rate to 0.00019932334517027295.\n",
      "1773/3560 [=============>................] - ETA: 3:44 - loss: 0.5710 - accuracy: 0.8392\n",
      "Batch 08894: setting learning rate to 0.00019932293108529313.\n",
      "1774/3560 [=============>................] - ETA: 3:43 - loss: 0.5709 - accuracy: 0.8393\n",
      "Batch 08895: setting learning rate to 0.00019932251687408096.\n",
      "1775/3560 [=============>................] - ETA: 3:43 - loss: 0.5708 - accuracy: 0.8393\n",
      "Batch 08896: setting learning rate to 0.00019932210253663694.\n",
      "1776/3560 [=============>................] - ETA: 3:43 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08897: setting learning rate to 0.00019932168807296164.\n",
      "1777/3560 [=============>................] - ETA: 3:43 - loss: 0.5710 - accuracy: 0.8393\n",
      "Batch 08898: setting learning rate to 0.00019932127348305548.\n",
      "1778/3560 [=============>................] - ETA: 3:43 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08899: setting learning rate to 0.00019932085876691913.\n",
      "1779/3560 [=============>................] - ETA: 3:43 - loss: 0.5712 - accuracy: 0.8393\n",
      "Batch 08900: setting learning rate to 0.00019932044392455302.\n",
      "1780/3560 [==============>...............] - ETA: 3:43 - loss: 0.5711 - accuracy: 0.8394\n",
      "Batch 08901: setting learning rate to 0.0001993200289559577.\n",
      "1781/3560 [==============>...............] - ETA: 3:43 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08902: setting learning rate to 0.00019931961386113368.\n",
      "1782/3560 [==============>...............] - ETA: 3:43 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08903: setting learning rate to 0.00019931919864008156.\n",
      "\n",
      "Batch 08904: setting learning rate to 0.0001993187832928018.\n",
      "1784/3560 [==============>...............] - ETA: 3:42 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08905: setting learning rate to 0.0001993183678192949.\n",
      "1785/3560 [==============>...............] - ETA: 3:42 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08906: setting learning rate to 0.0001993179522195615.\n",
      "1786/3560 [==============>...............] - ETA: 3:42 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08907: setting learning rate to 0.00019931753649360203.\n",
      "1787/3560 [==============>...............] - ETA: 3:42 - loss: 0.5713 - accuracy: 0.8393\n",
      "Batch 08908: setting learning rate to 0.00019931712064141707.\n",
      "\n",
      "Batch 08909: setting learning rate to 0.00019931670466300706.\n",
      "1789/3560 [==============>...............] - ETA: 3:42 - loss: 0.5712 - accuracy: 0.8393\n",
      "Batch 08910: setting learning rate to 0.00019931628855837267.\n",
      "1790/3560 [==============>...............] - ETA: 3:41 - loss: 0.5711 - accuracy: 0.8394\n",
      "Batch 08911: setting learning rate to 0.00019931587232751433.\n",
      "1791/3560 [==============>...............] - ETA: 3:41 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08912: setting learning rate to 0.00019931545597043257.\n",
      "1792/3560 [==============>...............] - ETA: 3:41 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08913: setting learning rate to 0.00019931503948712796.\n",
      "1793/3560 [==============>...............] - ETA: 3:41 - loss: 0.5711 - accuracy: 0.8394\n",
      "Batch 08914: setting learning rate to 0.00019931462287760106.\n",
      "1794/3560 [==============>...............] - ETA: 3:41 - loss: 0.5709 - accuracy: 0.8394\n",
      "Batch 08915: setting learning rate to 0.0001993142061418523.\n",
      "\n",
      "Batch 08916: setting learning rate to 0.00019931378927988226.\n",
      "1796/3560 [==============>...............] - ETA: 3:41 - loss: 0.5709 - accuracy: 0.8394\n",
      "Batch 08917: setting learning rate to 0.0001993133722916915.\n",
      "1797/3560 [==============>...............] - ETA: 3:41 - loss: 0.5708 - accuracy: 0.8394\n",
      "Batch 08918: setting learning rate to 0.0001993129551772805.\n",
      "1798/3560 [==============>...............] - ETA: 3:41 - loss: 0.5708 - accuracy: 0.8394\n",
      "Batch 08919: setting learning rate to 0.0001993125379366498.\n",
      "1799/3560 [==============>...............] - ETA: 3:41 - loss: 0.5708 - accuracy: 0.8394\n",
      "Batch 08920: setting learning rate to 0.00019931212056979996.\n",
      "1800/3560 [==============>...............] - ETA: 3:40 - loss: 0.5708 - accuracy: 0.8393\n",
      "Batch 08921: setting learning rate to 0.0001993117030767315.\n",
      "1801/3560 [==============>...............] - ETA: 3:40 - loss: 0.5707 - accuracy: 0.8394\n",
      "Batch 08922: setting learning rate to 0.00019931128545744496.\n",
      "\n",
      "Batch 08923: setting learning rate to 0.0001993108677119408.\n",
      "1803/3560 [==============>...............] - ETA: 3:40 - loss: 0.5709 - accuracy: 0.8393\n",
      "Batch 08924: setting learning rate to 0.0001993104498402196.\n",
      "1804/3560 [==============>...............] - ETA: 3:40 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08925: setting learning rate to 0.00019931003184228197.\n",
      "1805/3560 [==============>...............] - ETA: 3:40 - loss: 0.5710 - accuracy: 0.8394\n",
      "Batch 08926: setting learning rate to 0.00019930961371812832.\n",
      "\n",
      "Batch 08927: setting learning rate to 0.00019930919546775925.\n",
      "1807/3560 [==============>...............] - ETA: 3:39 - loss: 0.5711 - accuracy: 0.8394\n",
      "Batch 08928: setting learning rate to 0.00019930877709117525.\n",
      "1808/3560 [==============>...............] - ETA: 3:39 - loss: 0.5715 - accuracy: 0.8393\n",
      "Batch 08929: setting learning rate to 0.00019930835858837686.\n",
      "1809/3560 [==============>...............] - ETA: 3:39 - loss: 0.5715 - accuracy: 0.8393\n",
      "Batch 08930: setting learning rate to 0.00019930793995936465.\n",
      "1810/3560 [==============>...............] - ETA: 3:39 - loss: 0.5714 - accuracy: 0.8393\n",
      "Batch 08931: setting learning rate to 0.00019930752120413911.\n",
      "\n",
      "Batch 08932: setting learning rate to 0.0001993071023227008.\n",
      "1812/3560 [==============>...............] - ETA: 3:39 - loss: 0.5714 - accuracy: 0.8392\n",
      "Batch 08933: setting learning rate to 0.00019930668331505022.\n",
      "1813/3560 [==============>...............] - ETA: 3:39 - loss: 0.5714 - accuracy: 0.8392\n",
      "Batch 08934: setting learning rate to 0.00019930626418118794.\n",
      "1814/3560 [==============>...............] - ETA: 3:39 - loss: 0.5713 - accuracy: 0.8392\n",
      "Batch 08935: setting learning rate to 0.00019930584492111448.\n",
      "1815/3560 [==============>...............] - ETA: 3:39 - loss: 0.5713 - accuracy: 0.8392\n",
      "Batch 08936: setting learning rate to 0.00019930542553483037.\n",
      "1816/3560 [==============>...............] - ETA: 3:39 - loss: 0.5713 - accuracy: 0.8392\n",
      "Batch 08937: setting learning rate to 0.00019930500602233613.\n",
      "\n",
      "Batch 08938: setting learning rate to 0.0001993045863836323.\n",
      "1818/3560 [==============>...............] - ETA: 3:38 - loss: 0.5712 - accuracy: 0.8391\n",
      "Batch 08939: setting learning rate to 0.00019930416661871942.\n",
      "1819/3560 [==============>...............] - ETA: 3:38 - loss: 0.5711 - accuracy: 0.8391\n",
      "Batch 08940: setting learning rate to 0.00019930374672759804.\n",
      "1820/3560 [==============>...............] - ETA: 3:38 - loss: 0.5711 - accuracy: 0.8390\n",
      "Batch 08941: setting learning rate to 0.00019930332671026866.\n",
      "1821/3560 [==============>...............] - ETA: 3:38 - loss: 0.5710 - accuracy: 0.8391\n",
      "Batch 08942: setting learning rate to 0.00019930290656673184.\n",
      "1822/3560 [==============>...............] - ETA: 3:38 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08943: setting learning rate to 0.00019930248629698805.\n",
      "\n",
      "Batch 08944: setting learning rate to 0.00019930206590103796.\n",
      "1824/3560 [==============>...............] - ETA: 3:37 - loss: 0.5708 - accuracy: 0.8391\n",
      "Batch 08945: setting learning rate to 0.000199301645378882.\n",
      "1825/3560 [==============>...............] - ETA: 3:37 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08946: setting learning rate to 0.00019930122473052069.\n",
      "1826/3560 [==============>...............] - ETA: 3:37 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08947: setting learning rate to 0.00019930080395595462.\n",
      "1827/3560 [==============>...............] - ETA: 3:37 - loss: 0.5708 - accuracy: 0.8391\n",
      "Batch 08948: setting learning rate to 0.00019930038305518427.\n",
      "1828/3560 [==============>...............] - ETA: 3:37 - loss: 0.5708 - accuracy: 0.8391\n",
      "Batch 08949: setting learning rate to 0.00019929996202821024.\n",
      "1829/3560 [==============>...............] - ETA: 3:37 - loss: 0.5708 - accuracy: 0.8391\n",
      "Batch 08950: setting learning rate to 0.00019929954087503305.\n",
      "1830/3560 [==============>...............] - ETA: 3:37 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08951: setting learning rate to 0.00019929911959565318.\n",
      "1831/3560 [==============>...............] - ETA: 3:37 - loss: 0.5706 - accuracy: 0.8392\n",
      "Batch 08952: setting learning rate to 0.00019929869819007126.\n",
      "1832/3560 [==============>...............] - ETA: 3:36 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08953: setting learning rate to 0.00019929827665828774.\n",
      "1833/3560 [==============>...............] - ETA: 3:36 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08954: setting learning rate to 0.0001992978550003032.\n",
      "1834/3560 [==============>...............] - ETA: 3:36 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08955: setting learning rate to 0.00019929743321611817.\n",
      "1835/3560 [==============>...............] - ETA: 3:36 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08956: setting learning rate to 0.00019929701130573315.\n",
      "1836/3560 [==============>...............] - ETA: 3:36 - loss: 0.5709 - accuracy: 0.8392\n",
      "Batch 08957: setting learning rate to 0.0001992965892691487.\n",
      "1837/3560 [==============>...............] - ETA: 3:36 - loss: 0.5709 - accuracy: 0.8391\n",
      "Batch 08958: setting learning rate to 0.00019929616710636538.\n",
      "\n",
      "Batch 08959: setting learning rate to 0.00019929574481738374.\n",
      "1839/3560 [==============>...............] - ETA: 3:35 - loss: 0.5709 - accuracy: 0.8390\n",
      "Batch 08960: setting learning rate to 0.00019929532240220424.\n",
      "1840/3560 [==============>...............] - ETA: 3:35 - loss: 0.5709 - accuracy: 0.8390\n",
      "Batch 08961: setting learning rate to 0.00019929489986082746.\n",
      "1841/3560 [==============>...............] - ETA: 3:35 - loss: 0.5708 - accuracy: 0.8390\n",
      "Batch 08962: setting learning rate to 0.000199294477193254.\n",
      "1842/3560 [==============>...............] - ETA: 3:35 - loss: 0.5709 - accuracy: 0.8390\n",
      "Batch 08963: setting learning rate to 0.00019929405439948425.\n",
      "1843/3560 [==============>...............] - ETA: 3:35 - loss: 0.5708 - accuracy: 0.8390\n",
      "Batch 08964: setting learning rate to 0.0001992936314795189.\n",
      "1844/3560 [==============>...............] - ETA: 3:35 - loss: 0.5708 - accuracy: 0.8390\n",
      "Batch 08965: setting learning rate to 0.00019929320843335837.\n",
      "1845/3560 [==============>...............] - ETA: 3:35 - loss: 0.5708 - accuracy: 0.8391\n",
      "Batch 08966: setting learning rate to 0.00019929278526100328.\n",
      "1846/3560 [==============>...............] - ETA: 3:35 - loss: 0.5708 - accuracy: 0.8390\n",
      "Batch 08967: setting learning rate to 0.00019929236196245413.\n",
      "\n",
      "Batch 08968: setting learning rate to 0.00019929193853771146.\n",
      "1848/3560 [==============>...............] - ETA: 3:35 - loss: 0.5709 - accuracy: 0.8390\n",
      "Batch 08969: setting learning rate to 0.0001992915149867758.\n",
      "\n",
      "Batch 08970: setting learning rate to 0.00019929109130964774.\n",
      "1850/3560 [==============>...............] - ETA: 3:34 - loss: 0.5707 - accuracy: 0.8391\n",
      "Batch 08971: setting learning rate to 0.00019929066750632774.\n",
      "1851/3560 [==============>...............] - ETA: 3:34 - loss: 0.5707 - accuracy: 0.8390\n",
      "Batch 08972: setting learning rate to 0.00019929024357681637.\n",
      "1852/3560 [==============>...............] - ETA: 3:34 - loss: 0.5706 - accuracy: 0.8391\n",
      "Batch 08973: setting learning rate to 0.00019928981952111423.\n",
      "1853/3560 [==============>...............] - ETA: 3:34 - loss: 0.5710 - accuracy: 0.8391\n",
      "Batch 08974: setting learning rate to 0.00019928939533922176.\n",
      "1854/3560 [==============>...............] - ETA: 3:34 - loss: 0.5710 - accuracy: 0.8391\n",
      "Batch 08975: setting learning rate to 0.00019928897103113958.\n",
      "1855/3560 [==============>...............] - ETA: 3:33 - loss: 0.5710 - accuracy: 0.8391\n",
      "Batch 08976: setting learning rate to 0.00019928854659686818.\n",
      "1856/3560 [==============>...............] - ETA: 3:33 - loss: 0.5710 - accuracy: 0.8392\n",
      "Batch 08977: setting learning rate to 0.0001992881220364081.\n",
      "1857/3560 [==============>...............] - ETA: 3:33 - loss: 0.5711 - accuracy: 0.8392\n",
      "Batch 08978: setting learning rate to 0.0001992876973497599.\n",
      "1858/3560 [==============>...............] - ETA: 3:33 - loss: 0.5710 - accuracy: 0.8392\n",
      "Batch 08979: setting learning rate to 0.0001992872725369241.\n",
      "1859/3560 [==============>...............] - ETA: 3:33 - loss: 0.5709 - accuracy: 0.8392\n",
      "Batch 08980: setting learning rate to 0.00019928684759790125.\n",
      "1860/3560 [==============>...............] - ETA: 3:33 - loss: 0.5708 - accuracy: 0.8393\n",
      "Batch 08981: setting learning rate to 0.00019928642253269193.\n",
      "1861/3560 [==============>...............] - ETA: 3:33 - loss: 0.5708 - accuracy: 0.8392\n",
      "Batch 08982: setting learning rate to 0.0001992859973412966.\n",
      "1862/3560 [==============>...............] - ETA: 3:33 - loss: 0.5708 - accuracy: 0.8392\n",
      "Batch 08983: setting learning rate to 0.00019928557202371588.\n",
      "1863/3560 [==============>...............] - ETA: 3:33 - loss: 0.5708 - accuracy: 0.8392\n",
      "Batch 08984: setting learning rate to 0.00019928514657995024.\n",
      "1864/3560 [==============>...............] - ETA: 3:33 - loss: 0.5708 - accuracy: 0.8392\n",
      "Batch 08985: setting learning rate to 0.00019928472101000025.\n",
      "1865/3560 [==============>...............] - ETA: 3:33 - loss: 0.5707 - accuracy: 0.8392\n",
      "Batch 08986: setting learning rate to 0.0001992842953138665.\n",
      "1866/3560 [==============>...............] - ETA: 3:32 - loss: 0.5705 - accuracy: 0.8393\n",
      "Batch 08987: setting learning rate to 0.00019928386949154948.\n",
      "1867/3560 [==============>...............] - ETA: 3:32 - loss: 0.5705 - accuracy: 0.8393\n",
      "Batch 08988: setting learning rate to 0.0001992834435430497.\n",
      "\n",
      "Batch 08989: setting learning rate to 0.00019928301746836776.\n",
      "1869/3560 [==============>...............] - ETA: 3:32 - loss: 0.5703 - accuracy: 0.8394\n",
      "Batch 08990: setting learning rate to 0.0001992825912675042.\n",
      "\n",
      "Batch 08991: setting learning rate to 0.00019928216494045952.\n",
      "1871/3560 [==============>...............] - ETA: 3:32 - loss: 0.5702 - accuracy: 0.8394\n",
      "Batch 08992: setting learning rate to 0.00019928173848723427.\n",
      "1872/3560 [==============>...............] - ETA: 3:31 - loss: 0.5703 - accuracy: 0.8394\n",
      "Batch 08993: setting learning rate to 0.00019928131190782904.\n",
      "1873/3560 [==============>...............] - ETA: 3:31 - loss: 0.5704 - accuracy: 0.8394\n",
      "Batch 08994: setting learning rate to 0.0001992808852022443.\n",
      "\n",
      "Batch 08995: setting learning rate to 0.00019928045837048065.\n",
      "1875/3560 [==============>...............] - ETA: 3:31 - loss: 0.5703 - accuracy: 0.8395\n",
      "Batch 08996: setting learning rate to 0.00019928003141253862.\n",
      "1876/3560 [==============>...............] - ETA: 3:31 - loss: 0.5703 - accuracy: 0.8394\n",
      "Batch 08997: setting learning rate to 0.00019927960432841876.\n",
      "1877/3560 [==============>...............] - ETA: 3:31 - loss: 0.5702 - accuracy: 0.8395\n",
      "Batch 08998: setting learning rate to 0.00019927917711812156.\n",
      "1878/3560 [==============>...............] - ETA: 3:31 - loss: 0.5701 - accuracy: 0.8395\n",
      "Batch 08999: setting learning rate to 0.0001992787497816476.\n",
      "1879/3560 [==============>...............] - ETA: 3:31 - loss: 0.5701 - accuracy: 0.8395\n",
      "Batch 09000: setting learning rate to 0.00019927832231899745.\n",
      "1880/3560 [==============>...............] - ETA: 3:31 - loss: 0.5701 - accuracy: 0.8395\n",
      "Batch 09001: setting learning rate to 0.0001992778947301716.\n",
      "1881/3560 [==============>...............] - ETA: 3:30 - loss: 0.5699 - accuracy: 0.8395\n",
      "Batch 09002: setting learning rate to 0.00019927746701517066.\n",
      "1882/3560 [==============>...............] - ETA: 3:30 - loss: 0.5699 - accuracy: 0.8395\n",
      "Batch 09003: setting learning rate to 0.00019927703917399514.\n",
      "1883/3560 [==============>...............] - ETA: 3:30 - loss: 0.5699 - accuracy: 0.8395\n",
      "Batch 09004: setting learning rate to 0.00019927661120664554.\n",
      "1884/3560 [==============>...............] - ETA: 3:30 - loss: 0.5699 - accuracy: 0.8395\n",
      "Batch 09005: setting learning rate to 0.00019927618311312245.\n",
      "1885/3560 [==============>...............] - ETA: 3:30 - loss: 0.5698 - accuracy: 0.8395\n",
      "Batch 09006: setting learning rate to 0.0001992757548934264.\n",
      "1886/3560 [==============>...............] - ETA: 3:30 - loss: 0.5698 - accuracy: 0.8395\n",
      "Batch 09007: setting learning rate to 0.000199275326547558.\n",
      "\n",
      "Batch 09008: setting learning rate to 0.00019927489807551764.\n",
      "1888/3560 [==============>...............] - ETA: 3:30 - loss: 0.5697 - accuracy: 0.8396\n",
      "Batch 09009: setting learning rate to 0.000199274469477306.\n",
      "1889/3560 [==============>...............] - ETA: 3:29 - loss: 0.5696 - accuracy: 0.8396\n",
      "Batch 09010: setting learning rate to 0.00019927404075292362.\n",
      "1890/3560 [==============>...............] - ETA: 3:29 - loss: 0.5696 - accuracy: 0.8396\n",
      "Batch 09011: setting learning rate to 0.000199273611902371.\n",
      "1891/3560 [==============>...............] - ETA: 3:29 - loss: 0.5695 - accuracy: 0.8397\n",
      "Batch 09012: setting learning rate to 0.00019927318292564867.\n",
      "1892/3560 [==============>...............] - ETA: 3:29 - loss: 0.5696 - accuracy: 0.8396\n",
      "Batch 09013: setting learning rate to 0.00019927275382275719.\n",
      "1893/3560 [==============>...............] - ETA: 3:29 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09014: setting learning rate to 0.00019927232459369715.\n",
      "1894/3560 [==============>...............] - ETA: 3:29 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09015: setting learning rate to 0.00019927189523846902.\n",
      "1895/3560 [==============>...............] - ETA: 3:29 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09016: setting learning rate to 0.0001992714657570734.\n",
      "1896/3560 [==============>...............] - ETA: 3:28 - loss: 0.5698 - accuracy: 0.8395\n",
      "Batch 09017: setting learning rate to 0.00019927103614951084.\n",
      "1897/3560 [==============>...............] - ETA: 3:28 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09018: setting learning rate to 0.00019927060641578186.\n",
      "1898/3560 [==============>...............] - ETA: 3:28 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09019: setting learning rate to 0.000199270176555887.\n",
      "1899/3560 [===============>..............] - ETA: 3:28 - loss: 0.5696 - accuracy: 0.8396\n",
      "Batch 09020: setting learning rate to 0.0001992697465698268.\n",
      "1900/3560 [===============>..............] - ETA: 3:28 - loss: 0.5695 - accuracy: 0.8396\n",
      "Batch 09021: setting learning rate to 0.0001992693164576019.\n",
      "\n",
      "Batch 09022: setting learning rate to 0.00019926888621921274.\n",
      "1902/3560 [===============>..............] - ETA: 3:28 - loss: 0.5693 - accuracy: 0.8396\n",
      "Batch 09023: setting learning rate to 0.00019926845585465988.\n",
      "\n",
      "Batch 09024: setting learning rate to 0.00019926802536394389.\n",
      "1904/3560 [===============>..............] - ETA: 3:27 - loss: 0.5694 - accuracy: 0.8397\n",
      "Batch 09025: setting learning rate to 0.00019926759474706533.\n",
      "1905/3560 [===============>..............] - ETA: 3:27 - loss: 0.5694 - accuracy: 0.8397\n",
      "Batch 09026: setting learning rate to 0.00019926716400402473.\n",
      "1906/3560 [===============>..............] - ETA: 3:27 - loss: 0.5694 - accuracy: 0.8397\n",
      "Batch 09027: setting learning rate to 0.00019926673313482262.\n",
      "1907/3560 [===============>..............] - ETA: 3:27 - loss: 0.5693 - accuracy: 0.8397\n",
      "Batch 09028: setting learning rate to 0.00019926630213945958.\n",
      "1908/3560 [===============>..............] - ETA: 3:27 - loss: 0.5693 - accuracy: 0.8397\n",
      "Batch 09029: setting learning rate to 0.00019926587101793615.\n",
      "1909/3560 [===============>..............] - ETA: 3:27 - loss: 0.5692 - accuracy: 0.8397\n",
      "Batch 09030: setting learning rate to 0.00019926543977025286.\n",
      "\n",
      "Batch 09031: setting learning rate to 0.00019926500839641026.\n",
      "1911/3560 [===============>..............] - ETA: 3:27 - loss: 0.5694 - accuracy: 0.8396\n",
      "Batch 09032: setting learning rate to 0.00019926457689640895.\n",
      "1912/3560 [===============>..............] - ETA: 3:26 - loss: 0.5693 - accuracy: 0.8396\n",
      "Batch 09033: setting learning rate to 0.0001992641452702494.\n",
      "1913/3560 [===============>..............] - ETA: 3:26 - loss: 0.5693 - accuracy: 0.8396\n",
      "Batch 09034: setting learning rate to 0.00019926371351793222.\n",
      "\n",
      "Batch 09035: setting learning rate to 0.0001992632816394579.\n",
      "1915/3560 [===============>..............] - ETA: 3:26 - loss: 0.5692 - accuracy: 0.8396\n",
      "Batch 09036: setting learning rate to 0.00019926284963482706.\n",
      "1916/3560 [===============>..............] - ETA: 3:26 - loss: 0.5693 - accuracy: 0.8396\n",
      "Batch 09037: setting learning rate to 0.0001992624175040402.\n",
      "\n",
      "Batch 09038: setting learning rate to 0.00019926198524709788.\n",
      "1918/3560 [===============>..............] - ETA: 3:26 - loss: 0.5692 - accuracy: 0.8395\n",
      "Batch 09039: setting learning rate to 0.00019926155286400062.\n",
      "1919/3560 [===============>..............] - ETA: 3:26 - loss: 0.5692 - accuracy: 0.8395\n",
      "Batch 09040: setting learning rate to 0.00019926112035474906.\n",
      "1920/3560 [===============>..............] - ETA: 3:26 - loss: 0.5692 - accuracy: 0.8396\n",
      "Batch 09041: setting learning rate to 0.00019926068771934364.\n",
      "1921/3560 [===============>..............] - ETA: 3:25 - loss: 0.5695 - accuracy: 0.8395\n",
      "Batch 09042: setting learning rate to 0.000199260254957785.\n",
      "1922/3560 [===============>..............] - ETA: 3:25 - loss: 0.5697 - accuracy: 0.8395\n",
      "Batch 09043: setting learning rate to 0.00019925982207007363.\n",
      "1923/3560 [===============>..............] - ETA: 3:25 - loss: 0.5696 - accuracy: 0.8395\n",
      "Batch 09044: setting learning rate to 0.0001992593890562101.\n",
      "1924/3560 [===============>..............] - ETA: 3:25 - loss: 0.5695 - accuracy: 0.8395\n",
      "Batch 09045: setting learning rate to 0.00019925895591619498.\n",
      "1925/3560 [===============>..............] - ETA: 3:25 - loss: 0.5695 - accuracy: 0.8395\n",
      "Batch 09046: setting learning rate to 0.00019925852265002876.\n",
      "1926/3560 [===============>..............] - ETA: 3:25 - loss: 0.5694 - accuracy: 0.8394\n",
      "Batch 09047: setting learning rate to 0.00019925808925771204.\n",
      "1927/3560 [===============>..............] - ETA: 3:25 - loss: 0.5695 - accuracy: 0.8394\n",
      "Batch 09048: setting learning rate to 0.0001992576557392454.\n",
      "1928/3560 [===============>..............] - ETA: 3:25 - loss: 0.5696 - accuracy: 0.8394\n",
      "Batch 09049: setting learning rate to 0.00019925722209462933.\n",
      "1929/3560 [===============>..............] - ETA: 3:24 - loss: 0.5695 - accuracy: 0.8394\n",
      "Batch 09050: setting learning rate to 0.0001992567883238644.\n",
      "1930/3560 [===============>..............] - ETA: 3:24 - loss: 0.5695 - accuracy: 0.8393\n",
      "Batch 09051: setting learning rate to 0.00019925635442695117.\n",
      "1931/3560 [===============>..............] - ETA: 3:24 - loss: 0.5695 - accuracy: 0.8394\n",
      "Batch 09052: setting learning rate to 0.0001992559204038902.\n",
      "\n",
      "Batch 09053: setting learning rate to 0.000199255486254682.\n",
      "1933/3560 [===============>..............] - ETA: 3:24 - loss: 0.5695 - accuracy: 0.8394\n",
      "Batch 09054: setting learning rate to 0.00019925505197932716.\n",
      "\n",
      "Batch 09055: setting learning rate to 0.00019925461757782625.\n",
      "1935/3560 [===============>..............] - ETA: 3:24 - loss: 0.5696 - accuracy: 0.8394\n",
      "Batch 09056: setting learning rate to 0.00019925418305017978.\n",
      "1936/3560 [===============>..............] - ETA: 3:23 - loss: 0.5695 - accuracy: 0.8394\n",
      "Batch 09057: setting learning rate to 0.00019925374839638828.\n",
      "\n",
      "Batch 09058: setting learning rate to 0.0001992533136164524.\n",
      "1938/3560 [===============>..............] - ETA: 3:23 - loss: 0.5694 - accuracy: 0.8395\n",
      "Batch 09059: setting learning rate to 0.00019925287871037258.\n",
      "\n",
      "Batch 09060: setting learning rate to 0.00019925244367814945.\n",
      "1940/3560 [===============>..............] - ETA: 3:23 - loss: 0.5694 - accuracy: 0.8394\n",
      "Batch 09061: setting learning rate to 0.00019925200851978353.\n",
      "\n",
      "Batch 09062: setting learning rate to 0.0001992515732352754.\n",
      "1942/3560 [===============>..............] - ETA: 3:23 - loss: 0.5693 - accuracy: 0.8395\n",
      "Batch 09063: setting learning rate to 0.00019925113782462558.\n",
      "1943/3560 [===============>..............] - ETA: 3:22 - loss: 0.5692 - accuracy: 0.8395\n",
      "Batch 09064: setting learning rate to 0.00019925070228783462.\n",
      "\n",
      "Batch 09065: setting learning rate to 0.0001992502666249031.\n",
      "1945/3560 [===============>..............] - ETA: 3:22 - loss: 0.5690 - accuracy: 0.8396\n",
      "Batch 09066: setting learning rate to 0.0001992498308358316.\n",
      "1946/3560 [===============>..............] - ETA: 3:22 - loss: 0.5690 - accuracy: 0.8396\n",
      "Batch 09067: setting learning rate to 0.00019924939492062057.\n",
      "1947/3560 [===============>..............] - ETA: 3:22 - loss: 0.5689 - accuracy: 0.8396\n",
      "Batch 09068: setting learning rate to 0.00019924895887927068.\n",
      "1948/3560 [===============>..............] - ETA: 3:22 - loss: 0.5689 - accuracy: 0.8396\n",
      "Batch 09069: setting learning rate to 0.00019924852271178245.\n",
      "1949/3560 [===============>..............] - ETA: 3:22 - loss: 0.5687 - accuracy: 0.8397\n",
      "Batch 09070: setting learning rate to 0.00019924808641815636.\n",
      "1950/3560 [===============>..............] - ETA: 3:22 - loss: 0.5686 - accuracy: 0.8398\n",
      "Batch 09071: setting learning rate to 0.00019924764999839308.\n",
      "1951/3560 [===============>..............] - ETA: 3:21 - loss: 0.5685 - accuracy: 0.8398\n",
      "Batch 09072: setting learning rate to 0.00019924721345249312.\n",
      "1952/3560 [===============>..............] - ETA: 3:21 - loss: 0.5684 - accuracy: 0.8398\n",
      "Batch 09073: setting learning rate to 0.00019924677678045697.\n",
      "1953/3560 [===============>..............] - ETA: 3:21 - loss: 0.5683 - accuracy: 0.8399\n",
      "Batch 09074: setting learning rate to 0.00019924633998228528.\n",
      "1954/3560 [===============>..............] - ETA: 3:21 - loss: 0.5683 - accuracy: 0.8399\n",
      "Batch 09075: setting learning rate to 0.00019924590305797857.\n",
      "1955/3560 [===============>..............] - ETA: 3:21 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09076: setting learning rate to 0.00019924546600753735.\n",
      "1956/3560 [===============>..............] - ETA: 3:21 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09077: setting learning rate to 0.00019924502883096224.\n",
      "\n",
      "Batch 09078: setting learning rate to 0.0001992445915282538.\n",
      "1958/3560 [===============>..............] - ETA: 3:21 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09079: setting learning rate to 0.00019924415409941252.\n",
      "1959/3560 [===============>..............] - ETA: 3:21 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09080: setting learning rate to 0.00019924371654443898.\n",
      "1960/3560 [===============>..............] - ETA: 3:20 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09081: setting learning rate to 0.00019924327886333378.\n",
      "1961/3560 [===============>..............] - ETA: 3:20 - loss: 0.5683 - accuracy: 0.8399\n",
      "Batch 09082: setting learning rate to 0.00019924284105609744.\n",
      "1962/3560 [===============>..............] - ETA: 3:20 - loss: 0.5683 - accuracy: 0.8399\n",
      "Batch 09083: setting learning rate to 0.0001992424031227305.\n",
      "1963/3560 [===============>..............] - ETA: 3:20 - loss: 0.5682 - accuracy: 0.8399\n",
      "Batch 09084: setting learning rate to 0.00019924196506323355.\n",
      "\n",
      "Batch 09085: setting learning rate to 0.00019924152687760715.\n",
      "1965/3560 [===============>..............] - ETA: 3:20 - loss: 0.5682 - accuracy: 0.8400\n",
      "Batch 09086: setting learning rate to 0.00019924108856585182.\n",
      "1966/3560 [===============>..............] - ETA: 3:19 - loss: 0.5683 - accuracy: 0.8400\n",
      "Batch 09087: setting learning rate to 0.00019924065012796817.\n",
      "\n",
      "Batch 09088: setting learning rate to 0.00019924021156395673.\n",
      "1968/3560 [===============>..............] - ETA: 3:19 - loss: 0.5683 - accuracy: 0.8400\n",
      "Batch 09089: setting learning rate to 0.000199239772873818.\n",
      "1969/3560 [===============>..............] - ETA: 3:19 - loss: 0.5682 - accuracy: 0.8400\n",
      "Batch 09090: setting learning rate to 0.00019923933405755262.\n",
      "1970/3560 [===============>..............] - ETA: 3:19 - loss: 0.5682 - accuracy: 0.8400\n",
      "Batch 09091: setting learning rate to 0.00019923889511516113.\n",
      "1971/3560 [===============>..............] - ETA: 3:19 - loss: 0.5682 - accuracy: 0.8400\n",
      "Batch 09092: setting learning rate to 0.00019923845604664407.\n",
      "1972/3560 [===============>..............] - ETA: 3:19 - loss: 0.5681 - accuracy: 0.8400\n",
      "Batch 09093: setting learning rate to 0.00019923801685200202.\n",
      "1973/3560 [===============>..............] - ETA: 3:19 - loss: 0.5680 - accuracy: 0.8400\n",
      "Batch 09094: setting learning rate to 0.00019923757753123548.\n",
      "1974/3560 [===============>..............] - ETA: 3:19 - loss: 0.5680 - accuracy: 0.8401\n",
      "Batch 09095: setting learning rate to 0.00019923713808434507.\n",
      "1975/3560 [===============>..............] - ETA: 3:18 - loss: 0.5680 - accuracy: 0.8401\n",
      "Batch 09096: setting learning rate to 0.00019923669851133134.\n",
      "1976/3560 [===============>..............] - ETA: 3:18 - loss: 0.5679 - accuracy: 0.8401\n",
      "Batch 09097: setting learning rate to 0.00019923625881219486.\n",
      "1977/3560 [===============>..............] - ETA: 3:18 - loss: 0.5679 - accuracy: 0.8401\n",
      "Batch 09098: setting learning rate to 0.0001992358189869361.\n",
      "1978/3560 [===============>..............] - ETA: 3:18 - loss: 0.5677 - accuracy: 0.8402\n",
      "Batch 09099: setting learning rate to 0.00019923537903555576.\n",
      "1979/3560 [===============>..............] - ETA: 3:18 - loss: 0.5677 - accuracy: 0.8402\n",
      "Batch 09100: setting learning rate to 0.0001992349389580543.\n",
      "1980/3560 [===============>..............] - ETA: 3:18 - loss: 0.5678 - accuracy: 0.8402\n",
      "Batch 09101: setting learning rate to 0.0001992344987544323.\n",
      "1981/3560 [===============>..............] - ETA: 3:17 - loss: 0.5680 - accuracy: 0.8401\n",
      "Batch 09102: setting learning rate to 0.0001992340584246903.\n",
      "1982/3560 [===============>..............] - ETA: 3:17 - loss: 0.5679 - accuracy: 0.8401\n",
      "Batch 09103: setting learning rate to 0.0001992336179688289.\n",
      "1983/3560 [===============>..............] - ETA: 3:17 - loss: 0.5678 - accuracy: 0.8401\n",
      "Batch 09104: setting learning rate to 0.00019923317738684867.\n",
      "1984/3560 [===============>..............] - ETA: 3:17 - loss: 0.5679 - accuracy: 0.8401\n",
      "Batch 09105: setting learning rate to 0.00019923273667875013.\n",
      "1985/3560 [===============>..............] - ETA: 3:17 - loss: 0.5678 - accuracy: 0.8401\n",
      "Batch 09106: setting learning rate to 0.00019923229584453385.\n",
      "1986/3560 [===============>..............] - ETA: 3:17 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09107: setting learning rate to 0.0001992318548842004.\n",
      "1987/3560 [===============>..............] - ETA: 3:17 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09108: setting learning rate to 0.00019923141379775031.\n",
      "1988/3560 [===============>..............] - ETA: 3:17 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09109: setting learning rate to 0.00019923097258518418.\n",
      "1989/3560 [===============>..............] - ETA: 3:17 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09110: setting learning rate to 0.00019923053124650255.\n",
      "1990/3560 [===============>..............] - ETA: 3:17 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09111: setting learning rate to 0.000199230089781706.\n",
      "1991/3560 [===============>..............] - ETA: 3:16 - loss: 0.5676 - accuracy: 0.8402\n",
      "Batch 09112: setting learning rate to 0.00019922964819079508.\n",
      "\n",
      "Batch 09113: setting learning rate to 0.00019922920647377033.\n",
      "1993/3560 [===============>..............] - ETA: 3:16 - loss: 0.5674 - accuracy: 0.8403\n",
      "Batch 09114: setting learning rate to 0.00019922876463063233.\n",
      "\n",
      "Batch 09115: setting learning rate to 0.00019922832266138166.\n",
      "1995/3560 [===============>..............] - ETA: 3:16 - loss: 0.5673 - accuracy: 0.8403\n",
      "Batch 09116: setting learning rate to 0.00019922788056601887.\n",
      "1996/3560 [===============>..............] - ETA: 3:16 - loss: 0.5672 - accuracy: 0.8403\n",
      "Batch 09117: setting learning rate to 0.00019922743834454448.\n",
      "1997/3560 [===============>..............] - ETA: 3:15 - loss: 0.5673 - accuracy: 0.8404\n",
      "Batch 09118: setting learning rate to 0.00019922699599695914.\n",
      "\n",
      "Batch 09119: setting learning rate to 0.00019922655352326332.\n",
      "1999/3560 [===============>..............] - ETA: 3:15 - loss: 0.5672 - accuracy: 0.8404\n",
      "Batch 09120: setting learning rate to 0.00019922611092345761.\n",
      "2000/3560 [===============>..............] - ETA: 3:15 - loss: 0.5671 - accuracy: 0.8404\n",
      "Batch 09121: setting learning rate to 0.00019922566819754263.\n",
      "2001/3560 [===============>..............] - ETA: 3:15 - loss: 0.5671 - accuracy: 0.8404\n",
      "Batch 09122: setting learning rate to 0.00019922522534551886.\n",
      "2002/3560 [===============>..............] - ETA: 3:15 - loss: 0.5672 - accuracy: 0.8404\n",
      "Batch 09123: setting learning rate to 0.00019922478236738693.\n",
      "\n",
      "Batch 09124: setting learning rate to 0.00019922433926314735.\n",
      "2004/3560 [===============>..............] - ETA: 3:15 - loss: 0.5675 - accuracy: 0.8404\n",
      "Batch 09125: setting learning rate to 0.00019922389603280072.\n",
      "2005/3560 [===============>..............] - ETA: 3:15 - loss: 0.5678 - accuracy: 0.8404\n",
      "Batch 09126: setting learning rate to 0.00019922345267634758.\n",
      "2006/3560 [===============>..............] - ETA: 3:14 - loss: 0.5678 - accuracy: 0.8403\n",
      "Batch 09127: setting learning rate to 0.00019922300919378853.\n",
      "2007/3560 [===============>..............] - ETA: 3:14 - loss: 0.5678 - accuracy: 0.8403\n",
      "Batch 09128: setting learning rate to 0.00019922256558512405.\n",
      "2008/3560 [===============>..............] - ETA: 3:14 - loss: 0.5678 - accuracy: 0.8402\n",
      "Batch 09129: setting learning rate to 0.0001992221218503548.\n",
      "2009/3560 [===============>..............] - ETA: 3:14 - loss: 0.5678 - accuracy: 0.8402\n",
      "Batch 09130: setting learning rate to 0.00019922167798948128.\n",
      "\n",
      "Batch 09131: setting learning rate to 0.0001992212340025041.\n",
      "2011/3560 [===============>..............] - ETA: 3:14 - loss: 0.5677 - accuracy: 0.8402\n",
      "Batch 09132: setting learning rate to 0.00019922078988942381.\n",
      "2012/3560 [===============>..............] - ETA: 3:14 - loss: 0.5678 - accuracy: 0.8402\n",
      "Batch 09133: setting learning rate to 0.00019922034565024097.\n",
      "2013/3560 [===============>..............] - ETA: 3:13 - loss: 0.5678 - accuracy: 0.8401\n",
      "Batch 09134: setting learning rate to 0.0001992199012849561.\n",
      "2014/3560 [===============>..............] - ETA: 3:13 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09135: setting learning rate to 0.00019921945679356987.\n",
      "2015/3560 [===============>..............] - ETA: 3:13 - loss: 0.5681 - accuracy: 0.8399\n",
      "Batch 09136: setting learning rate to 0.00019921901217608272.\n",
      "2016/3560 [===============>..............] - ETA: 3:13 - loss: 0.5679 - accuracy: 0.8399\n",
      "Batch 09137: setting learning rate to 0.0001992185674324953.\n",
      "2017/3560 [===============>..............] - ETA: 3:13 - loss: 0.5680 - accuracy: 0.8399\n",
      "Batch 09138: setting learning rate to 0.00019921812256280816.\n",
      "2018/3560 [================>.............] - ETA: 3:13 - loss: 0.5678 - accuracy: 0.8399\n",
      "Batch 09139: setting learning rate to 0.00019921767756702184.\n",
      "2019/3560 [================>.............] - ETA: 3:13 - loss: 0.5679 - accuracy: 0.8399\n",
      "Batch 09140: setting learning rate to 0.00019921723244513694.\n",
      "\n",
      "Batch 09141: setting learning rate to 0.00019921678719715403.\n",
      "2021/3560 [================>.............] - ETA: 3:12 - loss: 0.5677 - accuracy: 0.8400\n",
      "Batch 09142: setting learning rate to 0.00019921634182307362.\n",
      "2022/3560 [================>.............] - ETA: 3:12 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09143: setting learning rate to 0.0001992158963228963.\n",
      "\n",
      "Batch 09144: setting learning rate to 0.00019921545069662266.\n",
      "2024/3560 [================>.............] - ETA: 3:12 - loss: 0.5679 - accuracy: 0.8400\n",
      "Batch 09145: setting learning rate to 0.00019921500494425324.\n",
      "2025/3560 [================>.............] - ETA: 3:12 - loss: 0.5680 - accuracy: 0.8400\n",
      "Batch 09146: setting learning rate to 0.00019921455906578867.\n",
      "2026/3560 [================>.............] - ETA: 3:12 - loss: 0.5679 - accuracy: 0.8400\n",
      "Batch 09147: setting learning rate to 0.0001992141130612294.\n",
      "\n",
      "Batch 09148: setting learning rate to 0.0001992136669305761.\n",
      "2028/3560 [================>.............] - ETA: 3:11 - loss: 0.5678 - accuracy: 0.8401\n",
      "Batch 09149: setting learning rate to 0.0001992132206738293.\n",
      "2029/3560 [================>.............] - ETA: 3:12 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09150: setting learning rate to 0.00019921277429098958.\n",
      "2030/3560 [================>.............] - ETA: 3:11 - loss: 0.5678 - accuracy: 0.8401\n",
      "Batch 09151: setting learning rate to 0.00019921232778205748.\n",
      "2031/3560 [================>.............] - ETA: 3:11 - loss: 0.5681 - accuracy: 0.8400\n",
      "Batch 09152: setting learning rate to 0.00019921188114703357.\n",
      "2032/3560 [================>.............] - ETA: 3:11 - loss: 0.5681 - accuracy: 0.8400\n",
      "Batch 09153: setting learning rate to 0.00019921143438591843.\n",
      "2033/3560 [================>.............] - ETA: 3:11 - loss: 0.5681 - accuracy: 0.8400\n",
      "Batch 09154: setting learning rate to 0.00019921098749871264.\n",
      "2034/3560 [================>.............] - ETA: 3:11 - loss: 0.5681 - accuracy: 0.8399\n",
      "Batch 09155: setting learning rate to 0.00019921054048541677.\n",
      "2035/3560 [================>.............] - ETA: 3:10 - loss: 0.5681 - accuracy: 0.8399\n",
      "Batch 09156: setting learning rate to 0.00019921009334603133.\n",
      "2036/3560 [================>.............] - ETA: 3:10 - loss: 0.5680 - accuracy: 0.8399\n",
      "Batch 09157: setting learning rate to 0.00019920964608055697.\n",
      "2037/3560 [================>.............] - ETA: 3:11 - loss: 0.5681 - accuracy: 0.8399\n",
      "Batch 09158: setting learning rate to 0.0001992091986889942.\n",
      "2038/3560 [================>.............] - ETA: 3:10 - loss: 0.5680 - accuracy: 0.8399\n",
      "Batch 09159: setting learning rate to 0.00019920875117134364.\n",
      "2039/3560 [================>.............] - ETA: 3:10 - loss: 0.5681 - accuracy: 0.8398\n",
      "Batch 09160: setting learning rate to 0.00019920830352760578.\n",
      "2040/3560 [================>.............] - ETA: 3:10 - loss: 0.5679 - accuracy: 0.8398\n",
      "Batch 09161: setting learning rate to 0.00019920785575778128.\n",
      "\n",
      "Batch 09162: setting learning rate to 0.00019920740786187065.\n",
      "2042/3560 [================>.............] - ETA: 3:10 - loss: 0.5680 - accuracy: 0.8398\n",
      "Batch 09163: setting learning rate to 0.00019920695983987444.\n",
      "2043/3560 [================>.............] - ETA: 3:09 - loss: 0.5680 - accuracy: 0.8398\n",
      "Batch 09164: setting learning rate to 0.0001992065116917933.\n",
      "2044/3560 [================>.............] - ETA: 3:09 - loss: 0.5680 - accuracy: 0.8397\n",
      "Batch 09165: setting learning rate to 0.00019920606341762773.\n",
      "2045/3560 [================>.............] - ETA: 3:09 - loss: 0.5680 - accuracy: 0.8397\n",
      "Batch 09166: setting learning rate to 0.00019920561501737832.\n",
      "2046/3560 [================>.............] - ETA: 3:09 - loss: 0.5679 - accuracy: 0.8397\n",
      "Batch 09167: setting learning rate to 0.00019920516649104566.\n",
      "2047/3560 [================>.............] - ETA: 3:09 - loss: 0.5681 - accuracy: 0.8397\n",
      "Batch 09168: setting learning rate to 0.0001992047178386303.\n",
      "\n",
      "Batch 09169: setting learning rate to 0.00019920426906013284.\n",
      "2049/3560 [================>.............] - ETA: 3:09 - loss: 0.5681 - accuracy: 0.8398\n",
      "Batch 09170: setting learning rate to 0.00019920382015555378.\n",
      "\n",
      "Batch 09171: setting learning rate to 0.00019920337112489374.\n",
      "2051/3560 [================>.............] - ETA: 3:09 - loss: 0.5681 - accuracy: 0.8398\n",
      "Batch 09172: setting learning rate to 0.00019920292196815332.\n",
      "2052/3560 [================>.............] - ETA: 3:09 - loss: 0.5681 - accuracy: 0.8398\n",
      "Batch 09173: setting learning rate to 0.00019920247268533304.\n",
      "2053/3560 [================>.............] - ETA: 3:08 - loss: 0.5680 - accuracy: 0.8398\n",
      "Batch 09174: setting learning rate to 0.00019920202327643348.\n",
      "\n",
      "Batch 09175: setting learning rate to 0.0001992015737414552.\n",
      "2055/3560 [================>.............] - ETA: 3:08 - loss: 0.5678 - accuracy: 0.8399\n",
      "Batch 09176: setting learning rate to 0.00019920112408039882.\n",
      "\n",
      "Batch 09177: setting learning rate to 0.00019920067429326485.\n",
      "2057/3560 [================>.............] - ETA: 3:08 - loss: 0.5677 - accuracy: 0.8400\n",
      "Batch 09178: setting learning rate to 0.00019920022438005392.\n",
      "2058/3560 [================>.............] - ETA: 3:08 - loss: 0.5677 - accuracy: 0.8400\n",
      "Batch 09179: setting learning rate to 0.00019919977434076656.\n",
      "2059/3560 [================>.............] - ETA: 3:08 - loss: 0.5677 - accuracy: 0.8400\n",
      "Batch 09180: setting learning rate to 0.00019919932417540337.\n",
      "2060/3560 [================>.............] - ETA: 3:08 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09181: setting learning rate to 0.00019919887388396488.\n",
      "2061/3560 [================>.............] - ETA: 3:07 - loss: 0.5675 - accuracy: 0.8400\n",
      "Batch 09182: setting learning rate to 0.00019919842346645172.\n",
      "\n",
      "Batch 09183: setting learning rate to 0.00019919797292286445.\n",
      "2063/3560 [================>.............] - ETA: 3:07 - loss: 0.5674 - accuracy: 0.8400\n",
      "Batch 09184: setting learning rate to 0.00019919752225320357.\n",
      "2064/3560 [================>.............] - ETA: 3:07 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09185: setting learning rate to 0.00019919707145746974.\n",
      "2065/3560 [================>.............] - ETA: 3:07 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09186: setting learning rate to 0.0001991966205356635.\n",
      "2066/3560 [================>.............] - ETA: 3:07 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09187: setting learning rate to 0.00019919616948778544.\n",
      "2067/3560 [================>.............] - ETA: 3:07 - loss: 0.5676 - accuracy: 0.8401\n",
      "Batch 09188: setting learning rate to 0.0001991957183138361.\n",
      "2068/3560 [================>.............] - ETA: 3:06 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09189: setting learning rate to 0.00019919526701381608.\n",
      "2069/3560 [================>.............] - ETA: 3:06 - loss: 0.5677 - accuracy: 0.8400\n",
      "Batch 09190: setting learning rate to 0.00019919481558772594.\n",
      "2070/3560 [================>.............] - ETA: 3:06 - loss: 0.5679 - accuracy: 0.8400\n",
      "Batch 09191: setting learning rate to 0.00019919436403556626.\n",
      "2071/3560 [================>.............] - ETA: 3:06 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09192: setting learning rate to 0.0001991939123573376.\n",
      "2072/3560 [================>.............] - ETA: 3:06 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09193: setting learning rate to 0.00019919346055304054.\n",
      "2073/3560 [================>.............] - ETA: 3:06 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09194: setting learning rate to 0.0001991930086226757.\n",
      "2074/3560 [================>.............] - ETA: 3:05 - loss: 0.5678 - accuracy: 0.8400\n",
      "Batch 09195: setting learning rate to 0.0001991925565662436.\n",
      "\n",
      "Batch 09196: setting learning rate to 0.00019919210438374484.\n",
      "2076/3560 [================>.............] - ETA: 3:05 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09197: setting learning rate to 0.00019919165207517997.\n",
      "2077/3560 [================>.............] - ETA: 3:05 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09198: setting learning rate to 0.00019919119964054955.\n",
      "2078/3560 [================>.............] - ETA: 3:05 - loss: 0.5675 - accuracy: 0.8401\n",
      "Batch 09199: setting learning rate to 0.00019919074707985425.\n",
      "2079/3560 [================>.............] - ETA: 3:05 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09200: setting learning rate to 0.0001991902943930945.\n",
      "2080/3560 [================>.............] - ETA: 3:05 - loss: 0.5675 - accuracy: 0.8401\n",
      "Batch 09201: setting learning rate to 0.000199189841580271.\n",
      "\n",
      "Batch 09202: setting learning rate to 0.0001991893886413843.\n",
      "2082/3560 [================>.............] - ETA: 3:05 - loss: 0.5675 - accuracy: 0.8400\n",
      "Batch 09203: setting learning rate to 0.00019918893557643492.\n",
      "2083/3560 [================>.............] - ETA: 3:05 - loss: 0.5675 - accuracy: 0.8400\n",
      "Batch 09204: setting learning rate to 0.00019918848238542348.\n",
      "2084/3560 [================>.............] - ETA: 3:04 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09205: setting learning rate to 0.00019918802906835055.\n",
      "2085/3560 [================>.............] - ETA: 3:04 - loss: 0.5675 - accuracy: 0.8400\n",
      "Batch 09206: setting learning rate to 0.00019918757562521674.\n",
      "2086/3560 [================>.............] - ETA: 3:04 - loss: 0.5675 - accuracy: 0.8400\n",
      "Batch 09207: setting learning rate to 0.00019918712205602254.\n",
      "2087/3560 [================>.............] - ETA: 3:04 - loss: 0.5675 - accuracy: 0.8401\n",
      "Batch 09208: setting learning rate to 0.0001991866683607686.\n",
      "2088/3560 [================>.............] - ETA: 3:04 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09209: setting learning rate to 0.00019918621453945544.\n",
      "2089/3560 [================>.............] - ETA: 3:04 - loss: 0.5676 - accuracy: 0.8400\n",
      "Batch 09210: setting learning rate to 0.00019918576059208372.\n",
      "2090/3560 [================>.............] - ETA: 3:03 - loss: 0.5675 - accuracy: 0.8401\n",
      "Batch 09211: setting learning rate to 0.00019918530651865394.\n",
      "\n",
      "Batch 09212: setting learning rate to 0.0001991848523191667.\n",
      "2092/3560 [================>.............] - ETA: 3:03 - loss: 0.5675 - accuracy: 0.8401\n",
      "Batch 09213: setting learning rate to 0.00019918439799362258.\n",
      "\n",
      "Batch 09214: setting learning rate to 0.00019918394354202218.\n",
      "2094/3560 [================>.............] - ETA: 3:03 - loss: 0.5676 - accuracy: 0.8402\n",
      "Batch 09215: setting learning rate to 0.00019918348896436606.\n",
      "2095/3560 [================>.............] - ETA: 3:03 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09216: setting learning rate to 0.00019918303426065477.\n",
      "\n",
      "Batch 09217: setting learning rate to 0.0001991825794308889.\n",
      "2097/3560 [================>.............] - ETA: 3:03 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09218: setting learning rate to 0.00019918212447506906.\n",
      "2098/3560 [================>.............] - ETA: 3:02 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09219: setting learning rate to 0.00019918166939319584.\n",
      "2099/3560 [================>.............] - ETA: 3:02 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09220: setting learning rate to 0.00019918121418526977.\n",
      "2100/3560 [================>.............] - ETA: 3:02 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09221: setting learning rate to 0.0001991807588512914.\n",
      "\n",
      "Batch 09222: setting learning rate to 0.0001991803033912614.\n",
      "2102/3560 [================>.............] - ETA: 3:02 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09223: setting learning rate to 0.0001991798478051803.\n",
      "2103/3560 [================>.............] - ETA: 3:02 - loss: 0.5676 - accuracy: 0.8402\n",
      "Batch 09224: setting learning rate to 0.00019917939209304866.\n",
      "2104/3560 [================>.............] - ETA: 3:02 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09225: setting learning rate to 0.0001991789362548671.\n",
      "2105/3560 [================>.............] - ETA: 3:01 - loss: 0.5676 - accuracy: 0.8402\n",
      "Batch 09226: setting learning rate to 0.00019917848029063614.\n",
      "\n",
      "Batch 09227: setting learning rate to 0.00019917802420035642.\n",
      "2107/3560 [================>.............] - ETA: 3:01 - loss: 0.5675 - accuracy: 0.8402\n",
      "Batch 09228: setting learning rate to 0.00019917756798402852.\n",
      "2108/3560 [================>.............] - ETA: 3:01 - loss: 0.5677 - accuracy: 0.8401\n",
      "Batch 09229: setting learning rate to 0.000199177111641653.\n",
      "2109/3560 [================>.............] - ETA: 3:01 - loss: 0.5676 - accuracy: 0.8402\n",
      "Batch 09230: setting learning rate to 0.0001991766551732304.\n",
      "\n",
      "Batch 09231: setting learning rate to 0.00019917619857876136.\n",
      "2111/3560 [================>.............] - ETA: 3:01 - loss: 0.5673 - accuracy: 0.8402\n",
      "Batch 09232: setting learning rate to 0.00019917574185824647.\n",
      "2112/3560 [================>.............] - ETA: 3:01 - loss: 0.5673 - accuracy: 0.8403\n",
      "Batch 09233: setting learning rate to 0.00019917528501168627.\n",
      "2113/3560 [================>.............] - ETA: 3:01 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09234: setting learning rate to 0.00019917482803908133.\n",
      "\n",
      "Batch 09235: setting learning rate to 0.00019917437094043225.\n",
      "2115/3560 [================>.............] - ETA: 3:00 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09236: setting learning rate to 0.00019917391371573962.\n",
      "2116/3560 [================>.............] - ETA: 3:00 - loss: 0.5673 - accuracy: 0.8402\n",
      "Batch 09237: setting learning rate to 0.00019917345636500403.\n",
      "2117/3560 [================>.............] - ETA: 3:00 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09238: setting learning rate to 0.000199172998888226.\n",
      "2118/3560 [================>.............] - ETA: 3:00 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09239: setting learning rate to 0.00019917254128540618.\n",
      "2119/3560 [================>.............] - ETA: 3:00 - loss: 0.5671 - accuracy: 0.8402\n",
      "Batch 09240: setting learning rate to 0.00019917208355654516.\n",
      "2120/3560 [================>.............] - ETA: 3:00 - loss: 0.5671 - accuracy: 0.8402\n",
      "Batch 09241: setting learning rate to 0.00019917162570164346.\n",
      "2121/3560 [================>.............] - ETA: 2:59 - loss: 0.5671 - accuracy: 0.8402\n",
      "Batch 09242: setting learning rate to 0.0001991711677207017.\n",
      "2122/3560 [================>.............] - ETA: 2:59 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09243: setting learning rate to 0.00019917070961372044.\n",
      "2123/3560 [================>.............] - ETA: 2:59 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09244: setting learning rate to 0.00019917025138070028.\n",
      "2124/3560 [================>.............] - ETA: 2:59 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09245: setting learning rate to 0.0001991697930216418.\n",
      "2125/3560 [================>.............] - ETA: 2:59 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09246: setting learning rate to 0.0001991693345365456.\n",
      "2126/3560 [================>.............] - ETA: 2:59 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09247: setting learning rate to 0.00019916887592541223.\n",
      "\n",
      "Batch 09248: setting learning rate to 0.00019916841718824226.\n",
      "2128/3560 [================>.............] - ETA: 2:59 - loss: 0.5673 - accuracy: 0.8402\n",
      "Batch 09249: setting learning rate to 0.0001991679583250363.\n",
      "2129/3560 [================>.............] - ETA: 2:59 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09250: setting learning rate to 0.00019916749933579497.\n",
      "\n",
      "Batch 09251: setting learning rate to 0.0001991670402205188.\n",
      "2131/3560 [================>.............] - ETA: 2:59 - loss: 0.5674 - accuracy: 0.8401\n",
      "Batch 09252: setting learning rate to 0.0001991665809792084.\n",
      "2132/3560 [================>.............] - ETA: 2:58 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09253: setting learning rate to 0.00019916612161186432.\n",
      "2133/3560 [================>.............] - ETA: 2:58 - loss: 0.5673 - accuracy: 0.8402\n",
      "Batch 09254: setting learning rate to 0.0001991656621184872.\n",
      "2134/3560 [================>.............] - ETA: 2:58 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09255: setting learning rate to 0.00019916520249907755.\n",
      "2135/3560 [================>.............] - ETA: 2:58 - loss: 0.5674 - accuracy: 0.8402\n",
      "Batch 09256: setting learning rate to 0.00019916474275363601.\n",
      "2136/3560 [=================>............] - ETA: 2:58 - loss: 0.5673 - accuracy: 0.8402\n",
      "Batch 09257: setting learning rate to 0.00019916428288216316.\n",
      "2137/3560 [=================>............] - ETA: 2:57 - loss: 0.5673 - accuracy: 0.8403\n",
      "Batch 09258: setting learning rate to 0.00019916382288465956.\n",
      "2138/3560 [=================>............] - ETA: 2:57 - loss: 0.5674 - accuracy: 0.8403\n",
      "Batch 09259: setting learning rate to 0.0001991633627611258.\n",
      "\n",
      "Batch 09260: setting learning rate to 0.0001991629025115625.\n",
      "2140/3560 [=================>............] - ETA: 2:57 - loss: 0.5672 - accuracy: 0.8403\n",
      "Batch 09261: setting learning rate to 0.0001991624421359702.\n",
      "\n",
      "Batch 09262: setting learning rate to 0.00019916198163434952.\n",
      "2142/3560 [=================>............] - ETA: 2:57 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09263: setting learning rate to 0.000199161521006701.\n",
      "2143/3560 [=================>............] - ETA: 2:57 - loss: 0.5672 - accuracy: 0.8403\n",
      "Batch 09264: setting learning rate to 0.00019916106025302528.\n",
      "2144/3560 [=================>............] - ETA: 2:57 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09265: setting learning rate to 0.0001991605993733229.\n",
      "2145/3560 [=================>............] - ETA: 2:56 - loss: 0.5670 - accuracy: 0.8403\n",
      "Batch 09266: setting learning rate to 0.0001991601383675945.\n",
      "\n",
      "Batch 09267: setting learning rate to 0.0001991596772358406.\n",
      "2147/3560 [=================>............] - ETA: 2:56 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09268: setting learning rate to 0.00019915921597806182.\n",
      "2148/3560 [=================>............] - ETA: 2:56 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09269: setting learning rate to 0.00019915875459425875.\n",
      "\n",
      "Batch 09270: setting learning rate to 0.00019915829308443197.\n",
      "2150/3560 [=================>............] - ETA: 2:56 - loss: 0.5672 - accuracy: 0.8403\n",
      "Batch 09271: setting learning rate to 0.00019915783144858207.\n",
      "2151/3560 [=================>............] - ETA: 2:56 - loss: 0.5673 - accuracy: 0.8403\n",
      "Batch 09272: setting learning rate to 0.0001991573696867096.\n",
      "2152/3560 [=================>............] - ETA: 2:56 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09273: setting learning rate to 0.0001991569077988152.\n",
      "2153/3560 [=================>............] - ETA: 2:55 - loss: 0.5672 - accuracy: 0.8403\n",
      "Batch 09274: setting learning rate to 0.00019915644578489945.\n",
      "2154/3560 [=================>............] - ETA: 2:55 - loss: 0.5672 - accuracy: 0.8402\n",
      "Batch 09275: setting learning rate to 0.00019915598364496294.\n",
      "2155/3560 [=================>............] - ETA: 2:55 - loss: 0.5671 - accuracy: 0.8403\n",
      "Batch 09276: setting learning rate to 0.0001991555213790062.\n",
      "2156/3560 [=================>............] - ETA: 2:55 - loss: 0.5670 - accuracy: 0.8403\n",
      "Batch 09277: setting learning rate to 0.00019915505898702987.\n",
      "2157/3560 [=================>............] - ETA: 2:55 - loss: 0.5670 - accuracy: 0.8403\n",
      "Batch 09278: setting learning rate to 0.00019915459646903453.\n",
      "2158/3560 [=================>............] - ETA: 2:55 - loss: 0.5670 - accuracy: 0.8402\n",
      "Batch 09279: setting learning rate to 0.00019915413382502078.\n",
      "2159/3560 [=================>............] - ETA: 2:55 - loss: 0.5671 - accuracy: 0.8402\n",
      "Batch 09280: setting learning rate to 0.00019915367105498917.\n",
      "2160/3560 [=================>............] - ETA: 2:55 - loss: 0.5670 - accuracy: 0.8402\n",
      "Batch 09281: setting learning rate to 0.00019915320815894032.\n",
      "2161/3560 [=================>............] - ETA: 2:54 - loss: 0.5670 - accuracy: 0.8402\n",
      "Batch 09282: setting learning rate to 0.0001991527451368748.\n",
      "2162/3560 [=================>............] - ETA: 2:54 - loss: 0.5671 - accuracy: 0.8402\n",
      "Batch 09283: setting learning rate to 0.0001991522819887932.\n",
      "2163/3560 [=================>............] - ETA: 2:54 - loss: 0.5670 - accuracy: 0.8402\n",
      "Batch 09284: setting learning rate to 0.00019915181871469614.\n",
      "2164/3560 [=================>............] - ETA: 2:54 - loss: 0.5669 - accuracy: 0.8402\n",
      "Batch 09285: setting learning rate to 0.0001991513553145842.\n",
      "2165/3560 [=================>............] - ETA: 2:54 - loss: 0.5669 - accuracy: 0.8402\n",
      "Batch 09286: setting learning rate to 0.00019915089178845793.\n",
      "\n",
      "Batch 09287: setting learning rate to 0.00019915042813631795.\n",
      "2167/3560 [=================>............] - ETA: 2:54 - loss: 0.5667 - accuracy: 0.8402\n",
      "Batch 09288: setting learning rate to 0.00019914996435816483.\n",
      "2168/3560 [=================>............] - ETA: 2:53 - loss: 0.5667 - accuracy: 0.8403\n",
      "Batch 09289: setting learning rate to 0.00019914950045399915.\n",
      "2169/3560 [=================>............] - ETA: 2:53 - loss: 0.5666 - accuracy: 0.8404\n",
      "Batch 09290: setting learning rate to 0.00019914903642382153.\n",
      "2170/3560 [=================>............] - ETA: 2:53 - loss: 0.5665 - accuracy: 0.8404\n",
      "Batch 09291: setting learning rate to 0.0001991485722676326.\n",
      "2171/3560 [=================>............] - ETA: 2:53 - loss: 0.5665 - accuracy: 0.8404\n",
      "Batch 09292: setting learning rate to 0.00019914810798543286.\n",
      "2172/3560 [=================>............] - ETA: 2:53 - loss: 0.5666 - accuracy: 0.8404\n",
      "Batch 09293: setting learning rate to 0.00019914764357722295.\n",
      "\n",
      "Batch 09294: setting learning rate to 0.00019914717904300346.\n",
      "2174/3560 [=================>............] - ETA: 2:53 - loss: 0.5666 - accuracy: 0.8404\n",
      "Batch 09295: setting learning rate to 0.00019914671438277495.\n",
      "2175/3560 [=================>............] - ETA: 2:52 - loss: 0.5666 - accuracy: 0.8404\n",
      "Batch 09296: setting learning rate to 0.00019914624959653805.\n",
      "2176/3560 [=================>............] - ETA: 2:52 - loss: 0.5666 - accuracy: 0.8405\n",
      "Batch 09297: setting learning rate to 0.00019914578468429334.\n",
      "2177/3560 [=================>............] - ETA: 2:52 - loss: 0.5666 - accuracy: 0.8405\n",
      "Batch 09298: setting learning rate to 0.00019914531964604137.\n",
      "2178/3560 [=================>............] - ETA: 2:52 - loss: 0.5665 - accuracy: 0.8405\n",
      "Batch 09299: setting learning rate to 0.0001991448544817828.\n",
      "2179/3560 [=================>............] - ETA: 2:52 - loss: 0.5667 - accuracy: 0.8405\n",
      "Batch 09300: setting learning rate to 0.00019914438919151815.\n",
      "2180/3560 [=================>............] - ETA: 2:52 - loss: 0.5665 - accuracy: 0.8405\n",
      "Batch 09301: setting learning rate to 0.00019914392377524807.\n",
      "2181/3560 [=================>............] - ETA: 2:52 - loss: 0.5666 - accuracy: 0.8404\n",
      "Batch 09302: setting learning rate to 0.00019914345823297315.\n",
      "\n",
      "Batch 09303: setting learning rate to 0.00019914299256469393.\n",
      "2183/3560 [=================>............] - ETA: 2:52 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09304: setting learning rate to 0.000199142526770411.\n",
      "\n",
      "Batch 09305: setting learning rate to 0.00019914206085012507.\n",
      "2185/3560 [=================>............] - ETA: 2:51 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09306: setting learning rate to 0.00019914159480383657.\n",
      "2186/3560 [=================>............] - ETA: 2:51 - loss: 0.5665 - accuracy: 0.8402\n",
      "Batch 09307: setting learning rate to 0.00019914112863154618.\n",
      "2187/3560 [=================>............] - ETA: 2:51 - loss: 0.5666 - accuracy: 0.8402\n",
      "Batch 09308: setting learning rate to 0.00019914066233325453.\n",
      "2188/3560 [=================>............] - ETA: 2:51 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09309: setting learning rate to 0.00019914019590896214.\n",
      "\n",
      "Batch 09310: setting learning rate to 0.0001991397293586696.\n",
      "2190/3560 [=================>............] - ETA: 2:51 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09311: setting learning rate to 0.00019913926268237754.\n",
      "2191/3560 [=================>............] - ETA: 2:51 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09312: setting learning rate to 0.00019913879588008654.\n",
      "2192/3560 [=================>............] - ETA: 2:50 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09313: setting learning rate to 0.00019913832895179721.\n",
      "2193/3560 [=================>............] - ETA: 2:50 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09314: setting learning rate to 0.00019913786189751012.\n",
      "\n",
      "Batch 09315: setting learning rate to 0.00019913739471722587.\n",
      "2195/3560 [=================>............] - ETA: 2:50 - loss: 0.5666 - accuracy: 0.8403\n",
      "Batch 09316: setting learning rate to 0.0001991369274109451.\n",
      "2196/3560 [=================>............] - ETA: 2:50 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09317: setting learning rate to 0.0001991364599786683.\n",
      "2197/3560 [=================>............] - ETA: 2:50 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09318: setting learning rate to 0.00019913599242039616.\n",
      "\n",
      "Batch 09319: setting learning rate to 0.00019913552473612925.\n",
      "2199/3560 [=================>............] - ETA: 2:50 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09320: setting learning rate to 0.00019913505692586812.\n",
      "2200/3560 [=================>............] - ETA: 2:49 - loss: 0.5661 - accuracy: 0.8404\n",
      "Batch 09321: setting learning rate to 0.0001991345889896134.\n",
      "2201/3560 [=================>............] - ETA: 2:49 - loss: 0.5662 - accuracy: 0.8404\n",
      "Batch 09322: setting learning rate to 0.0001991341209273657.\n",
      "2202/3560 [=================>............] - ETA: 2:49 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09323: setting learning rate to 0.00019913365273912557.\n",
      "2203/3560 [=================>............] - ETA: 2:49 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09324: setting learning rate to 0.00019913318442489367.\n",
      "2204/3560 [=================>............] - ETA: 2:49 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09325: setting learning rate to 0.00019913271598467054.\n",
      "2205/3560 [=================>............] - ETA: 2:49 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09326: setting learning rate to 0.0001991322474184568.\n",
      "2206/3560 [=================>............] - ETA: 2:49 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09327: setting learning rate to 0.000199131778726253.\n",
      "2207/3560 [=================>............] - ETA: 2:49 - loss: 0.5664 - accuracy: 0.8405\n",
      "Batch 09328: setting learning rate to 0.00019913130990805981.\n",
      "\n",
      "Batch 09329: setting learning rate to 0.00019913084096387777.\n",
      "2209/3560 [=================>............] - ETA: 2:48 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09330: setting learning rate to 0.0001991303718937075.\n",
      "\n",
      "Batch 09331: setting learning rate to 0.00019912990269754964.\n",
      "2211/3560 [=================>............] - ETA: 2:48 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09332: setting learning rate to 0.00019912943337540472.\n",
      "2212/3560 [=================>............] - ETA: 2:48 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09333: setting learning rate to 0.0001991289639272733.\n",
      "2213/3560 [=================>............] - ETA: 2:48 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09334: setting learning rate to 0.0001991284943531561.\n",
      "\n",
      "Batch 09335: setting learning rate to 0.00019912802465305357.\n",
      "2215/3560 [=================>............] - ETA: 2:48 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09336: setting learning rate to 0.00019912755482696644.\n",
      "\n",
      "Batch 09337: setting learning rate to 0.00019912708487489526.\n",
      "2217/3560 [=================>............] - ETA: 2:47 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09338: setting learning rate to 0.0001991266147968406.\n",
      "2218/3560 [=================>............] - ETA: 2:47 - loss: 0.5659 - accuracy: 0.8405\n",
      "Batch 09339: setting learning rate to 0.00019912614459280308.\n",
      "2219/3560 [=================>............] - ETA: 2:47 - loss: 0.5660 - accuracy: 0.8405\n",
      "Batch 09340: setting learning rate to 0.00019912567426278328.\n",
      "2220/3560 [=================>............] - ETA: 2:47 - loss: 0.5659 - accuracy: 0.8405\n",
      "Batch 09341: setting learning rate to 0.0001991252038067818.\n",
      "2221/3560 [=================>............] - ETA: 2:47 - loss: 0.5659 - accuracy: 0.8406\n",
      "Batch 09342: setting learning rate to 0.00019912473322479933.\n",
      "\n",
      "Batch 09343: setting learning rate to 0.00019912426251683633.\n",
      "2223/3560 [=================>............] - ETA: 2:46 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09344: setting learning rate to 0.00019912379168289345.\n",
      "\n",
      "Batch 09345: setting learning rate to 0.0001991233207229713.\n",
      "2225/3560 [=================>............] - ETA: 2:46 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09346: setting learning rate to 0.00019912284963707045.\n",
      "\n",
      "Batch 09347: setting learning rate to 0.00019912237842519158.\n",
      "2227/3560 [=================>............] - ETA: 2:46 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09348: setting learning rate to 0.0001991219070873352.\n",
      "2228/3560 [=================>............] - ETA: 2:46 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09349: setting learning rate to 0.00019912143562350197.\n",
      "2229/3560 [=================>............] - ETA: 2:46 - loss: 0.5663 - accuracy: 0.8403\n",
      "Batch 09350: setting learning rate to 0.0001991209640336924.\n",
      "\n",
      "Batch 09351: setting learning rate to 0.0001991204923179072.\n",
      "2231/3560 [=================>............] - ETA: 2:46 - loss: 0.5661 - accuracy: 0.8404\n",
      "Batch 09352: setting learning rate to 0.00019912002047614688.\n",
      "\n",
      "Batch 09353: setting learning rate to 0.00019911954850841213.\n",
      "2233/3560 [=================>............] - ETA: 2:45 - loss: 0.5661 - accuracy: 0.8404\n",
      "Batch 09354: setting learning rate to 0.00019911907641470347.\n",
      "2234/3560 [=================>............] - ETA: 2:45 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09355: setting learning rate to 0.00019911860419502152.\n",
      "2235/3560 [=================>............] - ETA: 2:45 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09356: setting learning rate to 0.00019911813184936687.\n",
      "2236/3560 [=================>............] - ETA: 2:45 - loss: 0.5658 - accuracy: 0.8404\n",
      "Batch 09357: setting learning rate to 0.00019911765937774016.\n",
      "2237/3560 [=================>............] - ETA: 2:45 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09358: setting learning rate to 0.00019911718678014198.\n",
      "2238/3560 [=================>............] - ETA: 2:45 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09359: setting learning rate to 0.0001991167140565729.\n",
      "2239/3560 [=================>............] - ETA: 2:45 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09360: setting learning rate to 0.00019911624120703354.\n",
      "2240/3560 [=================>............] - ETA: 2:44 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09361: setting learning rate to 0.00019911576823152452.\n",
      "2241/3560 [=================>............] - ETA: 2:44 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09362: setting learning rate to 0.0001991152951300464.\n",
      "2242/3560 [=================>............] - ETA: 2:44 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09363: setting learning rate to 0.00019911482190259982.\n",
      "2243/3560 [=================>............] - ETA: 2:44 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09364: setting learning rate to 0.00019911434854918535.\n",
      "2244/3560 [=================>............] - ETA: 2:44 - loss: 0.5661 - accuracy: 0.8406\n",
      "Batch 09365: setting learning rate to 0.00019911387506980362.\n",
      "\n",
      "Batch 09366: setting learning rate to 0.00019911340146445524.\n",
      "2246/3560 [=================>............] - ETA: 2:44 - loss: 0.5661 - accuracy: 0.8405\n",
      "Batch 09367: setting learning rate to 0.00019911292773314076.\n",
      "2247/3560 [=================>............] - ETA: 2:43 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09368: setting learning rate to 0.00019911245387586082.\n",
      "2248/3560 [=================>............] - ETA: 2:44 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09369: setting learning rate to 0.000199111979892616.\n",
      "\n",
      "Batch 09370: setting learning rate to 0.00019911150578340694.\n",
      "2250/3560 [=================>............] - ETA: 2:43 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09371: setting learning rate to 0.0001991110315482342.\n",
      "2251/3560 [=================>............] - ETA: 2:43 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09372: setting learning rate to 0.00019911055718709842.\n",
      "2252/3560 [=================>............] - ETA: 2:43 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09373: setting learning rate to 0.00019911008270000018.\n",
      "2253/3560 [=================>............] - ETA: 2:43 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09374: setting learning rate to 0.0001991096080869401.\n",
      "2254/3560 [=================>............] - ETA: 2:43 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09375: setting learning rate to 0.00019910913334791875.\n",
      "2255/3560 [==================>...........] - ETA: 2:43 - loss: 0.5664 - accuracy: 0.8403\n",
      "Batch 09376: setting learning rate to 0.00019910865848293675.\n",
      "2256/3560 [==================>...........] - ETA: 2:43 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09377: setting learning rate to 0.00019910818349199472.\n",
      "2257/3560 [==================>...........] - ETA: 2:42 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09378: setting learning rate to 0.00019910770837509325.\n",
      "\n",
      "Batch 09379: setting learning rate to 0.00019910723313223296.\n",
      "2259/3560 [==================>...........] - ETA: 2:42 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09380: setting learning rate to 0.00019910675776341444.\n",
      "2260/3560 [==================>...........] - ETA: 2:42 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09381: setting learning rate to 0.00019910628226863826.\n",
      "2261/3560 [==================>...........] - ETA: 2:42 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09382: setting learning rate to 0.00019910580664790506.\n",
      "2262/3560 [==================>...........] - ETA: 2:42 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09383: setting learning rate to 0.00019910533090121548.\n",
      "2263/3560 [==================>...........] - ETA: 2:41 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09384: setting learning rate to 0.00019910485502857008.\n",
      "2264/3560 [==================>...........] - ETA: 2:41 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09385: setting learning rate to 0.00019910437902996946.\n",
      "\n",
      "Batch 09386: setting learning rate to 0.00019910390290541423.\n",
      "2266/3560 [==================>...........] - ETA: 2:41 - loss: 0.5662 - accuracy: 0.8405\n",
      "Batch 09387: setting learning rate to 0.000199103426654905.\n",
      "2267/3560 [==================>...........] - ETA: 2:41 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09388: setting learning rate to 0.00019910295027844238.\n",
      "2268/3560 [==================>...........] - ETA: 2:41 - loss: 0.5663 - accuracy: 0.8405\n",
      "Batch 09389: setting learning rate to 0.000199102473776027.\n",
      "2269/3560 [==================>...........] - ETA: 2:41 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09390: setting learning rate to 0.0001991019971476594.\n",
      "2270/3560 [==================>...........] - ETA: 2:41 - loss: 0.5662 - accuracy: 0.8404\n",
      "Batch 09391: setting learning rate to 0.00019910152039334027.\n",
      "2271/3560 [==================>...........] - ETA: 2:41 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09392: setting learning rate to 0.00019910104351307013.\n",
      "2272/3560 [==================>...........] - ETA: 2:40 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09393: setting learning rate to 0.00019910056650684964.\n",
      "2273/3560 [==================>...........] - ETA: 2:40 - loss: 0.5664 - accuracy: 0.8403\n",
      "Batch 09394: setting learning rate to 0.0001991000893746794.\n",
      "2274/3560 [==================>...........] - ETA: 2:40 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09395: setting learning rate to 0.00019909961211656.\n",
      "2275/3560 [==================>...........] - ETA: 2:40 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09396: setting learning rate to 0.00019909913473249206.\n",
      "2276/3560 [==================>...........] - ETA: 2:40 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09397: setting learning rate to 0.00019909865722247619.\n",
      "2277/3560 [==================>...........] - ETA: 2:40 - loss: 0.5663 - accuracy: 0.8404\n",
      "Batch 09398: setting learning rate to 0.00019909817958651296.\n",
      "\n",
      "Batch 09399: setting learning rate to 0.00019909770182460304.\n",
      "2279/3560 [==================>...........] - ETA: 2:39 - loss: 0.5665 - accuracy: 0.8404\n",
      "Batch 09400: setting learning rate to 0.00019909722393674696.\n",
      "2280/3560 [==================>...........] - ETA: 2:39 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09401: setting learning rate to 0.00019909674592294543.\n",
      "2281/3560 [==================>...........] - ETA: 2:39 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09402: setting learning rate to 0.00019909626778319897.\n",
      "2282/3560 [==================>...........] - ETA: 2:39 - loss: 0.5664 - accuracy: 0.8403\n",
      "Batch 09403: setting learning rate to 0.0001990957895175082.\n",
      "2283/3560 [==================>...........] - ETA: 2:39 - loss: 0.5664 - accuracy: 0.8403\n",
      "Batch 09404: setting learning rate to 0.00019909531112587375.\n",
      "2284/3560 [==================>...........] - ETA: 2:39 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09405: setting learning rate to 0.00019909483260829625.\n",
      "\n",
      "Batch 09406: setting learning rate to 0.00019909435396477625.\n",
      "2286/3560 [==================>...........] - ETA: 2:39 - loss: 0.5664 - accuracy: 0.8404\n",
      "Batch 09407: setting learning rate to 0.0001990938751953144.\n",
      "2287/3560 [==================>...........] - ETA: 2:39 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09408: setting learning rate to 0.0001990933962999113.\n",
      "2288/3560 [==================>...........] - ETA: 2:38 - loss: 0.5665 - accuracy: 0.8403\n",
      "Batch 09409: setting learning rate to 0.00019909291727856755.\n",
      "\n",
      "Batch 09410: setting learning rate to 0.00019909243813128375.\n",
      "2290/3560 [==================>...........] - ETA: 2:38 - loss: 0.5666 - accuracy: 0.8403\n",
      "Batch 09411: setting learning rate to 0.00019909195885806056.\n",
      "2291/3560 [==================>...........] - ETA: 2:38 - loss: 0.5666 - accuracy: 0.8402\n",
      "Batch 09412: setting learning rate to 0.0001990914794588985.\n",
      "2292/3560 [==================>...........] - ETA: 2:38 - loss: 0.5666 - accuracy: 0.8402\n",
      "Batch 09413: setting learning rate to 0.00019909099993379827.\n",
      "2293/3560 [==================>...........] - ETA: 2:38 - loss: 0.5666 - accuracy: 0.8402\n",
      "Batch 09414: setting learning rate to 0.00019909052028276042.\n",
      "\n",
      "Batch 09415: setting learning rate to 0.00019909004050578562.\n",
      "2295/3560 [==================>...........] - ETA: 2:37 - loss: 0.5665 - accuracy: 0.8402\n",
      "Batch 09416: setting learning rate to 0.0001990895606028744.\n",
      "\n",
      "Batch 09417: setting learning rate to 0.00019908908057402743.\n",
      "2297/3560 [==================>...........] - ETA: 2:37 - loss: 0.5666 - accuracy: 0.8402\n",
      "Batch 09418: setting learning rate to 0.0001990886004192453.\n",
      "2298/3560 [==================>...........] - ETA: 2:37 - loss: 0.5665 - accuracy: 0.8402\n",
      "Batch 09419: setting learning rate to 0.00019908812013852862.\n",
      "2299/3560 [==================>...........] - ETA: 2:37 - loss: 0.5666 - accuracy: 0.8401\n",
      "Batch 09420: setting learning rate to 0.00019908763973187799.\n",
      "\n",
      "Batch 09421: setting learning rate to 0.00019908715919929405.\n",
      "2301/3560 [==================>...........] - ETA: 2:37 - loss: 0.5666 - accuracy: 0.8401\n",
      "Batch 09422: setting learning rate to 0.00019908667854077737.\n",
      "2302/3560 [==================>...........] - ETA: 2:37 - loss: 0.5666 - accuracy: 0.8401\n",
      "Batch 09423: setting learning rate to 0.00019908619775632858.\n",
      "2303/3560 [==================>...........] - ETA: 2:36 - loss: 0.5666 - accuracy: 0.8401\n",
      "Batch 09424: setting learning rate to 0.0001990857168459483.\n",
      "2304/3560 [==================>...........] - ETA: 2:36 - loss: 0.5665 - accuracy: 0.8401\n",
      "Batch 09425: setting learning rate to 0.00019908523580963717.\n",
      "2305/3560 [==================>...........] - ETA: 2:36 - loss: 0.5665 - accuracy: 0.8402\n",
      "Batch 09426: setting learning rate to 0.00019908475464739574.\n",
      "2306/3560 [==================>...........] - ETA: 2:36 - loss: 0.5664 - accuracy: 0.8402\n",
      "Batch 09427: setting learning rate to 0.00019908427335922464.\n",
      "2307/3560 [==================>...........] - ETA: 2:36 - loss: 0.5663 - accuracy: 0.8402\n",
      "Batch 09428: setting learning rate to 0.0001990837919451245.\n",
      "2308/3560 [==================>...........] - ETA: 2:36 - loss: 0.5663 - accuracy: 0.8402\n",
      "Batch 09429: setting learning rate to 0.00019908331040509588.\n",
      "2309/3560 [==================>...........] - ETA: 2:36 - loss: 0.5662 - accuracy: 0.8402\n",
      "Batch 09430: setting learning rate to 0.00019908282873913952.\n",
      "\n",
      "Batch 09431: setting learning rate to 0.0001990823469472559.\n",
      "2311/3560 [==================>...........] - ETA: 2:35 - loss: 0.5661 - accuracy: 0.8403\n",
      "Batch 09432: setting learning rate to 0.00019908186502944566.\n",
      "2312/3560 [==================>...........] - ETA: 2:35 - loss: 0.5661 - accuracy: 0.8403\n",
      "Batch 09433: setting learning rate to 0.00019908138298570943.\n",
      "2313/3560 [==================>...........] - ETA: 2:35 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09434: setting learning rate to 0.00019908090081604787.\n",
      "2314/3560 [==================>...........] - ETA: 2:35 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09435: setting learning rate to 0.0001990804185204615.\n",
      "2315/3560 [==================>...........] - ETA: 2:35 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09436: setting learning rate to 0.000199079936098951.\n",
      "2316/3560 [==================>...........] - ETA: 2:35 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09437: setting learning rate to 0.00019907945355151696.\n",
      "2317/3560 [==================>...........] - ETA: 2:35 - loss: 0.5660 - accuracy: 0.8404\n",
      "Batch 09438: setting learning rate to 0.00019907897087816.\n",
      "\n",
      "Batch 09439: setting learning rate to 0.00019907848807888072.\n",
      "2319/3560 [==================>...........] - ETA: 2:34 - loss: 0.5658 - accuracy: 0.8404\n",
      "Batch 09440: setting learning rate to 0.00019907800515367975.\n",
      "2320/3560 [==================>...........] - ETA: 2:34 - loss: 0.5658 - accuracy: 0.8404\n",
      "Batch 09441: setting learning rate to 0.00019907752210255767.\n",
      "2321/3560 [==================>...........] - ETA: 2:34 - loss: 0.5656 - accuracy: 0.8405\n",
      "Batch 09442: setting learning rate to 0.00019907703892551516.\n",
      "\n",
      "Batch 09443: setting learning rate to 0.00019907655562255278.\n",
      "2323/3560 [==================>...........] - ETA: 2:34 - loss: 0.5657 - accuracy: 0.8405\n",
      "Batch 09444: setting learning rate to 0.00019907607219367117.\n",
      "2324/3560 [==================>...........] - ETA: 2:34 - loss: 0.5657 - accuracy: 0.8405\n",
      "Batch 09445: setting learning rate to 0.00019907558863887094.\n",
      "2325/3560 [==================>...........] - ETA: 2:34 - loss: 0.5657 - accuracy: 0.8405\n",
      "Batch 09446: setting learning rate to 0.00019907510495815266.\n",
      "2326/3560 [==================>...........] - ETA: 2:34 - loss: 0.5658 - accuracy: 0.8405\n",
      "Batch 09447: setting learning rate to 0.000199074621151517.\n",
      "2327/3560 [==================>...........] - ETA: 2:33 - loss: 0.5658 - accuracy: 0.8405\n",
      "Batch 09448: setting learning rate to 0.00019907413721896456.\n",
      "2328/3560 [==================>...........] - ETA: 2:33 - loss: 0.5658 - accuracy: 0.8405\n",
      "Batch 09449: setting learning rate to 0.00019907365316049593.\n",
      "2329/3560 [==================>...........] - ETA: 2:33 - loss: 0.5657 - accuracy: 0.8405\n",
      "Batch 09450: setting learning rate to 0.0001990731689761118.\n",
      "2330/3560 [==================>...........] - ETA: 2:33 - loss: 0.5658 - accuracy: 0.8405\n",
      "Batch 09451: setting learning rate to 0.00019907268466581269.\n",
      "\n",
      "Batch 09452: setting learning rate to 0.00019907220022959927.\n",
      "2332/3560 [==================>...........] - ETA: 2:33 - loss: 0.5657 - accuracy: 0.8405\n",
      "Batch 09453: setting learning rate to 0.00019907171566747213.\n",
      "2333/3560 [==================>...........] - ETA: 2:33 - loss: 0.5656 - accuracy: 0.8405\n",
      "Batch 09454: setting learning rate to 0.0001990712309794319.\n",
      "2334/3560 [==================>...........] - ETA: 2:33 - loss: 0.5656 - accuracy: 0.8405\n",
      "Batch 09455: setting learning rate to 0.00019907074616547923.\n",
      "2335/3560 [==================>...........] - ETA: 2:32 - loss: 0.5656 - accuracy: 0.8405\n",
      "Batch 09456: setting learning rate to 0.00019907026122561468.\n",
      "2336/3560 [==================>...........] - ETA: 2:32 - loss: 0.5655 - accuracy: 0.8405\n",
      "Batch 09457: setting learning rate to 0.0001990697761598389.\n",
      "2337/3560 [==================>...........] - ETA: 2:32 - loss: 0.5655 - accuracy: 0.8405\n",
      "Batch 09458: setting learning rate to 0.00019906929096815245.\n",
      "2338/3560 [==================>...........] - ETA: 2:32 - loss: 0.5655 - accuracy: 0.8405\n",
      "Batch 09459: setting learning rate to 0.00019906880565055603.\n",
      "2339/3560 [==================>...........] - ETA: 2:32 - loss: 0.5654 - accuracy: 0.8405\n",
      "Batch 09460: setting learning rate to 0.00019906832020705025.\n",
      "2340/3560 [==================>...........] - ETA: 2:32 - loss: 0.5655 - accuracy: 0.8405\n",
      "Batch 09461: setting learning rate to 0.00019906783463763565.\n",
      "2341/3560 [==================>...........] - ETA: 2:31 - loss: 0.5654 - accuracy: 0.8405\n",
      "Batch 09462: setting learning rate to 0.00019906734894231288.\n",
      "2342/3560 [==================>...........] - ETA: 2:31 - loss: 0.5653 - accuracy: 0.8406\n",
      "Batch 09463: setting learning rate to 0.0001990668631210826.\n",
      "2343/3560 [==================>...........] - ETA: 2:31 - loss: 0.5652 - accuracy: 0.8406\n",
      "Batch 09464: setting learning rate to 0.0001990663771739454.\n",
      "\n",
      "Batch 09465: setting learning rate to 0.00019906589110090187.\n",
      "2345/3560 [==================>...........] - ETA: 2:31 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09466: setting learning rate to 0.00019906540490195268.\n",
      "2346/3560 [==================>...........] - ETA: 2:31 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09467: setting learning rate to 0.00019906491857709838.\n",
      "2347/3560 [==================>...........] - ETA: 2:31 - loss: 0.5651 - accuracy: 0.8407\n",
      "Batch 09468: setting learning rate to 0.00019906443212633967.\n",
      "2348/3560 [==================>...........] - ETA: 2:31 - loss: 0.5653 - accuracy: 0.8407\n",
      "Batch 09469: setting learning rate to 0.00019906394554967713.\n",
      "\n",
      "Batch 09470: setting learning rate to 0.00019906345884711135.\n",
      "2350/3560 [==================>...........] - ETA: 2:31 - loss: 0.5652 - accuracy: 0.8407\n",
      "Batch 09471: setting learning rate to 0.000199062972018643.\n",
      "2351/3560 [==================>...........] - ETA: 2:30 - loss: 0.5652 - accuracy: 0.8407\n",
      "Batch 09472: setting learning rate to 0.00019906248506427264.\n",
      "\n",
      "Batch 09473: setting learning rate to 0.00019906199798400094.\n",
      "2353/3560 [==================>...........] - ETA: 2:30 - loss: 0.5652 - accuracy: 0.8408\n",
      "Batch 09474: setting learning rate to 0.00019906151077782848.\n",
      "2354/3560 [==================>...........] - ETA: 2:30 - loss: 0.5651 - accuracy: 0.8408\n",
      "Batch 09475: setting learning rate to 0.0001990610234457559.\n",
      "2355/3560 [==================>...........] - ETA: 2:30 - loss: 0.5652 - accuracy: 0.8408\n",
      "Batch 09476: setting learning rate to 0.00019906053598778384.\n",
      "2356/3560 [==================>...........] - ETA: 2:30 - loss: 0.5651 - accuracy: 0.8408\n",
      "Batch 09477: setting learning rate to 0.0001990600484039129.\n",
      "2357/3560 [==================>...........] - ETA: 2:30 - loss: 0.5652 - accuracy: 0.8408\n",
      "Batch 09478: setting learning rate to 0.00019905956069414372.\n",
      "\n",
      "Batch 09479: setting learning rate to 0.00019905907285847684.\n",
      "2359/3560 [==================>...........] - ETA: 2:29 - loss: 0.5653 - accuracy: 0.8407\n",
      "Batch 09480: setting learning rate to 0.00019905858489691297.\n",
      "2360/3560 [==================>...........] - ETA: 2:29 - loss: 0.5654 - accuracy: 0.8406\n",
      "Batch 09481: setting learning rate to 0.00019905809680945268.\n",
      "2361/3560 [==================>...........] - ETA: 2:29 - loss: 0.5653 - accuracy: 0.8407\n",
      "Batch 09482: setting learning rate to 0.00019905760859609663.\n",
      "2362/3560 [==================>...........] - ETA: 2:29 - loss: 0.5652 - accuracy: 0.8407\n",
      "Batch 09483: setting learning rate to 0.00019905712025684543.\n",
      "2363/3560 [==================>...........] - ETA: 2:29 - loss: 0.5652 - accuracy: 0.8407\n",
      "Batch 09484: setting learning rate to 0.00019905663179169966.\n",
      "\n",
      "Batch 09485: setting learning rate to 0.00019905614320066.\n",
      "2365/3560 [==================>...........] - ETA: 2:29 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09486: setting learning rate to 0.00019905565448372702.\n",
      "2366/3560 [==================>...........] - ETA: 2:29 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09487: setting learning rate to 0.00019905516564090137.\n",
      "2367/3560 [==================>...........] - ETA: 2:28 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09488: setting learning rate to 0.00019905467667218364.\n",
      "\n",
      "Batch 09489: setting learning rate to 0.00019905418757757453.\n",
      "2369/3560 [==================>...........] - ETA: 2:28 - loss: 0.5649 - accuracy: 0.8408\n",
      "Batch 09490: setting learning rate to 0.00019905369835707454.\n",
      "2370/3560 [==================>...........] - ETA: 2:28 - loss: 0.5649 - accuracy: 0.8408\n",
      "Batch 09491: setting learning rate to 0.00019905320901068442.\n",
      "2371/3560 [==================>...........] - ETA: 2:28 - loss: 0.5648 - accuracy: 0.8408\n",
      "Batch 09492: setting learning rate to 0.0001990527195384047.\n",
      "2372/3560 [==================>...........] - ETA: 2:28 - loss: 0.5647 - accuracy: 0.8409\n",
      "Batch 09493: setting learning rate to 0.00019905222994023603.\n",
      "2373/3560 [==================>...........] - ETA: 2:28 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09494: setting learning rate to 0.00019905174021617902.\n",
      "\n",
      "Batch 09495: setting learning rate to 0.00019905125036623434.\n",
      "2375/3560 [===================>..........] - ETA: 2:27 - loss: 0.5648 - accuracy: 0.8408\n",
      "Batch 09496: setting learning rate to 0.00019905076039040257.\n",
      "2376/3560 [===================>..........] - ETA: 2:27 - loss: 0.5649 - accuracy: 0.8409\n",
      "Batch 09497: setting learning rate to 0.00019905027028868432.\n",
      "\n",
      "Batch 09498: setting learning rate to 0.00019904978006108026.\n",
      "2378/3560 [===================>..........] - ETA: 2:27 - loss: 0.5649 - accuracy: 0.8408\n",
      "Batch 09499: setting learning rate to 0.000199049289707591.\n",
      "2379/3560 [===================>..........] - ETA: 2:27 - loss: 0.5648 - accuracy: 0.8409\n",
      "Batch 09500: setting learning rate to 0.00019904879922821712.\n",
      "2380/3560 [===================>..........] - ETA: 2:27 - loss: 0.5648 - accuracy: 0.8409\n",
      "Batch 09501: setting learning rate to 0.0001990483086229593.\n",
      "2381/3560 [===================>..........] - ETA: 2:26 - loss: 0.5648 - accuracy: 0.8409\n",
      "Batch 09502: setting learning rate to 0.00019904781789181812.\n",
      "2382/3560 [===================>..........] - ETA: 2:26 - loss: 0.5647 - accuracy: 0.8409\n",
      "Batch 09503: setting learning rate to 0.00019904732703479426.\n",
      "2383/3560 [===================>..........] - ETA: 2:26 - loss: 0.5647 - accuracy: 0.8409\n",
      "Batch 09504: setting learning rate to 0.0001990468360518883.\n",
      "2384/3560 [===================>..........] - ETA: 2:26 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09505: setting learning rate to 0.0001990463449431008.\n",
      "2385/3560 [===================>..........] - ETA: 2:26 - loss: 0.5647 - accuracy: 0.8409\n",
      "Batch 09506: setting learning rate to 0.00019904585370843252.\n",
      "2386/3560 [===================>..........] - ETA: 2:26 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09507: setting learning rate to 0.00019904536234788397.\n",
      "2387/3560 [===================>..........] - ETA: 2:26 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09508: setting learning rate to 0.0001990448708614559.\n",
      "2388/3560 [===================>..........] - ETA: 2:26 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09509: setting learning rate to 0.0001990443792491488.\n",
      "\n",
      "Batch 09510: setting learning rate to 0.00019904388751096333.\n",
      "2390/3560 [===================>..........] - ETA: 2:25 - loss: 0.5646 - accuracy: 0.8408\n",
      "Batch 09511: setting learning rate to 0.0001990433956469002.\n",
      "2391/3560 [===================>..........] - ETA: 2:25 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09512: setting learning rate to 0.00019904290365695994.\n",
      "2392/3560 [===================>..........] - ETA: 2:25 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09513: setting learning rate to 0.0001990424115411432.\n",
      "\n",
      "Batch 09514: setting learning rate to 0.00019904191929945064.\n",
      "2394/3560 [===================>..........] - ETA: 2:25 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09515: setting learning rate to 0.00019904142693188287.\n",
      "2395/3560 [===================>..........] - ETA: 2:25 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09516: setting learning rate to 0.00019904093443844046.\n",
      "2396/3560 [===================>..........] - ETA: 2:25 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09517: setting learning rate to 0.0001990404418191241.\n",
      "2397/3560 [===================>..........] - ETA: 2:25 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09518: setting learning rate to 0.0001990399490739344.\n",
      "2398/3560 [===================>..........] - ETA: 2:24 - loss: 0.5646 - accuracy: 0.8408\n",
      "Batch 09519: setting learning rate to 0.00019903945620287198.\n",
      "2399/3560 [===================>..........] - ETA: 2:24 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09520: setting learning rate to 0.00019903896320593747.\n",
      "\n",
      "Batch 09521: setting learning rate to 0.0001990384700831315.\n",
      "2401/3560 [===================>..........] - ETA: 2:24 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09522: setting learning rate to 0.00019903797683445466.\n",
      "2402/3560 [===================>..........] - ETA: 2:24 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09523: setting learning rate to 0.00019903748345990766.\n",
      "2403/3560 [===================>..........] - ETA: 2:24 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09524: setting learning rate to 0.00019903698995949105.\n",
      "2404/3560 [===================>..........] - ETA: 2:24 - loss: 0.5647 - accuracy: 0.8409\n",
      "Batch 09525: setting learning rate to 0.0001990364963332055.\n",
      "2405/3560 [===================>..........] - ETA: 2:23 - loss: 0.5648 - accuracy: 0.8409\n",
      "Batch 09526: setting learning rate to 0.0001990360025810516.\n",
      "\n",
      "Batch 09527: setting learning rate to 0.00019903550870303.\n",
      "2407/3560 [===================>..........] - ETA: 2:23 - loss: 0.5651 - accuracy: 0.8408\n",
      "Batch 09528: setting learning rate to 0.00019903501469914134.\n",
      "2408/3560 [===================>..........] - ETA: 2:23 - loss: 0.5651 - accuracy: 0.8407\n",
      "Batch 09529: setting learning rate to 0.00019903452056938624.\n",
      "2409/3560 [===================>..........] - ETA: 2:23 - loss: 0.5651 - accuracy: 0.8407\n",
      "Batch 09530: setting learning rate to 0.0001990340263137653.\n",
      "2410/3560 [===================>..........] - ETA: 2:23 - loss: 0.5650 - accuracy: 0.8407\n",
      "Batch 09531: setting learning rate to 0.0001990335319322792.\n",
      "\n",
      "Batch 09532: setting learning rate to 0.00019903303742492852.\n",
      "2412/3560 [===================>..........] - ETA: 2:22 - loss: 0.5649 - accuracy: 0.8407\n",
      "Batch 09533: setting learning rate to 0.0001990325427917139.\n",
      "\n",
      "Batch 09534: setting learning rate to 0.00019903204803263598.\n",
      "2414/3560 [===================>..........] - ETA: 2:22 - loss: 0.5649 - accuracy: 0.8407\n",
      "Batch 09535: setting learning rate to 0.00019903155314769539.\n",
      "2415/3560 [===================>..........] - ETA: 2:22 - loss: 0.5649 - accuracy: 0.8408\n",
      "Batch 09536: setting learning rate to 0.00019903105813689275.\n",
      "2416/3560 [===================>..........] - ETA: 2:22 - loss: 0.5648 - accuracy: 0.8408\n",
      "Batch 09537: setting learning rate to 0.0001990305630002287.\n",
      "2417/3560 [===================>..........] - ETA: 2:22 - loss: 0.5648 - accuracy: 0.8408\n",
      "Batch 09538: setting learning rate to 0.00019903006773770384.\n",
      "\n",
      "Batch 09539: setting learning rate to 0.00019902957234931885.\n",
      "2419/3560 [===================>..........] - ETA: 2:22 - loss: 0.5648 - accuracy: 0.8407\n",
      "Batch 09540: setting learning rate to 0.00019902907683507434.\n",
      "2420/3560 [===================>..........] - ETA: 2:22 - loss: 0.5647 - accuracy: 0.8408\n",
      "Batch 09541: setting learning rate to 0.00019902858119497089.\n",
      "\n",
      "Batch 09542: setting learning rate to 0.00019902808542900918.\n",
      "2422/3560 [===================>..........] - ETA: 2:21 - loss: 0.5647 - accuracy: 0.8408\n",
      "Batch 09543: setting learning rate to 0.00019902758953718985.\n",
      "2423/3560 [===================>..........] - ETA: 2:21 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09544: setting learning rate to 0.0001990270935195135.\n",
      "2424/3560 [===================>..........] - ETA: 2:21 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09545: setting learning rate to 0.00019902659737598078.\n",
      "\n",
      "Batch 09546: setting learning rate to 0.00019902610110659232.\n",
      "2426/3560 [===================>..........] - ETA: 2:21 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09547: setting learning rate to 0.00019902560471134873.\n",
      "2427/3560 [===================>..........] - ETA: 2:21 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09548: setting learning rate to 0.00019902510819025065.\n",
      "2428/3560 [===================>..........] - ETA: 2:20 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09549: setting learning rate to 0.00019902461154329873.\n",
      "\n",
      "Batch 09550: setting learning rate to 0.00019902411477049358.\n",
      "2430/3560 [===================>..........] - ETA: 2:20 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09551: setting learning rate to 0.0001990236178718358.\n",
      "2431/3560 [===================>..........] - ETA: 2:20 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09552: setting learning rate to 0.00019902312084732612.\n",
      "2432/3560 [===================>..........] - ETA: 2:20 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09553: setting learning rate to 0.00019902262369696504.\n",
      "2433/3560 [===================>..........] - ETA: 2:20 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09554: setting learning rate to 0.00019902212642075332.\n",
      "\n",
      "Batch 09555: setting learning rate to 0.00019902162901869154.\n",
      "2435/3560 [===================>..........] - ETA: 2:20 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09556: setting learning rate to 0.00019902113149078028.\n",
      "\n",
      "Batch 09557: setting learning rate to 0.00019902063383702023.\n",
      "2437/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09558: setting learning rate to 0.00019902013605741203.\n",
      "2438/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09559: setting learning rate to 0.0001990196381519563.\n",
      "2439/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09560: setting learning rate to 0.00019901914012065365.\n",
      "2440/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09561: setting learning rate to 0.00019901864196350473.\n",
      "2441/3560 [===================>..........] - ETA: 2:19 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09562: setting learning rate to 0.00019901814368051017.\n",
      "2442/3560 [===================>..........] - ETA: 2:19 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09563: setting learning rate to 0.00019901764527167063.\n",
      "2443/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09564: setting learning rate to 0.0001990171467369867.\n",
      "2444/3560 [===================>..........] - ETA: 2:19 - loss: 0.5643 - accuracy: 0.8408\n",
      "Batch 09565: setting learning rate to 0.00019901664807645903.\n",
      "2445/3560 [===================>..........] - ETA: 2:18 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09566: setting learning rate to 0.00019901614929008826.\n",
      "2446/3560 [===================>..........] - ETA: 2:18 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09567: setting learning rate to 0.00019901565037787501.\n",
      "2447/3560 [===================>..........] - ETA: 2:18 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09568: setting learning rate to 0.00019901515133981997.\n",
      "2448/3560 [===================>..........] - ETA: 2:18 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09569: setting learning rate to 0.0001990146521759237.\n",
      "2449/3560 [===================>..........] - ETA: 2:18 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09570: setting learning rate to 0.00019901415288618685.\n",
      "2450/3560 [===================>..........] - ETA: 2:18 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09571: setting learning rate to 0.0001990136534706101.\n",
      "2451/3560 [===================>..........] - ETA: 2:18 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09572: setting learning rate to 0.000199013153929194.\n",
      "\n",
      "Batch 09573: setting learning rate to 0.00019901265426193926.\n",
      "2453/3560 [===================>..........] - ETA: 2:17 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09574: setting learning rate to 0.00019901215446884653.\n",
      "2454/3560 [===================>..........] - ETA: 2:17 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09575: setting learning rate to 0.00019901165454991638.\n",
      "\n",
      "Batch 09576: setting learning rate to 0.00019901115450514947.\n",
      "2456/3560 [===================>..........] - ETA: 2:17 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09577: setting learning rate to 0.00019901065433454643.\n",
      "2457/3560 [===================>..........] - ETA: 2:17 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09578: setting learning rate to 0.00019901015403810793.\n",
      "2458/3560 [===================>..........] - ETA: 2:17 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09579: setting learning rate to 0.00019900965361583457.\n",
      "2459/3560 [===================>..........] - ETA: 2:17 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09580: setting learning rate to 0.000199009153067727.\n",
      "2460/3560 [===================>..........] - ETA: 2:17 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09581: setting learning rate to 0.00019900865239378583.\n",
      "2461/3560 [===================>..........] - ETA: 2:16 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09582: setting learning rate to 0.00019900815159401173.\n",
      "2462/3560 [===================>..........] - ETA: 2:16 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09583: setting learning rate to 0.00019900765066840537.\n",
      "\n",
      "Batch 09584: setting learning rate to 0.0001990071496169673.\n",
      "2464/3560 [===================>..........] - ETA: 2:16 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09585: setting learning rate to 0.00019900664843969818.\n",
      "2465/3560 [===================>..........] - ETA: 2:16 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09586: setting learning rate to 0.00019900614713659872.\n",
      "2466/3560 [===================>..........] - ETA: 2:16 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09587: setting learning rate to 0.00019900564570766944.\n",
      "2467/3560 [===================>..........] - ETA: 2:16 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09588: setting learning rate to 0.00019900514415291108.\n",
      "2468/3560 [===================>..........] - ETA: 2:16 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09589: setting learning rate to 0.00019900464247232422.\n",
      "2469/3560 [===================>..........] - ETA: 2:15 - loss: 0.5645 - accuracy: 0.8407\n",
      "Batch 09590: setting learning rate to 0.00019900414066590952.\n",
      "2470/3560 [===================>..........] - ETA: 2:15 - loss: 0.5645 - accuracy: 0.8407\n",
      "Batch 09591: setting learning rate to 0.00019900363873366763.\n",
      "2471/3560 [===================>..........] - ETA: 2:15 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09592: setting learning rate to 0.00019900313667559915.\n",
      "2472/3560 [===================>..........] - ETA: 2:15 - loss: 0.5643 - accuracy: 0.8408\n",
      "Batch 09593: setting learning rate to 0.00019900263449170474.\n",
      "\n",
      "Batch 09594: setting learning rate to 0.00019900213218198505.\n",
      "2474/3560 [===================>..........] - ETA: 2:15 - loss: 0.5642 - accuracy: 0.8408\n",
      "Batch 09595: setting learning rate to 0.00019900162974644073.\n",
      "2475/3560 [===================>..........] - ETA: 2:15 - loss: 0.5642 - accuracy: 0.8408\n",
      "Batch 09596: setting learning rate to 0.00019900112718507234.\n",
      "\n",
      "Batch 09597: setting learning rate to 0.00019900062449788059.\n",
      "2477/3560 [===================>..........] - ETA: 2:14 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09598: setting learning rate to 0.00019900012168486613.\n",
      "2478/3560 [===================>..........] - ETA: 2:14 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09599: setting learning rate to 0.00019899961874602956.\n",
      "2479/3560 [===================>..........] - ETA: 2:14 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09600: setting learning rate to 0.0001989991156813715.\n",
      "2480/3560 [===================>..........] - ETA: 2:14 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09601: setting learning rate to 0.00019899861249089265.\n",
      "\n",
      "Batch 09602: setting learning rate to 0.00019899810917459358.\n",
      "2482/3560 [===================>..........] - ETA: 2:14 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09603: setting learning rate to 0.000198997605732475.\n",
      "2483/3560 [===================>..........] - ETA: 2:14 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09604: setting learning rate to 0.0001989971021645375.\n",
      "2484/3560 [===================>..........] - ETA: 2:14 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09605: setting learning rate to 0.00019899659847078178.\n",
      "2485/3560 [===================>..........] - ETA: 2:13 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09606: setting learning rate to 0.0001989960946512084.\n",
      "\n",
      "Batch 09607: setting learning rate to 0.00019899559070581804.\n",
      "2487/3560 [===================>..........] - ETA: 2:13 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09608: setting learning rate to 0.00019899508663461134.\n",
      "2488/3560 [===================>..........] - ETA: 2:13 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09609: setting learning rate to 0.00019899458243758896.\n",
      "2489/3560 [===================>..........] - ETA: 2:13 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09610: setting learning rate to 0.0001989940781147515.\n",
      "2490/3560 [===================>..........] - ETA: 2:13 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09611: setting learning rate to 0.00019899357366609966.\n",
      "2491/3560 [===================>..........] - ETA: 2:13 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09612: setting learning rate to 0.000198993069091634.\n",
      "2492/3560 [====================>.........] - ETA: 2:13 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09613: setting learning rate to 0.00019899256439135523.\n",
      "2493/3560 [====================>.........] - ETA: 2:13 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09614: setting learning rate to 0.00019899205956526396.\n",
      "2494/3560 [====================>.........] - ETA: 2:12 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09615: setting learning rate to 0.0001989915546133608.\n",
      "\n",
      "Batch 09616: setting learning rate to 0.00019899104953564648.\n",
      "2496/3560 [====================>.........] - ETA: 2:12 - loss: 0.5639 - accuracy: 0.8410\n",
      "Batch 09617: setting learning rate to 0.00019899054433212158.\n",
      "2497/3560 [====================>.........] - ETA: 2:12 - loss: 0.5638 - accuracy: 0.8410\n",
      "Batch 09618: setting learning rate to 0.00019899003900278675.\n",
      "\n",
      "Batch 09619: setting learning rate to 0.0001989895335476426.\n",
      "2499/3560 [====================>.........] - ETA: 2:12 - loss: 0.5638 - accuracy: 0.8411\n",
      "Batch 09620: setting learning rate to 0.00019898902796668987.\n",
      "\n",
      "Batch 09621: setting learning rate to 0.00019898852225992908.\n",
      "2501/3560 [====================>.........] - ETA: 2:11 - loss: 0.5638 - accuracy: 0.8411\n",
      "Batch 09622: setting learning rate to 0.00019898801642736098.\n",
      "2502/3560 [====================>.........] - ETA: 2:11 - loss: 0.5637 - accuracy: 0.8411\n",
      "Batch 09623: setting learning rate to 0.00019898751046898614.\n",
      "2503/3560 [====================>.........] - ETA: 2:11 - loss: 0.5636 - accuracy: 0.8412\n",
      "Batch 09624: setting learning rate to 0.00019898700438480523.\n",
      "2504/3560 [====================>.........] - ETA: 2:11 - loss: 0.5636 - accuracy: 0.8412\n",
      "Batch 09625: setting learning rate to 0.0001989864981748189.\n",
      "2505/3560 [====================>.........] - ETA: 2:11 - loss: 0.5635 - accuracy: 0.8412\n",
      "Batch 09626: setting learning rate to 0.00019898599183902779.\n",
      "2506/3560 [====================>.........] - ETA: 2:11 - loss: 0.5635 - accuracy: 0.8412\n",
      "Batch 09627: setting learning rate to 0.00019898548537743252.\n",
      "2507/3560 [====================>.........] - ETA: 2:11 - loss: 0.5635 - accuracy: 0.8412\n",
      "Batch 09628: setting learning rate to 0.00019898497879003376.\n",
      "2508/3560 [====================>.........] - ETA: 2:11 - loss: 0.5635 - accuracy: 0.8412\n",
      "Batch 09629: setting learning rate to 0.00019898447207683214.\n",
      "2509/3560 [====================>.........] - ETA: 2:10 - loss: 0.5635 - accuracy: 0.8412\n",
      "Batch 09630: setting learning rate to 0.00019898396523782835.\n",
      "2510/3560 [====================>.........] - ETA: 2:10 - loss: 0.5634 - accuracy: 0.8412\n",
      "Batch 09631: setting learning rate to 0.00019898345827302295.\n",
      "2511/3560 [====================>.........] - ETA: 2:10 - loss: 0.5634 - accuracy: 0.8412\n",
      "Batch 09632: setting learning rate to 0.00019898295118241666.\n",
      "2512/3560 [====================>.........] - ETA: 2:10 - loss: 0.5634 - accuracy: 0.8412\n",
      "Batch 09633: setting learning rate to 0.00019898244396601003.\n",
      "2513/3560 [====================>.........] - ETA: 2:10 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09634: setting learning rate to 0.00019898193662380384.\n",
      "\n",
      "Batch 09635: setting learning rate to 0.00019898142915579864.\n",
      "2515/3560 [====================>.........] - ETA: 2:10 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09636: setting learning rate to 0.00019898092156199511.\n",
      "2516/3560 [====================>.........] - ETA: 2:10 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09637: setting learning rate to 0.00019898041384239386.\n",
      "2517/3560 [====================>.........] - ETA: 2:09 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09638: setting learning rate to 0.00019897990599699553.\n",
      "2518/3560 [====================>.........] - ETA: 2:09 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09639: setting learning rate to 0.00019897939802580086.\n",
      "2519/3560 [====================>.........] - ETA: 2:09 - loss: 0.5635 - accuracy: 0.8411\n",
      "Batch 09640: setting learning rate to 0.0001989788899288104.\n",
      "2520/3560 [====================>.........] - ETA: 2:09 - loss: 0.5636 - accuracy: 0.8411\n",
      "Batch 09641: setting learning rate to 0.0001989783817060248.\n",
      "2521/3560 [====================>.........] - ETA: 2:09 - loss: 0.5636 - accuracy: 0.8412\n",
      "Batch 09642: setting learning rate to 0.00019897787335744477.\n",
      "\n",
      "Batch 09643: setting learning rate to 0.00019897736488307092.\n",
      "2523/3560 [====================>.........] - ETA: 2:09 - loss: 0.5637 - accuracy: 0.8412\n",
      "Batch 09644: setting learning rate to 0.00019897685628290386.\n",
      "\n",
      "Batch 09645: setting learning rate to 0.00019897634755694428.\n",
      "2525/3560 [====================>.........] - ETA: 2:09 - loss: 0.5637 - accuracy: 0.8411\n",
      "Batch 09646: setting learning rate to 0.0001989758387051928.\n",
      "2526/3560 [====================>.........] - ETA: 2:08 - loss: 0.5638 - accuracy: 0.8411\n",
      "Batch 09647: setting learning rate to 0.00019897532972765013.\n",
      "2527/3560 [====================>.........] - ETA: 2:08 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09648: setting learning rate to 0.00019897482062431683.\n",
      "\n",
      "Batch 09649: setting learning rate to 0.0001989743113951936.\n",
      "2529/3560 [====================>.........] - ETA: 2:08 - loss: 0.5638 - accuracy: 0.8411\n",
      "Batch 09650: setting learning rate to 0.00019897380204028105.\n",
      "2530/3560 [====================>.........] - ETA: 2:08 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09651: setting learning rate to 0.00019897329255957988.\n",
      "\n",
      "Batch 09652: setting learning rate to 0.0001989727829530907.\n",
      "2532/3560 [====================>.........] - ETA: 2:08 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09653: setting learning rate to 0.00019897227322081417.\n",
      "2533/3560 [====================>.........] - ETA: 2:07 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09654: setting learning rate to 0.00019897176336275093.\n",
      "2534/3560 [====================>.........] - ETA: 2:07 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09655: setting learning rate to 0.00019897125337890164.\n",
      "2535/3560 [====================>.........] - ETA: 2:07 - loss: 0.5639 - accuracy: 0.8411\n",
      "Batch 09656: setting learning rate to 0.00019897074326926694.\n",
      "\n",
      "Batch 09657: setting learning rate to 0.00019897023303384748.\n",
      "2537/3560 [====================>.........] - ETA: 2:07 - loss: 0.5640 - accuracy: 0.8410\n",
      "Batch 09658: setting learning rate to 0.0001989697226726439.\n",
      "2538/3560 [====================>.........] - ETA: 2:07 - loss: 0.5640 - accuracy: 0.8410\n",
      "Batch 09659: setting learning rate to 0.00019896921218565686.\n",
      "2539/3560 [====================>.........] - ETA: 2:07 - loss: 0.5640 - accuracy: 0.8410\n",
      "Batch 09660: setting learning rate to 0.000198968701572887.\n",
      "2540/3560 [====================>.........] - ETA: 2:07 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09661: setting learning rate to 0.00019896819083433498.\n",
      "2541/3560 [====================>.........] - ETA: 2:06 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09662: setting learning rate to 0.00019896767997000143.\n",
      "2542/3560 [====================>.........] - ETA: 2:06 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09663: setting learning rate to 0.000198967168979887.\n",
      "2543/3560 [====================>.........] - ETA: 2:06 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09664: setting learning rate to 0.00019896665786399239.\n",
      "2544/3560 [====================>.........] - ETA: 2:06 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09665: setting learning rate to 0.00019896614662231817.\n",
      "\n",
      "Batch 09666: setting learning rate to 0.0001989656352548651.\n",
      "2546/3560 [====================>.........] - ETA: 2:06 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09667: setting learning rate to 0.00019896512376163368.\n",
      "2547/3560 [====================>.........] - ETA: 2:06 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09668: setting learning rate to 0.0001989646121426247.\n",
      "2548/3560 [====================>.........] - ETA: 2:06 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09669: setting learning rate to 0.0001989641003978387.\n",
      "2549/3560 [====================>.........] - ETA: 2:05 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09670: setting learning rate to 0.00019896358852727642.\n",
      "2550/3560 [====================>.........] - ETA: 2:05 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09671: setting learning rate to 0.00019896307653093843.\n",
      "2551/3560 [====================>.........] - ETA: 2:05 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09672: setting learning rate to 0.00019896256440882546.\n",
      "2552/3560 [====================>.........] - ETA: 2:05 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09673: setting learning rate to 0.0001989620521609381.\n",
      "2553/3560 [====================>.........] - ETA: 2:05 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09674: setting learning rate to 0.00019896153978727705.\n",
      "2554/3560 [====================>.........] - ETA: 2:05 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09675: setting learning rate to 0.00019896102728784293.\n",
      "2555/3560 [====================>.........] - ETA: 2:05 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09676: setting learning rate to 0.0001989605146626364.\n",
      "2556/3560 [====================>.........] - ETA: 2:05 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09677: setting learning rate to 0.0001989600019116581.\n",
      "2557/3560 [====================>.........] - ETA: 2:05 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09678: setting learning rate to 0.0001989594890349087.\n",
      "2558/3560 [====================>.........] - ETA: 2:04 - loss: 0.5646 - accuracy: 0.8409\n",
      "Batch 09679: setting learning rate to 0.0001989589760323888.\n",
      "2559/3560 [====================>.........] - ETA: 2:04 - loss: 0.5646 - accuracy: 0.8408\n",
      "Batch 09680: setting learning rate to 0.00019895846290409914.\n",
      "2560/3560 [====================>.........] - ETA: 2:04 - loss: 0.5646 - accuracy: 0.8408\n",
      "Batch 09681: setting learning rate to 0.0001989579496500403.\n",
      "2561/3560 [====================>.........] - ETA: 2:04 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09682: setting learning rate to 0.000198957436270213.\n",
      "2562/3560 [====================>.........] - ETA: 2:04 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09683: setting learning rate to 0.00019895692276461778.\n",
      "2563/3560 [====================>.........] - ETA: 2:04 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09684: setting learning rate to 0.00019895640913325543.\n",
      "2564/3560 [====================>.........] - ETA: 2:04 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09685: setting learning rate to 0.00019895589537612652.\n",
      "2565/3560 [====================>.........] - ETA: 2:04 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09686: setting learning rate to 0.0001989553814932317.\n",
      "2566/3560 [====================>.........] - ETA: 2:03 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09687: setting learning rate to 0.00019895486748457164.\n",
      "\n",
      "Batch 09688: setting learning rate to 0.00019895435335014701.\n",
      "2568/3560 [====================>.........] - ETA: 2:03 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09689: setting learning rate to 0.00019895383908995844.\n",
      "2569/3560 [====================>.........] - ETA: 2:03 - loss: 0.5643 - accuracy: 0.8410\n",
      "Batch 09690: setting learning rate to 0.0001989533247040066.\n",
      "2570/3560 [====================>.........] - ETA: 2:03 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09691: setting learning rate to 0.00019895281019229215.\n",
      "2571/3560 [====================>.........] - ETA: 2:03 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09692: setting learning rate to 0.00019895229555481572.\n",
      "2572/3560 [====================>.........] - ETA: 2:03 - loss: 0.5643 - accuracy: 0.8409\n",
      "Batch 09693: setting learning rate to 0.00019895178079157796.\n",
      "2573/3560 [====================>.........] - ETA: 2:03 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09694: setting learning rate to 0.00019895126590257955.\n",
      "2574/3560 [====================>.........] - ETA: 2:02 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09695: setting learning rate to 0.00019895075088782114.\n",
      "2575/3560 [====================>.........] - ETA: 2:02 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09696: setting learning rate to 0.0001989502357473034.\n",
      "2576/3560 [====================>.........] - ETA: 2:02 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09697: setting learning rate to 0.00019894972048102689.\n",
      "2577/3560 [====================>.........] - ETA: 2:02 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09698: setting learning rate to 0.00019894920508899236.\n",
      "2578/3560 [====================>.........] - ETA: 2:02 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09699: setting learning rate to 0.0001989486895712005.\n",
      "2579/3560 [====================>.........] - ETA: 2:02 - loss: 0.5641 - accuracy: 0.8410\n",
      "Batch 09700: setting learning rate to 0.00019894817392765186.\n",
      "2580/3560 [====================>.........] - ETA: 2:02 - loss: 0.5640 - accuracy: 0.8410\n",
      "Batch 09701: setting learning rate to 0.00019894765815834715.\n",
      "2581/3560 [====================>.........] - ETA: 2:01 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09702: setting learning rate to 0.00019894714226328702.\n",
      "2582/3560 [====================>.........] - ETA: 2:01 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09703: setting learning rate to 0.00019894662624247213.\n",
      "2583/3560 [====================>.........] - ETA: 2:01 - loss: 0.5642 - accuracy: 0.8410\n",
      "Batch 09704: setting learning rate to 0.00019894611009590313.\n",
      "2584/3560 [====================>.........] - ETA: 2:01 - loss: 0.5644 - accuracy: 0.8410\n",
      "Batch 09705: setting learning rate to 0.00019894559382358065.\n",
      "2585/3560 [====================>.........] - ETA: 2:01 - loss: 0.5644 - accuracy: 0.8410\n",
      "Batch 09706: setting learning rate to 0.00019894507742550542.\n",
      "2586/3560 [====================>.........] - ETA: 2:01 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09707: setting learning rate to 0.00019894456090167802.\n",
      "2587/3560 [====================>.........] - ETA: 2:01 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09708: setting learning rate to 0.0001989440442520991.\n",
      "2588/3560 [====================>.........] - ETA: 2:01 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09709: setting learning rate to 0.00019894352747676939.\n",
      "2589/3560 [====================>.........] - ETA: 2:00 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09710: setting learning rate to 0.0001989430105756895.\n",
      "2590/3560 [====================>.........] - ETA: 2:00 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09711: setting learning rate to 0.00019894249354886009.\n",
      "2591/3560 [====================>.........] - ETA: 2:00 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09712: setting learning rate to 0.00019894197639628184.\n",
      "2592/3560 [====================>.........] - ETA: 2:00 - loss: 0.5644 - accuracy: 0.8409\n",
      "Batch 09713: setting learning rate to 0.00019894145911795538.\n",
      "2593/3560 [====================>.........] - ETA: 2:00 - loss: 0.5645 - accuracy: 0.8409\n",
      "Batch 09714: setting learning rate to 0.00019894094171388137.\n",
      "2594/3560 [====================>.........] - ETA: 2:00 - loss: 0.5645 - accuracy: 0.8408\n",
      "Batch 09715: setting learning rate to 0.00019894042418406048.\n",
      "\n",
      "Batch 09716: setting learning rate to 0.00019893990652849336.\n",
      "2596/3560 [====================>.........] - ETA: 2:00 - loss: 0.5644 - accuracy: 0.8408\n",
      "Batch 09717: setting learning rate to 0.0001989393887471807.\n",
      "2597/3560 [====================>.........] - ETA: 1:59 - loss: 0.5643 - accuracy: 0.8408\n",
      "Batch 09718: setting learning rate to 0.00019893887084012312.\n",
      "2598/3560 [====================>.........] - ETA: 1:59 - loss: 0.5643 - accuracy: 0.8408\n",
      "Batch 09719: setting learning rate to 0.00019893835280732124.\n",
      "2599/3560 [====================>.........] - ETA: 1:59 - loss: 0.5642 - accuracy: 0.8408\n",
      "Batch 09720: setting learning rate to 0.0001989378346487758.\n",
      "2600/3560 [====================>.........] - ETA: 1:59 - loss: 0.5642 - accuracy: 0.8408\n",
      "Batch 09721: setting learning rate to 0.0001989373163644874.\n",
      "2601/3560 [====================>.........] - ETA: 1:59 - loss: 0.5641 - accuracy: 0.8408\n",
      "Batch 09722: setting learning rate to 0.00019893679795445675.\n",
      "2602/3560 [====================>.........] - ETA: 1:59 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09723: setting learning rate to 0.00019893627941868446.\n",
      "\n",
      "Batch 09724: setting learning rate to 0.00019893576075717123.\n",
      "2604/3560 [====================>.........] - ETA: 1:59 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09725: setting learning rate to 0.00019893524196991767.\n",
      "\n",
      "Batch 09726: setting learning rate to 0.00019893472305692448.\n",
      "2606/3560 [====================>.........] - ETA: 1:58 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09727: setting learning rate to 0.00019893420401819232.\n",
      "\n",
      "Batch 09728: setting learning rate to 0.00019893368485372182.\n",
      "2608/3560 [====================>.........] - ETA: 1:58 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09729: setting learning rate to 0.00019893316556351368.\n",
      "2609/3560 [====================>.........] - ETA: 1:58 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09730: setting learning rate to 0.0001989326461475685.\n",
      "2610/3560 [====================>.........] - ETA: 1:58 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09731: setting learning rate to 0.00019893212660588701.\n",
      "2611/3560 [=====================>........] - ETA: 1:58 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09732: setting learning rate to 0.00019893160693846982.\n",
      "2612/3560 [=====================>........] - ETA: 1:58 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09733: setting learning rate to 0.00019893108714531764.\n",
      "\n",
      "Batch 09734: setting learning rate to 0.00019893056722643108.\n",
      "2614/3560 [=====================>........] - ETA: 1:57 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09735: setting learning rate to 0.00019893004718181078.\n",
      "2615/3560 [=====================>........] - ETA: 1:57 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09736: setting learning rate to 0.0001989295270114575.\n",
      "2616/3560 [=====================>........] - ETA: 1:57 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09737: setting learning rate to 0.00019892900671537184.\n",
      "\n",
      "Batch 09738: setting learning rate to 0.0001989284862935544.\n",
      "2618/3560 [=====================>........] - ETA: 1:57 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09739: setting learning rate to 0.00019892796574600595.\n",
      "2619/3560 [=====================>........] - ETA: 1:57 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09740: setting learning rate to 0.0001989274450727271.\n",
      "2620/3560 [=====================>........] - ETA: 1:57 - loss: 0.5642 - accuracy: 0.8409\n",
      "Batch 09741: setting learning rate to 0.00019892692427371853.\n",
      "2621/3560 [=====================>........] - ETA: 1:56 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09742: setting learning rate to 0.00019892640334898088.\n",
      "2622/3560 [=====================>........] - ETA: 1:56 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09743: setting learning rate to 0.00019892588229851482.\n",
      "2623/3560 [=====================>........] - ETA: 1:56 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09744: setting learning rate to 0.000198925361122321.\n",
      "\n",
      "Batch 09745: setting learning rate to 0.0001989248398204001.\n",
      "2625/3560 [=====================>........] - ETA: 1:56 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09746: setting learning rate to 0.00019892431839275282.\n",
      "2626/3560 [=====================>........] - ETA: 1:56 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09747: setting learning rate to 0.00019892379683937974.\n",
      "2627/3560 [=====================>........] - ETA: 1:56 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09748: setting learning rate to 0.00019892327516028154.\n",
      "2628/3560 [=====================>........] - ETA: 1:56 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09749: setting learning rate to 0.00019892275335545897.\n",
      "2629/3560 [=====================>........] - ETA: 1:55 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09750: setting learning rate to 0.0001989222314249126.\n",
      "\n",
      "Batch 09751: setting learning rate to 0.0001989217093686431.\n",
      "2631/3560 [=====================>........] - ETA: 1:55 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09752: setting learning rate to 0.0001989211871866512.\n",
      "\n",
      "Batch 09753: setting learning rate to 0.0001989206648789375.\n",
      "2633/3560 [=====================>........] - ETA: 1:55 - loss: 0.5638 - accuracy: 0.8410\n",
      "Batch 09754: setting learning rate to 0.0001989201424455027.\n",
      "2634/3560 [=====================>........] - ETA: 1:55 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09755: setting learning rate to 0.00019891961988634745.\n",
      "2635/3560 [=====================>........] - ETA: 1:55 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09756: setting learning rate to 0.00019891909720147236.\n",
      "2636/3560 [=====================>........] - ETA: 1:55 - loss: 0.5641 - accuracy: 0.8409\n",
      "Batch 09757: setting learning rate to 0.00019891857439087823.\n",
      "2637/3560 [=====================>........] - ETA: 1:55 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09758: setting learning rate to 0.00019891805145456557.\n",
      "2638/3560 [=====================>........] - ETA: 1:54 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09759: setting learning rate to 0.00019891752839253514.\n",
      "2639/3560 [=====================>........] - ETA: 1:54 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09760: setting learning rate to 0.0001989170052047876.\n",
      "\n",
      "Batch 09761: setting learning rate to 0.00019891648189132358.\n",
      "2641/3560 [=====================>........] - ETA: 1:54 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09762: setting learning rate to 0.00019891595845214374.\n",
      "\n",
      "Batch 09763: setting learning rate to 0.0001989154348872488.\n",
      "2643/3560 [=====================>........] - ETA: 1:54 - loss: 0.5638 - accuracy: 0.8409\n",
      "Batch 09764: setting learning rate to 0.0001989149111966394.\n",
      "2644/3560 [=====================>........] - ETA: 1:54 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09765: setting learning rate to 0.00019891438738031615.\n",
      "2645/3560 [=====================>........] - ETA: 1:53 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09766: setting learning rate to 0.0001989138634382798.\n",
      "\n",
      "Batch 09767: setting learning rate to 0.00019891333937053097.\n",
      "2647/3560 [=====================>........] - ETA: 1:53 - loss: 0.5638 - accuracy: 0.8409\n",
      "Batch 09768: setting learning rate to 0.00019891281517707033.\n",
      "2648/3560 [=====================>........] - ETA: 1:53 - loss: 0.5639 - accuracy: 0.8408\n",
      "Batch 09769: setting learning rate to 0.00019891229085789857.\n",
      "\n",
      "Batch 09770: setting learning rate to 0.00019891176641301632.\n",
      "2650/3560 [=====================>........] - ETA: 1:53 - loss: 0.5639 - accuracy: 0.8408\n",
      "Batch 09771: setting learning rate to 0.00019891124184242425.\n",
      "2651/3560 [=====================>........] - ETA: 1:53 - loss: 0.5638 - accuracy: 0.8409\n",
      "Batch 09772: setting learning rate to 0.0001989107171461231.\n",
      "2652/3560 [=====================>........] - ETA: 1:53 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09773: setting learning rate to 0.0001989101923241134.\n",
      "2653/3560 [=====================>........] - ETA: 1:53 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09774: setting learning rate to 0.00019890966737639594.\n",
      "2654/3560 [=====================>........] - ETA: 1:52 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09775: setting learning rate to 0.00019890914230297132.\n",
      "2655/3560 [=====================>........] - ETA: 1:52 - loss: 0.5641 - accuracy: 0.8408\n",
      "Batch 09776: setting learning rate to 0.00019890861710384025.\n",
      "2656/3560 [=====================>........] - ETA: 1:52 - loss: 0.5640 - accuracy: 0.8408\n",
      "Batch 09777: setting learning rate to 0.00019890809177900337.\n",
      "2657/3560 [=====================>........] - ETA: 1:52 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09778: setting learning rate to 0.00019890756632846135.\n",
      "2658/3560 [=====================>........] - ETA: 1:52 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09779: setting learning rate to 0.00019890704075221485.\n",
      "2659/3560 [=====================>........] - ETA: 1:52 - loss: 0.5640 - accuracy: 0.8408\n",
      "Batch 09780: setting learning rate to 0.00019890651505026456.\n",
      "\n",
      "Batch 09781: setting learning rate to 0.00019890598922261114.\n",
      "2661/3560 [=====================>........] - ETA: 1:51 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09782: setting learning rate to 0.00019890546326925527.\n",
      "2662/3560 [=====================>........] - ETA: 1:51 - loss: 0.5640 - accuracy: 0.8409\n",
      "Batch 09783: setting learning rate to 0.00019890493719019762.\n",
      "2663/3560 [=====================>........] - ETA: 1:51 - loss: 0.5640 - accuracy: 0.8408\n",
      "Batch 09784: setting learning rate to 0.0001989044109854388.\n",
      "2664/3560 [=====================>........] - ETA: 1:51 - loss: 0.5639 - accuracy: 0.8408\n",
      "Batch 09785: setting learning rate to 0.00019890388465497954.\n",
      "2665/3560 [=====================>........] - ETA: 1:51 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09786: setting learning rate to 0.0001989033581988205.\n",
      "2666/3560 [=====================>........] - ETA: 1:51 - loss: 0.5639 - accuracy: 0.8409\n",
      "Batch 09787: setting learning rate to 0.00019890283161696232.\n",
      "\n",
      "Batch 09788: setting learning rate to 0.00019890230490940568.\n",
      "2668/3560 [=====================>........] - ETA: 1:51 - loss: 0.5638 - accuracy: 0.8409\n",
      "Batch 09789: setting learning rate to 0.00019890177807615128.\n",
      "2669/3560 [=====================>........] - ETA: 1:51 - loss: 0.5638 - accuracy: 0.8409\n",
      "Batch 09790: setting learning rate to 0.0001989012511171998.\n",
      "2670/3560 [=====================>........] - ETA: 1:50 - loss: 0.5638 - accuracy: 0.8408\n",
      "Batch 09791: setting learning rate to 0.00019890072403255183.\n",
      "2671/3560 [=====================>........] - ETA: 1:50 - loss: 0.5639 - accuracy: 0.8408\n",
      "Batch 09792: setting learning rate to 0.0001989001968222081.\n",
      "\n",
      "Batch 09793: setting learning rate to 0.00019889966948616927.\n",
      "2673/3560 [=====================>........] - ETA: 1:50 - loss: 0.5639 - accuracy: 0.8408\n",
      "Batch 09794: setting learning rate to 0.00019889914202443602.\n",
      "2674/3560 [=====================>........] - ETA: 1:50 - loss: 0.5639 - accuracy: 0.8407\n",
      "Batch 09795: setting learning rate to 0.00019889861443700898.\n",
      "2675/3560 [=====================>........] - ETA: 1:50 - loss: 0.5638 - accuracy: 0.8408\n",
      "Batch 09796: setting learning rate to 0.00019889808672388887.\n",
      "2676/3560 [=====================>........] - ETA: 1:50 - loss: 0.5638 - accuracy: 0.8408\n",
      "Batch 09797: setting learning rate to 0.00019889755888507636.\n",
      "2677/3560 [=====================>........] - ETA: 1:49 - loss: 0.5638 - accuracy: 0.8408\n",
      "Batch 09798: setting learning rate to 0.00019889703092057208.\n",
      "\n",
      "Batch 09799: setting learning rate to 0.0001988965028303767.\n",
      "2679/3560 [=====================>........] - ETA: 1:49 - loss: 0.5638 - accuracy: 0.8407\n",
      "Batch 09800: setting learning rate to 0.00019889597461449093.\n",
      "2680/3560 [=====================>........] - ETA: 1:49 - loss: 0.5637 - accuracy: 0.8408\n",
      "Batch 09801: setting learning rate to 0.00019889544627291544.\n",
      "2681/3560 [=====================>........] - ETA: 1:49 - loss: 0.5638 - accuracy: 0.8407\n",
      "Batch 09802: setting learning rate to 0.00019889491780565087.\n",
      "2682/3560 [=====================>........] - ETA: 1:49 - loss: 0.5639 - accuracy: 0.8407\n",
      "Batch 09803: setting learning rate to 0.00019889438921269793.\n",
      "2683/3560 [=====================>........] - ETA: 1:49 - loss: 0.5639 - accuracy: 0.8406\n",
      "Batch 09804: setting learning rate to 0.00019889386049405726.\n",
      "2684/3560 [=====================>........] - ETA: 1:49 - loss: 0.5639 - accuracy: 0.8406\n",
      "Batch 09805: setting learning rate to 0.0001988933316497295.\n",
      "2685/3560 [=====================>........] - ETA: 1:48 - loss: 0.5639 - accuracy: 0.8406\n",
      "Batch 09806: setting learning rate to 0.00019889280267971538.\n",
      "2686/3560 [=====================>........] - ETA: 1:48 - loss: 0.5639 - accuracy: 0.8406\n",
      "Batch 09807: setting learning rate to 0.0001988922735840156.\n",
      "2687/3560 [=====================>........] - ETA: 1:48 - loss: 0.5638 - accuracy: 0.8406\n",
      "Batch 09808: setting learning rate to 0.00019889174436263075.\n",
      "2688/3560 [=====================>........] - ETA: 1:48 - loss: 0.5638 - accuracy: 0.8406\n",
      "Batch 09809: setting learning rate to 0.00019889121501556157.\n",
      "2689/3560 [=====================>........] - ETA: 1:48 - loss: 0.5636 - accuracy: 0.8407\n",
      "Batch 09810: setting learning rate to 0.00019889068554280868.\n",
      "2690/3560 [=====================>........] - ETA: 1:48 - loss: 0.5635 - accuracy: 0.8407\n",
      "Batch 09811: setting learning rate to 0.00019889015594437277.\n",
      "\n",
      "Batch 09812: setting learning rate to 0.0001988896262202545.\n",
      "2692/3560 [=====================>........] - ETA: 1:48 - loss: 0.5636 - accuracy: 0.8407\n",
      "Batch 09813: setting learning rate to 0.0001988890963704546.\n",
      "2693/3560 [=====================>........] - ETA: 1:47 - loss: 0.5635 - accuracy: 0.8408\n",
      "Batch 09814: setting learning rate to 0.0001988885663949737.\n",
      "2694/3560 [=====================>........] - ETA: 1:47 - loss: 0.5635 - accuracy: 0.8407\n",
      "Batch 09815: setting learning rate to 0.0001988880362938125.\n",
      "2695/3560 [=====================>........] - ETA: 1:47 - loss: 0.5634 - accuracy: 0.8407\n",
      "Batch 09816: setting learning rate to 0.0001988875060669716.\n",
      "2696/3560 [=====================>........] - ETA: 1:47 - loss: 0.5635 - accuracy: 0.8408\n",
      "Batch 09817: setting learning rate to 0.00019888697571445176.\n",
      "2697/3560 [=====================>........] - ETA: 1:47 - loss: 0.5634 - accuracy: 0.8408\n",
      "Batch 09818: setting learning rate to 0.00019888644523625363.\n",
      "\n",
      "Batch 09819: setting learning rate to 0.00019888591463237786.\n",
      "2699/3560 [=====================>........] - ETA: 1:47 - loss: 0.5633 - accuracy: 0.8408\n",
      "Batch 09820: setting learning rate to 0.00019888538390282516.\n",
      "2700/3560 [=====================>........] - ETA: 1:47 - loss: 0.5632 - accuracy: 0.8409\n",
      "Batch 09821: setting learning rate to 0.00019888485304759616.\n",
      "2701/3560 [=====================>........] - ETA: 1:46 - loss: 0.5632 - accuracy: 0.8409\n",
      "Batch 09822: setting learning rate to 0.00019888432206669157.\n",
      "2702/3560 [=====================>........] - ETA: 1:46 - loss: 0.5631 - accuracy: 0.8409\n",
      "Batch 09823: setting learning rate to 0.00019888379096011204.\n",
      "\n",
      "Batch 09824: setting learning rate to 0.0001988832597278583.\n",
      "2704/3560 [=====================>........] - ETA: 1:46 - loss: 0.5630 - accuracy: 0.8409\n",
      "Batch 09825: setting learning rate to 0.00019888272836993094.\n",
      "\n",
      "Batch 09826: setting learning rate to 0.00019888219688633067.\n",
      "2706/3560 [=====================>........] - ETA: 1:46 - loss: 0.5629 - accuracy: 0.8409\n",
      "Batch 09827: setting learning rate to 0.0001988816652770582.\n",
      "\n",
      "Batch 09828: setting learning rate to 0.0001988811335421142.\n",
      "2708/3560 [=====================>........] - ETA: 1:46 - loss: 0.5630 - accuracy: 0.8409\n",
      "Batch 09829: setting learning rate to 0.0001988806016814993.\n",
      "2709/3560 [=====================>........] - ETA: 1:45 - loss: 0.5630 - accuracy: 0.8409\n",
      "Batch 09830: setting learning rate to 0.00019888006969521422.\n",
      "2710/3560 [=====================>........] - ETA: 1:45 - loss: 0.5629 - accuracy: 0.8409\n",
      "Batch 09831: setting learning rate to 0.0001988795375832596.\n",
      "2711/3560 [=====================>........] - ETA: 1:45 - loss: 0.5629 - accuracy: 0.8409\n",
      "Batch 09832: setting learning rate to 0.00019887900534563616.\n",
      "2712/3560 [=====================>........] - ETA: 1:45 - loss: 0.5628 - accuracy: 0.8410\n",
      "Batch 09833: setting learning rate to 0.00019887847298234452.\n",
      "2713/3560 [=====================>........] - ETA: 1:45 - loss: 0.5628 - accuracy: 0.8410\n",
      "Batch 09834: setting learning rate to 0.00019887794049338537.\n",
      "2714/3560 [=====================>........] - ETA: 1:45 - loss: 0.5628 - accuracy: 0.8410\n",
      "Batch 09835: setting learning rate to 0.00019887740787875947.\n",
      "2715/3560 [=====================>........] - ETA: 1:45 - loss: 0.5627 - accuracy: 0.8410\n",
      "Batch 09836: setting learning rate to 0.00019887687513846737.\n",
      "2716/3560 [=====================>........] - ETA: 1:45 - loss: 0.5627 - accuracy: 0.8410\n",
      "Batch 09837: setting learning rate to 0.00019887634227250985.\n",
      "2717/3560 [=====================>........] - ETA: 1:45 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09838: setting learning rate to 0.00019887580928088753.\n",
      "2718/3560 [=====================>........] - ETA: 1:44 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09839: setting learning rate to 0.0001988752761636011.\n",
      "2719/3560 [=====================>........] - ETA: 1:44 - loss: 0.5627 - accuracy: 0.8410\n",
      "Batch 09840: setting learning rate to 0.00019887474292065122.\n",
      "2720/3560 [=====================>........] - ETA: 1:44 - loss: 0.5627 - accuracy: 0.8410\n",
      "Batch 09841: setting learning rate to 0.00019887420955203862.\n",
      "2721/3560 [=====================>........] - ETA: 1:44 - loss: 0.5628 - accuracy: 0.8410\n",
      "Batch 09842: setting learning rate to 0.00019887367605776393.\n",
      "2722/3560 [=====================>........] - ETA: 1:44 - loss: 0.5629 - accuracy: 0.8410\n",
      "Batch 09843: setting learning rate to 0.00019887314243782785.\n",
      "2723/3560 [=====================>........] - ETA: 1:44 - loss: 0.5629 - accuracy: 0.8410\n",
      "Batch 09844: setting learning rate to 0.00019887260869223106.\n",
      "2724/3560 [=====================>........] - ETA: 1:44 - loss: 0.5629 - accuracy: 0.8410\n",
      "Batch 09845: setting learning rate to 0.0001988720748209742.\n",
      "2725/3560 [=====================>........] - ETA: 1:43 - loss: 0.5629 - accuracy: 0.8410\n",
      "Batch 09846: setting learning rate to 0.00019887154082405802.\n",
      "2726/3560 [=====================>........] - ETA: 1:43 - loss: 0.5629 - accuracy: 0.8410\n",
      "Batch 09847: setting learning rate to 0.00019887100670148313.\n",
      "2727/3560 [=====================>........] - ETA: 1:43 - loss: 0.5630 - accuracy: 0.8410\n",
      "Batch 09848: setting learning rate to 0.00019887047245325027.\n",
      "\n",
      "Batch 09849: setting learning rate to 0.00019886993807936008.\n",
      "2729/3560 [=====================>........] - ETA: 1:43 - loss: 0.5628 - accuracy: 0.8410\n",
      "Batch 09850: setting learning rate to 0.00019886940357981321.\n",
      "2730/3560 [======================>.......] - ETA: 1:43 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09851: setting learning rate to 0.00019886886895461038.\n",
      "2731/3560 [======================>.......] - ETA: 1:43 - loss: 0.5628 - accuracy: 0.8411\n",
      "Batch 09852: setting learning rate to 0.00019886833420375229.\n",
      "2732/3560 [======================>.......] - ETA: 1:43 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09853: setting learning rate to 0.00019886779932723958.\n",
      "\n",
      "Batch 09854: setting learning rate to 0.00019886726432507296.\n",
      "2734/3560 [======================>.......] - ETA: 1:42 - loss: 0.5626 - accuracy: 0.8411\n",
      "Batch 09855: setting learning rate to 0.00019886672919725305.\n",
      "2735/3560 [======================>.......] - ETA: 1:42 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09856: setting learning rate to 0.0001988661939437806.\n",
      "2736/3560 [======================>.......] - ETA: 1:42 - loss: 0.5626 - accuracy: 0.8411\n",
      "Batch 09857: setting learning rate to 0.00019886565856465626.\n",
      "2737/3560 [======================>.......] - ETA: 1:42 - loss: 0.5626 - accuracy: 0.8412\n",
      "Batch 09858: setting learning rate to 0.00019886512305988073.\n",
      "2738/3560 [======================>.......] - ETA: 1:42 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09859: setting learning rate to 0.00019886458742945467.\n",
      "\n",
      "Batch 09860: setting learning rate to 0.00019886405167337875.\n",
      "2740/3560 [======================>.......] - ETA: 1:42 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09861: setting learning rate to 0.00019886351579165366.\n",
      "2741/3560 [======================>.......] - ETA: 1:41 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09862: setting learning rate to 0.0001988629797842801.\n",
      "2742/3560 [======================>.......] - ETA: 1:41 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09863: setting learning rate to 0.00019886244365125872.\n",
      "2743/3560 [======================>.......] - ETA: 1:41 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09864: setting learning rate to 0.00019886190739259026.\n",
      "2744/3560 [======================>.......] - ETA: 1:41 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09865: setting learning rate to 0.00019886137100827534.\n",
      "2745/3560 [======================>.......] - ETA: 1:41 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09866: setting learning rate to 0.00019886083449831466.\n",
      "\n",
      "Batch 09867: setting learning rate to 0.0001988602978627089.\n",
      "2747/3560 [======================>.......] - ETA: 1:41 - loss: 0.5624 - accuracy: 0.8411\n",
      "Batch 09868: setting learning rate to 0.00019885976110145875.\n",
      "2748/3560 [======================>.......] - ETA: 1:41 - loss: 0.5623 - accuracy: 0.8411\n",
      "Batch 09869: setting learning rate to 0.0001988592242145649.\n",
      "2749/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09870: setting learning rate to 0.000198858687202028.\n",
      "2750/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8411\n",
      "Batch 09871: setting learning rate to 0.00019885815006384877.\n",
      "2751/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8411\n",
      "Batch 09872: setting learning rate to 0.00019885761280002788.\n",
      "2752/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09873: setting learning rate to 0.00019885707541056599.\n",
      "2753/3560 [======================>.......] - ETA: 1:40 - loss: 0.5624 - accuracy: 0.8411\n",
      "Batch 09874: setting learning rate to 0.00019885653789546384.\n",
      "2754/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09875: setting learning rate to 0.00019885600025472205.\n",
      "2755/3560 [======================>.......] - ETA: 1:40 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09876: setting learning rate to 0.00019885546248834133.\n",
      "2756/3560 [======================>.......] - ETA: 1:40 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09877: setting learning rate to 0.00019885492459632235.\n",
      "2757/3560 [======================>.......] - ETA: 1:39 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09878: setting learning rate to 0.00019885438657866582.\n",
      "2758/3560 [======================>.......] - ETA: 1:39 - loss: 0.5622 - accuracy: 0.8412\n",
      "Batch 09879: setting learning rate to 0.00019885384843537242.\n",
      "2759/3560 [======================>.......] - ETA: 1:39 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09880: setting learning rate to 0.0001988533101664428.\n",
      "2760/3560 [======================>.......] - ETA: 1:39 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09881: setting learning rate to 0.0001988527717718777.\n",
      "2761/3560 [======================>.......] - ETA: 1:39 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09882: setting learning rate to 0.00019885223325167775.\n",
      "2762/3560 [======================>.......] - ETA: 1:39 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09883: setting learning rate to 0.00019885169460584362.\n",
      "2763/3560 [======================>.......] - ETA: 1:39 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09884: setting learning rate to 0.0001988511558343761.\n",
      "\n",
      "Batch 09885: setting learning rate to 0.00019885061693727577.\n",
      "2765/3560 [======================>.......] - ETA: 1:38 - loss: 0.5623 - accuracy: 0.8412\n",
      "Batch 09886: setting learning rate to 0.00019885007791454334.\n",
      "\n",
      "Batch 09887: setting learning rate to 0.00019884953876617953.\n",
      "2767/3560 [======================>.......] - ETA: 1:38 - loss: 0.5624 - accuracy: 0.8412\n",
      "Batch 09888: setting learning rate to 0.00019884899949218498.\n",
      "2768/3560 [======================>.......] - ETA: 1:38 - loss: 0.5626 - accuracy: 0.8412\n",
      "Batch 09889: setting learning rate to 0.0001988484600925604.\n",
      "2769/3560 [======================>.......] - ETA: 1:38 - loss: 0.5626 - accuracy: 0.8412\n",
      "Batch 09890: setting learning rate to 0.0001988479205673065.\n",
      "2770/3560 [======================>.......] - ETA: 1:38 - loss: 0.5626 - accuracy: 0.8412\n",
      "Batch 09891: setting learning rate to 0.0001988473809164239.\n",
      "2771/3560 [======================>.......] - ETA: 1:38 - loss: 0.5627 - accuracy: 0.8412\n",
      "Batch 09892: setting learning rate to 0.00019884684113991336.\n",
      "2772/3560 [======================>.......] - ETA: 1:38 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09893: setting learning rate to 0.00019884630123777553.\n",
      "2773/3560 [======================>.......] - ETA: 1:37 - loss: 0.5628 - accuracy: 0.8411\n",
      "Batch 09894: setting learning rate to 0.00019884576121001105.\n",
      "\n",
      "Batch 09895: setting learning rate to 0.0001988452210566207.\n",
      "2775/3560 [======================>.......] - ETA: 1:37 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09896: setting learning rate to 0.00019884468077760507.\n",
      "2776/3560 [======================>.......] - ETA: 1:37 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09897: setting learning rate to 0.00019884414037296493.\n",
      "2777/3560 [======================>.......] - ETA: 1:37 - loss: 0.5627 - accuracy: 0.8411\n",
      "Batch 09898: setting learning rate to 0.00019884359984270093.\n",
      "2778/3560 [======================>.......] - ETA: 1:37 - loss: 0.5626 - accuracy: 0.8411\n",
      "Batch 09899: setting learning rate to 0.00019884305918681377.\n",
      "2779/3560 [======================>.......] - ETA: 1:37 - loss: 0.5625 - accuracy: 0.8411\n",
      "Batch 09900: setting learning rate to 0.0001988425184053041.\n",
      "2780/3560 [======================>.......] - ETA: 1:37 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09901: setting learning rate to 0.00019884197749817263.\n",
      "2781/3560 [======================>.......] - ETA: 1:37 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09902: setting learning rate to 0.0001988414364654201.\n",
      "2782/3560 [======================>.......] - ETA: 1:36 - loss: 0.5625 - accuracy: 0.8412\n",
      "Batch 09903: setting learning rate to 0.00019884089530704707.\n",
      "\n",
      "Batch 09904: setting learning rate to 0.00019884035402305438.\n",
      "2784/3560 [======================>.......] - ETA: 1:36 - loss: 0.5626 - accuracy: 0.8412\n",
      "Batch 09905: setting learning rate to 0.0001988398126134426.\n",
      "2785/3560 [======================>.......] - ETA: 1:36 - loss: 0.5627 - accuracy: 0.8412\n",
      "Batch 09906: setting learning rate to 0.00019883927107821247.\n",
      "2786/3560 [======================>.......] - ETA: 1:36 - loss: 0.5627 - accuracy: 0.8412\n",
      "Batch 09907: setting learning rate to 0.00019883872941736468.\n",
      "2787/3560 [======================>.......] - ETA: 1:36 - loss: 0.5628 - accuracy: 0.8412\n",
      "Batch 09908: setting learning rate to 0.0001988381876308999.\n",
      "2788/3560 [======================>.......] - ETA: 1:36 - loss: 0.5629 - accuracy: 0.8412\n",
      "Batch 09909: setting learning rate to 0.00019883764571881885.\n",
      "2789/3560 [======================>.......] - ETA: 1:35 - loss: 0.5628 - accuracy: 0.8413\n",
      "Batch 09910: setting learning rate to 0.00019883710368112217.\n",
      "\n",
      "Batch 09911: setting learning rate to 0.00019883656151781058.\n",
      "2791/3560 [======================>.......] - ETA: 1:35 - loss: 0.5629 - accuracy: 0.8412\n",
      "Batch 09912: setting learning rate to 0.00019883601922888477.\n",
      "2792/3560 [======================>.......] - ETA: 1:35 - loss: 0.5629 - accuracy: 0.8412\n",
      "Batch 09913: setting learning rate to 0.0001988354768143454.\n",
      "2793/3560 [======================>.......] - ETA: 1:35 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09914: setting learning rate to 0.00019883493427419322.\n",
      "2794/3560 [======================>.......] - ETA: 1:35 - loss: 0.5630 - accuracy: 0.8411\n",
      "Batch 09915: setting learning rate to 0.00019883439160842885.\n",
      "2795/3560 [======================>.......] - ETA: 1:35 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09916: setting learning rate to 0.00019883384881705303.\n",
      "2796/3560 [======================>.......] - ETA: 1:35 - loss: 0.5633 - accuracy: 0.8410\n",
      "Batch 09917: setting learning rate to 0.00019883330590006644.\n",
      "2797/3560 [======================>.......] - ETA: 1:35 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09918: setting learning rate to 0.00019883276285746974.\n",
      "2798/3560 [======================>.......] - ETA: 1:34 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09919: setting learning rate to 0.00019883221968926366.\n",
      "2799/3560 [======================>.......] - ETA: 1:34 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09920: setting learning rate to 0.00019883167639544883.\n",
      "2800/3560 [======================>.......] - ETA: 1:34 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09921: setting learning rate to 0.00019883113297602606.\n",
      "2801/3560 [======================>.......] - ETA: 1:34 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09922: setting learning rate to 0.0001988305894309959.\n",
      "2802/3560 [======================>.......] - ETA: 1:34 - loss: 0.5631 - accuracy: 0.8410\n",
      "Batch 09923: setting learning rate to 0.00019883004576035912.\n",
      "2803/3560 [======================>.......] - ETA: 1:34 - loss: 0.5631 - accuracy: 0.8410\n",
      "Batch 09924: setting learning rate to 0.0001988295019641164.\n",
      "2804/3560 [======================>.......] - ETA: 1:34 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09925: setting learning rate to 0.00019882895804226842.\n",
      "2805/3560 [======================>.......] - ETA: 1:33 - loss: 0.5632 - accuracy: 0.8410\n",
      "Batch 09926: setting learning rate to 0.0001988284139948159.\n",
      "2806/3560 [======================>.......] - ETA: 1:33 - loss: 0.5631 - accuracy: 0.8410\n",
      "Batch 09927: setting learning rate to 0.00019882786982175949.\n",
      "2807/3560 [======================>.......] - ETA: 1:33 - loss: 0.5630 - accuracy: 0.8411\n",
      "Batch 09928: setting learning rate to 0.0001988273255230999.\n",
      "\n",
      "Batch 09929: setting learning rate to 0.00019882678109883783.\n",
      "2809/3560 [======================>.......] - ETA: 1:33 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09930: setting learning rate to 0.00019882623654897397.\n",
      "2810/3560 [======================>.......] - ETA: 1:33 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09931: setting learning rate to 0.000198825691873509.\n",
      "2811/3560 [======================>.......] - ETA: 1:33 - loss: 0.5628 - accuracy: 0.8411\n",
      "Batch 09932: setting learning rate to 0.0001988251470724436.\n",
      "2812/3560 [======================>.......] - ETA: 1:33 - loss: 0.5629 - accuracy: 0.8411\n",
      "Batch 09933: setting learning rate to 0.0001988246021457785.\n",
      "2813/3560 [======================>.......] - ETA: 1:33 - loss: 0.5628 - accuracy: 0.8411\n",
      "Batch 09934: setting learning rate to 0.00019882405709351438.\n",
      "2814/3560 [======================>.......] - ETA: 1:32 - loss: 0.5628 - accuracy: 0.8411\n",
      "Batch 09935: setting learning rate to 0.0001988235119156519.\n",
      "2815/3560 [======================>.......] - ETA: 1:32 - loss: 0.5628 - accuracy: 0.8412\n",
      "Batch 09936: setting learning rate to 0.0001988229666121918.\n",
      "\n",
      "Batch 09937: setting learning rate to 0.00019882242118313476.\n",
      "2817/3560 [======================>.......] - ETA: 1:32 - loss: 0.5628 - accuracy: 0.8412\n",
      "Batch 09938: setting learning rate to 0.00019882187562848144.\n",
      "2818/3560 [======================>.......] - ETA: 1:32 - loss: 0.5627 - accuracy: 0.8412\n",
      "Batch 09939: setting learning rate to 0.00019882132994823257.\n",
      "2819/3560 [======================>.......] - ETA: 1:32 - loss: 0.5626 - accuracy: 0.8413\n",
      "Batch 09940: setting learning rate to 0.00019882078414238885.\n",
      "2820/3560 [======================>.......] - ETA: 1:32 - loss: 0.5625 - accuracy: 0.8413\n",
      "Batch 09941: setting learning rate to 0.00019882023821095093.\n",
      "2821/3560 [======================>.......] - ETA: 1:31 - loss: 0.5626 - accuracy: 0.8413\n",
      "Batch 09942: setting learning rate to 0.00019881969215391953.\n",
      "2822/3560 [======================>.......] - ETA: 1:31 - loss: 0.5625 - accuracy: 0.8413\n",
      "Batch 09943: setting learning rate to 0.00019881914597129536.\n",
      "2823/3560 [======================>.......] - ETA: 1:31 - loss: 0.5624 - accuracy: 0.8414\n",
      "Batch 09944: setting learning rate to 0.0001988185996630791.\n",
      "2824/3560 [======================>.......] - ETA: 1:31 - loss: 0.5624 - accuracy: 0.8414\n",
      "Batch 09945: setting learning rate to 0.00019881805322927143.\n",
      "\n",
      "Batch 09946: setting learning rate to 0.00019881750666987305.\n",
      "2826/3560 [======================>.......] - ETA: 1:31 - loss: 0.5623 - accuracy: 0.8414\n",
      "Batch 09947: setting learning rate to 0.00019881695998488468.\n",
      "2827/3560 [======================>.......] - ETA: 1:31 - loss: 0.5623 - accuracy: 0.8414\n",
      "Batch 09948: setting learning rate to 0.00019881641317430699.\n",
      "2828/3560 [======================>.......] - ETA: 1:31 - loss: 0.5623 - accuracy: 0.8414\n",
      "Batch 09949: setting learning rate to 0.00019881586623814068.\n",
      "2829/3560 [======================>.......] - ETA: 1:30 - loss: 0.5623 - accuracy: 0.8414\n",
      "Batch 09950: setting learning rate to 0.00019881531917638644.\n",
      "2830/3560 [======================>.......] - ETA: 1:30 - loss: 0.5623 - accuracy: 0.8414\n",
      "Batch 09951: setting learning rate to 0.000198814771989045.\n",
      "\n",
      "Batch 09952: setting learning rate to 0.000198814224676117.\n",
      "2832/3560 [======================>.......] - ETA: 1:30 - loss: 0.5621 - accuracy: 0.8415\n",
      "Batch 09953: setting learning rate to 0.00019881367723760315.\n",
      "\n",
      "Batch 09954: setting learning rate to 0.0001988131296735042.\n",
      "2834/3560 [======================>.......] - ETA: 1:30 - loss: 0.5621 - accuracy: 0.8414\n",
      "Batch 09955: setting learning rate to 0.0001988125819838208.\n",
      "2835/3560 [======================>.......] - ETA: 1:30 - loss: 0.5622 - accuracy: 0.8414\n",
      "Batch 09956: setting learning rate to 0.00019881203416855357.\n",
      "2836/3560 [======================>.......] - ETA: 1:30 - loss: 0.5622 - accuracy: 0.8414\n",
      "Batch 09957: setting learning rate to 0.00019881148622770338.\n",
      "2837/3560 [======================>.......] - ETA: 1:29 - loss: 0.5621 - accuracy: 0.8415\n",
      "Batch 09958: setting learning rate to 0.00019881093816127079.\n",
      "2838/3560 [======================>.......] - ETA: 1:29 - loss: 0.5621 - accuracy: 0.8415\n",
      "Batch 09959: setting learning rate to 0.00019881038996925657.\n",
      "2839/3560 [======================>.......] - ETA: 1:29 - loss: 0.5620 - accuracy: 0.8415\n",
      "Batch 09960: setting learning rate to 0.00019880984165166136.\n",
      "2840/3560 [======================>.......] - ETA: 1:29 - loss: 0.5620 - accuracy: 0.8416\n",
      "Batch 09961: setting learning rate to 0.00019880929320848588.\n",
      "2841/3560 [======================>.......] - ETA: 1:29 - loss: 0.5620 - accuracy: 0.8416\n",
      "Batch 09962: setting learning rate to 0.00019880874463973084.\n",
      "2842/3560 [======================>.......] - ETA: 1:29 - loss: 0.5618 - accuracy: 0.8416\n",
      "Batch 09963: setting learning rate to 0.00019880819594539695.\n",
      "2843/3560 [======================>.......] - ETA: 1:29 - loss: 0.5618 - accuracy: 0.8416\n",
      "Batch 09964: setting learning rate to 0.00019880764712548485.\n",
      "2844/3560 [======================>.......] - ETA: 1:29 - loss: 0.5618 - accuracy: 0.8416\n",
      "Batch 09965: setting learning rate to 0.00019880709817999528.\n",
      "2845/3560 [======================>.......] - ETA: 1:28 - loss: 0.5617 - accuracy: 0.8416\n",
      "Batch 09966: setting learning rate to 0.00019880654910892892.\n",
      "2846/3560 [======================>.......] - ETA: 1:28 - loss: 0.5618 - accuracy: 0.8416\n",
      "Batch 09967: setting learning rate to 0.00019880599991228652.\n",
      "2847/3560 [======================>.......] - ETA: 1:28 - loss: 0.5617 - accuracy: 0.8416\n",
      "Batch 09968: setting learning rate to 0.0001988054505900687.\n",
      "2848/3560 [=======================>......] - ETA: 1:28 - loss: 0.5616 - accuracy: 0.8417\n",
      "Batch 09969: setting learning rate to 0.0001988049011422762.\n",
      "2849/3560 [=======================>......] - ETA: 1:28 - loss: 0.5617 - accuracy: 0.8417\n",
      "Batch 09970: setting learning rate to 0.00019880435156890972.\n",
      "2850/3560 [=======================>......] - ETA: 1:28 - loss: 0.5617 - accuracy: 0.8417\n",
      "Batch 09971: setting learning rate to 0.00019880380186996992.\n",
      "2851/3560 [=======================>......] - ETA: 1:28 - loss: 0.5618 - accuracy: 0.8417\n",
      "Batch 09972: setting learning rate to 0.00019880325204545756.\n",
      "2852/3560 [=======================>......] - ETA: 1:28 - loss: 0.5618 - accuracy: 0.8417\n",
      "Batch 09973: setting learning rate to 0.0001988027020953733.\n",
      "2853/3560 [=======================>......] - ETA: 1:27 - loss: 0.5617 - accuracy: 0.8417\n",
      "Batch 09974: setting learning rate to 0.00019880215201971787.\n",
      "2854/3560 [=======================>......] - ETA: 1:27 - loss: 0.5620 - accuracy: 0.8417\n",
      "Batch 09975: setting learning rate to 0.0001988016018184919.\n",
      "2855/3560 [=======================>......] - ETA: 1:27 - loss: 0.5621 - accuracy: 0.8417\n",
      "Batch 09976: setting learning rate to 0.00019880105149169616.\n",
      "2856/3560 [=======================>......] - ETA: 1:27 - loss: 0.5624 - accuracy: 0.8416\n",
      "Batch 09977: setting learning rate to 0.00019880050103933134.\n",
      "2857/3560 [=======================>......] - ETA: 1:27 - loss: 0.5624 - accuracy: 0.8416\n",
      "Batch 09978: setting learning rate to 0.0001987999504613981.\n",
      "2858/3560 [=======================>......] - ETA: 1:27 - loss: 0.5624 - accuracy: 0.8416\n",
      "Batch 09979: setting learning rate to 0.0001987993997578972.\n",
      "2859/3560 [=======================>......] - ETA: 1:27 - loss: 0.5623 - accuracy: 0.8416\n",
      "Batch 09980: setting learning rate to 0.00019879884892882928.\n",
      "\n",
      "Batch 09981: setting learning rate to 0.00019879829797419504.\n",
      "2861/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09982: setting learning rate to 0.0001987977468939952.\n",
      "2862/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09983: setting learning rate to 0.00019879719568823053.\n",
      "2863/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09984: setting learning rate to 0.00019879664435690163.\n",
      "2864/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09985: setting learning rate to 0.00019879609290000922.\n",
      "\n",
      "Batch 09986: setting learning rate to 0.00019879554131755402.\n",
      "2866/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09987: setting learning rate to 0.00019879498960953673.\n",
      "2867/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09988: setting learning rate to 0.00019879443777595808.\n",
      "2868/3560 [=======================>......] - ETA: 1:26 - loss: 0.5623 - accuracy: 0.8415\n",
      "Batch 09989: setting learning rate to 0.0001987938858168187.\n",
      "\n",
      "Batch 09990: setting learning rate to 0.00019879333373211937.\n",
      "2870/3560 [=======================>......] - ETA: 1:25 - loss: 0.5625 - accuracy: 0.8415\n",
      "Batch 09991: setting learning rate to 0.00019879278152186073.\n",
      "2871/3560 [=======================>......] - ETA: 1:25 - loss: 0.5625 - accuracy: 0.8414\n",
      "Batch 09992: setting learning rate to 0.0001987922291860435.\n",
      "2872/3560 [=======================>......] - ETA: 1:25 - loss: 0.5624 - accuracy: 0.8414\n",
      "Batch 09993: setting learning rate to 0.00019879167672466838.\n",
      "2873/3560 [=======================>......] - ETA: 1:25 - loss: 0.5625 - accuracy: 0.8415\n",
      "Batch 09994: setting learning rate to 0.00019879112413773612.\n",
      "\n",
      "Batch 09995: setting learning rate to 0.00019879057142524733.\n",
      "2875/3560 [=======================>......] - ETA: 1:25 - loss: 0.5625 - accuracy: 0.8415\n",
      "Batch 09996: setting learning rate to 0.00019879001858720278.\n",
      "2876/3560 [=======================>......] - ETA: 1:25 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 09997: setting learning rate to 0.00019878946562360317.\n",
      "2877/3560 [=======================>......] - ETA: 1:25 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 09998: setting learning rate to 0.0001987889125344492.\n",
      "2878/3560 [=======================>......] - ETA: 1:24 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 09999: setting learning rate to 0.00019878835931974156.\n",
      "2879/3560 [=======================>......] - ETA: 1:24 - loss: 0.5625 - accuracy: 0.8415\n",
      "Batch 10000: setting learning rate to 0.00019878780597948096.\n",
      "2880/3560 [=======================>......] - ETA: 1:24 - loss: 0.5625 - accuracy: 0.8415\n",
      "Batch 10001: setting learning rate to 0.0001987872525136681.\n",
      "2881/3560 [=======================>......] - ETA: 1:24 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10002: setting learning rate to 0.00019878669892230364.\n",
      "2882/3560 [=======================>......] - ETA: 1:24 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10003: setting learning rate to 0.00019878614520538835.\n",
      "2883/3560 [=======================>......] - ETA: 1:24 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10004: setting learning rate to 0.0001987855913629229.\n",
      "2884/3560 [=======================>......] - ETA: 1:24 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10005: setting learning rate to 0.000198785037394908.\n",
      "2885/3560 [=======================>......] - ETA: 1:23 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10006: setting learning rate to 0.0001987844833013444.\n",
      "\n",
      "Batch 10007: setting learning rate to 0.00019878392908223274.\n",
      "2887/3560 [=======================>......] - ETA: 1:23 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10008: setting learning rate to 0.00019878337473757372.\n",
      "2888/3560 [=======================>......] - ETA: 1:23 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10009: setting learning rate to 0.0001987828202673681.\n",
      "2889/3560 [=======================>......] - ETA: 1:23 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10010: setting learning rate to 0.00019878226567161656.\n",
      "\n",
      "Batch 10011: setting learning rate to 0.00019878171095031978.\n",
      "2891/3560 [=======================>......] - ETA: 1:23 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10012: setting learning rate to 0.00019878115610347848.\n",
      "2892/3560 [=======================>......] - ETA: 1:23 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10013: setting learning rate to 0.0001987806011310934.\n",
      "2893/3560 [=======================>......] - ETA: 1:23 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10014: setting learning rate to 0.0001987800460331652.\n",
      "2894/3560 [=======================>......] - ETA: 1:22 - loss: 0.5629 - accuracy: 0.8415\n",
      "Batch 10015: setting learning rate to 0.0001987794908096946.\n",
      "2895/3560 [=======================>......] - ETA: 1:22 - loss: 0.5629 - accuracy: 0.8414\n",
      "Batch 10016: setting learning rate to 0.0001987789354606823.\n",
      "2896/3560 [=======================>......] - ETA: 1:22 - loss: 0.5629 - accuracy: 0.8414\n",
      "Batch 10017: setting learning rate to 0.000198778379986129.\n",
      "2897/3560 [=======================>......] - ETA: 1:22 - loss: 0.5629 - accuracy: 0.8415\n",
      "Batch 10018: setting learning rate to 0.00019877782438603545.\n",
      "2898/3560 [=======================>......] - ETA: 1:22 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10019: setting learning rate to 0.00019877726866040233.\n",
      "2899/3560 [=======================>......] - ETA: 1:22 - loss: 0.5628 - accuracy: 0.8414\n",
      "Batch 10020: setting learning rate to 0.00019877671280923032.\n",
      "2900/3560 [=======================>......] - ETA: 1:22 - loss: 0.5628 - accuracy: 0.8414\n",
      "Batch 10021: setting learning rate to 0.00019877615683252015.\n",
      "2901/3560 [=======================>......] - ETA: 1:21 - loss: 0.5627 - accuracy: 0.8414\n",
      "Batch 10022: setting learning rate to 0.0001987756007302725.\n",
      "2902/3560 [=======================>......] - ETA: 1:21 - loss: 0.5628 - accuracy: 0.8414\n",
      "Batch 10023: setting learning rate to 0.00019877504450248817.\n",
      "2903/3560 [=======================>......] - ETA: 1:21 - loss: 0.5628 - accuracy: 0.8414\n",
      "Batch 10024: setting learning rate to 0.0001987744881491677.\n",
      "\n",
      "Batch 10025: setting learning rate to 0.000198773931670312.\n",
      "2905/3560 [=======================>......] - ETA: 1:21 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10026: setting learning rate to 0.00019877337506592161.\n",
      "2906/3560 [=======================>......] - ETA: 1:21 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10027: setting learning rate to 0.0001987728183359973.\n",
      "\n",
      "Batch 10028: setting learning rate to 0.0001987722614805398.\n",
      "2908/3560 [=======================>......] - ETA: 1:21 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10029: setting learning rate to 0.00019877170449954977.\n",
      "2909/3560 [=======================>......] - ETA: 1:21 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10030: setting learning rate to 0.00019877114739302794.\n",
      "\n",
      "Batch 10031: setting learning rate to 0.00019877059016097504.\n",
      "2911/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10032: setting learning rate to 0.00019877003280339178.\n",
      "2912/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10033: setting learning rate to 0.0001987694753202788.\n",
      "2913/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10034: setting learning rate to 0.0001987689177116369.\n",
      "2914/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10035: setting learning rate to 0.00019876835997746672.\n",
      "2915/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10036: setting learning rate to 0.000198767802117769.\n",
      "2916/3560 [=======================>......] - ETA: 1:20 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10037: setting learning rate to 0.00019876724413254445.\n",
      "2917/3560 [=======================>......] - ETA: 1:19 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10038: setting learning rate to 0.00019876668602179375.\n",
      "2918/3560 [=======================>......] - ETA: 1:19 - loss: 0.5629 - accuracy: 0.8415\n",
      "Batch 10039: setting learning rate to 0.00019876612778551764.\n",
      "2919/3560 [=======================>......] - ETA: 1:19 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10040: setting learning rate to 0.00019876556942371684.\n",
      "2920/3560 [=======================>......] - ETA: 1:19 - loss: 0.5630 - accuracy: 0.8415\n",
      "Batch 10041: setting learning rate to 0.000198765010936392.\n",
      "2921/3560 [=======================>......] - ETA: 1:19 - loss: 0.5629 - accuracy: 0.8415\n",
      "Batch 10042: setting learning rate to 0.0001987644523235439.\n",
      "\n",
      "Batch 10043: setting learning rate to 0.00019876389358517322.\n",
      "2923/3560 [=======================>......] - ETA: 1:19 - loss: 0.5628 - accuracy: 0.8415\n",
      "Batch 10044: setting learning rate to 0.00019876333472128066.\n",
      "2924/3560 [=======================>......] - ETA: 1:19 - loss: 0.5627 - accuracy: 0.8415\n",
      "Batch 10045: setting learning rate to 0.00019876277573186696.\n",
      "2925/3560 [=======================>......] - ETA: 1:19 - loss: 0.5626 - accuracy: 0.8416\n",
      "Batch 10046: setting learning rate to 0.00019876221661693278.\n",
      "2926/3560 [=======================>......] - ETA: 1:18 - loss: 0.5626 - accuracy: 0.8416\n",
      "Batch 10047: setting learning rate to 0.00019876165737647887.\n",
      "2927/3560 [=======================>......] - ETA: 1:18 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10048: setting learning rate to 0.00019876109801050592.\n",
      "2928/3560 [=======================>......] - ETA: 1:18 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10049: setting learning rate to 0.00019876053851901467.\n",
      "2929/3560 [=======================>......] - ETA: 1:18 - loss: 0.5626 - accuracy: 0.8415\n",
      "Batch 10050: setting learning rate to 0.00019875997890200583.\n",
      "\n",
      "Batch 10051: setting learning rate to 0.00019875941915948006.\n",
      "2931/3560 [=======================>......] - ETA: 1:18 - loss: 0.5625 - accuracy: 0.8416\n",
      "Batch 10052: setting learning rate to 0.00019875885929143813.\n",
      "2932/3560 [=======================>......] - ETA: 1:18 - loss: 0.5626 - accuracy: 0.8416\n",
      "Batch 10053: setting learning rate to 0.00019875829929788075.\n",
      "2933/3560 [=======================>......] - ETA: 1:17 - loss: 0.5626 - accuracy: 0.8416\n",
      "Batch 10054: setting learning rate to 0.00019875773917880856.\n",
      "\n",
      "Batch 10055: setting learning rate to 0.00019875717893422235.\n",
      "2935/3560 [=======================>......] - ETA: 1:17 - loss: 0.5625 - accuracy: 0.8417\n",
      "Batch 10056: setting learning rate to 0.0001987566185641228.\n",
      "2936/3560 [=======================>......] - ETA: 1:17 - loss: 0.5626 - accuracy: 0.8417\n",
      "Batch 10057: setting learning rate to 0.0001987560580685106.\n",
      "2937/3560 [=======================>......] - ETA: 1:17 - loss: 0.5626 - accuracy: 0.8417\n",
      "Batch 10058: setting learning rate to 0.00019875549744738654.\n",
      "\n",
      "Batch 10059: setting learning rate to 0.00019875493670075124.\n",
      "2939/3560 [=======================>......] - ETA: 1:17 - loss: 0.5625 - accuracy: 0.8418\n",
      "Batch 10060: setting learning rate to 0.00019875437582860545.\n",
      "2940/3560 [=======================>......] - ETA: 1:17 - loss: 0.5626 - accuracy: 0.8418\n",
      "Batch 10061: setting learning rate to 0.00019875381483094992.\n",
      "2941/3560 [=======================>......] - ETA: 1:17 - loss: 0.5625 - accuracy: 0.8418\n",
      "Batch 10062: setting learning rate to 0.00019875325370778533.\n",
      "2942/3560 [=======================>......] - ETA: 1:17 - loss: 0.5625 - accuracy: 0.8418\n",
      "Batch 10063: setting learning rate to 0.00019875269245911236.\n",
      "2943/3560 [=======================>......] - ETA: 1:16 - loss: 0.5625 - accuracy: 0.8418\n",
      "Batch 10064: setting learning rate to 0.00019875213108493177.\n",
      "2944/3560 [=======================>......] - ETA: 1:16 - loss: 0.5624 - accuracy: 0.8418\n",
      "Batch 10065: setting learning rate to 0.00019875156958524425.\n",
      "2945/3560 [=======================>......] - ETA: 1:16 - loss: 0.5624 - accuracy: 0.8418\n",
      "Batch 10066: setting learning rate to 0.00019875100796005053.\n",
      "2946/3560 [=======================>......] - ETA: 1:16 - loss: 0.5623 - accuracy: 0.8418\n",
      "Batch 10067: setting learning rate to 0.00019875044620935132.\n",
      "2947/3560 [=======================>......] - ETA: 1:16 - loss: 0.5623 - accuracy: 0.8418\n",
      "Batch 10068: setting learning rate to 0.00019874988433314734.\n",
      "2948/3560 [=======================>......] - ETA: 1:16 - loss: 0.5623 - accuracy: 0.8418\n",
      "Batch 10069: setting learning rate to 0.00019874932233143928.\n",
      "2949/3560 [=======================>......] - ETA: 1:16 - loss: 0.5623 - accuracy: 0.8418\n",
      "Batch 10070: setting learning rate to 0.00019874876020422786.\n",
      "2950/3560 [=======================>......] - ETA: 1:15 - loss: 0.5622 - accuracy: 0.8418\n",
      "Batch 10071: setting learning rate to 0.00019874819795151383.\n",
      "2951/3560 [=======================>......] - ETA: 1:15 - loss: 0.5621 - accuracy: 0.8418\n",
      "Batch 10072: setting learning rate to 0.00019874763557329786.\n",
      "\n",
      "Batch 10073: setting learning rate to 0.0001987470730695807.\n",
      "2953/3560 [=======================>......] - ETA: 1:15 - loss: 0.5621 - accuracy: 0.8418\n",
      "Batch 10074: setting learning rate to 0.00019874651044036302.\n",
      "\n",
      "Batch 10075: setting learning rate to 0.00019874594768564557.\n",
      "2955/3560 [=======================>......] - ETA: 1:15 - loss: 0.5620 - accuracy: 0.8418\n",
      "Batch 10076: setting learning rate to 0.0001987453848054291.\n",
      "2956/3560 [=======================>......] - ETA: 1:15 - loss: 0.5620 - accuracy: 0.8418\n",
      "Batch 10077: setting learning rate to 0.00019874482179971424.\n",
      "2957/3560 [=======================>......] - ETA: 1:15 - loss: 0.5620 - accuracy: 0.8418\n",
      "Batch 10078: setting learning rate to 0.00019874425866850173.\n",
      "2958/3560 [=======================>......] - ETA: 1:14 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10079: setting learning rate to 0.00019874369541179234.\n",
      "2959/3560 [=======================>......] - ETA: 1:14 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10080: setting learning rate to 0.00019874313202958673.\n",
      "\n",
      "Batch 10081: setting learning rate to 0.00019874256852188564.\n",
      "2961/3560 [=======================>......] - ETA: 1:14 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10082: setting learning rate to 0.00019874200488868978.\n",
      "2962/3560 [=======================>......] - ETA: 1:14 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10083: setting learning rate to 0.0001987414411299999.\n",
      "2963/3560 [=======================>......] - ETA: 1:14 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10084: setting learning rate to 0.00019874087724581666.\n",
      "2964/3560 [=======================>......] - ETA: 1:14 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10085: setting learning rate to 0.0001987403132361408.\n",
      "\n",
      "Batch 10086: setting learning rate to 0.00019873974910097306.\n",
      "2966/3560 [=======================>......] - ETA: 1:13 - loss: 0.5621 - accuracy: 0.8418\n",
      "Batch 10087: setting learning rate to 0.00019873918484031414.\n",
      "2967/3560 [========================>.....] - ETA: 1:13 - loss: 0.5621 - accuracy: 0.8418\n",
      "Batch 10088: setting learning rate to 0.00019873862045416472.\n",
      "2968/3560 [========================>.....] - ETA: 1:13 - loss: 0.5622 - accuracy: 0.8418\n",
      "Batch 10089: setting learning rate to 0.00019873805594252555.\n",
      "\n",
      "Batch 10090: setting learning rate to 0.00019873749130539737.\n",
      "2970/3560 [========================>.....] - ETA: 1:13 - loss: 0.5621 - accuracy: 0.8419\n",
      "Batch 10091: setting learning rate to 0.00019873692654278087.\n",
      "2971/3560 [========================>.....] - ETA: 1:13 - loss: 0.5621 - accuracy: 0.8419\n",
      "Batch 10092: setting learning rate to 0.00019873636165467678.\n",
      "2972/3560 [========================>.....] - ETA: 1:13 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10093: setting learning rate to 0.0001987357966410858.\n",
      "2973/3560 [========================>.....] - ETA: 1:12 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10094: setting learning rate to 0.00019873523150200866.\n",
      "2974/3560 [========================>.....] - ETA: 1:12 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10095: setting learning rate to 0.00019873466623744607.\n",
      "2975/3560 [========================>.....] - ETA: 1:12 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10096: setting learning rate to 0.00019873410084739876.\n",
      "2976/3560 [========================>.....] - ETA: 1:12 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10097: setting learning rate to 0.00019873353533186744.\n",
      "2977/3560 [========================>.....] - ETA: 1:12 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10098: setting learning rate to 0.00019873296969085284.\n",
      "2978/3560 [========================>.....] - ETA: 1:12 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10099: setting learning rate to 0.00019873240392435568.\n",
      "2979/3560 [========================>.....] - ETA: 1:12 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10100: setting learning rate to 0.00019873183803237665.\n",
      "2980/3560 [========================>.....] - ETA: 1:12 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10101: setting learning rate to 0.0001987312720149165.\n",
      "2981/3560 [========================>.....] - ETA: 1:12 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10102: setting learning rate to 0.00019873070587197599.\n",
      "2982/3560 [========================>.....] - ETA: 1:11 - loss: 0.5620 - accuracy: 0.8418\n",
      "Batch 10103: setting learning rate to 0.0001987301396035557.\n",
      "2983/3560 [========================>.....] - ETA: 1:11 - loss: 0.5619 - accuracy: 0.8418\n",
      "Batch 10104: setting learning rate to 0.00019872957320965647.\n",
      "2984/3560 [========================>.....] - ETA: 1:11 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10105: setting learning rate to 0.00019872900669027903.\n",
      "2985/3560 [========================>.....] - ETA: 1:11 - loss: 0.5620 - accuracy: 0.8419\n",
      "Batch 10106: setting learning rate to 0.00019872844004542405.\n",
      "2986/3560 [========================>.....] - ETA: 1:11 - loss: 0.5620 - accuracy: 0.8418\n",
      "Batch 10107: setting learning rate to 0.0001987278732750922.\n",
      "\n",
      "Batch 10108: setting learning rate to 0.00019872730637928433.\n",
      "2988/3560 [========================>.....] - ETA: 1:11 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10109: setting learning rate to 0.00019872673935800105.\n",
      "2989/3560 [========================>.....] - ETA: 1:11 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10110: setting learning rate to 0.0001987261722112431.\n",
      "2990/3560 [========================>.....] - ETA: 1:10 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10111: setting learning rate to 0.00019872560493901126.\n",
      "2991/3560 [========================>.....] - ETA: 1:10 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10112: setting learning rate to 0.0001987250375413062.\n",
      "2992/3560 [========================>.....] - ETA: 1:10 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10113: setting learning rate to 0.00019872447001812864.\n",
      "2993/3560 [========================>.....] - ETA: 1:10 - loss: 0.5619 - accuracy: 0.8419\n",
      "Batch 10114: setting learning rate to 0.00019872390236947934.\n",
      "2994/3560 [========================>.....] - ETA: 1:10 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10115: setting learning rate to 0.00019872333459535898.\n",
      "2995/3560 [========================>.....] - ETA: 1:10 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10116: setting learning rate to 0.0001987227666957683.\n",
      "2996/3560 [========================>.....] - ETA: 1:10 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10117: setting learning rate to 0.000198722198670708.\n",
      "2997/3560 [========================>.....] - ETA: 1:10 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10118: setting learning rate to 0.00019872163052017886.\n",
      "2998/3560 [========================>.....] - ETA: 1:09 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10119: setting learning rate to 0.00019872106224418155.\n",
      "2999/3560 [========================>.....] - ETA: 1:09 - loss: 0.5618 - accuracy: 0.8419\n",
      "Batch 10120: setting learning rate to 0.00019872049384271677.\n",
      "3000/3560 [========================>.....] - ETA: 1:09 - loss: 0.5618 - accuracy: 0.8420\n",
      "Batch 10121: setting learning rate to 0.00019871992531578534.\n",
      "\n",
      "Batch 10122: setting learning rate to 0.00019871935666338785.\n",
      "3002/3560 [========================>.....] - ETA: 1:09 - loss: 0.5617 - accuracy: 0.8420\n",
      "Batch 10123: setting learning rate to 0.00019871878788552515.\n",
      "3003/3560 [========================>.....] - ETA: 1:09 - loss: 0.5616 - accuracy: 0.8421\n",
      "Batch 10124: setting learning rate to 0.0001987182189821979.\n",
      "3004/3560 [========================>.....] - ETA: 1:09 - loss: 0.5616 - accuracy: 0.8421\n",
      "Batch 10125: setting learning rate to 0.0001987176499534068.\n",
      "3005/3560 [========================>.....] - ETA: 1:09 - loss: 0.5616 - accuracy: 0.8421\n",
      "Batch 10126: setting learning rate to 0.0001987170807991526.\n",
      "3006/3560 [========================>.....] - ETA: 1:08 - loss: 0.5617 - accuracy: 0.8421\n",
      "Batch 10127: setting learning rate to 0.00019871651151943606.\n",
      "3007/3560 [========================>.....] - ETA: 1:08 - loss: 0.5616 - accuracy: 0.8421\n",
      "Batch 10128: setting learning rate to 0.00019871594211425786.\n",
      "3008/3560 [========================>.....] - ETA: 1:08 - loss: 0.5616 - accuracy: 0.8421\n",
      "Batch 10129: setting learning rate to 0.00019871537258361874.\n",
      "\n",
      "Batch 10130: setting learning rate to 0.00019871480292751938.\n",
      "3010/3560 [========================>.....] - ETA: 1:08 - loss: 0.5616 - accuracy: 0.8420\n",
      "Batch 10131: setting learning rate to 0.00019871423314596055.\n",
      "3011/3560 [========================>.....] - ETA: 1:08 - loss: 0.5615 - accuracy: 0.8420\n",
      "Batch 10132: setting learning rate to 0.00019871366323894298.\n",
      "\n",
      "Batch 10133: setting learning rate to 0.0001987130932064674.\n",
      "3013/3560 [========================>.....] - ETA: 1:08 - loss: 0.5615 - accuracy: 0.8421\n",
      "Batch 10134: setting learning rate to 0.0001987125230485345.\n",
      "\n",
      "Batch 10135: setting learning rate to 0.000198711952765145.\n",
      "3015/3560 [========================>.....] - ETA: 1:07 - loss: 0.5614 - accuracy: 0.8421\n",
      "Batch 10136: setting learning rate to 0.00019871138235629966.\n",
      "3016/3560 [========================>.....] - ETA: 1:07 - loss: 0.5614 - accuracy: 0.8421\n",
      "Batch 10137: setting learning rate to 0.00019871081182199916.\n",
      "3017/3560 [========================>.....] - ETA: 1:07 - loss: 0.5613 - accuracy: 0.8421\n",
      "Batch 10138: setting learning rate to 0.00019871024116224425.\n",
      "3018/3560 [========================>.....] - ETA: 1:07 - loss: 0.5614 - accuracy: 0.8421\n",
      "Batch 10139: setting learning rate to 0.0001987096703770357.\n",
      "3019/3560 [========================>.....] - ETA: 1:07 - loss: 0.5614 - accuracy: 0.8421\n",
      "Batch 10140: setting learning rate to 0.0001987090994663742.\n",
      "\n",
      "Batch 10141: setting learning rate to 0.00019870852843026043.\n",
      "3021/3560 [========================>.....] - ETA: 1:07 - loss: 0.5613 - accuracy: 0.8421\n",
      "Batch 10142: setting learning rate to 0.00019870795726869515.\n",
      "3022/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8421\n",
      "Batch 10143: setting learning rate to 0.00019870738598167913.\n",
      "3023/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8421\n",
      "Batch 10144: setting learning rate to 0.00019870681456921302.\n",
      "3024/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10145: setting learning rate to 0.00019870624303129758.\n",
      "3025/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10146: setting learning rate to 0.00019870567136793358.\n",
      "\n",
      "Batch 10147: setting learning rate to 0.0001987050995791217.\n",
      "3027/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10148: setting learning rate to 0.00019870452766486264.\n",
      "3028/3560 [========================>.....] - ETA: 1:06 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10149: setting learning rate to 0.00019870395562515718.\n",
      "\n",
      "Batch 10150: setting learning rate to 0.00019870338346000604.\n",
      "3030/3560 [========================>.....] - ETA: 1:05 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10151: setting learning rate to 0.0001987028111694099.\n",
      "3031/3560 [========================>.....] - ETA: 1:05 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10152: setting learning rate to 0.00019870223875336954.\n",
      "\n",
      "Batch 10153: setting learning rate to 0.00019870166621188567.\n",
      "3033/3560 [========================>.....] - ETA: 1:05 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10154: setting learning rate to 0.00019870109354495902.\n",
      "\n",
      "Batch 10155: setting learning rate to 0.0001987005207525903.\n",
      "3035/3560 [========================>.....] - ETA: 1:05 - loss: 0.5610 - accuracy: 0.8423\n",
      "Batch 10156: setting learning rate to 0.00019869994783478027.\n",
      "\n",
      "Batch 10157: setting learning rate to 0.00019869937479152964.\n",
      "3037/3560 [========================>.....] - ETA: 1:05 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10158: setting learning rate to 0.00019869880162283913.\n",
      "3038/3560 [========================>.....] - ETA: 1:04 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10159: setting learning rate to 0.00019869822832870948.\n",
      "3039/3560 [========================>.....] - ETA: 1:04 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10160: setting learning rate to 0.00019869765490914142.\n",
      "3040/3560 [========================>.....] - ETA: 1:04 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10161: setting learning rate to 0.00019869708136413566.\n",
      "3041/3560 [========================>.....] - ETA: 1:04 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10162: setting learning rate to 0.00019869650769369294.\n",
      "\n",
      "Batch 10163: setting learning rate to 0.000198695933897814.\n",
      "3043/3560 [========================>.....] - ETA: 1:04 - loss: 0.5610 - accuracy: 0.8422\n",
      "Batch 10164: setting learning rate to 0.00019869535997649957.\n",
      "3044/3560 [========================>.....] - ETA: 1:04 - loss: 0.5610 - accuracy: 0.8422\n",
      "Batch 10165: setting learning rate to 0.00019869478592975036.\n",
      "3045/3560 [========================>.....] - ETA: 1:04 - loss: 0.5610 - accuracy: 0.8422\n",
      "Batch 10166: setting learning rate to 0.00019869421175756712.\n",
      "3046/3560 [========================>.....] - ETA: 1:03 - loss: 0.5610 - accuracy: 0.8422\n",
      "Batch 10167: setting learning rate to 0.00019869363745995058.\n",
      "3047/3560 [========================>.....] - ETA: 1:03 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10168: setting learning rate to 0.00019869306303690144.\n",
      "3048/3560 [========================>.....] - ETA: 1:03 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10169: setting learning rate to 0.0001986924884884205.\n",
      "3049/3560 [========================>.....] - ETA: 1:03 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10170: setting learning rate to 0.00019869191381450838.\n",
      "3050/3560 [========================>.....] - ETA: 1:03 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10171: setting learning rate to 0.00019869133901516587.\n",
      "3051/3560 [========================>.....] - ETA: 1:03 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10172: setting learning rate to 0.00019869076409039372.\n",
      "3052/3560 [========================>.....] - ETA: 1:03 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10173: setting learning rate to 0.00019869018904019266.\n",
      "3053/3560 [========================>.....] - ETA: 1:03 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10174: setting learning rate to 0.0001986896138645634.\n",
      "3054/3560 [========================>.....] - ETA: 1:02 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10175: setting learning rate to 0.00019868903856350666.\n",
      "\n",
      "Batch 10176: setting learning rate to 0.00019868846313702315.\n",
      "3056/3560 [========================>.....] - ETA: 1:02 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10177: setting learning rate to 0.0001986878875851137.\n",
      "\n",
      "Batch 10178: setting learning rate to 0.00019868731190777897.\n",
      "3058/3560 [========================>.....] - ETA: 1:02 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10179: setting learning rate to 0.00019868673610501966.\n",
      "3059/3560 [========================>.....] - ETA: 1:02 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10180: setting learning rate to 0.00019868616017683656.\n",
      "3060/3560 [========================>.....] - ETA: 1:02 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10181: setting learning rate to 0.0001986855841232304.\n",
      "\n",
      "Batch 10182: setting learning rate to 0.0001986850079442019.\n",
      "3062/3560 [========================>.....] - ETA: 1:02 - loss: 0.5613 - accuracy: 0.8422\n",
      "Batch 10183: setting learning rate to 0.00019868443163975174.\n",
      "3063/3560 [========================>.....] - ETA: 1:01 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10184: setting learning rate to 0.00019868385520988073.\n",
      "3064/3560 [========================>.....] - ETA: 1:01 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10185: setting learning rate to 0.00019868327865458956.\n",
      "3065/3560 [========================>.....] - ETA: 1:01 - loss: 0.5612 - accuracy: 0.8422\n",
      "Batch 10186: setting learning rate to 0.00019868270197387903.\n",
      "3066/3560 [========================>.....] - ETA: 1:01 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10187: setting learning rate to 0.00019868212516774975.\n",
      "3067/3560 [========================>.....] - ETA: 1:01 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10188: setting learning rate to 0.00019868154823620256.\n",
      "3068/3560 [========================>.....] - ETA: 1:01 - loss: 0.5611 - accuracy: 0.8422\n",
      "Batch 10189: setting learning rate to 0.00019868097117923815.\n",
      "3069/3560 [========================>.....] - ETA: 1:01 - loss: 0.5611 - accuracy: 0.8423\n",
      "Batch 10190: setting learning rate to 0.00019868039399685726.\n",
      "3070/3560 [========================>.....] - ETA: 1:00 - loss: 0.5610 - accuracy: 0.8423\n",
      "Batch 10191: setting learning rate to 0.0001986798166890606.\n",
      "3071/3560 [========================>.....] - ETA: 1:00 - loss: 0.5610 - accuracy: 0.8423\n",
      "Batch 10192: setting learning rate to 0.00019867923925584894.\n",
      "3072/3560 [========================>.....] - ETA: 1:00 - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10193: setting learning rate to 0.00019867866169722299.\n",
      "3073/3560 [========================>.....] - ETA: 1:00 - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10194: setting learning rate to 0.00019867808401318352.\n",
      "3074/3560 [========================>.....] - ETA: 1:00 - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10195: setting learning rate to 0.0001986775062037312.\n",
      "3075/3560 [========================>.....] - ETA: 1:00 - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10196: setting learning rate to 0.00019867692826886684.\n",
      "\n",
      "Batch 10197: setting learning rate to 0.0001986763502085911.\n",
      "3077/3560 [========================>.....] - ETA: 1:00 - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10198: setting learning rate to 0.0001986757720229048.\n",
      "\n",
      "Batch 10199: setting learning rate to 0.00019867519371180857.\n",
      "3079/3560 [========================>.....] - ETA: 59s - loss: 0.5609 - accuracy: 0.8423 \n",
      "Batch 10200: setting learning rate to 0.00019867461527530323.\n",
      "3080/3560 [========================>.....] - ETA: 59s - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10201: setting learning rate to 0.0001986740367133895.\n",
      "3081/3560 [========================>.....] - ETA: 59s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10202: setting learning rate to 0.00019867345802606807.\n",
      "3082/3560 [========================>.....] - ETA: 59s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10203: setting learning rate to 0.00019867287921333974.\n",
      "3083/3560 [========================>.....] - ETA: 59s - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10204: setting learning rate to 0.0001986723002752052.\n",
      "3084/3560 [========================>.....] - ETA: 59s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10205: setting learning rate to 0.0001986717212116652.\n",
      "3085/3560 [========================>.....] - ETA: 59s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10206: setting learning rate to 0.00019867114202272044.\n",
      "3086/3560 [=========================>....] - ETA: 58s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10207: setting learning rate to 0.00019867056270837173.\n",
      "3087/3560 [=========================>....] - ETA: 58s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10208: setting learning rate to 0.00019866998326861977.\n",
      "3088/3560 [=========================>....] - ETA: 58s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10209: setting learning rate to 0.00019866940370346527.\n",
      "3089/3560 [=========================>....] - ETA: 58s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10210: setting learning rate to 0.000198668824012909.\n",
      "3090/3560 [=========================>....] - ETA: 58s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10211: setting learning rate to 0.00019866824419695166.\n",
      "3091/3560 [=========================>....] - ETA: 58s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10212: setting learning rate to 0.00019866766425559408.\n",
      "3092/3560 [=========================>....] - ETA: 58s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10213: setting learning rate to 0.00019866708418883686.\n",
      "3093/3560 [=========================>....] - ETA: 58s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10214: setting learning rate to 0.00019866650399668085.\n",
      "3094/3560 [=========================>....] - ETA: 57s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10215: setting learning rate to 0.0001986659236791267.\n",
      "3095/3560 [=========================>....] - ETA: 57s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10216: setting learning rate to 0.00019866534323617524.\n",
      "3096/3560 [=========================>....] - ETA: 57s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10217: setting learning rate to 0.00019866476266782717.\n",
      "3097/3560 [=========================>....] - ETA: 57s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10218: setting learning rate to 0.0001986641819740832.\n",
      "\n",
      "Batch 10219: setting learning rate to 0.00019866360115494404.\n",
      "3099/3560 [=========================>....] - ETA: 57s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10220: setting learning rate to 0.00019866302021041054.\n",
      "\n",
      "Batch 10221: setting learning rate to 0.00019866243914048334.\n",
      "3101/3560 [=========================>....] - ETA: 57s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10222: setting learning rate to 0.0001986618579451632.\n",
      "3102/3560 [=========================>....] - ETA: 56s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10223: setting learning rate to 0.0001986612766244509.\n",
      "3103/3560 [=========================>....] - ETA: 56s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10224: setting learning rate to 0.00019866069517834712.\n",
      "3104/3560 [=========================>....] - ETA: 56s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10225: setting learning rate to 0.00019866011360685266.\n",
      "3105/3560 [=========================>....] - ETA: 56s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10226: setting learning rate to 0.00019865953190996823.\n",
      "3106/3560 [=========================>....] - ETA: 56s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10227: setting learning rate to 0.00019865895008769452.\n",
      "3107/3560 [=========================>....] - ETA: 56s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10228: setting learning rate to 0.00019865836814003237.\n",
      "3108/3560 [=========================>....] - ETA: 56s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10229: setting learning rate to 0.00019865778606698243.\n",
      "3109/3560 [=========================>....] - ETA: 56s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10230: setting learning rate to 0.00019865720386854548.\n",
      "3110/3560 [=========================>....] - ETA: 55s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10231: setting learning rate to 0.00019865662154472226.\n",
      "3111/3560 [=========================>....] - ETA: 55s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10232: setting learning rate to 0.0001986560390955135.\n",
      "3112/3560 [=========================>....] - ETA: 55s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10233: setting learning rate to 0.00019865545652091995.\n",
      "3113/3560 [=========================>....] - ETA: 55s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10234: setting learning rate to 0.00019865487382094235.\n",
      "3114/3560 [=========================>....] - ETA: 55s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10235: setting learning rate to 0.0001986542909955814.\n",
      "\n",
      "Batch 10236: setting learning rate to 0.00019865370804483793.\n",
      "3116/3560 [=========================>....] - ETA: 55s - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10237: setting learning rate to 0.0001986531249687126.\n",
      "3117/3560 [=========================>....] - ETA: 55s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10238: setting learning rate to 0.0001986525417672062.\n",
      "3118/3560 [=========================>....] - ETA: 54s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10239: setting learning rate to 0.00019865195844031943.\n",
      "\n",
      "Batch 10240: setting learning rate to 0.00019865137498805305.\n",
      "3120/3560 [=========================>....] - ETA: 54s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10241: setting learning rate to 0.00019865079141040778.\n",
      "3121/3560 [=========================>....] - ETA: 54s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10242: setting learning rate to 0.00019865020770738444.\n",
      "3122/3560 [=========================>....] - ETA: 54s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10243: setting learning rate to 0.00019864962387898367.\n",
      "3123/3560 [=========================>....] - ETA: 54s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10244: setting learning rate to 0.0001986490399252063.\n",
      "3124/3560 [=========================>....] - ETA: 54s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10245: setting learning rate to 0.00019864845584605302.\n",
      "3125/3560 [=========================>....] - ETA: 54s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10246: setting learning rate to 0.00019864787164152454.\n",
      "3126/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10247: setting learning rate to 0.0001986472873116217.\n",
      "3127/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10248: setting learning rate to 0.00019864670285634514.\n",
      "3128/3560 [=========================>....] - ETA: 53s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10249: setting learning rate to 0.0001986461182756957.\n",
      "3129/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10250: setting learning rate to 0.00019864553356967405.\n",
      "3130/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10251: setting learning rate to 0.00019864494873828093.\n",
      "3131/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10252: setting learning rate to 0.00019864436378151716.\n",
      "3132/3560 [=========================>....] - ETA: 53s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10253: setting learning rate to 0.00019864377869938343.\n",
      "3133/3560 [=========================>....] - ETA: 53s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10254: setting learning rate to 0.00019864319349188042.\n",
      "\n",
      "Batch 10255: setting learning rate to 0.000198642608159009.\n",
      "3135/3560 [=========================>....] - ETA: 52s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10256: setting learning rate to 0.00019864202270076985.\n",
      "3136/3560 [=========================>....] - ETA: 52s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10257: setting learning rate to 0.00019864143711716372.\n",
      "3137/3560 [=========================>....] - ETA: 52s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10258: setting learning rate to 0.00019864085140819135.\n",
      "3138/3560 [=========================>....] - ETA: 52s - loss: 0.5607 - accuracy: 0.8422\n",
      "Batch 10259: setting learning rate to 0.0001986402655738535.\n",
      "3139/3560 [=========================>....] - ETA: 52s - loss: 0.5606 - accuracy: 0.8422\n",
      "Batch 10260: setting learning rate to 0.0001986396796141509.\n",
      "3140/3560 [=========================>....] - ETA: 52s - loss: 0.5606 - accuracy: 0.8422\n",
      "Batch 10261: setting learning rate to 0.00019863909352908426.\n",
      "3141/3560 [=========================>....] - ETA: 52s - loss: 0.5609 - accuracy: 0.8422\n",
      "Batch 10262: setting learning rate to 0.00019863850731865438.\n",
      "\n",
      "Batch 10263: setting learning rate to 0.00019863792098286198.\n",
      "3143/3560 [=========================>....] - ETA: 51s - loss: 0.5608 - accuracy: 0.8422\n",
      "Batch 10264: setting learning rate to 0.00019863733452170785.\n",
      "3144/3560 [=========================>....] - ETA: 51s - loss: 0.5608 - accuracy: 0.8422\n",
      "Batch 10265: setting learning rate to 0.00019863674793519268.\n",
      "3145/3560 [=========================>....] - ETA: 51s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10266: setting learning rate to 0.0001986361612233172.\n",
      "\n",
      "Batch 10267: setting learning rate to 0.00019863557438608222.\n",
      "3147/3560 [=========================>....] - ETA: 51s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10268: setting learning rate to 0.00019863498742348846.\n",
      "3148/3560 [=========================>....] - ETA: 51s - loss: 0.5607 - accuracy: 0.8423\n",
      "Batch 10269: setting learning rate to 0.00019863440033553664.\n",
      "\n",
      "Batch 10270: setting learning rate to 0.00019863381312222754.\n",
      "3150/3560 [=========================>....] - ETA: 51s - loss: 0.5606 - accuracy: 0.8423\n",
      "Batch 10271: setting learning rate to 0.00019863322578356188.\n",
      "3151/3560 [=========================>....] - ETA: 50s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10272: setting learning rate to 0.00019863263831954045.\n",
      "3152/3560 [=========================>....] - ETA: 50s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10273: setting learning rate to 0.0001986320507301639.\n",
      "3153/3560 [=========================>....] - ETA: 50s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10274: setting learning rate to 0.00019863146301543313.\n",
      "3154/3560 [=========================>....] - ETA: 50s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10275: setting learning rate to 0.00019863087517534874.\n",
      "3155/3560 [=========================>....] - ETA: 50s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10276: setting learning rate to 0.00019863028720991155.\n",
      "3156/3560 [=========================>....] - ETA: 50s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10277: setting learning rate to 0.0001986296991191223.\n",
      "3157/3560 [=========================>....] - ETA: 50s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10278: setting learning rate to 0.00019862911090298173.\n",
      "3158/3560 [=========================>....] - ETA: 49s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10279: setting learning rate to 0.0001986285225614906.\n",
      "\n",
      "Batch 10280: setting learning rate to 0.0001986279340946496.\n",
      "3160/3560 [=========================>....] - ETA: 49s - loss: 0.5605 - accuracy: 0.8423\n",
      "Batch 10281: setting learning rate to 0.00019862734550245956.\n",
      "3161/3560 [=========================>....] - ETA: 49s - loss: 0.5605 - accuracy: 0.8423\n",
      "Batch 10282: setting learning rate to 0.0001986267567849212.\n",
      "3162/3560 [=========================>....] - ETA: 49s - loss: 0.5605 - accuracy: 0.8423\n",
      "Batch 10283: setting learning rate to 0.00019862616794203526.\n",
      "3163/3560 [=========================>....] - ETA: 49s - loss: 0.5604 - accuracy: 0.8423\n",
      "Batch 10284: setting learning rate to 0.00019862557897380248.\n",
      "3164/3560 [=========================>....] - ETA: 49s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10285: setting learning rate to 0.00019862498988022363.\n",
      "3165/3560 [=========================>....] - ETA: 49s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10286: setting learning rate to 0.00019862440066129944.\n",
      "3166/3560 [=========================>....] - ETA: 48s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10287: setting learning rate to 0.00019862381131703066.\n",
      "3167/3560 [=========================>....] - ETA: 48s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10288: setting learning rate to 0.00019862322184741805.\n",
      "3168/3560 [=========================>....] - ETA: 48s - loss: 0.5603 - accuracy: 0.8424\n",
      "Batch 10289: setting learning rate to 0.00019862263225246235.\n",
      "3169/3560 [=========================>....] - ETA: 48s - loss: 0.5603 - accuracy: 0.8424\n",
      "Batch 10290: setting learning rate to 0.0001986220425321643.\n",
      "3170/3560 [=========================>....] - ETA: 48s - loss: 0.5602 - accuracy: 0.8424\n",
      "Batch 10291: setting learning rate to 0.00019862145268652467.\n",
      "3171/3560 [=========================>....] - ETA: 48s - loss: 0.5602 - accuracy: 0.8425\n",
      "Batch 10292: setting learning rate to 0.0001986208627155442.\n",
      "\n",
      "Batch 10293: setting learning rate to 0.00019862027261922366.\n",
      "3173/3560 [=========================>....] - ETA: 48s - loss: 0.5602 - accuracy: 0.8425\n",
      "Batch 10294: setting learning rate to 0.00019861968239756378.\n",
      "3174/3560 [=========================>....] - ETA: 47s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10295: setting learning rate to 0.00019861909205056528.\n",
      "3175/3560 [=========================>....] - ETA: 47s - loss: 0.5602 - accuracy: 0.8425\n",
      "Batch 10296: setting learning rate to 0.00019861850157822897.\n",
      "\n",
      "Batch 10297: setting learning rate to 0.00019861791098055558.\n",
      "3177/3560 [=========================>....] - ETA: 47s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10298: setting learning rate to 0.00019861732025754582.\n",
      "3178/3560 [=========================>....] - ETA: 47s - loss: 0.5604 - accuracy: 0.8424\n",
      "Batch 10299: setting learning rate to 0.0001986167294092005.\n",
      "3179/3560 [=========================>....] - ETA: 47s - loss: 0.5604 - accuracy: 0.8425\n",
      "Batch 10300: setting learning rate to 0.00019861613843552035.\n",
      "3180/3560 [=========================>....] - ETA: 47s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10301: setting learning rate to 0.0001986155473365061.\n",
      "3181/3560 [=========================>....] - ETA: 47s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10302: setting learning rate to 0.00019861495611215855.\n",
      "3182/3560 [=========================>....] - ETA: 46s - loss: 0.5602 - accuracy: 0.8425\n",
      "Batch 10303: setting learning rate to 0.0001986143647624784.\n",
      "3183/3560 [=========================>....] - ETA: 46s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10304: setting learning rate to 0.00019861377328746639.\n",
      "3184/3560 [=========================>....] - ETA: 46s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10305: setting learning rate to 0.00019861318168712332.\n",
      "3185/3560 [=========================>....] - ETA: 46s - loss: 0.5604 - accuracy: 0.8425\n",
      "Batch 10306: setting learning rate to 0.00019861258996144995.\n",
      "3186/3560 [=========================>....] - ETA: 46s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10307: setting learning rate to 0.00019861199811044698.\n",
      "\n",
      "Batch 10308: setting learning rate to 0.0001986114061341152.\n",
      "3188/3560 [=========================>....] - ETA: 46s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10309: setting learning rate to 0.00019861081403245532.\n",
      "3189/3560 [=========================>....] - ETA: 46s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10310: setting learning rate to 0.00019861022180546817.\n",
      "3190/3560 [=========================>....] - ETA: 46s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10311: setting learning rate to 0.00019860962945315443.\n",
      "3191/3560 [=========================>....] - ETA: 45s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10312: setting learning rate to 0.00019860903697551486.\n",
      "3192/3560 [=========================>....] - ETA: 45s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10313: setting learning rate to 0.00019860844437255025.\n",
      "3193/3560 [=========================>....] - ETA: 45s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10314: setting learning rate to 0.00019860785164426136.\n",
      "3194/3560 [=========================>....] - ETA: 45s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10315: setting learning rate to 0.0001986072587906489.\n",
      "3195/3560 [=========================>....] - ETA: 45s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10316: setting learning rate to 0.00019860666581171364.\n",
      "3196/3560 [=========================>....] - ETA: 45s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10317: setting learning rate to 0.00019860607270745634.\n",
      "3197/3560 [=========================>....] - ETA: 45s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10318: setting learning rate to 0.00019860547947787773.\n",
      "3198/3560 [=========================>....] - ETA: 44s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10319: setting learning rate to 0.0001986048861229786.\n",
      "3199/3560 [=========================>....] - ETA: 44s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10320: setting learning rate to 0.00019860429264275967.\n",
      "3200/3560 [=========================>....] - ETA: 44s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10321: setting learning rate to 0.0001986036990372217.\n",
      "3201/3560 [=========================>....] - ETA: 44s - loss: 0.5606 - accuracy: 0.8426\n",
      "Batch 10322: setting learning rate to 0.0001986031053063655.\n",
      "3202/3560 [=========================>....] - ETA: 44s - loss: 0.5606 - accuracy: 0.8426\n",
      "Batch 10323: setting learning rate to 0.00019860251145019175.\n",
      "3203/3560 [=========================>....] - ETA: 44s - loss: 0.5606 - accuracy: 0.8426\n",
      "Batch 10324: setting learning rate to 0.00019860191746870126.\n",
      "3204/3560 [==========================>...] - ETA: 44s - loss: 0.5606 - accuracy: 0.8426\n",
      "Batch 10325: setting learning rate to 0.00019860132336189473.\n",
      "\n",
      "Batch 10326: setting learning rate to 0.00019860072912977297.\n",
      "3206/3560 [==========================>...] - ETA: 43s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10327: setting learning rate to 0.0001986001347723367.\n",
      "\n",
      "Batch 10328: setting learning rate to 0.00019859954028958668.\n",
      "3208/3560 [==========================>...] - ETA: 43s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10329: setting learning rate to 0.00019859894568152367.\n",
      "3209/3560 [==========================>...] - ETA: 43s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10330: setting learning rate to 0.00019859835094814844.\n",
      "3210/3560 [==========================>...] - ETA: 43s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10331: setting learning rate to 0.00019859775608946172.\n",
      "3211/3560 [==========================>...] - ETA: 43s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10332: setting learning rate to 0.00019859716110546432.\n",
      "3212/3560 [==========================>...] - ETA: 43s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10333: setting learning rate to 0.0001985965659961569.\n",
      "3213/3560 [==========================>...] - ETA: 43s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10334: setting learning rate to 0.00019859597076154028.\n",
      "3214/3560 [==========================>...] - ETA: 43s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10335: setting learning rate to 0.0001985953754016152.\n",
      "3215/3560 [==========================>...] - ETA: 42s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10336: setting learning rate to 0.00019859477991638247.\n",
      "3216/3560 [==========================>...] - ETA: 42s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10337: setting learning rate to 0.00019859418430584277.\n",
      "3217/3560 [==========================>...] - ETA: 42s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10338: setting learning rate to 0.0001985935885699969.\n",
      "3218/3560 [==========================>...] - ETA: 42s - loss: 0.5607 - accuracy: 0.8425\n",
      "Batch 10339: setting learning rate to 0.00019859299270884559.\n",
      "3219/3560 [==========================>...] - ETA: 42s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10340: setting learning rate to 0.00019859239672238963.\n",
      "\n",
      "Batch 10341: setting learning rate to 0.00019859180061062976.\n",
      "3221/3560 [==========================>...] - ETA: 42s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10342: setting learning rate to 0.0001985912043735667.\n",
      "3222/3560 [==========================>...] - ETA: 42s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10343: setting learning rate to 0.00019859060801120132.\n",
      "3223/3560 [==========================>...] - ETA: 41s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10344: setting learning rate to 0.00019859001152353422.\n",
      "3224/3560 [==========================>...] - ETA: 41s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10345: setting learning rate to 0.00019858941491056632.\n",
      "3225/3560 [==========================>...] - ETA: 41s - loss: 0.5610 - accuracy: 0.8425\n",
      "Batch 10346: setting learning rate to 0.00019858881817229823.\n",
      "3226/3560 [==========================>...] - ETA: 41s - loss: 0.5610 - accuracy: 0.8425\n",
      "Batch 10347: setting learning rate to 0.0001985882213087308.\n",
      "3227/3560 [==========================>...] - ETA: 41s - loss: 0.5610 - accuracy: 0.8425\n",
      "Batch 10348: setting learning rate to 0.00019858762431986478.\n",
      "3228/3560 [==========================>...] - ETA: 41s - loss: 0.5610 - accuracy: 0.8425\n",
      "Batch 10349: setting learning rate to 0.00019858702720570092.\n",
      "3229/3560 [==========================>...] - ETA: 41s - loss: 0.5610 - accuracy: 0.8425\n",
      "Batch 10350: setting learning rate to 0.00019858642996623997.\n",
      "3230/3560 [==========================>...] - ETA: 41s - loss: 0.5609 - accuracy: 0.8425\n",
      "Batch 10351: setting learning rate to 0.00019858583260148267.\n",
      "\n",
      "Batch 10352: setting learning rate to 0.00019858523511142982.\n",
      "3232/3560 [==========================>...] - ETA: 40s - loss: 0.5608 - accuracy: 0.8425\n",
      "Batch 10353: setting learning rate to 0.00019858463749608215.\n",
      "3233/3560 [==========================>...] - ETA: 40s - loss: 0.5608 - accuracy: 0.8426\n",
      "Batch 10354: setting learning rate to 0.00019858403975544047.\n",
      "3234/3560 [==========================>...] - ETA: 40s - loss: 0.5607 - accuracy: 0.8425\n",
      "Batch 10355: setting learning rate to 0.0001985834418895055.\n",
      "3235/3560 [==========================>...] - ETA: 40s - loss: 0.5607 - accuracy: 0.8426\n",
      "Batch 10356: setting learning rate to 0.00019858284389827794.\n",
      "\n",
      "Batch 10357: setting learning rate to 0.00019858224578175865.\n",
      "3237/3560 [==========================>...] - ETA: 40s - loss: 0.5606 - accuracy: 0.8426\n",
      "Batch 10358: setting learning rate to 0.00019858164753994837.\n",
      "3238/3560 [==========================>...] - ETA: 40s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10359: setting learning rate to 0.00019858104917284782.\n",
      "\n",
      "Batch 10360: setting learning rate to 0.00019858045068045776.\n",
      "3240/3560 [==========================>...] - ETA: 39s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10361: setting learning rate to 0.000198579852062779.\n",
      "3241/3560 [==========================>...] - ETA: 39s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10362: setting learning rate to 0.00019857925331981225.\n",
      "\n",
      "Batch 10363: setting learning rate to 0.00019857865445155833.\n",
      "3243/3560 [==========================>...] - ETA: 39s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10364: setting learning rate to 0.00019857805545801796.\n",
      "3244/3560 [==========================>...] - ETA: 39s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10365: setting learning rate to 0.0001985774563391919.\n",
      "3245/3560 [==========================>...] - ETA: 39s - loss: 0.5605 - accuracy: 0.8427\n",
      "Batch 10366: setting learning rate to 0.00019857685709508092.\n",
      "3246/3560 [==========================>...] - ETA: 39s - loss: 0.5605 - accuracy: 0.8427\n",
      "Batch 10367: setting learning rate to 0.00019857625772568577.\n",
      "3247/3560 [==========================>...] - ETA: 38s - loss: 0.5605 - accuracy: 0.8427\n",
      "Batch 10368: setting learning rate to 0.0001985756582310072.\n",
      "3248/3560 [==========================>...] - ETA: 38s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10369: setting learning rate to 0.00019857505861104605.\n",
      "3249/3560 [==========================>...] - ETA: 38s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10370: setting learning rate to 0.000198574458865803.\n",
      "3250/3560 [==========================>...] - ETA: 38s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10371: setting learning rate to 0.0001985738589952788.\n",
      "3251/3560 [==========================>...] - ETA: 38s - loss: 0.5605 - accuracy: 0.8427\n",
      "Batch 10372: setting learning rate to 0.0001985732589994743.\n",
      "3252/3560 [==========================>...] - ETA: 38s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10373: setting learning rate to 0.00019857265887839018.\n",
      "3253/3560 [==========================>...] - ETA: 38s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10374: setting learning rate to 0.00019857205863202726.\n",
      "3254/3560 [==========================>...] - ETA: 38s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10375: setting learning rate to 0.00019857145826038627.\n",
      "\n",
      "Batch 10376: setting learning rate to 0.000198570857763468.\n",
      "3256/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10377: setting learning rate to 0.00019857025714127316.\n",
      "3257/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10378: setting learning rate to 0.00019856965639380257.\n",
      "3258/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10379: setting learning rate to 0.00019856905552105697.\n",
      "3259/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10380: setting learning rate to 0.00019856845452303711.\n",
      "\n",
      "Batch 10381: setting learning rate to 0.0001985678533997438.\n",
      "3261/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10382: setting learning rate to 0.00019856725215117776.\n",
      "3262/3560 [==========================>...] - ETA: 37s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10383: setting learning rate to 0.00019856665077733974.\n",
      "3263/3560 [==========================>...] - ETA: 36s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10384: setting learning rate to 0.00019856604927823054.\n",
      "3264/3560 [==========================>...] - ETA: 36s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10385: setting learning rate to 0.00019856544765385094.\n",
      "3265/3560 [==========================>...] - ETA: 36s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10386: setting learning rate to 0.00019856484590420167.\n",
      "3266/3560 [==========================>...] - ETA: 36s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10387: setting learning rate to 0.00019856424402928352.\n",
      "3267/3560 [==========================>...] - ETA: 36s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10388: setting learning rate to 0.00019856364202909722.\n",
      "\n",
      "Batch 10389: setting learning rate to 0.00019856303990364356.\n",
      "3269/3560 [==========================>...] - ETA: 36s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10390: setting learning rate to 0.0001985624376529233.\n",
      "3270/3560 [==========================>...] - ETA: 36s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10391: setting learning rate to 0.0001985618352769372.\n",
      "3271/3560 [==========================>...] - ETA: 35s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10392: setting learning rate to 0.00019856123277568603.\n",
      "3272/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10393: setting learning rate to 0.00019856063014917058.\n",
      "3273/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10394: setting learning rate to 0.00019856002739739156.\n",
      "3274/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10395: setting learning rate to 0.0001985594245203498.\n",
      "3275/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10396: setting learning rate to 0.00019855882151804602.\n",
      "3276/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10397: setting learning rate to 0.000198558218390481.\n",
      "3277/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10398: setting learning rate to 0.0001985576151376555.\n",
      "3278/3560 [==========================>...] - ETA: 35s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10399: setting learning rate to 0.00019855701175957032.\n",
      "3279/3560 [==========================>...] - ETA: 34s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10400: setting learning rate to 0.00019855640825622618.\n",
      "3280/3560 [==========================>...] - ETA: 34s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10401: setting learning rate to 0.0001985558046276239.\n",
      "3281/3560 [==========================>...] - ETA: 34s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10402: setting learning rate to 0.00019855520087376418.\n",
      "3282/3560 [==========================>...] - ETA: 34s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10403: setting learning rate to 0.00019855459699464785.\n",
      "\n",
      "Batch 10404: setting learning rate to 0.00019855399299027564.\n",
      "3284/3560 [==========================>...] - ETA: 34s - loss: 0.5604 - accuracy: 0.8425\n",
      "Batch 10405: setting learning rate to 0.00019855338886064832.\n",
      "3285/3560 [==========================>...] - ETA: 34s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10406: setting learning rate to 0.00019855278460576667.\n",
      "3286/3560 [==========================>...] - ETA: 34s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10407: setting learning rate to 0.00019855218022563146.\n",
      "3287/3560 [==========================>...] - ETA: 33s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10408: setting learning rate to 0.00019855157572024344.\n",
      "3288/3560 [==========================>...] - ETA: 33s - loss: 0.5602 - accuracy: 0.8427\n",
      "Batch 10409: setting learning rate to 0.0001985509710896034.\n",
      "3289/3560 [==========================>...] - ETA: 33s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10410: setting learning rate to 0.00019855036633371212.\n",
      "3290/3560 [==========================>...] - ETA: 33s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10411: setting learning rate to 0.00019854976145257033.\n",
      "\n",
      "Batch 10412: setting learning rate to 0.0001985491564461788.\n",
      "3292/3560 [==========================>...] - ETA: 33s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10413: setting learning rate to 0.00019854855131453834.\n",
      "3293/3560 [==========================>...] - ETA: 33s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10414: setting learning rate to 0.00019854794605764968.\n",
      "3294/3560 [==========================>...] - ETA: 33s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10415: setting learning rate to 0.0001985473406755136.\n",
      "3295/3560 [==========================>...] - ETA: 32s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10416: setting learning rate to 0.0001985467351681309.\n",
      "3296/3560 [==========================>...] - ETA: 32s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10417: setting learning rate to 0.0001985461295355023.\n",
      "3297/3560 [==========================>...] - ETA: 32s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10418: setting learning rate to 0.00019854552377762861.\n",
      "3298/3560 [==========================>...] - ETA: 32s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10419: setting learning rate to 0.00019854491789451055.\n",
      "3299/3560 [==========================>...] - ETA: 32s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10420: setting learning rate to 0.00019854431188614895.\n",
      "\n",
      "Batch 10421: setting learning rate to 0.00019854370575254454.\n",
      "3301/3560 [==========================>...] - ETA: 32s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10422: setting learning rate to 0.0001985430994936981.\n",
      "3302/3560 [==========================>...] - ETA: 32s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10423: setting learning rate to 0.00019854249310961045.\n",
      "3303/3560 [==========================>...] - ETA: 31s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10424: setting learning rate to 0.00019854188660028225.\n",
      "\n",
      "Batch 10425: setting learning rate to 0.00019854127996571437.\n",
      "3305/3560 [==========================>...] - ETA: 31s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10426: setting learning rate to 0.00019854067320590756.\n",
      "3306/3560 [==========================>...] - ETA: 31s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10427: setting learning rate to 0.00019854006632086252.\n",
      "3307/3560 [==========================>...] - ETA: 31s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10428: setting learning rate to 0.00019853945931058012.\n",
      "3308/3560 [==========================>...] - ETA: 31s - loss: 0.5599 - accuracy: 0.8428\n",
      "Batch 10429: setting learning rate to 0.00019853885217506107.\n",
      "3309/3560 [==========================>...] - ETA: 31s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10430: setting learning rate to 0.0001985382449143062.\n",
      "\n",
      "Batch 10431: setting learning rate to 0.0001985376375283162.\n",
      "3311/3560 [==========================>...] - ETA: 30s - loss: 0.5599 - accuracy: 0.8428\n",
      "Batch 10432: setting learning rate to 0.0001985370300170919.\n",
      "\n",
      "Batch 10433: setting learning rate to 0.00019853642238063405.\n",
      "3313/3560 [==========================>...] - ETA: 30s - loss: 0.5599 - accuracy: 0.8428\n",
      "Batch 10434: setting learning rate to 0.00019853581461894344.\n",
      "3314/3560 [==========================>...] - ETA: 30s - loss: 0.5599 - accuracy: 0.8428\n",
      "Batch 10435: setting learning rate to 0.00019853520673202083.\n",
      "3315/3560 [==========================>...] - ETA: 30s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10436: setting learning rate to 0.000198534598719867.\n",
      "3316/3560 [==========================>...] - ETA: 30s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10437: setting learning rate to 0.0001985339905824827.\n",
      "3317/3560 [==========================>...] - ETA: 30s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10438: setting learning rate to 0.00019853338231986872.\n",
      "3318/3560 [==========================>...] - ETA: 30s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10439: setting learning rate to 0.00019853277393202588.\n",
      "\n",
      "Batch 10440: setting learning rate to 0.00019853216541895486.\n",
      "3320/3560 [==========================>...] - ETA: 29s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10441: setting learning rate to 0.0001985315567806565.\n",
      "3321/3560 [==========================>...] - ETA: 29s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10442: setting learning rate to 0.00019853094801713152.\n",
      "3322/3560 [==========================>...] - ETA: 29s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10443: setting learning rate to 0.00019853033912838077.\n",
      "\n",
      "Batch 10444: setting learning rate to 0.00019852973011440497.\n",
      "3324/3560 [===========================>..] - ETA: 29s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10445: setting learning rate to 0.0001985291209752049.\n",
      "3325/3560 [===========================>..] - ETA: 29s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10446: setting learning rate to 0.00019852851171078134.\n",
      "3326/3560 [===========================>..] - ETA: 29s - loss: 0.5600 - accuracy: 0.8427\n",
      "Batch 10447: setting learning rate to 0.00019852790232113504.\n",
      "3327/3560 [===========================>..] - ETA: 28s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10448: setting learning rate to 0.00019852729280626683.\n",
      "3328/3560 [===========================>..] - ETA: 28s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10449: setting learning rate to 0.00019852668316617744.\n",
      "\n",
      "Batch 10450: setting learning rate to 0.00019852607340086766.\n",
      "3330/3560 [===========================>..] - ETA: 28s - loss: 0.5602 - accuracy: 0.8427\n",
      "Batch 10451: setting learning rate to 0.00019852546351033828.\n",
      "\n",
      "Batch 10452: setting learning rate to 0.00019852485349459002.\n",
      "3332/3560 [===========================>..] - ETA: 28s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10453: setting learning rate to 0.0001985242433536237.\n",
      "3333/3560 [===========================>..] - ETA: 28s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10454: setting learning rate to 0.00019852363308744012.\n",
      "3334/3560 [===========================>..] - ETA: 28s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10455: setting learning rate to 0.00019852302269604.\n",
      "\n",
      "Batch 10456: setting learning rate to 0.00019852241217942416.\n",
      "3336/3560 [===========================>..] - ETA: 27s - loss: 0.5600 - accuracy: 0.8426\n",
      "Batch 10457: setting learning rate to 0.00019852180153759333.\n",
      "3337/3560 [===========================>..] - ETA: 27s - loss: 0.5600 - accuracy: 0.8426\n",
      "Batch 10458: setting learning rate to 0.0001985211907705483.\n",
      "3338/3560 [===========================>..] - ETA: 27s - loss: 0.5600 - accuracy: 0.8426\n",
      "Batch 10459: setting learning rate to 0.00019852057987828988.\n",
      "\n",
      "Batch 10460: setting learning rate to 0.00019851996886081883.\n",
      "3340/3560 [===========================>..] - ETA: 27s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10461: setting learning rate to 0.0001985193577181359.\n",
      "3341/3560 [===========================>..] - ETA: 27s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10462: setting learning rate to 0.0001985187464502419.\n",
      "3342/3560 [===========================>..] - ETA: 27s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10463: setting learning rate to 0.0001985181350571376.\n",
      "3343/3560 [===========================>..] - ETA: 27s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10464: setting learning rate to 0.00019851752353882378.\n",
      "3344/3560 [===========================>..] - ETA: 26s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10465: setting learning rate to 0.0001985169118953012.\n",
      "3345/3560 [===========================>..] - ETA: 26s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10466: setting learning rate to 0.00019851630012657063.\n",
      "3346/3560 [===========================>..] - ETA: 26s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10467: setting learning rate to 0.00019851568823263288.\n",
      "3347/3560 [===========================>..] - ETA: 26s - loss: 0.5601 - accuracy: 0.8427\n",
      "Batch 10468: setting learning rate to 0.0001985150762134887.\n",
      "\n",
      "Batch 10469: setting learning rate to 0.0001985144640691389.\n",
      "3349/3560 [===========================>..] - ETA: 26s - loss: 0.5602 - accuracy: 0.8427\n",
      "Batch 10470: setting learning rate to 0.00019851385179958422.\n",
      "3350/3560 [===========================>..] - ETA: 26s - loss: 0.5602 - accuracy: 0.8427\n",
      "Batch 10471: setting learning rate to 0.00019851323940482543.\n",
      "3351/3560 [===========================>..] - ETA: 25s - loss: 0.5602 - accuracy: 0.8427\n",
      "Batch 10472: setting learning rate to 0.00019851262688486338.\n",
      "\n",
      "Batch 10473: setting learning rate to 0.00019851201423969878.\n",
      "3353/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8427\n",
      "Batch 10474: setting learning rate to 0.00019851140146933243.\n",
      "3354/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8427\n",
      "Batch 10475: setting learning rate to 0.0001985107885737651.\n",
      "\n",
      "Batch 10476: setting learning rate to 0.00019851017555299762.\n",
      "3356/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10477: setting learning rate to 0.0001985095624070307.\n",
      "3357/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10478: setting learning rate to 0.00019850894913586516.\n",
      "3358/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10479: setting learning rate to 0.00019850833573950173.\n",
      "3359/3560 [===========================>..] - ETA: 25s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10480: setting learning rate to 0.00019850772221794122.\n",
      "3360/3560 [===========================>..] - ETA: 24s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10481: setting learning rate to 0.00019850710857118446.\n",
      "3361/3560 [===========================>..] - ETA: 24s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10482: setting learning rate to 0.00019850649479923217.\n",
      "\n",
      "Batch 10483: setting learning rate to 0.00019850588090208516.\n",
      "3363/3560 [===========================>..] - ETA: 24s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10484: setting learning rate to 0.00019850526687974416.\n",
      "3364/3560 [===========================>..] - ETA: 24s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10485: setting learning rate to 0.00019850465273221.\n",
      "3365/3560 [===========================>..] - ETA: 24s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10486: setting learning rate to 0.00019850403845948346.\n",
      "3366/3560 [===========================>..] - ETA: 24s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10487: setting learning rate to 0.0001985034240615653.\n",
      "3367/3560 [===========================>..] - ETA: 24s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10488: setting learning rate to 0.0001985028095384563.\n",
      "3368/3560 [===========================>..] - ETA: 23s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10489: setting learning rate to 0.00019850219489015727.\n",
      "3369/3560 [===========================>..] - ETA: 23s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10490: setting learning rate to 0.00019850158011666894.\n",
      "\n",
      "Batch 10491: setting learning rate to 0.00019850096521799215.\n",
      "3371/3560 [===========================>..] - ETA: 23s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10492: setting learning rate to 0.00019850035019412766.\n",
      "3372/3560 [===========================>..] - ETA: 23s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10493: setting learning rate to 0.00019849973504507622.\n",
      "3373/3560 [===========================>..] - ETA: 23s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10494: setting learning rate to 0.0001984991197708386.\n",
      "\n",
      "Batch 10495: setting learning rate to 0.0001984985043714157.\n",
      "3375/3560 [===========================>..] - ETA: 23s - loss: 0.5604 - accuracy: 0.8426\n",
      "Batch 10496: setting learning rate to 0.00019849788884680817.\n",
      "3376/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10497: setting learning rate to 0.00019849727319701686.\n",
      "3377/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10498: setting learning rate to 0.0001984966574220425.\n",
      "3378/3560 [===========================>..] - ETA: 22s - loss: 0.5604 - accuracy: 0.8427\n",
      "Batch 10499: setting learning rate to 0.00019849604152188594.\n",
      "3379/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8427\n",
      "Batch 10500: setting learning rate to 0.00019849542549654796.\n",
      "3380/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10501: setting learning rate to 0.00019849480934602926.\n",
      "3381/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10502: setting learning rate to 0.0001984941930703307.\n",
      "3382/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10503: setting learning rate to 0.00019849357666945302.\n",
      "3383/3560 [===========================>..] - ETA: 22s - loss: 0.5605 - accuracy: 0.8426\n",
      "Batch 10504: setting learning rate to 0.00019849296014339706.\n",
      "3384/3560 [===========================>..] - ETA: 21s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10505: setting learning rate to 0.00019849234349216354.\n",
      "3385/3560 [===========================>..] - ETA: 21s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10506: setting learning rate to 0.0001984917267157533.\n",
      "3386/3560 [===========================>..] - ETA: 21s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10507: setting learning rate to 0.00019849110981416709.\n",
      "3387/3560 [===========================>..] - ETA: 21s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10508: setting learning rate to 0.00019849049278740567.\n",
      "\n",
      "Batch 10509: setting learning rate to 0.00019848987563546986.\n",
      "3389/3560 [===========================>..] - ETA: 21s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10510: setting learning rate to 0.00019848925835836047.\n",
      "3390/3560 [===========================>..] - ETA: 21s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10511: setting learning rate to 0.0001984886409560782.\n",
      "\n",
      "Batch 10512: setting learning rate to 0.0001984880234286239.\n",
      "3392/3560 [===========================>..] - ETA: 20s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10513: setting learning rate to 0.00019848740577599835.\n",
      "3393/3560 [===========================>..] - ETA: 20s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10514: setting learning rate to 0.00019848678799820233.\n",
      "3394/3560 [===========================>..] - ETA: 20s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10515: setting learning rate to 0.0001984861700952366.\n",
      "3395/3560 [===========================>..] - ETA: 20s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10516: setting learning rate to 0.00019848555206710203.\n",
      "3396/3560 [===========================>..] - ETA: 20s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10517: setting learning rate to 0.0001984849339137993.\n",
      "3397/3560 [===========================>..] - ETA: 20s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10518: setting learning rate to 0.00019848431563532923.\n",
      "3398/3560 [===========================>..] - ETA: 20s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10519: setting learning rate to 0.00019848369723169263.\n",
      "3399/3560 [===========================>..] - ETA: 20s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10520: setting learning rate to 0.00019848307870289024.\n",
      "3400/3560 [===========================>..] - ETA: 19s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10521: setting learning rate to 0.00019848246004892288.\n",
      "3401/3560 [===========================>..] - ETA: 19s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10522: setting learning rate to 0.00019848184126979135.\n",
      "3402/3560 [===========================>..] - ETA: 19s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10523: setting learning rate to 0.00019848122236549643.\n",
      "3403/3560 [===========================>..] - ETA: 19s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10524: setting learning rate to 0.00019848060333603885.\n",
      "\n",
      "Batch 10525: setting learning rate to 0.0001984799841814195.\n",
      "3405/3560 [===========================>..] - ETA: 19s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10526: setting learning rate to 0.00019847936490163906.\n",
      "3406/3560 [===========================>..] - ETA: 19s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10527: setting learning rate to 0.0001984787454966984.\n",
      "\n",
      "Batch 10528: setting learning rate to 0.00019847812596659824.\n",
      "3408/3560 [===========================>..] - ETA: 18s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10529: setting learning rate to 0.00019847750631133944.\n",
      "3409/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10530: setting learning rate to 0.00019847688653092273.\n",
      "3410/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10531: setting learning rate to 0.00019847626662534892.\n",
      "3411/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10532: setting learning rate to 0.00019847564659461876.\n",
      "3412/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10533: setting learning rate to 0.0001984750264387331.\n",
      "3413/3560 [===========================>..] - ETA: 18s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10534: setting learning rate to 0.00019847440615769268.\n",
      "3414/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10535: setting learning rate to 0.00019847378575149835.\n",
      "3415/3560 [===========================>..] - ETA: 18s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10536: setting learning rate to 0.0001984731652201508.\n",
      "3416/3560 [===========================>..] - ETA: 17s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10537: setting learning rate to 0.00019847254456365092.\n",
      "3417/3560 [===========================>..] - ETA: 17s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10538: setting learning rate to 0.00019847192378199944.\n",
      "3418/3560 [===========================>..] - ETA: 17s - loss: 0.5609 - accuracy: 0.8424\n",
      "Batch 10539: setting learning rate to 0.00019847130287519718.\n",
      "3419/3560 [===========================>..] - ETA: 17s - loss: 0.5608 - accuracy: 0.8424\n",
      "Batch 10540: setting learning rate to 0.00019847068184324486.\n",
      "3420/3560 [===========================>..] - ETA: 17s - loss: 0.5609 - accuracy: 0.8423\n",
      "Batch 10541: setting learning rate to 0.00019847006068614338.\n",
      "3421/3560 [===========================>..] - ETA: 17s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10542: setting learning rate to 0.00019846943940389342.\n",
      "3422/3560 [===========================>..] - ETA: 17s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10543: setting learning rate to 0.00019846881799649585.\n",
      "3423/3560 [===========================>..] - ETA: 17s - loss: 0.5608 - accuracy: 0.8423\n",
      "Batch 10544: setting learning rate to 0.00019846819646395143.\n",
      "3424/3560 [===========================>..] - ETA: 16s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10545: setting learning rate to 0.00019846757480626093.\n",
      "3425/3560 [===========================>..] - ETA: 16s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10546: setting learning rate to 0.00019846695302342518.\n",
      "3426/3560 [===========================>..] - ETA: 16s - loss: 0.5607 - accuracy: 0.8424\n",
      "Batch 10547: setting learning rate to 0.00019846633111544494.\n",
      "\n",
      "Batch 10548: setting learning rate to 0.00019846570908232104.\n",
      "3428/3560 [===========================>..] - ETA: 16s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10549: setting learning rate to 0.0001984650869240542.\n",
      "3429/3560 [===========================>..] - ETA: 16s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10550: setting learning rate to 0.00019846446464064527.\n",
      "3430/3560 [===========================>..] - ETA: 16s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10551: setting learning rate to 0.00019846384223209503.\n",
      "3431/3560 [===========================>..] - ETA: 16s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10552: setting learning rate to 0.00019846321969840426.\n",
      "\n",
      "Batch 10553: setting learning rate to 0.00019846259703957376.\n",
      "3433/3560 [===========================>..] - ETA: 15s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10554: setting learning rate to 0.0001984619742556043.\n",
      "3434/3560 [===========================>..] - ETA: 15s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10555: setting learning rate to 0.00019846135134649667.\n",
      "\n",
      "Batch 10556: setting learning rate to 0.0001984607283122517.\n",
      "3436/3560 [===========================>..] - ETA: 15s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10557: setting learning rate to 0.00019846010515287016.\n",
      "3437/3560 [===========================>..] - ETA: 15s - loss: 0.5606 - accuracy: 0.8425\n",
      "Batch 10558: setting learning rate to 0.00019845948186835287.\n",
      "3438/3560 [===========================>..] - ETA: 15s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10559: setting learning rate to 0.00019845885845870055.\n",
      "\n",
      "Batch 10560: setting learning rate to 0.00019845823492391408.\n",
      "3440/3560 [===========================>..] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10561: setting learning rate to 0.00019845761126399417.\n",
      "3441/3560 [===========================>..] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10562: setting learning rate to 0.00019845698747894167.\n",
      "3442/3560 [============================>.] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10563: setting learning rate to 0.0001984563635687574.\n",
      "3443/3560 [============================>.] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10564: setting learning rate to 0.00019845573953344205.\n",
      "3444/3560 [============================>.] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10565: setting learning rate to 0.00019845511537299647.\n",
      "3445/3560 [============================>.] - ETA: 14s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10566: setting learning rate to 0.0001984544910874215.\n",
      "3446/3560 [============================>.] - ETA: 14s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10567: setting learning rate to 0.00019845386667671785.\n",
      "3447/3560 [============================>.] - ETA: 14s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10568: setting learning rate to 0.00019845324214088635.\n",
      "3448/3560 [============================>.] - ETA: 13s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10569: setting learning rate to 0.00019845261747992782.\n",
      "3449/3560 [============================>.] - ETA: 13s - loss: 0.5606 - accuracy: 0.8424\n",
      "Batch 10570: setting learning rate to 0.00019845199269384302.\n",
      "3450/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10571: setting learning rate to 0.00019845136778263276.\n",
      "3451/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10572: setting learning rate to 0.00019845074274629781.\n",
      "3452/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10573: setting learning rate to 0.000198450117584839.\n",
      "3453/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8424\n",
      "Batch 10574: setting learning rate to 0.0001984494922982571.\n",
      "3454/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10575: setting learning rate to 0.0001984488668865529.\n",
      "3455/3560 [============================>.] - ETA: 13s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10576: setting learning rate to 0.00019844824134972723.\n",
      "\n",
      "Batch 10577: setting learning rate to 0.00019844761568778085.\n",
      "3457/3560 [============================>.] - ETA: 12s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10578: setting learning rate to 0.00019844698990071458.\n",
      "3458/3560 [============================>.] - ETA: 12s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10579: setting learning rate to 0.0001984463639885292.\n",
      "3459/3560 [============================>.] - ETA: 12s - loss: 0.5604 - accuracy: 0.8425\n",
      "Batch 10580: setting learning rate to 0.0001984457379512255.\n",
      "\n",
      "Batch 10581: setting learning rate to 0.00019844511178880426.\n",
      "3461/3560 [============================>.] - ETA: 12s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10582: setting learning rate to 0.00019844448550126632.\n",
      "3462/3560 [============================>.] - ETA: 12s - loss: 0.5605 - accuracy: 0.8425\n",
      "Batch 10583: setting learning rate to 0.00019844385908861245.\n",
      "3463/3560 [============================>.] - ETA: 12s - loss: 0.5604 - accuracy: 0.8425\n",
      "Batch 10584: setting learning rate to 0.00019844323255084346.\n",
      "3464/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8425\n",
      "Batch 10585: setting learning rate to 0.00019844260588796012.\n",
      "3465/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10586: setting learning rate to 0.00019844197909996326.\n",
      "\n",
      "Batch 10587: setting learning rate to 0.00019844135218685365.\n",
      "3467/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10588: setting learning rate to 0.00019844072514863212.\n",
      "\n",
      "Batch 10589: setting learning rate to 0.0001984400979852994.\n",
      "3469/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10590: setting learning rate to 0.00019843947069685637.\n",
      "3470/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10591: setting learning rate to 0.00019843884328330378.\n",
      "3471/3560 [============================>.] - ETA: 11s - loss: 0.5603 - accuracy: 0.8426\n",
      "Batch 10592: setting learning rate to 0.00019843821574464242.\n",
      "3472/3560 [============================>.] - ETA: 10s - loss: 0.5602 - accuracy: 0.8426\n",
      "Batch 10593: setting learning rate to 0.00019843758808087313.\n",
      "3473/3560 [============================>.] - ETA: 10s - loss: 0.5601 - accuracy: 0.8426\n",
      "Batch 10594: setting learning rate to 0.00019843696029199666.\n",
      "\n",
      "Batch 10595: setting learning rate to 0.00019843633237801383.\n",
      "3475/3560 [============================>.] - ETA: 10s - loss: 0.5600 - accuracy: 0.8426\n",
      "Batch 10596: setting learning rate to 0.00019843570433892543.\n",
      "3476/3560 [============================>.] - ETA: 10s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10597: setting learning rate to 0.00019843507617473227.\n",
      "3477/3560 [============================>.] - ETA: 10s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10598: setting learning rate to 0.00019843444788543514.\n",
      "3478/3560 [============================>.] - ETA: 10s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10599: setting learning rate to 0.00019843381947103487.\n",
      "\n",
      "Batch 10600: setting learning rate to 0.00019843319093153222.\n",
      "3480/3560 [============================>.] - ETA: 9s - loss: 0.5598 - accuracy: 0.8427 \n",
      "Batch 10601: setting learning rate to 0.000198432562266928.\n",
      "3481/3560 [============================>.] - ETA: 9s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10602: setting learning rate to 0.00019843193347722298.\n",
      "3482/3560 [============================>.] - ETA: 9s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10603: setting learning rate to 0.000198431304562418.\n",
      "3483/3560 [============================>.] - ETA: 9s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10604: setting learning rate to 0.00019843067552251386.\n",
      "\n",
      "Batch 10605: setting learning rate to 0.00019843004635751134.\n",
      "3485/3560 [============================>.] - ETA: 9s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10606: setting learning rate to 0.00019842941706741125.\n",
      "3486/3560 [============================>.] - ETA: 9s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10607: setting learning rate to 0.00019842878765221437.\n",
      "\n",
      "Batch 10608: setting learning rate to 0.00019842815811192154.\n",
      "3488/3560 [============================>.] - ETA: 8s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10609: setting learning rate to 0.0001984275284465335.\n",
      "3489/3560 [============================>.] - ETA: 8s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10610: setting learning rate to 0.00019842689865605113.\n",
      "\n",
      "Batch 10611: setting learning rate to 0.00019842626874047516.\n",
      "3491/3560 [============================>.] - ETA: 8s - loss: 0.5596 - accuracy: 0.8428\n",
      "Batch 10612: setting learning rate to 0.0001984256386998064.\n",
      "3492/3560 [============================>.] - ETA: 8s - loss: 0.5596 - accuracy: 0.8428\n",
      "Batch 10613: setting learning rate to 0.00019842500853404574.\n",
      "3493/3560 [============================>.] - ETA: 8s - loss: 0.5596 - accuracy: 0.8428\n",
      "Batch 10614: setting learning rate to 0.00019842437824319382.\n",
      "\n",
      "Batch 10615: setting learning rate to 0.00019842374782725157.\n",
      "3495/3560 [============================>.] - ETA: 8s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10616: setting learning rate to 0.00019842311728621975.\n",
      "3496/3560 [============================>.] - ETA: 7s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10617: setting learning rate to 0.00019842248662009916.\n",
      "3497/3560 [============================>.] - ETA: 7s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10618: setting learning rate to 0.00019842185582889061.\n",
      "\n",
      "Batch 10619: setting learning rate to 0.0001984212249125949.\n",
      "3499/3560 [============================>.] - ETA: 7s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10620: setting learning rate to 0.0001984205938712128.\n",
      "3500/3560 [============================>.] - ETA: 7s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10621: setting learning rate to 0.00019841996270474516.\n",
      "\n",
      "Batch 10622: setting learning rate to 0.00019841933141319279.\n",
      "3502/3560 [============================>.] - ETA: 7s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10623: setting learning rate to 0.0001984186999965564.\n",
      "3503/3560 [============================>.] - ETA: 7s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10624: setting learning rate to 0.00019841806845483692.\n",
      "3504/3560 [============================>.] - ETA: 6s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10625: setting learning rate to 0.00019841743678803504.\n",
      "3505/3560 [============================>.] - ETA: 6s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10626: setting learning rate to 0.00019841680499615164.\n",
      "3506/3560 [============================>.] - ETA: 6s - loss: 0.5598 - accuracy: 0.8428\n",
      "Batch 10627: setting learning rate to 0.00019841617307918746.\n",
      "3507/3560 [============================>.] - ETA: 6s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10628: setting learning rate to 0.00019841554103714338.\n",
      "3508/3560 [============================>.] - ETA: 6s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10629: setting learning rate to 0.00019841490887002015.\n",
      "3509/3560 [============================>.] - ETA: 6s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10630: setting learning rate to 0.00019841427657781856.\n",
      "\n",
      "Batch 10631: setting learning rate to 0.00019841364416053946.\n",
      "3511/3560 [============================>.] - ETA: 6s - loss: 0.5599 - accuracy: 0.8426\n",
      "Batch 10632: setting learning rate to 0.00019841301161818361.\n",
      "3512/3560 [============================>.] - ETA: 5s - loss: 0.5599 - accuracy: 0.8426\n",
      "Batch 10633: setting learning rate to 0.00019841237895075188.\n",
      "3513/3560 [============================>.] - ETA: 5s - loss: 0.5599 - accuracy: 0.8426\n",
      "Batch 10634: setting learning rate to 0.000198411746158245.\n",
      "3514/3560 [============================>.] - ETA: 5s - loss: 0.5599 - accuracy: 0.8426\n",
      "Batch 10635: setting learning rate to 0.00019841111324066382.\n",
      "3515/3560 [============================>.] - ETA: 5s - loss: 0.5599 - accuracy: 0.8426\n",
      "Batch 10636: setting learning rate to 0.00019841048019800912.\n",
      "\n",
      "Batch 10637: setting learning rate to 0.0001984098470302817.\n",
      "3517/3560 [============================>.] - ETA: 5s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10638: setting learning rate to 0.0001984092137374824.\n",
      "3518/3560 [============================>.] - ETA: 5s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10639: setting learning rate to 0.000198408580319612.\n",
      "3519/3560 [============================>.] - ETA: 5s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10640: setting learning rate to 0.00019840794677667128.\n",
      "3520/3560 [============================>.] - ETA: 4s - loss: 0.5599 - accuracy: 0.8427\n",
      "Batch 10641: setting learning rate to 0.0001984073131086611.\n",
      "3521/3560 [============================>.] - ETA: 4s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10642: setting learning rate to 0.0001984066793155822.\n",
      "3522/3560 [============================>.] - ETA: 4s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10643: setting learning rate to 0.00019840604539743547.\n",
      "3523/3560 [============================>.] - ETA: 4s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10644: setting learning rate to 0.00019840541135422165.\n",
      "3524/3560 [============================>.] - ETA: 4s - loss: 0.5598 - accuracy: 0.8427\n",
      "Batch 10645: setting learning rate to 0.00019840477718594156.\n",
      "3525/3560 [============================>.] - ETA: 4s - loss: 0.5597 - accuracy: 0.8428\n",
      "Batch 10646: setting learning rate to 0.000198404142892596.\n",
      "3526/3560 [============================>.] - ETA: 4s - loss: 0.5597 - accuracy: 0.8427\n",
      "Batch 10647: setting learning rate to 0.00019840350847418582.\n",
      "3527/3560 [============================>.] - ETA: 4s - loss: 0.5596 - accuracy: 0.8428\n",
      "Batch 10648: setting learning rate to 0.00019840287393071176.\n",
      "3528/3560 [============================>.] - ETA: 3s - loss: 0.5596 - accuracy: 0.8427\n",
      "Batch 10649: setting learning rate to 0.00019840223926217472.\n",
      "3529/3560 [============================>.] - ETA: 3s - loss: 0.5595 - accuracy: 0.8428\n",
      "Batch 10650: setting learning rate to 0.00019840160446857539.\n",
      "3530/3560 [============================>.] - ETA: 3s - loss: 0.5595 - accuracy: 0.8428\n",
      "Batch 10651: setting learning rate to 0.00019840096954991466.\n",
      "\n",
      "Batch 10652: setting learning rate to 0.00019840033450619328.\n",
      "3532/3560 [============================>.] - ETA: 3s - loss: 0.5593 - accuracy: 0.8428\n",
      "Batch 10653: setting learning rate to 0.00019839969933741213.\n",
      "3533/3560 [============================>.] - ETA: 3s - loss: 0.5592 - accuracy: 0.8429\n",
      "Batch 10654: setting learning rate to 0.00019839906404357197.\n",
      "3534/3560 [============================>.] - ETA: 3s - loss: 0.5592 - accuracy: 0.8429\n",
      "Batch 10655: setting learning rate to 0.00019839842862467356.\n",
      "\n",
      "Batch 10656: setting learning rate to 0.0001983977930807178.\n",
      "3536/3560 [============================>.] - ETA: 2s - loss: 0.5592 - accuracy: 0.8429\n",
      "Batch 10657: setting learning rate to 0.00019839715741170545.\n",
      "3537/3560 [============================>.] - ETA: 2s - loss: 0.5592 - accuracy: 0.8429\n",
      "Batch 10658: setting learning rate to 0.00019839652161763734.\n",
      "3538/3560 [============================>.] - ETA: 2s - loss: 0.5591 - accuracy: 0.8429\n",
      "Batch 10659: setting learning rate to 0.00019839588569851423.\n",
      "3539/3560 [============================>.] - ETA: 2s - loss: 0.5591 - accuracy: 0.8429\n",
      "Batch 10660: setting learning rate to 0.000198395249654337.\n",
      "3540/3560 [============================>.] - ETA: 2s - loss: 0.5590 - accuracy: 0.8430\n",
      "Batch 10661: setting learning rate to 0.00019839461348510642.\n",
      "3541/3560 [============================>.] - ETA: 2s - loss: 0.5590 - accuracy: 0.8430\n",
      "Batch 10662: setting learning rate to 0.00019839397719082326.\n",
      "\n",
      "Batch 10663: setting learning rate to 0.0001983933407714884.\n",
      "3543/3560 [============================>.] - ETA: 2s - loss: 0.5591 - accuracy: 0.8430\n",
      "Batch 10664: setting learning rate to 0.00019839270422710258.\n",
      "3544/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8430\n",
      "Batch 10665: setting learning rate to 0.0001983920675576667.\n",
      "3545/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8430\n",
      "Batch 10666: setting learning rate to 0.00019839143076318146.\n",
      "3546/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8430\n",
      "Batch 10667: setting learning rate to 0.00019839079384364775.\n",
      "\n",
      "Batch 10668: setting learning rate to 0.00019839015679906636.\n",
      "3548/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8429\n",
      "Batch 10669: setting learning rate to 0.00019838951962943807.\n",
      "\n",
      "Batch 10670: setting learning rate to 0.00019838888233476374.\n",
      "3550/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8429\n",
      "Batch 10671: setting learning rate to 0.00019838824491504414.\n",
      "3551/3560 [============================>.] - ETA: 1s - loss: 0.5593 - accuracy: 0.8429\n",
      "Batch 10672: setting learning rate to 0.00019838760737028008.\n",
      "\n",
      "Batch 10673: setting learning rate to 0.00019838696970047242.\n",
      "3553/3560 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.8430\n",
      "Batch 10674: setting learning rate to 0.00019838633190562188.\n",
      "\n",
      "Batch 10675: setting learning rate to 0.00019838569398572938.\n",
      "3555/3560 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.8429\n",
      "Batch 10676: setting learning rate to 0.00019838505594079565.\n",
      "3556/3560 [============================>.] - ETA: 0s - loss: 0.5591 - accuracy: 0.8429\n",
      "Batch 10677: setting learning rate to 0.00019838441777082148.\n",
      "3557/3560 [============================>.] - ETA: 0s - loss: 0.5591 - accuracy: 0.8430\n",
      "Batch 10678: setting learning rate to 0.0001983837794758078.\n",
      "3558/3560 [============================>.] - ETA: 0s - loss: 0.5590 - accuracy: 0.8430\n",
      "Batch 10679: setting learning rate to 0.0001983831410557553.\n",
      "\n",
      "Batch 10680: setting learning rate to 0.00019838250251066485.\n"
     ]
    }
   ],
   "source": [
    "run_training(dropout = 0.5, lr_rate = 0.00001, architecture = 'mobilenet', batch = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'mobilenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "564DXmWLDMxa"
   },
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "1qVdSNFxjg5-",
    "outputId": "c571704d-0a0e-4a65-a7f8-15fcb6b82127"
   },
   "outputs": [],
   "source": [
    "# run_training(dropout = 0.5, lr_rate = 0.0002, architecture = 'efficientnet', batch = 256, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'efficientnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training(dropout = 0.5, lr_rate = 0.0002, architecture = 'densenet', batch = 256, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'densenet')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-6Yocnrq2u4F"
   ],
   "name": "25_May.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
