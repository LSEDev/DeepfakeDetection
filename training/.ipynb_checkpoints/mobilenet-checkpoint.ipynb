{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udRhv-d-2i8l"
   },
   "source": [
    "# Train preliminary models - Xception, ResNet, EfficentNet etc.\n",
    "       -- built for FF+ dataset with file structure as required by Keras' flow_from_directory method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "t7E1CjC9fqhq",
    "outputId": "abdef6eb-823c-4fb1-ad28-7521345d04fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 12 15:29:12 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   67C    P0    29W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# See available GPU RAM \n",
    "!nvidia-smi # can also be run from linux shell while GPU is training\n",
    "# !nvidia-smi dmon # this will stream memory utilisation\n",
    "# !watch -n0.1 nvidia-smi # better way to see GPU utilisation\n",
    "# !htop # cpu threads and if they're all working\n",
    "# !pip3 install --no-cache-dir -I tensorflow==2.2 #Â use if no gpu is attached so code will run \n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Llx-HRnYiWQU",
    "outputId": "6e6a3556-fbb1-4972-b046-8586183f768a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "# This cell has the latest set up for AI Platform\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import *\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/visualisations')\n",
    "sys.path.insert(1, '/home/jupyter/DeepFake-2019-20/hyperparameters')\n",
    "import VisualisationTools as plotting\n",
    "import hyper_utils as hp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(100)\n",
    "plot_losses = plotting.PlotLearning()\n",
    "os.chdir('/home/jupyter/DeepFake-2019-20')\n",
    "\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "3DRA3QPDgLLR",
    "outputId": "ed171b89-378d-469d-a254-c291be71af4d"
   },
   "outputs": [],
   "source": [
    "# Required for EfficientNet\n",
    "# !pip install git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtO5vELz8i3-"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ7mWThq32JA"
   },
   "outputs": [],
   "source": [
    "def build_model(dropout, lr_rate, architecture):\n",
    "    '''Builds a specified network with the selected dropout after the last dense layer.\n",
    "\n",
    "    Architectures that can be selected are:\n",
    "    vgg, xception, resnet50, mobilenet, efficientnet, densenet\n",
    "    \n",
    "    Optimiser is Adam, with a provided learning rate (lr_rate) and fixed\n",
    "    decay 1e-6, loss is traditionally categorical_crossentropy.'''\n",
    "\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "    if architecture=='xception':\n",
    "        from tensorflow.keras.applications.xception import Xception\n",
    "        conv_base = Xception(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture=='vgg':\n",
    "        from tensorflow.keras.applications.vgg16 import VGG16\n",
    "        conv_base = VGG16(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "      \n",
    "    elif architecture=='resnet50':\n",
    "        from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "        conv_base = ResNet50(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "      \n",
    "    elif architecture=='mobilenet':\n",
    "        from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        conv_base = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture== 'efficientnet':\n",
    "        # EfficientNetB7 has the highest top-1 accuracy on imagenet\n",
    "        # among EfficientNextB{0:7}\n",
    "        from efficientnet.tfkeras import EfficientNetB0\n",
    "        conv_base = EfficientNetB0(weights='noisy-student', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "        \n",
    "    elif architecture== 'densenet':\n",
    "        from tensorflow.keras.applications.densenet import DenseNet201\n",
    "        conv_base = DenseNet201(weights='imagenet', include_top=False,\n",
    "                        input_shape=(224,224,3))\n",
    "\n",
    "    elif architecture not in ['vgg', 'xception', 'resnet50',\n",
    "                              'mobilenet', 'efficientnet', 'densenet']:\n",
    "        return \"An unknown network is specified\"\n",
    "    \n",
    "\n",
    "    outputconv_base = conv_base.output\n",
    "    t_flat = Flatten()(outputconv_base)\n",
    "    t_dense1 = Dense(1024, activation='relu')(t_flat)\n",
    "    t_dense2 = Dense(256, activation='relu')(t_dense1)\n",
    "    t_dense3 = Dense(128, activation='relu')(t_dense2)\n",
    "    t_do = Dropout(dropout)(t_dense3)\n",
    "    predictions = Dense(2, activation= 'softmax')(t_do)\n",
    "\n",
    "    model = Model(inputs=conv_base.input, outputs=predictions, name = 'model')\n",
    "\n",
    "#     conv_base.trainable = False # freeze the convolutional base\n",
    "    \n",
    "    # # Code below trains all layers without using any pretrained weights\n",
    "    #for layer in conv_base.layers:\n",
    "    #  layer.trainable = True\n",
    "\n",
    "#     opt = tf.keras.optimizers.Adam(learning_rate= lr_rate, decay=1e-6)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_rate)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(directory, batch):\n",
    "    '''Prepares train-time augmentation using given training and validations data)\n",
    "    \n",
    "    Returns train_data, val_data'''\n",
    "\n",
    "    datagen_train = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=True,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=True,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "#             width_shift_range=0.1,\n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "#             height_shift_range=0.1,\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            brightness_range=[0.6, 1.4],\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function=None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            )\n",
    "    \n",
    "    datagen_test = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "    # Classes give the folders storing the two different categories\n",
    "    train_data = datagen_train.flow_from_directory(directory + '/train',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    val_data = datagen_test.flow_from_directory(directory + '/validation',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary train time functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_data):\n",
    "    '''Calculates class weights that weight the data based on the imbalance.\n",
    "    Allows for better analysis in the case of imbalanced data - has no effect\n",
    "    if data is balanced since the weights are then equal for each class.\n",
    "    Use the generator obtained from the flow_from_directory method to obtain\n",
    "    the class_weights.\n",
    "    \n",
    "    Input:\n",
    "    train_data: the generator obtained during augmentation\n",
    "    \n",
    "    Returns a dictionary with class weights, required format for training'''\n",
    "    \n",
    "    # Calculate class weights which are required to fully balance the classes\n",
    "    # Compares frequencies of appearence for each distinct label\n",
    "    \n",
    "    # The line of code below can be used on a generator to find the index labels\n",
    "    print('Ensure class weights function corresponds to these class indices:',\n",
    "          train_data.class_indices)\n",
    "    \n",
    "    counter = Counter(train_data.classes)                          \n",
    "    max_val = float(max(counter.values()))       \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "    return class_weights\n",
    "\n",
    "def load_model_weights(model, architecture):\n",
    "    '''An alternative to training if there are already some generated weights\n",
    "    \n",
    "    Takes a built model (and its architecture type) and loads the weights\n",
    "    with the highest validation accuracy.\n",
    "    \n",
    "    If there are no saved weights, a message is printed. '''\n",
    "\n",
    "    path_to_weights = \"../all_faces_bucket/trained_models/weights/mobilenet_new\"\n",
    "    # get all the weights file names in a list\n",
    "    if os.path.exists(path_to_weights):\n",
    "        all_weights = sorted(os.listdir(path_to_weights + '/'))\n",
    "    # if there is at least one file\n",
    "        if len(all_weights) >= 1:\n",
    "            # pick out accuracies out of file names\n",
    "            acc = [el[len(el)-10 : len(el)-5] for el in all_weights]\n",
    "            # get index of the first maximum accuracy\n",
    "            optimal_index = acc.index(max(acc))\n",
    "            # get the name of the file with optimal weights, load corresponding weights\n",
    "            optimal_weights = all_weights[optimal_index]\n",
    "            print(\"Loading\", path_to_weights + '/' + optimal_weights)\n",
    "            model.load_weights(path_to_weights + '/' + optimal_weights)\n",
    "            \n",
    "        else: # otherwise warn that no weights were loaded\n",
    "            print(\"There are no weights stored. Training model from scratch:\")   \n",
    "    \n",
    "    else: # otherwise warn that no weights were loaded\n",
    "        print(\"There are no weights stored. Training model from scratch:\")   \n",
    "        \n",
    "def save_model_from_best_weights(dropout, lr_rate, architecture):\n",
    "    '''Takes the weights with the highest val accuracy and saves the corresponding model.'''\n",
    "    model = build_model(dropout, lr_rate, architecture)\n",
    "    load_model_weights(model, architecture)\n",
    "    model.save('../all_faces_bucket/trained_models/saved_models/mobilenet_new_model_fine_tuned.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, val_data, epochs, class_weights, architecture):\n",
    "    '''Trains a provided model.\n",
    "    Takes 6 arguments:\n",
    "    \n",
    "    1. model: a built model with an architecture specified in the build function\n",
    "    2. train_data: augmented data obtained from the augment_data function\n",
    "    3. val_data: validation data obtained from the augment_data function\n",
    "    4. epochs -- number of epochs\n",
    "    5. class weights -- a dictionary with weights (equal for balanced data so\n",
    "    no negative impact)\n",
    "    6. architecture: can choose vgg, xception, resnet50, mobilenet or efficientnet\n",
    "    '''\n",
    "    \n",
    "    # Make a trained_models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models')\n",
    "    \n",
    "    # Make a weights folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights')\n",
    "        \n",
    "    # Make a weights folder for the architecture if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/weights/mobilenet_new'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/weights/mobilenet_new_fine_tuned')\n",
    "\n",
    "    # Save weights - below saves every epoch where there is improvement\n",
    "    # filepath=\"../all_faces_bucket/trained_models/weights/\" + architecture + \"/epochs:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5\"\n",
    "    # Below saves on file - the weights with the highest validation accuracy\n",
    "    filepath=\"../all_faces_bucket/trained_models/weights/mobilenet_new_fine_tuned/highest_val_acc.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
    "                                verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    # Make a folder to store training accuracies if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/training_accuracies'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/training_accuracies')\n",
    "    \n",
    "    # Callback to save training accuracies after each epoch\n",
    "    csv_logger = CSVLogger('../all_faces_bucket/trained_models/training_accuracies/mobilenet_new_fine_tuned.csv',\n",
    "                           separator=',', append=True)\n",
    "    \n",
    "    # Stop after 3 epochs if val_accuracy doesn't improve\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "                          \n",
    "    # Load previous weights from training if there are any\n",
    "    load_model_weights(model, architecture)\n",
    "    \n",
    "    # Set learning rate config \n",
    "    sample_count = 60000 # number of training samples\n",
    "    epochs = 50 # total epochs - affects total steps (and hence speed of decay)\n",
    "    warmup_epoch = 3 # number of warmup epochs\n",
    "    batch_size = train_data.batch_size\n",
    "    learning_rate_base = 0.00001\n",
    "    total_steps = int(epochs * sample_count / batch_size)\n",
    "    warmup_steps = int(warmup_epoch * sample_count / batch_size)\n",
    "    \n",
    "    warm_up_lr = hp.WarmUpCosineDecayScheduler(learning_rate_base=learning_rate_base,\n",
    "                                        total_steps=total_steps,\n",
    "                                        warmup_learning_rate=0.0,\n",
    "                                        warmup_steps=warmup_steps,\n",
    "                                        hold_base_rate_steps=2,\n",
    "                                        verbose=0)\n",
    "\n",
    "    history = model.fit(train_data, epochs=epochs, shuffle=True,\n",
    "              steps_per_epoch = train_data.n//train_data.batch_size,\n",
    "              validation_data = val_data, \n",
    "              validation_steps = val_data.n//val_data.batch_size,\n",
    "              class_weight=class_weights,\n",
    "              callbacks=[plot_losses, checkpoint, csv_logger, es, warm_up_lr],\n",
    "              verbose=1,\n",
    "              max_queue_size=100,                # maximum size for the generator queue\n",
    "              workers=16,                        # maximum number of processes to spin up when using process-based threading\n",
    "              use_multiprocessing=False)\n",
    "    \n",
    "    # Make a saved models folder if it doesn't exist\n",
    "    if not os.path.exists('../all_faces_bucket/trained_models/saved_models'):\n",
    "        os.makedirs('../all_faces_bucket/trained_models/saved_models')\n",
    "        \n",
    "    model.save_weights('../all_faces_bucket/trained_models/weights/mobilenet_new_fine_tunedlastepoch.hdf5') \n",
    "    model.save('../all_faces_bucket/trained_models/saved_models/mobilenet_new_model_fine_tunedlastepoch.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIUZirJoxsdx"
   },
   "source": [
    "## Unifying Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYFsNbZMqYTv"
   },
   "outputs": [],
   "source": [
    "def run_training(dropout = 0.5, lr_rate = 0.0001, architecture = 'vgg', \n",
    "                 batch = 32, epochs = 50):\n",
    "\n",
    "    '''Builds a model based on the specified architecture, augments training\n",
    "    data (reserving a fraction for validation), then computes class weights to\n",
    "    balance data and trains the model.\n",
    "    \n",
    "    Inputs:\n",
    "    1. dropout  -- for the model\n",
    "    2. lr_rate\n",
    "    3. architecture -- a choice of vgg, resnet50, mobilenet, xception and efficientnet\n",
    "    4. batch -- batch size\n",
    "    5. epochs -- number of epochs\n",
    "    '''\n",
    "\n",
    "    # Build a model, augment data, get class_weights and train the model\n",
    "    # Strategy scope allows us to leverage multiple GPUs\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    \n",
    "    with strategy.scope(): # Allows for parallel GPUs\n",
    "        model = build_model(dropout, lr_rate, architecture)\n",
    "    train_data, val_data = augment_data('../all_faces_disk/home/jupyter/forensics_split', batch)\n",
    "    class_weights = calculate_class_weights(train_data)\n",
    "    trained_model = train_model(model, train_data, val_data, epochs, class_weights, architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "in8HHH594qtA"
   },
   "source": [
    "## Train Various Model Architectures\n",
    "Note: Make sure CPUs have enough memory for each batch eg. 1 core with 3.75GB RAM cant take batches larger than 32.  \n",
    "8 CPUs with 30GB RAM typically works well for batches of 256.\n",
    "\n",
    "In this model: 4 cores/8GB and T4 used - took approx 8 hours to train top dense layers and fine tune. \n",
    "\n",
    "Also note that while multiprocessing speeds up training, it interacts badly with Tensorflow and leads to deadlocks. To be on the safe side, set use_multiprocessing to False when training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gz0ilB_F8F4g"
   },
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "id": "_GZwsiNC7rkK",
    "outputId": "7b0348f4-e292-4cb7-af8f-49af0eda2638"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy improved from 0.97797 to 0.98037, saving model to ../all_faces_bucket/trained_models/weights/mobilenet_new_fine_tuned/highest_val_acc.hdf5\n",
      "1780/1780 [==============================] - 803s 451ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.9804 - val_loss: 0.1159\n",
      "Epoch 11/50\n",
      "\n",
      "Batch 17801: setting learning rate to 7.40712493694138e-06.\n",
      "   1/1780 [..............................] - ETA: 0s - accuracy: 1.0000 - loss: 0.0168\n",
      "Batch 17802: setting learning rate to 7.406812458789538e-06.\n",
      "   2/1780 [..............................] - ETA: 6:33 - accuracy: 1.0000 - loss: 0.0090\n",
      "Batch 17803: setting learning rate to 7.406499968401872e-06.\n",
      "   3/1780 [..............................] - ETA: 8:32 - accuracy: 1.0000 - loss: 0.0078\n",
      "Batch 17804: setting learning rate to 7.406187465779968e-06.\n",
      "   4/1780 [..............................] - ETA: 9:36 - accuracy: 1.0000 - loss: 0.0075\n",
      "Batch 17805: setting learning rate to 7.405874950925415e-06.\n",
      "   5/1780 [..............................] - ETA: 10:18 - accuracy: 1.0000 - loss: 0.0060\n",
      "Batch 17806: setting learning rate to 7.4055624238398014e-06.\n",
      "   6/1780 [..............................] - ETA: 10:46 - accuracy: 1.0000 - loss: 0.0052\n",
      "Batch 17807: setting learning rate to 7.4052498845247165e-06.\n",
      "   7/1780 [..............................] - ETA: 11:02 - accuracy: 1.0000 - loss: 0.0050\n",
      "Batch 17808: setting learning rate to 7.4049373329817505e-06.\n",
      "   8/1780 [..............................] - ETA: 11:13 - accuracy: 1.0000 - loss: 0.0068\n",
      "Batch 17809: setting learning rate to 7.404624769212491e-06.\n",
      "   9/1780 [..............................] - ETA: 11:22 - accuracy: 1.0000 - loss: 0.0061\n",
      "Batch 17810: setting learning rate to 7.404312193218527e-06.\n",
      "  10/1780 [..............................] - ETA: 11:30 - accuracy: 1.0000 - loss: 0.0056\n",
      "Batch 17811: setting learning rate to 7.4039996050014475e-06.\n",
      "  11/1780 [..............................] - ETA: 11:36 - accuracy: 0.9986 - loss: 0.0063\n",
      "Batch 17812: setting learning rate to 7.403687004562841e-06.\n",
      "  12/1780 [..............................] - ETA: 11:43 - accuracy: 0.9987 - loss: 0.0058\n",
      "Batch 17813: setting learning rate to 7.403374391904301e-06.\n",
      "  13/1780 [..............................] - ETA: 11:47 - accuracy: 0.9988 - loss: 0.0054\n",
      "Batch 17814: setting learning rate to 7.403061767027411e-06.\n",
      "  14/1780 [..............................] - ETA: 11:55 - accuracy: 0.9989 - loss: 0.0050\n",
      "Batch 17815: setting learning rate to 7.402749129933762e-06.\n",
      "  15/1780 [..............................] - ETA: 11:56 - accuracy: 0.9990 - loss: 0.0047\n",
      "Batch 17816: setting learning rate to 7.402436480624945e-06.\n",
      "  16/1780 [..............................] - ETA: 11:59 - accuracy: 0.9990 - loss: 0.0044\n",
      "Batch 17817: setting learning rate to 7.402123819102549e-06.\n",
      "  17/1780 [..............................] - ETA: 12:01 - accuracy: 0.9982 - loss: 0.0052\n",
      "Batch 17818: setting learning rate to 7.401811145368163e-06.\n",
      "  18/1780 [..............................] - ETA: 12:04 - accuracy: 0.9983 - loss: 0.0049\n",
      "Batch 17819: setting learning rate to 7.4014984594233765e-06.\n",
      "  19/1780 [..............................] - ETA: 12:08 - accuracy: 0.9984 - loss: 0.0046\n",
      "Batch 17820: setting learning rate to 7.40118576126978e-06.\n",
      "  20/1780 [..............................] - ETA: 12:11 - accuracy: 0.9977 - loss: 0.0052\n",
      "Batch 17821: setting learning rate to 7.400873050908962e-06.\n",
      "  21/1780 [..............................] - ETA: 12:14 - accuracy: 0.9978 - loss: 0.0049\n",
      "Batch 17822: setting learning rate to 7.400560328342512e-06.\n",
      "  22/1780 [..............................] - ETA: 12:17 - accuracy: 0.9979 - loss: 0.0047\n",
      "Batch 17823: setting learning rate to 7.4002475935720234e-06.\n",
      "  23/1780 [..............................] - ETA: 12:19 - accuracy: 0.9980 - loss: 0.0045\n",
      "Batch 17824: setting learning rate to 7.399934846599081e-06.\n",
      "  24/1780 [..............................] - ETA: 12:22 - accuracy: 0.9974 - loss: 0.0055\n",
      "Batch 17825: setting learning rate to 7.399622087425277e-06.\n",
      "  25/1780 [..............................] - ETA: 12:24 - accuracy: 0.9975 - loss: 0.0054\n",
      "Batch 17826: setting learning rate to 7.399309316052201e-06.\n",
      "  26/1780 [..............................] - ETA: 12:22 - accuracy: 0.9976 - loss: 0.0052\n",
      "Batch 17827: setting learning rate to 7.398996532481446e-06.\n",
      "  27/1780 [..............................] - ETA: 12:22 - accuracy: 0.9977 - loss: 0.0051\n",
      "Batch 17828: setting learning rate to 7.398683736714598e-06.\n",
      "  28/1780 [..............................] - ETA: 12:23 - accuracy: 0.9978 - loss: 0.0054\n",
      "Batch 17829: setting learning rate to 7.398370928753249e-06.\n",
      "  29/1780 [..............................] - ETA: 12:21 - accuracy: 0.9978 - loss: 0.0052\n",
      "Batch 17830: setting learning rate to 7.398058108598989e-06.\n",
      "  30/1780 [..............................] - ETA: 12:22 - accuracy: 0.9979 - loss: 0.0050\n",
      "Batch 17831: setting learning rate to 7.3977452762534075e-06.\n",
      "  31/1780 [..............................] - ETA: 12:24 - accuracy: 0.9980 - loss: 0.0049\n",
      "Batch 17832: setting learning rate to 7.397432431718099e-06.\n",
      "  32/1780 [..............................] - ETA: 12:24 - accuracy: 0.9980 - loss: 0.0052\n",
      "Batch 17833: setting learning rate to 7.397119574994649e-06.\n",
      "  33/1780 [..............................] - ETA: 12:24 - accuracy: 0.9981 - loss: 0.0051\n",
      "Batch 17834: setting learning rate to 7.3968067060846495e-06.\n",
      "  34/1780 [..............................] - ETA: 12:24 - accuracy: 0.9982 - loss: 0.0049\n",
      "Batch 17835: setting learning rate to 7.396493824989691e-06.\n",
      "  35/1780 [..............................] - ETA: 12:24 - accuracy: 0.9978 - loss: 0.0062\n",
      "Batch 17836: setting learning rate to 7.396180931711365e-06.\n",
      "  36/1780 [..............................] - ETA: 12:25 - accuracy: 0.9978 - loss: 0.0061\n",
      "Batch 17837: setting learning rate to 7.395868026251263e-06.\n",
      "  37/1780 [..............................] - ETA: 12:24 - accuracy: 0.9979 - loss: 0.0059\n",
      "Batch 17838: setting learning rate to 7.3955551086109735e-06.\n",
      "  38/1780 [..............................] - ETA: 12:24 - accuracy: 0.9971 - loss: 0.0067\n",
      "Batch 17839: setting learning rate to 7.395242178792088e-06.\n",
      "  39/1780 [..............................] - ETA: 12:23 - accuracy: 0.9972 - loss: 0.0065\n",
      "Batch 17840: setting learning rate to 7.394929236796199e-06.\n",
      "  40/1780 [..............................] - ETA: 12:23 - accuracy: 0.9969 - loss: 0.0070\n",
      "Batch 17841: setting learning rate to 7.394616282624896e-06.\n",
      "  41/1780 [..............................] - ETA: 12:23 - accuracy: 0.9970 - loss: 0.0069\n",
      "Batch 17842: setting learning rate to 7.3943033162797685e-06.\n",
      "  42/1780 [..............................] - ETA: 12:24 - accuracy: 0.9970 - loss: 0.0067\n",
      "Batch 17843: setting learning rate to 7.39399033776241e-06.\n",
      "  43/1780 [..............................] - ETA: 12:24 - accuracy: 0.9971 - loss: 0.0066\n",
      "Batch 17844: setting learning rate to 7.393677347074412e-06.\n",
      "  44/1780 [..............................] - ETA: 12:25 - accuracy: 0.9972 - loss: 0.0065\n",
      "Batch 17845: setting learning rate to 7.393364344217363e-06.\n",
      "  45/1780 [..............................] - ETA: 12:25 - accuracy: 0.9972 - loss: 0.0063\n",
      "Batch 17846: setting learning rate to 7.393051329192856e-06.\n",
      "  46/1780 [..............................] - ETA: 12:26 - accuracy: 0.9973 - loss: 0.0062\n",
      "Batch 17847: setting learning rate to 7.392738302002483e-06.\n",
      "  47/1780 [..............................] - ETA: 12:26 - accuracy: 0.9973 - loss: 0.0061\n",
      "Batch 17848: setting learning rate to 7.392425262647835e-06.\n",
      "  48/1780 [..............................] - ETA: 12:25 - accuracy: 0.9974 - loss: 0.0060\n",
      "Batch 17849: setting learning rate to 7.392112211130501e-06.\n",
      "  49/1780 [..............................] - ETA: 12:25 - accuracy: 0.9971 - loss: 0.0062\n",
      "Batch 17850: setting learning rate to 7.3917991474520755e-06.\n",
      "  50/1780 [..............................] - ETA: 12:24 - accuracy: 0.9972 - loss: 0.0062\n",
      "Batch 17851: setting learning rate to 7.39148607161415e-06.\n",
      "  51/1780 [..............................] - ETA: 12:25 - accuracy: 0.9972 - loss: 0.0060\n",
      "Batch 17852: setting learning rate to 7.391172983618313e-06.\n",
      "  52/1780 [..............................] - ETA: 12:25 - accuracy: 0.9973 - loss: 0.0059\n",
      "Batch 17853: setting learning rate to 7.39085988346616e-06.\n",
      "  53/1780 [..............................] - ETA: 12:24 - accuracy: 0.9973 - loss: 0.0065\n",
      "Batch 17854: setting learning rate to 7.390546771159281e-06.\n",
      "  54/1780 [..............................] - ETA: 12:24 - accuracy: 0.9974 - loss: 0.0064\n",
      "Batch 17855: setting learning rate to 7.3902336466992675e-06.\n",
      "  55/1780 [..............................] - ETA: 12:24 - accuracy: 0.9974 - loss: 0.0062\n",
      "Batch 17856: setting learning rate to 7.389920510087711e-06.\n",
      "  56/1780 [..............................] - ETA: 12:24 - accuracy: 0.9975 - loss: 0.0061\n",
      "Batch 17857: setting learning rate to 7.3896073613262045e-06.\n",
      "  57/1780 [..............................] - ETA: 12:23 - accuracy: 0.9975 - loss: 0.0061\n",
      "Batch 17858: setting learning rate to 7.389294200416339e-06.\n",
      "  58/1780 [..............................] - ETA: 12:24 - accuracy: 0.9976 - loss: 0.0060\n",
      "Batch 17859: setting learning rate to 7.388981027359708e-06.\n",
      "  59/1780 [..............................] - ETA: 12:23 - accuracy: 0.9976 - loss: 0.0060\n",
      "Batch 17860: setting learning rate to 7.388667842157904e-06.\n",
      "  60/1780 [>.............................] - ETA: 12:22 - accuracy: 0.9977 - loss: 0.0059\n",
      "Batch 17861: setting learning rate to 7.388354644812517e-06.\n",
      "  61/1780 [>.............................] - ETA: 12:23 - accuracy: 0.9972 - loss: 0.0084\n",
      "Batch 17862: setting learning rate to 7.388041435325139e-06.\n",
      "  62/1780 [>.............................] - ETA: 12:23 - accuracy: 0.9970 - loss: 0.0090\n",
      "Batch 17863: setting learning rate to 7.387728213697365e-06.\n",
      "  63/1780 [>.............................] - ETA: 12:23 - accuracy: 0.9970 - loss: 0.0090\n",
      "Batch 17864: setting learning rate to 7.387414979930787e-06.\n",
      "  64/1780 [>.............................] - ETA: 12:23 - accuracy: 0.9971 - loss: 0.0089\n",
      "Batch 17865: setting learning rate to 7.387101734026995e-06.\n",
      "  65/1780 [>.............................] - ETA: 12:22 - accuracy: 0.9971 - loss: 0.0088\n",
      "Batch 17866: setting learning rate to 7.386788475987583e-06.\n",
      "  66/1780 [>.............................] - ETA: 12:22 - accuracy: 0.9969 - loss: 0.0089\n",
      "Batch 17867: setting learning rate to 7.386475205814143e-06.\n",
      "  67/1780 [>.............................] - ETA: 12:21 - accuracy: 0.9970 - loss: 0.0088\n",
      "Batch 17868: setting learning rate to 7.386161923508269e-06.\n",
      "  68/1780 [>.............................] - ETA: 12:21 - accuracy: 0.9966 - loss: 0.0112\n",
      "Batch 17869: setting learning rate to 7.385848629071551e-06.\n",
      "  69/1780 [>.............................] - ETA: 12:20 - accuracy: 0.9964 - loss: 0.0116\n",
      "Batch 17870: setting learning rate to 7.3855353225055845e-06.\n",
      "  70/1780 [>.............................] - ETA: 12:20 - accuracy: 0.9962 - loss: 0.0117\n",
      "Batch 17871: setting learning rate to 7.385222003811963e-06.\n",
      "  71/1780 [>.............................] - ETA: 12:19 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 17872: setting learning rate to 7.384908672992275e-06.\n",
      "  72/1780 [>.............................] - ETA: 12:19 - accuracy: 0.9963 - loss: 0.0123\n",
      "Batch 17873: setting learning rate to 7.384595330048117e-06.\n",
      "  73/1780 [>.............................] - ETA: 12:18 - accuracy: 0.9964 - loss: 0.0121\n",
      "Batch 17874: setting learning rate to 7.384281974981082e-06.\n",
      "  74/1780 [>.............................] - ETA: 12:18 - accuracy: 0.9964 - loss: 0.0120\n",
      "Batch 17875: setting learning rate to 7.383968607792759e-06.\n",
      "  75/1780 [>.............................] - ETA: 12:17 - accuracy: 0.9965 - loss: 0.0118\n",
      "Batch 17876: setting learning rate to 7.383655228484746e-06.\n",
      "  76/1780 [>.............................] - ETA: 12:17 - accuracy: 0.9963 - loss: 0.0120\n",
      "Batch 17877: setting learning rate to 7.383341837058635e-06.\n",
      "  77/1780 [>.............................] - ETA: 12:17 - accuracy: 0.9963 - loss: 0.0118\n",
      "Batch 17878: setting learning rate to 7.383028433516019e-06.\n",
      "  78/1780 [>.............................] - ETA: 12:16 - accuracy: 0.9964 - loss: 0.0117\n",
      "Batch 17879: setting learning rate to 7.3827150178584884e-06.\n",
      "  79/1780 [>.............................] - ETA: 12:16 - accuracy: 0.9960 - loss: 0.0118\n",
      "Batch 17880: setting learning rate to 7.38240159008764e-06.\n",
      "  80/1780 [>.............................] - ETA: 12:16 - accuracy: 0.9959 - loss: 0.0119\n",
      "Batch 17881: setting learning rate to 7.382088150205067e-06.\n",
      "  81/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9959 - loss: 0.0117\n",
      "Batch 17882: setting learning rate to 7.381774698212362e-06.\n",
      "  82/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9960 - loss: 0.0117\n",
      "Batch 17883: setting learning rate to 7.381461234111117e-06.\n",
      "  83/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9960 - loss: 0.0116\n",
      "Batch 17884: setting learning rate to 7.3811477579029285e-06.\n",
      "  84/1780 [>.............................] - ETA: 12:16 - accuracy: 0.9961 - loss: 0.0118\n",
      "Batch 17885: setting learning rate to 7.380834269589388e-06.\n",
      "  85/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9961 - loss: 0.0117\n",
      "Batch 17886: setting learning rate to 7.38052076917209e-06.\n",
      "  86/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9962 - loss: 0.0116\n",
      "Batch 17887: setting learning rate to 7.38020725665263e-06.\n",
      "  87/1780 [>.............................] - ETA: 12:15 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 17888: setting learning rate to 7.379893732032599e-06.\n",
      "  88/1780 [>.............................] - ETA: 12:14 - accuracy: 0.9963 - loss: 0.0114\n",
      "Batch 17889: setting learning rate to 7.379580195313593e-06.\n",
      "  89/1780 [>.............................] - ETA: 12:14 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 17890: setting learning rate to 7.379266646497204e-06.\n",
      "  90/1780 [>.............................] - ETA: 12:13 - accuracy: 0.9964 - loss: 0.0114\n",
      "Batch 17891: setting learning rate to 7.378953085585028e-06.\n",
      "  91/1780 [>.............................] - ETA: 12:12 - accuracy: 0.9962 - loss: 0.0126\n",
      "Batch 17892: setting learning rate to 7.378639512578658e-06.\n",
      "  92/1780 [>.............................] - ETA: 12:12 - accuracy: 0.9963 - loss: 0.0125\n",
      "Batch 17893: setting learning rate to 7.378325927479688e-06.\n",
      "  93/1780 [>.............................] - ETA: 12:11 - accuracy: 0.9963 - loss: 0.0124\n",
      "Batch 17894: setting learning rate to 7.378012330289712e-06.\n",
      "  94/1780 [>.............................] - ETA: 12:10 - accuracy: 0.9963 - loss: 0.0122\n",
      "Batch 17895: setting learning rate to 7.377698721010327e-06.\n",
      "  95/1780 [>.............................] - ETA: 12:10 - accuracy: 0.9964 - loss: 0.0121\n",
      "Batch 17896: setting learning rate to 7.377385099643123e-06.\n",
      "  96/1780 [>.............................] - ETA: 12:10 - accuracy: 0.9964 - loss: 0.0120\n",
      "Batch 17897: setting learning rate to 7.377071466189697e-06.\n",
      "  97/1780 [>.............................] - ETA: 12:09 - accuracy: 0.9963 - loss: 0.0120\n",
      "Batch 17898: setting learning rate to 7.376757820651643e-06.\n",
      "  98/1780 [>.............................] - ETA: 12:09 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 17899: setting learning rate to 7.376444163030556e-06.\n",
      "  99/1780 [>.............................] - ETA: 12:08 - accuracy: 0.9964 - loss: 0.0117\n",
      "Batch 17900: setting learning rate to 7.3761304933280296e-06.\n",
      " 100/1780 [>.............................] - ETA: 12:08 - accuracy: 0.9964 - loss: 0.0120\n",
      "Batch 17901: setting learning rate to 7.375816811545661e-06.\n",
      " 101/1780 [>.............................] - ETA: 12:08 - accuracy: 0.9964 - loss: 0.0119\n",
      "Batch 17902: setting learning rate to 7.375503117685041e-06.\n",
      " 102/1780 [>.............................] - ETA: 12:07 - accuracy: 0.9965 - loss: 0.0118\n",
      "Batch 17903: setting learning rate to 7.375189411747765e-06.\n",
      " 103/1780 [>.............................] - ETA: 12:07 - accuracy: 0.9964 - loss: 0.0118\n",
      "Batch 17904: setting learning rate to 7.3748756937354306e-06.\n",
      " 104/1780 [>.............................] - ETA: 12:07 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 17905: setting learning rate to 7.374561963649633e-06.\n",
      " 105/1780 [>.............................] - ETA: 12:06 - accuracy: 0.9963 - loss: 0.0120\n",
      "Batch 17906: setting learning rate to 7.374248221491962e-06.\n",
      " 106/1780 [>.............................] - ETA: 12:05 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 17907: setting learning rate to 7.373934467264018e-06.\n",
      " 107/1780 [>.............................] - ETA: 12:05 - accuracy: 0.9963 - loss: 0.0118\n",
      "Batch 17908: setting learning rate to 7.373620700967393e-06.\n",
      " 108/1780 [>.............................] - ETA: 12:06 - accuracy: 0.9964 - loss: 0.0117\n",
      "Batch 17909: setting learning rate to 7.373306922603684e-06.\n",
      " 109/1780 [>.............................] - ETA: 12:06 - accuracy: 0.9963 - loss: 0.0118\n",
      "Batch 17910: setting learning rate to 7.372993132174485e-06.\n",
      " 110/1780 [>.............................] - ETA: 12:05 - accuracy: 0.9963 - loss: 0.0117\n",
      "Batch 17911: setting learning rate to 7.372679329681391e-06.\n",
      " 111/1780 [>.............................] - ETA: 12:04 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 17912: setting learning rate to 7.372365515125999e-06.\n",
      " 112/1780 [>.............................] - ETA: 12:04 - accuracy: 0.9964 - loss: 0.0115\n",
      "Batch 17913: setting learning rate to 7.372051688509901e-06.\n",
      " 113/1780 [>.............................] - ETA: 12:04 - accuracy: 0.9963 - loss: 0.0118\n",
      "Batch 17914: setting learning rate to 7.371737849834697e-06.\n",
      " 114/1780 [>.............................] - ETA: 12:03 - accuracy: 0.9962 - loss: 0.0118\n",
      "Batch 17915: setting learning rate to 7.37142399910198e-06.\n",
      " 115/1780 [>.............................] - ETA: 12:02 - accuracy: 0.9962 - loss: 0.0118\n",
      "Batch 17916: setting learning rate to 7.371110136313345e-06.\n",
      " 116/1780 [>.............................] - ETA: 12:02 - accuracy: 0.9962 - loss: 0.0117\n",
      "Batch 17917: setting learning rate to 7.370796261470388e-06.\n",
      " 117/1780 [>.............................] - ETA: 12:02 - accuracy: 0.9963 - loss: 0.0117\n",
      "Batch 17918: setting learning rate to 7.370482374574707e-06.\n",
      " 118/1780 [>.............................] - ETA: 12:01 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 17919: setting learning rate to 7.370168475627895e-06.\n",
      " 119/1780 [=>............................] - ETA: 12:00 - accuracy: 0.9963 - loss: 0.0115\n",
      "Batch 17920: setting learning rate to 7.369854564631549e-06.\n",
      " 120/1780 [=>............................] - ETA: 12:00 - accuracy: 0.9964 - loss: 0.0115\n",
      "Batch 17921: setting learning rate to 7.369540641587263e-06.\n",
      " 121/1780 [=>............................] - ETA: 12:00 - accuracy: 0.9964 - loss: 0.0114\n",
      "Batch 17922: setting learning rate to 7.369226706496636e-06.\n",
      " 122/1780 [=>............................] - ETA: 11:59 - accuracy: 0.9964 - loss: 0.0113\n",
      "Batch 17923: setting learning rate to 7.368912759361262e-06.\n",
      " 123/1780 [=>............................] - ETA: 11:59 - accuracy: 0.9964 - loss: 0.0112\n",
      "Batch 17924: setting learning rate to 7.368598800182737e-06.\n",
      " 124/1780 [=>............................] - ETA: 11:59 - accuracy: 0.9965 - loss: 0.0111\n",
      "Batch 17925: setting learning rate to 7.3682848289626596e-06.\n",
      " 125/1780 [=>............................] - ETA: 11:58 - accuracy: 0.9965 - loss: 0.0110\n",
      "Batch 17926: setting learning rate to 7.367970845702621e-06.\n",
      " 126/1780 [=>............................] - ETA: 11:57 - accuracy: 0.9965 - loss: 0.0110\n",
      "Batch 17927: setting learning rate to 7.3676568504042225e-06.\n",
      " 127/1780 [=>............................] - ETA: 11:57 - accuracy: 0.9966 - loss: 0.0110\n",
      "Batch 17928: setting learning rate to 7.367342843069059e-06.\n",
      " 128/1780 [=>............................] - ETA: 11:56 - accuracy: 0.9966 - loss: 0.0109\n",
      "Batch 17929: setting learning rate to 7.367028823698724e-06.\n",
      " 129/1780 [=>............................] - ETA: 11:56 - accuracy: 0.9966 - loss: 0.0108\n",
      "Batch 17930: setting learning rate to 7.366714792294817e-06.\n",
      " 130/1780 [=>............................] - ETA: 11:55 - accuracy: 0.9966 - loss: 0.0107\n",
      "Batch 17931: setting learning rate to 7.366400748858933e-06.\n",
      " 131/1780 [=>............................] - ETA: 11:55 - accuracy: 0.9967 - loss: 0.0107\n",
      "Batch 17932: setting learning rate to 7.366086693392671e-06.\n",
      " 132/1780 [=>............................] - ETA: 11:54 - accuracy: 0.9967 - loss: 0.0106\n",
      "Batch 17933: setting learning rate to 7.3657726258976245e-06.\n",
      " 133/1780 [=>............................] - ETA: 11:53 - accuracy: 0.9967 - loss: 0.0105\n",
      "Batch 17934: setting learning rate to 7.365458546375392e-06.\n",
      " 134/1780 [=>............................] - ETA: 11:53 - accuracy: 0.9967 - loss: 0.0104\n",
      "Batch 17935: setting learning rate to 7.365144454827569e-06.\n",
      " 135/1780 [=>............................] - ETA: 11:52 - accuracy: 0.9968 - loss: 0.0104\n",
      "Batch 17936: setting learning rate to 7.364830351255752e-06.\n",
      " 136/1780 [=>............................] - ETA: 11:51 - accuracy: 0.9966 - loss: 0.0105\n",
      "Batch 17937: setting learning rate to 7.3645162356615404e-06.\n",
      " 137/1780 [=>............................] - ETA: 11:51 - accuracy: 0.9966 - loss: 0.0104\n",
      "Batch 17938: setting learning rate to 7.3642021080465285e-06.\n",
      " 138/1780 [=>............................] - ETA: 11:50 - accuracy: 0.9966 - loss: 0.0103\n",
      "Batch 17939: setting learning rate to 7.363887968412316e-06.\n",
      " 139/1780 [=>............................] - ETA: 11:50 - accuracy: 0.9966 - loss: 0.0102\n",
      "Batch 17940: setting learning rate to 7.363573816760495e-06.\n",
      " 140/1780 [=>............................] - ETA: 11:49 - accuracy: 0.9967 - loss: 0.0102\n",
      "Batch 17941: setting learning rate to 7.363259653092668e-06.\n",
      " 141/1780 [=>............................] - ETA: 11:48 - accuracy: 0.9967 - loss: 0.0101\n",
      "Batch 17942: setting learning rate to 7.362945477410431e-06.\n",
      " 142/1780 [=>............................] - ETA: 11:47 - accuracy: 0.9966 - loss: 0.0103\n",
      "Batch 17943: setting learning rate to 7.3626312897153785e-06.\n",
      " 143/1780 [=>............................] - ETA: 11:46 - accuracy: 0.9966 - loss: 0.0105\n",
      "Batch 17944: setting learning rate to 7.362317090009109e-06.\n",
      " 144/1780 [=>............................] - ETA: 11:45 - accuracy: 0.9966 - loss: 0.0105\n",
      "Batch 17945: setting learning rate to 7.362002878293222e-06.\n",
      " 145/1780 [=>............................] - ETA: 11:44 - accuracy: 0.9967 - loss: 0.0105\n",
      "Batch 17946: setting learning rate to 7.361688654569312e-06.\n",
      " 146/1780 [=>............................] - ETA: 11:44 - accuracy: 0.9967 - loss: 0.0104\n",
      "Batch 17947: setting learning rate to 7.361374418838978e-06.\n",
      " 147/1780 [=>............................] - ETA: 11:43 - accuracy: 0.9967 - loss: 0.0104\n",
      "Batch 17948: setting learning rate to 7.361060171103817e-06.\n",
      " 148/1780 [=>............................] - ETA: 11:42 - accuracy: 0.9967 - loss: 0.0103\n",
      "Batch 17949: setting learning rate to 7.360745911365427e-06.\n",
      " 149/1780 [=>............................] - ETA: 11:41 - accuracy: 0.9967 - loss: 0.0103\n",
      "Batch 17950: setting learning rate to 7.360431639625405e-06.\n",
      " 150/1780 [=>............................] - ETA: 11:40 - accuracy: 0.9968 - loss: 0.0102\n",
      "Batch 17951: setting learning rate to 7.360117355885349e-06.\n",
      " 151/1780 [=>............................] - ETA: 11:40 - accuracy: 0.9967 - loss: 0.0110\n",
      "Batch 17952: setting learning rate to 7.359803060146858e-06.\n",
      " 152/1780 [=>............................] - ETA: 11:39 - accuracy: 0.9967 - loss: 0.0109\n",
      "Batch 17953: setting learning rate to 7.359488752411528e-06.\n",
      " 153/1780 [=>............................] - ETA: 11:39 - accuracy: 0.9967 - loss: 0.0109\n",
      "Batch 17954: setting learning rate to 7.359174432680955e-06.\n",
      " 154/1780 [=>............................] - ETA: 11:38 - accuracy: 0.9968 - loss: 0.0109\n",
      "Batch 17955: setting learning rate to 7.358860100956744e-06.\n",
      " 155/1780 [=>............................] - ETA: 11:38 - accuracy: 0.9967 - loss: 0.0112\n",
      "Batch 17956: setting learning rate to 7.358545757240486e-06.\n",
      " 156/1780 [=>............................] - ETA: 11:37 - accuracy: 0.9967 - loss: 0.0112\n",
      "Batch 17957: setting learning rate to 7.3582314015337815e-06.\n",
      " 157/1780 [=>............................] - ETA: 11:37 - accuracy: 0.9967 - loss: 0.0111\n",
      "Batch 17958: setting learning rate to 7.357917033838229e-06.\n",
      " 158/1780 [=>............................] - ETA: 11:36 - accuracy: 0.9967 - loss: 0.0111\n",
      "Batch 17959: setting learning rate to 7.3576026541554265e-06.\n",
      " 159/1780 [=>............................] - ETA: 11:35 - accuracy: 0.9968 - loss: 0.0110\n",
      "Batch 17960: setting learning rate to 7.357288262486973e-06.\n",
      " 160/1780 [=>............................] - ETA: 11:35 - accuracy: 0.9968 - loss: 0.0110\n",
      "Batch 17961: setting learning rate to 7.356973858834465e-06.\n",
      " 161/1780 [=>............................] - ETA: 11:34 - accuracy: 0.9968 - loss: 0.0109\n",
      "Batch 17962: setting learning rate to 7.356659443199502e-06.\n",
      " 162/1780 [=>............................] - ETA: 11:33 - accuracy: 0.9968 - loss: 0.0108\n",
      "Batch 17963: setting learning rate to 7.356345015583682e-06.\n",
      " 163/1780 [=>............................] - ETA: 11:33 - accuracy: 0.9968 - loss: 0.0108\n",
      "Batch 17964: setting learning rate to 7.356030575988604e-06.\n",
      " 164/1780 [=>............................] - ETA: 11:32 - accuracy: 0.9969 - loss: 0.0107\n",
      "Batch 17965: setting learning rate to 7.355716124415867e-06.\n",
      " 165/1780 [=>............................] - ETA: 11:32 - accuracy: 0.9969 - loss: 0.0106\n",
      "Batch 17966: setting learning rate to 7.355401660867068e-06.\n",
      " 166/1780 [=>............................] - ETA: 11:31 - accuracy: 0.9969 - loss: 0.0106\n",
      "Batch 17967: setting learning rate to 7.355087185343808e-06.\n",
      " 167/1780 [=>............................] - ETA: 11:30 - accuracy: 0.9969 - loss: 0.0105\n",
      "Batch 17968: setting learning rate to 7.354772697847683e-06.\n",
      " 168/1780 [=>............................] - ETA: 11:30 - accuracy: 0.9969 - loss: 0.0105\n",
      "Batch 17969: setting learning rate to 7.354458198380294e-06.\n",
      " 169/1780 [=>............................] - ETA: 11:29 - accuracy: 0.9969 - loss: 0.0105\n",
      "Batch 17970: setting learning rate to 7.354143686943238e-06.\n",
      " 170/1780 [=>............................] - ETA: 11:29 - accuracy: 0.9970 - loss: 0.0104\n",
      "Batch 17971: setting learning rate to 7.3538291635381165e-06.\n",
      " 171/1780 [=>............................] - ETA: 11:28 - accuracy: 0.9970 - loss: 0.0103\n",
      "Batch 17972: setting learning rate to 7.353514628166527e-06.\n",
      " 172/1780 [=>............................] - ETA: 11:28 - accuracy: 0.9970 - loss: 0.0103\n",
      "Batch 17973: setting learning rate to 7.353200080830067e-06.\n",
      " 173/1780 [=>............................] - ETA: 11:27 - accuracy: 0.9969 - loss: 0.0103\n",
      "Batch 17974: setting learning rate to 7.352885521530337e-06.\n",
      " 174/1780 [=>............................] - ETA: 11:27 - accuracy: 0.9969 - loss: 0.0103\n",
      "Batch 17975: setting learning rate to 7.352570950268938e-06.\n",
      " 175/1780 [=>............................] - ETA: 11:26 - accuracy: 0.9970 - loss: 0.0102\n",
      "Batch 17976: setting learning rate to 7.3522563670474666e-06.\n",
      " 176/1780 [=>............................] - ETA: 11:25 - accuracy: 0.9970 - loss: 0.0102\n",
      "Batch 17977: setting learning rate to 7.351941771867523e-06.\n",
      " 177/1780 [=>............................] - ETA: 11:25 - accuracy: 0.9969 - loss: 0.0102\n",
      "Batch 17978: setting learning rate to 7.351627164730706e-06.\n",
      " 178/1780 [==>...........................] - ETA: 11:24 - accuracy: 0.9968 - loss: 0.0103\n",
      "Batch 17979: setting learning rate to 7.351312545638617e-06.\n",
      " 179/1780 [==>...........................] - ETA: 11:24 - accuracy: 0.9968 - loss: 0.0103\n",
      "Batch 17980: setting learning rate to 7.350997914592853e-06.\n",
      " 180/1780 [==>...........................] - ETA: 11:23 - accuracy: 0.9968 - loss: 0.0102\n",
      "Batch 17981: setting learning rate to 7.350683271595014e-06.\n",
      " 181/1780 [==>...........................] - ETA: 11:22 - accuracy: 0.9968 - loss: 0.0102\n",
      "Batch 17982: setting learning rate to 7.350368616646702e-06.\n",
      " 182/1780 [==>...........................] - ETA: 11:22 - accuracy: 0.9968 - loss: 0.0102\n",
      "Batch 17983: setting learning rate to 7.350053949749514e-06.\n",
      " 183/1780 [==>...........................] - ETA: 11:21 - accuracy: 0.9968 - loss: 0.0101\n",
      "Batch 17984: setting learning rate to 7.349739270905048e-06.\n",
      " 184/1780 [==>...........................] - ETA: 11:20 - accuracy: 0.9969 - loss: 0.0101\n",
      "Batch 17985: setting learning rate to 7.349424580114909e-06.\n",
      " 185/1780 [==>...........................] - ETA: 11:20 - accuracy: 0.9968 - loss: 0.0102\n",
      "Batch 17986: setting learning rate to 7.3491098773806945e-06.\n",
      " 186/1780 [==>...........................] - ETA: 11:19 - accuracy: 0.9968 - loss: 0.0101\n",
      "Batch 17987: setting learning rate to 7.348795162704002e-06.\n",
      " 187/1780 [==>...........................] - ETA: 11:19 - accuracy: 0.9968 - loss: 0.0101\n",
      "Batch 17988: setting learning rate to 7.348480436086434e-06.\n",
      " 188/1780 [==>...........................] - ETA: 11:18 - accuracy: 0.9968 - loss: 0.0100\n",
      "Batch 17989: setting learning rate to 7.34816569752959e-06.\n",
      " 189/1780 [==>...........................] - ETA: 11:18 - accuracy: 0.9968 - loss: 0.0101\n",
      "Batch 17990: setting learning rate to 7.347850947035071e-06.\n",
      " 190/1780 [==>...........................] - ETA: 11:17 - accuracy: 0.9968 - loss: 0.0101\n",
      "Batch 17991: setting learning rate to 7.347536184604476e-06.\n",
      " 191/1780 [==>...........................] - ETA: 11:17 - accuracy: 0.9968 - loss: 0.0100\n",
      "Batch 17992: setting learning rate to 7.347221410239405e-06.\n",
      " 192/1780 [==>...........................] - ETA: 11:16 - accuracy: 0.9968 - loss: 0.0100\n",
      "Batch 17993: setting learning rate to 7.346906623941459e-06.\n",
      " 193/1780 [==>...........................] - ETA: 11:16 - accuracy: 0.9968 - loss: 0.0099\n",
      "Batch 17994: setting learning rate to 7.346591825712237e-06.\n",
      " 194/1780 [==>...........................] - ETA: 11:15 - accuracy: 0.9969 - loss: 0.0099\n",
      "Batch 17995: setting learning rate to 7.34627701555334e-06.\n",
      " 195/1780 [==>...........................] - ETA: 11:15 - accuracy: 0.9969 - loss: 0.0098\n",
      "Batch 17996: setting learning rate to 7.345962193466371e-06.\n",
      " 196/1780 [==>...........................] - ETA: 11:14 - accuracy: 0.9968 - loss: 0.0099\n",
      "Batch 17997: setting learning rate to 7.345647359452926e-06.\n",
      " 197/1780 [==>...........................] - ETA: 11:13 - accuracy: 0.9968 - loss: 0.0098\n",
      "Batch 17998: setting learning rate to 7.345332513514609e-06.\n",
      " 198/1780 [==>...........................] - ETA: 11:13 - accuracy: 0.9968 - loss: 0.0098\n",
      "Batch 17999: setting learning rate to 7.34501765565302e-06.\n",
      " 199/1780 [==>...........................] - ETA: 11:12 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18000: setting learning rate to 7.344702785869759e-06.\n",
      " 200/1780 [==>...........................] - ETA: 11:12 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18001: setting learning rate to 7.3443879041664256e-06.\n",
      " 201/1780 [==>...........................] - ETA: 11:11 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18002: setting learning rate to 7.344073010544623e-06.\n",
      " 202/1780 [==>...........................] - ETA: 11:11 - accuracy: 0.9968 - loss: 0.0098\n",
      "Batch 18003: setting learning rate to 7.343758105005951e-06.\n",
      " 203/1780 [==>...........................] - ETA: 11:10 - accuracy: 0.9968 - loss: 0.0098\n",
      "Batch 18004: setting learning rate to 7.3434431875520104e-06.\n",
      " 204/1780 [==>...........................] - ETA: 11:09 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18005: setting learning rate to 7.343128258184402e-06.\n",
      " 205/1780 [==>...........................] - ETA: 11:09 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18006: setting learning rate to 7.342813316904729e-06.\n",
      " 206/1780 [==>...........................] - ETA: 11:08 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18007: setting learning rate to 7.342498363714589e-06.\n",
      " 207/1780 [==>...........................] - ETA: 11:08 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18008: setting learning rate to 7.342183398615584e-06.\n",
      " 208/1780 [==>...........................] - ETA: 11:07 - accuracy: 0.9968 - loss: 0.0096\n",
      "Batch 18009: setting learning rate to 7.341868421609316e-06.\n",
      " 209/1780 [==>...........................] - ETA: 11:07 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18010: setting learning rate to 7.341553432697388e-06.\n",
      " 210/1780 [==>...........................] - ETA: 11:06 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18011: setting learning rate to 7.341238431881399e-06.\n",
      " 211/1780 [==>...........................] - ETA: 11:06 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18012: setting learning rate to 7.340923419162951e-06.\n",
      " 212/1780 [==>...........................] - ETA: 11:05 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18013: setting learning rate to 7.3406083945436455e-06.\n",
      " 213/1780 [==>...........................] - ETA: 11:05 - accuracy: 0.9968 - loss: 0.0096\n",
      "Batch 18014: setting learning rate to 7.3402933580250846e-06.\n",
      " 214/1780 [==>...........................] - ETA: 11:04 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18015: setting learning rate to 7.3399783096088685e-06.\n",
      " 215/1780 [==>...........................] - ETA: 11:04 - accuracy: 0.9968 - loss: 0.0096\n",
      "Batch 18016: setting learning rate to 7.339663249296601e-06.\n",
      " 216/1780 [==>...........................] - ETA: 11:03 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18017: setting learning rate to 7.33934817708988e-06.\n",
      " 217/1780 [==>...........................] - ETA: 11:03 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18018: setting learning rate to 7.339033092990312e-06.\n",
      " 218/1780 [==>...........................] - ETA: 11:02 - accuracy: 0.9968 - loss: 0.0097\n",
      "Batch 18019: setting learning rate to 7.338717996999496e-06.\n",
      " 219/1780 [==>...........................] - ETA: 11:02 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18020: setting learning rate to 7.338402889119035e-06.\n",
      " 220/1780 [==>...........................] - ETA: 11:01 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18021: setting learning rate to 7.33808776935053e-06.\n",
      " 221/1780 [==>...........................] - ETA: 11:01 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18022: setting learning rate to 7.3377726376955835e-06.\n",
      " 222/1780 [==>...........................] - ETA: 11:00 - accuracy: 0.9969 - loss: 0.0096\n",
      "Batch 18023: setting learning rate to 7.3374574941558e-06.\n",
      " 223/1780 [==>...........................] - ETA: 10:59 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18024: setting learning rate to 7.337142338732776e-06.\n",
      " 224/1780 [==>...........................] - ETA: 10:59 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18025: setting learning rate to 7.336827171428118e-06.\n",
      " 225/1780 [==>...........................] - ETA: 10:59 - accuracy: 0.9969 - loss: 0.0098\n",
      "Batch 18026: setting learning rate to 7.3365119922434265e-06.\n",
      " 226/1780 [==>...........................] - ETA: 10:58 - accuracy: 0.9970 - loss: 0.0097\n",
      "Batch 18027: setting learning rate to 7.336196801180306e-06.\n",
      " 227/1780 [==>...........................] - ETA: 10:57 - accuracy: 0.9970 - loss: 0.0097\n",
      "Batch 18028: setting learning rate to 7.335881598240357e-06.\n",
      " 228/1780 [==>...........................] - ETA: 10:57 - accuracy: 0.9969 - loss: 0.0098\n",
      "Batch 18029: setting learning rate to 7.335566383425182e-06.\n",
      " 229/1780 [==>...........................] - ETA: 10:57 - accuracy: 0.9969 - loss: 0.0098\n",
      "Batch 18030: setting learning rate to 7.335251156736385e-06.\n",
      " 230/1780 [==>...........................] - ETA: 10:56 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18031: setting learning rate to 7.334935918175566e-06.\n",
      " 231/1780 [==>...........................] - ETA: 10:56 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18032: setting learning rate to 7.334620667744329e-06.\n",
      " 232/1780 [==>...........................] - ETA: 10:55 - accuracy: 0.9969 - loss: 0.0098\n",
      "Batch 18033: setting learning rate to 7.3343054054442775e-06.\n",
      " 233/1780 [==>...........................] - ETA: 10:55 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18034: setting learning rate to 7.333990131277013e-06.\n",
      " 234/1780 [==>...........................] - ETA: 10:54 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18035: setting learning rate to 7.3336748452441385e-06.\n",
      " 235/1780 [==>...........................] - ETA: 10:54 - accuracy: 0.9969 - loss: 0.0097\n",
      "Batch 18036: setting learning rate to 7.333359547347257e-06.\n",
      " 236/1780 [==>...........................] - ETA: 10:53 - accuracy: 0.9968 - loss: 0.0099\n",
      "Batch 18037: setting learning rate to 7.333044237587973e-06.\n",
      " 237/1780 [==>...........................] - ETA: 10:53 - accuracy: 0.9968 - loss: 0.0099\n",
      "Batch 18038: setting learning rate to 7.332728915967886e-06.\n",
      " 238/1780 [===>..........................] - ETA: 10:52 - accuracy: 0.9968 - loss: 0.0098\n",
      "Batch 18039: setting learning rate to 7.332413582488602e-06.\n",
      " 239/1780 [===>..........................] - ETA: 10:52 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18040: setting learning rate to 7.332098237151722e-06.\n",
      " 240/1780 [===>..........................] - ETA: 10:51 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18041: setting learning rate to 7.3317828799588516e-06.\n",
      " 241/1780 [===>..........................] - ETA: 10:51 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18042: setting learning rate to 7.331467510911593e-06.\n",
      " 242/1780 [===>..........................] - ETA: 10:50 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18043: setting learning rate to 7.3311521300115484e-06.\n",
      " 243/1780 [===>..........................] - ETA: 10:50 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18044: setting learning rate to 7.330836737260322e-06.\n",
      " 244/1780 [===>..........................] - ETA: 10:49 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18045: setting learning rate to 7.330521332659517e-06.\n",
      " 245/1780 [===>..........................] - ETA: 10:49 - accuracy: 0.9967 - loss: 0.0100\n",
      "Batch 18046: setting learning rate to 7.330205916210736e-06.\n",
      " 246/1780 [===>..........................] - ETA: 10:48 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18047: setting learning rate to 7.3298904879155865e-06.\n",
      " 247/1780 [===>..........................] - ETA: 10:47 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18048: setting learning rate to 7.329575047775667e-06.\n",
      " 248/1780 [===>..........................] - ETA: 10:47 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18049: setting learning rate to 7.3292595957925835e-06.\n",
      " 249/1780 [===>..........................] - ETA: 10:47 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18050: setting learning rate to 7.32894413196794e-06.\n",
      " 250/1780 [===>..........................] - ETA: 10:46 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18051: setting learning rate to 7.32862865630334e-06.\n",
      " 251/1780 [===>..........................] - ETA: 10:45 - accuracy: 0.9966 - loss: 0.0099\n",
      "Batch 18052: setting learning rate to 7.328313168800385e-06.\n",
      " 252/1780 [===>..........................] - ETA: 10:45 - accuracy: 0.9967 - loss: 0.0099\n",
      "Batch 18053: setting learning rate to 7.3279976694606825e-06.\n",
      " 253/1780 [===>..........................] - ETA: 10:44 - accuracy: 0.9967 - loss: 0.0098\n",
      "Batch 18054: setting learning rate to 7.327682158285836e-06.\n",
      " 254/1780 [===>..........................] - ETA: 10:44 - accuracy: 0.9967 - loss: 0.0098\n",
      "Batch 18055: setting learning rate to 7.327366635277446e-06.\n",
      " 255/1780 [===>..........................] - ETA: 10:43 - accuracy: 0.9966 - loss: 0.0104\n",
      "Batch 18056: setting learning rate to 7.3270511004371204e-06.\n",
      " 256/1780 [===>..........................] - ETA: 10:43 - accuracy: 0.9965 - loss: 0.0104\n",
      "Batch 18057: setting learning rate to 7.326735553766462e-06.\n",
      " 257/1780 [===>..........................] - ETA: 10:42 - accuracy: 0.9965 - loss: 0.0104\n",
      "Batch 18058: setting learning rate to 7.326419995267074e-06.\n",
      " 258/1780 [===>..........................] - ETA: 10:42 - accuracy: 0.9965 - loss: 0.0104\n",
      "Batch 18059: setting learning rate to 7.326104424940562e-06.\n",
      " 259/1780 [===>..........................] - ETA: 10:41 - accuracy: 0.9964 - loss: 0.0105\n",
      "Batch 18060: setting learning rate to 7.32578884278853e-06.\n",
      " 260/1780 [===>..........................] - ETA: 10:41 - accuracy: 0.9965 - loss: 0.0104\n",
      "Batch 18061: setting learning rate to 7.325473248812582e-06.\n",
      " 261/1780 [===>..........................] - ETA: 10:40 - accuracy: 0.9965 - loss: 0.0104\n",
      "Batch 18062: setting learning rate to 7.325157643014324e-06.\n",
      " 262/1780 [===>..........................] - ETA: 10:40 - accuracy: 0.9964 - loss: 0.0105\n",
      "Batch 18063: setting learning rate to 7.324842025395357e-06.\n",
      " 263/1780 [===>..........................] - ETA: 10:39 - accuracy: 0.9964 - loss: 0.0105\n",
      "Batch 18064: setting learning rate to 7.324526395957289e-06.\n",
      " 264/1780 [===>..........................] - ETA: 10:39 - accuracy: 0.9964 - loss: 0.0105\n",
      "Batch 18065: setting learning rate to 7.324210754701722e-06.\n",
      " 265/1780 [===>..........................] - ETA: 10:38 - accuracy: 0.9963 - loss: 0.0105\n",
      "Batch 18066: setting learning rate to 7.323895101630263e-06.\n",
      " 266/1780 [===>..........................] - ETA: 10:38 - accuracy: 0.9964 - loss: 0.0104\n",
      "Batch 18067: setting learning rate to 7.323579436744515e-06.\n",
      " 267/1780 [===>..........................] - ETA: 10:38 - accuracy: 0.9964 - loss: 0.0104\n",
      "Batch 18068: setting learning rate to 7.3232637600460825e-06.\n",
      " 268/1780 [===>..........................] - ETA: 10:37 - accuracy: 0.9964 - loss: 0.0104\n",
      "Batch 18069: setting learning rate to 7.322948071536573e-06.\n",
      " 269/1780 [===>..........................] - ETA: 10:37 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18070: setting learning rate to 7.322632371217588e-06.\n",
      " 270/1780 [===>..........................] - ETA: 10:36 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18071: setting learning rate to 7.322316659090736e-06.\n",
      " 271/1780 [===>..........................] - ETA: 10:36 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18072: setting learning rate to 7.322000935157619e-06.\n",
      " 272/1780 [===>..........................] - ETA: 10:35 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18073: setting learning rate to 7.321685199419844e-06.\n",
      " 273/1780 [===>..........................] - ETA: 10:35 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18074: setting learning rate to 7.321369451879015e-06.\n",
      " 274/1780 [===>..........................] - ETA: 10:34 - accuracy: 0.9964 - loss: 0.0104\n",
      "Batch 18075: setting learning rate to 7.321053692536738e-06.\n",
      " 275/1780 [===>..........................] - ETA: 10:34 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18076: setting learning rate to 7.320737921394617e-06.\n",
      " 276/1780 [===>..........................] - ETA: 10:33 - accuracy: 0.9964 - loss: 0.0104\n",
      "Batch 18077: setting learning rate to 7.320422138454259e-06.\n",
      " 277/1780 [===>..........................] - ETA: 10:33 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18078: setting learning rate to 7.3201063437172695e-06.\n",
      " 278/1780 [===>..........................] - ETA: 10:32 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18079: setting learning rate to 7.319790537185252e-06.\n",
      " 279/1780 [===>..........................] - ETA: 10:32 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18080: setting learning rate to 7.319474718859813e-06.\n",
      " 280/1780 [===>..........................] - ETA: 10:32 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18081: setting learning rate to 7.319158888742558e-06.\n",
      " 281/1780 [===>..........................] - ETA: 10:31 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18082: setting learning rate to 7.318843046835092e-06.\n",
      " 282/1780 [===>..........................] - ETA: 10:31 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18083: setting learning rate to 7.318527193139022e-06.\n",
      " 283/1780 [===>..........................] - ETA: 10:30 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18084: setting learning rate to 7.318211327655955e-06.\n",
      " 284/1780 [===>..........................] - ETA: 10:30 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18085: setting learning rate to 7.317895450387493e-06.\n",
      " 285/1780 [===>..........................] - ETA: 10:29 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18086: setting learning rate to 7.317579561335244e-06.\n",
      " 286/1780 [===>..........................] - ETA: 10:29 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18087: setting learning rate to 7.317263660500815e-06.\n",
      " 287/1780 [===>..........................] - ETA: 10:28 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18088: setting learning rate to 7.31694774788581e-06.\n",
      " 288/1780 [===>..........................] - ETA: 10:28 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18089: setting learning rate to 7.316631823491835e-06.\n",
      " 289/1780 [===>..........................] - ETA: 10:27 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18090: setting learning rate to 7.316315887320497e-06.\n",
      " 290/1780 [===>..........................] - ETA: 10:27 - accuracy: 0.9963 - loss: 0.0102\n",
      "Batch 18091: setting learning rate to 7.315999939373404e-06.\n",
      " 291/1780 [===>..........................] - ETA: 10:26 - accuracy: 0.9963 - loss: 0.0102\n",
      "Batch 18092: setting learning rate to 7.315683979652159e-06.\n",
      " 292/1780 [===>..........................] - ETA: 10:26 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18093: setting learning rate to 7.31536800815837e-06.\n",
      " 293/1780 [===>..........................] - ETA: 10:25 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18094: setting learning rate to 7.315052024893642e-06.\n",
      " 294/1780 [===>..........................] - ETA: 10:25 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18095: setting learning rate to 7.314736029859582e-06.\n",
      " 295/1780 [===>..........................] - ETA: 10:24 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18096: setting learning rate to 7.314420023057797e-06.\n",
      " 296/1780 [===>..........................] - ETA: 10:24 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18097: setting learning rate to 7.314104004489896e-06.\n",
      " 297/1780 [====>.........................] - ETA: 10:23 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18098: setting learning rate to 7.31378797415748e-06.\n",
      " 298/1780 [====>.........................] - ETA: 10:23 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18099: setting learning rate to 7.313471932062159e-06.\n",
      " 299/1780 [====>.........................] - ETA: 10:22 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18100: setting learning rate to 7.31315587820554e-06.\n",
      " 300/1780 [====>.........................] - ETA: 10:22 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18101: setting learning rate to 7.31283981258923e-06.\n",
      " 301/1780 [====>.........................] - ETA: 10:21 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18102: setting learning rate to 7.312523735214834e-06.\n",
      " 302/1780 [====>.........................] - ETA: 10:21 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18103: setting learning rate to 7.31220764608396e-06.\n",
      " 303/1780 [====>.........................] - ETA: 10:20 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18104: setting learning rate to 7.3118915451982146e-06.\n",
      " 304/1780 [====>.........................] - ETA: 10:20 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18105: setting learning rate to 7.311575432559204e-06.\n",
      " 305/1780 [====>.........................] - ETA: 10:19 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18106: setting learning rate to 7.311259308168536e-06.\n",
      " 306/1780 [====>.........................] - ETA: 10:19 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18107: setting learning rate to 7.3109431720278175e-06.\n",
      " 307/1780 [====>.........................] - ETA: 10:18 - accuracy: 0.9964 - loss: 0.0100\n",
      "Batch 18108: setting learning rate to 7.310627024138659e-06.\n",
      " 308/1780 [====>.........................] - ETA: 10:18 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18109: setting learning rate to 7.310310864502662e-06.\n",
      " 309/1780 [====>.........................] - ETA: 10:17 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18110: setting learning rate to 7.309994693121437e-06.\n",
      " 310/1780 [====>.........................] - ETA: 10:17 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18111: setting learning rate to 7.309678509996593e-06.\n",
      " 311/1780 [====>.........................] - ETA: 10:17 - accuracy: 0.9964 - loss: 0.0102\n",
      "Batch 18112: setting learning rate to 7.309362315129733e-06.\n",
      " 312/1780 [====>.........................] - ETA: 10:16 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18113: setting learning rate to 7.3090461085224675e-06.\n",
      " 313/1780 [====>.........................] - ETA: 10:16 - accuracy: 0.9965 - loss: 0.0101\n",
      "Batch 18114: setting learning rate to 7.308729890176404e-06.\n",
      " 314/1780 [====>.........................] - ETA: 10:15 - accuracy: 0.9965 - loss: 0.0101\n",
      "Batch 18115: setting learning rate to 7.30841366009315e-06.\n",
      " 315/1780 [====>.........................] - ETA: 10:15 - accuracy: 0.9964 - loss: 0.0101\n",
      "Batch 18116: setting learning rate to 7.308097418274312e-06.\n",
      " 316/1780 [====>.........................] - ETA: 10:14 - accuracy: 0.9964 - loss: 0.0100\n",
      "Batch 18117: setting learning rate to 7.307781164721497e-06.\n",
      " 317/1780 [====>.........................] - ETA: 10:14 - accuracy: 0.9965 - loss: 0.0100\n",
      "Batch 18118: setting learning rate to 7.307464899436317e-06.\n",
      " 318/1780 [====>.........................] - ETA: 10:13 - accuracy: 0.9965 - loss: 0.0100\n",
      "Batch 18119: setting learning rate to 7.3071486224203734e-06.\n",
      " 319/1780 [====>.........................] - ETA: 10:13 - accuracy: 0.9965 - loss: 0.0100\n",
      "Batch 18120: setting learning rate to 7.30683233367528e-06.\n",
      " 320/1780 [====>.........................] - ETA: 10:12 - accuracy: 0.9965 - loss: 0.0100\n",
      "Batch 18121: setting learning rate to 7.306516033202642e-06.\n",
      " 321/1780 [====>.........................] - ETA: 10:12 - accuracy: 0.9965 - loss: 0.0099\n",
      "Batch 18122: setting learning rate to 7.306199721004068e-06.\n",
      " 322/1780 [====>.........................] - ETA: 10:12 - accuracy: 0.9965 - loss: 0.0099\n",
      "Batch 18123: setting learning rate to 7.305883397081165e-06.\n",
      " 323/1780 [====>.........................] - ETA: 10:11 - accuracy: 0.9965 - loss: 0.0099\n",
      "Batch 18124: setting learning rate to 7.305567061435543e-06.\n",
      " 324/1780 [====>.........................] - ETA: 10:11 - accuracy: 0.9965 - loss: 0.0099\n",
      "Batch 18125: setting learning rate to 7.30525071406881e-06.\n",
      " 325/1780 [====>.........................] - ETA: 10:10 - accuracy: 0.9965 - loss: 0.0098\n",
      "Batch 18126: setting learning rate to 7.304934354982573e-06.\n",
      " 326/1780 [====>.........................] - ETA: 10:10 - accuracy: 0.9965 - loss: 0.0098\n",
      "Batch 18127: setting learning rate to 7.3046179841784405e-06.\n",
      " 327/1780 [====>.........................] - ETA: 10:09 - accuracy: 0.9965 - loss: 0.0099\n",
      "Batch 18128: setting learning rate to 7.304301601658022e-06.\n",
      " 328/1780 [====>.........................] - ETA: 10:09 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18129: setting learning rate to 7.3039852074229245e-06.\n",
      " 329/1780 [====>.........................] - ETA: 10:08 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18130: setting learning rate to 7.303668801474757e-06.\n",
      " 330/1780 [====>.........................] - ETA: 10:08 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18131: setting learning rate to 7.303352383815129e-06.\n",
      " 331/1780 [====>.........................] - ETA: 10:08 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18132: setting learning rate to 7.303035954445648e-06.\n",
      " 332/1780 [====>.........................] - ETA: 10:07 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18133: setting learning rate to 7.302719513367922e-06.\n",
      " 333/1780 [====>.........................] - ETA: 10:07 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18134: setting learning rate to 7.302403060583562e-06.\n",
      " 334/1780 [====>.........................] - ETA: 10:06 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18135: setting learning rate to 7.302086596094176e-06.\n",
      " 335/1780 [====>.........................] - ETA: 10:06 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18136: setting learning rate to 7.301770119901372e-06.\n",
      " 336/1780 [====>.........................] - ETA: 10:05 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18137: setting learning rate to 7.3014536320067575e-06.\n",
      " 337/1780 [====>.........................] - ETA: 10:05 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18138: setting learning rate to 7.301137132411946e-06.\n",
      " 338/1780 [====>.........................] - ETA: 10:04 - accuracy: 0.9964 - loss: 0.0098\n",
      "Batch 18139: setting learning rate to 7.300820621118542e-06.\n",
      " 339/1780 [====>.........................] - ETA: 10:04 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18140: setting learning rate to 7.300504098128156e-06.\n",
      " 340/1780 [====>.........................] - ETA: 10:03 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18141: setting learning rate to 7.3001875634423976e-06.\n",
      " 341/1780 [====>.........................] - ETA: 10:03 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18142: setting learning rate to 7.299871017062878e-06.\n",
      " 342/1780 [====>.........................] - ETA: 10:03 - accuracy: 0.9964 - loss: 0.0098\n",
      "Batch 18143: setting learning rate to 7.299554458991202e-06.\n",
      " 343/1780 [====>.........................] - ETA: 10:02 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18144: setting learning rate to 7.299237889228983e-06.\n",
      " 344/1780 [====>.........................] - ETA: 10:02 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18145: setting learning rate to 7.298921307777829e-06.\n",
      " 345/1780 [====>.........................] - ETA: 10:01 - accuracy: 0.9964 - loss: 0.0100\n",
      "Batch 18146: setting learning rate to 7.298604714639348e-06.\n",
      " 346/1780 [====>.........................] - ETA: 10:01 - accuracy: 0.9964 - loss: 0.0100\n",
      "Batch 18147: setting learning rate to 7.2982881098151515e-06.\n",
      " 347/1780 [====>.........................] - ETA: 10:00 - accuracy: 0.9964 - loss: 0.0100\n",
      "Batch 18148: setting learning rate to 7.297971493306848e-06.\n",
      " 348/1780 [====>.........................] - ETA: 10:00 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18149: setting learning rate to 7.2976548651160466e-06.\n",
      " 349/1780 [====>.........................] - ETA: 9:59 - accuracy: 0.9964 - loss: 0.0099 \n",
      "Batch 18150: setting learning rate to 7.2973382252443585e-06.\n",
      " 350/1780 [====>.........................] - ETA: 9:59 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18151: setting learning rate to 7.297021573693391e-06.\n",
      " 351/1780 [====>.........................] - ETA: 9:58 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18152: setting learning rate to 7.296704910464758e-06.\n",
      " 352/1780 [====>.........................] - ETA: 9:58 - accuracy: 0.9964 - loss: 0.0099\n",
      "Batch 18153: setting learning rate to 7.2963882355600666e-06.\n",
      " 353/1780 [====>.........................] - ETA: 9:57 - accuracy: 0.9965 - loss: 0.0098\n",
      "Batch 18154: setting learning rate to 7.296071548980926e-06.\n",
      " 354/1780 [====>.........................] - ETA: 9:57 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18155: setting learning rate to 7.295754850728949e-06.\n",
      " 355/1780 [====>.........................] - ETA: 9:57 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18156: setting learning rate to 7.295438140805742e-06.\n",
      " 356/1780 [=====>........................] - ETA: 9:56 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18157: setting learning rate to 7.295121419212918e-06.\n",
      " 357/1780 [=====>........................] - ETA: 9:56 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18158: setting learning rate to 7.294804685952086e-06.\n",
      " 358/1780 [=====>........................] - ETA: 9:55 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18159: setting learning rate to 7.2944879410248574e-06.\n",
      " 359/1780 [=====>........................] - ETA: 9:55 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18160: setting learning rate to 7.294171184432839e-06.\n",
      " 360/1780 [=====>........................] - ETA: 9:54 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18161: setting learning rate to 7.293854416177644e-06.\n",
      " 361/1780 [=====>........................] - ETA: 9:54 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18162: setting learning rate to 7.293537636260886e-06.\n",
      " 362/1780 [=====>........................] - ETA: 9:54 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18163: setting learning rate to 7.293220844684168e-06.\n",
      " 363/1780 [=====>........................] - ETA: 9:53 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18164: setting learning rate to 7.292904041449106e-06.\n",
      " 364/1780 [=====>........................] - ETA: 9:53 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18165: setting learning rate to 7.292587226557308e-06.\n",
      " 365/1780 [=====>........................] - ETA: 9:52 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18166: setting learning rate to 7.292270400010386e-06.\n",
      " 366/1780 [=====>........................] - ETA: 9:52 - accuracy: 0.9964 - loss: 0.0103\n",
      "Batch 18167: setting learning rate to 7.29195356180995e-06.\n",
      " 367/1780 [=====>........................] - ETA: 9:51 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18168: setting learning rate to 7.291636711957611e-06.\n",
      " 368/1780 [=====>........................] - ETA: 9:51 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18169: setting learning rate to 7.291319850454982e-06.\n",
      " 369/1780 [=====>........................] - ETA: 9:50 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18170: setting learning rate to 7.291002977303669e-06.\n",
      " 370/1780 [=====>........................] - ETA: 9:50 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18171: setting learning rate to 7.290686092505287e-06.\n",
      " 371/1780 [=====>........................] - ETA: 9:50 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18172: setting learning rate to 7.290369196061444e-06.\n",
      " 372/1780 [=====>........................] - ETA: 9:49 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18173: setting learning rate to 7.290052287973754e-06.\n",
      " 373/1780 [=====>........................] - ETA: 9:49 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18174: setting learning rate to 7.289735368243828e-06.\n",
      " 374/1780 [=====>........................] - ETA: 9:48 - accuracy: 0.9963 - loss: 0.0103\n",
      "Batch 18175: setting learning rate to 7.289418436873274e-06.\n",
      " 375/1780 [=====>........................] - ETA: 9:48 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18176: setting learning rate to 7.289101493863705e-06.\n",
      " 376/1780 [=====>........................] - ETA: 9:47 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18177: setting learning rate to 7.288784539216733e-06.\n",
      " 377/1780 [=====>........................] - ETA: 9:47 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18178: setting learning rate to 7.2884675729339685e-06.\n",
      " 378/1780 [=====>........................] - ETA: 9:46 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18179: setting learning rate to 7.288150595017025e-06.\n",
      " 379/1780 [=====>........................] - ETA: 9:46 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18180: setting learning rate to 7.28783360546751e-06.\n",
      " 380/1780 [=====>........................] - ETA: 9:46 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18181: setting learning rate to 7.287516604287037e-06.\n",
      " 381/1780 [=====>........................] - ETA: 9:45 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18182: setting learning rate to 7.287199591477219e-06.\n",
      " 382/1780 [=====>........................] - ETA: 9:45 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18183: setting learning rate to 7.286882567039667e-06.\n",
      " 383/1780 [=====>........................] - ETA: 9:44 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18184: setting learning rate to 7.286565530975991e-06.\n",
      " 384/1780 [=====>........................] - ETA: 9:44 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18185: setting learning rate to 7.286248483287804e-06.\n",
      " 385/1780 [=====>........................] - ETA: 9:43 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18186: setting learning rate to 7.285931423976717e-06.\n",
      " 386/1780 [=====>........................] - ETA: 9:43 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18187: setting learning rate to 7.285614353044344e-06.\n",
      " 387/1780 [=====>........................] - ETA: 9:42 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18188: setting learning rate to 7.285297270492294e-06.\n",
      " 388/1780 [=====>........................] - ETA: 9:42 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18189: setting learning rate to 7.284980176322183e-06.\n",
      " 389/1780 [=====>........................] - ETA: 9:42 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18190: setting learning rate to 7.284663070535618e-06.\n",
      " 390/1780 [=====>........................] - ETA: 9:41 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18191: setting learning rate to 7.284345953134213e-06.\n",
      " 391/1780 [=====>........................] - ETA: 9:41 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18192: setting learning rate to 7.284028824119584e-06.\n",
      " 392/1780 [=====>........................] - ETA: 9:40 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18193: setting learning rate to 7.283711683493338e-06.\n",
      " 393/1780 [=====>........................] - ETA: 9:40 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18194: setting learning rate to 7.283394531257088e-06.\n",
      " 394/1780 [=====>........................] - ETA: 9:39 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18195: setting learning rate to 7.28307736741245e-06.\n",
      " 395/1780 [=====>........................] - ETA: 9:39 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18196: setting learning rate to 7.2827601919610335e-06.\n",
      " 396/1780 [=====>........................] - ETA: 9:38 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18197: setting learning rate to 7.282443004904451e-06.\n",
      " 397/1780 [=====>........................] - ETA: 9:38 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18198: setting learning rate to 7.2821258062443156e-06.\n",
      " 398/1780 [=====>........................] - ETA: 9:37 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18199: setting learning rate to 7.281808595982241e-06.\n",
      " 399/1780 [=====>........................] - ETA: 9:37 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18200: setting learning rate to 7.2814913741198364e-06.\n",
      " 400/1780 [=====>........................] - ETA: 9:36 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18201: setting learning rate to 7.2811741406587185e-06.\n",
      " 401/1780 [=====>........................] - ETA: 9:36 - accuracy: 0.9961 - loss: 0.0104\n",
      "Batch 18202: setting learning rate to 7.280856895600499e-06.\n",
      " 402/1780 [=====>........................] - ETA: 9:36 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18203: setting learning rate to 7.280539638946789e-06.\n",
      " 403/1780 [=====>........................] - ETA: 9:35 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18204: setting learning rate to 7.280222370699202e-06.\n",
      " 404/1780 [=====>........................] - ETA: 9:35 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18205: setting learning rate to 7.279905090859351e-06.\n",
      " 405/1780 [=====>........................] - ETA: 9:34 - accuracy: 0.9962 - loss: 0.0103\n",
      "Batch 18206: setting learning rate to 7.279587799428851e-06.\n",
      " 406/1780 [=====>........................] - ETA: 9:34 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18207: setting learning rate to 7.279270496409313e-06.\n",
      " 407/1780 [=====>........................] - ETA: 9:33 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18208: setting learning rate to 7.278953181802351e-06.\n",
      " 408/1780 [=====>........................] - ETA: 9:33 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18209: setting learning rate to 7.278635855609577e-06.\n",
      " 409/1780 [=====>........................] - ETA: 9:32 - accuracy: 0.9961 - loss: 0.0105\n",
      "Batch 18210: setting learning rate to 7.278318517832606e-06.\n",
      " 410/1780 [=====>........................] - ETA: 9:32 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18211: setting learning rate to 7.278001168473049e-06.\n",
      " 411/1780 [=====>........................] - ETA: 9:31 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18212: setting learning rate to 7.27768380753252e-06.\n",
      " 412/1780 [=====>........................] - ETA: 9:31 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18213: setting learning rate to 7.277366435012635e-06.\n",
      " 413/1780 [=====>........................] - ETA: 9:31 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18214: setting learning rate to 7.277049050915004e-06.\n",
      " 414/1780 [=====>........................] - ETA: 9:30 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18215: setting learning rate to 7.276731655241243e-06.\n",
      " 415/1780 [=====>........................] - ETA: 9:30 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18216: setting learning rate to 7.276414247992965e-06.\n",
      " 416/1780 [======>.......................] - ETA: 9:29 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18217: setting learning rate to 7.276096829171782e-06.\n",
      " 417/1780 [======>.......................] - ETA: 9:29 - accuracy: 0.9961 - loss: 0.0107\n",
      "Batch 18218: setting learning rate to 7.275779398779309e-06.\n",
      " 418/1780 [======>.......................] - ETA: 9:28 - accuracy: 0.9961 - loss: 0.0106\n",
      "Batch 18219: setting learning rate to 7.27546195681716e-06.\n",
      " 419/1780 [======>.......................] - ETA: 9:28 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18220: setting learning rate to 7.2751445032869496e-06.\n",
      " 420/1780 [======>.......................] - ETA: 9:27 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18221: setting learning rate to 7.274827038190289e-06.\n",
      " 421/1780 [======>.......................] - ETA: 9:26 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18222: setting learning rate to 7.274509561528794e-06.\n",
      " 422/1780 [======>.......................] - ETA: 9:26 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18223: setting learning rate to 7.274192073304079e-06.\n",
      " 423/1780 [======>.......................] - ETA: 9:25 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18224: setting learning rate to 7.273874573517757e-06.\n",
      " 424/1780 [======>.......................] - ETA: 9:25 - accuracy: 0.9962 - loss: 0.0106\n",
      "Batch 18225: setting learning rate to 7.273557062171443e-06.\n",
      " 425/1780 [======>.......................] - ETA: 9:24 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18226: setting learning rate to 7.27323953926675e-06.\n",
      " 426/1780 [======>.......................] - ETA: 9:24 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18227: setting learning rate to 7.272922004805293e-06.\n",
      " 427/1780 [======>.......................] - ETA: 9:23 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18228: setting learning rate to 7.272604458788687e-06.\n",
      " 428/1780 [======>.......................] - ETA: 9:23 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18229: setting learning rate to 7.272286901218546e-06.\n",
      " 429/1780 [======>.......................] - ETA: 9:23 - accuracy: 0.9962 - loss: 0.0105\n",
      "Batch 18230: setting learning rate to 7.271969332096482e-06.\n",
      " 430/1780 [======>.......................] - ETA: 9:22 - accuracy: 0.9962 - loss: 0.0104\n",
      "Batch 18231: setting learning rate to 7.271651751424112e-06.\n",
      " 431/1780 [======>.......................] - ETA: 9:22 - accuracy: 0.9963 - loss: 0.0104\n",
      "Batch 18232: setting learning rate to 7.271334159203051e-06.\n",
      " 432/1780 [======>.......................] - ETA: 9:21 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18233: setting learning rate to 7.271016555434912e-06.\n",
      " 433/1780 [======>.......................] - ETA: 9:21 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18234: setting learning rate to 7.27069894012131e-06.\n",
      " 434/1780 [======>.......................] - ETA: 9:20 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18235: setting learning rate to 7.27038131326386e-06.\n",
      " 435/1780 [======>.......................] - ETA: 9:20 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18236: setting learning rate to 7.270063674864179e-06.\n",
      " 436/1780 [======>.......................] - ETA: 9:19 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18237: setting learning rate to 7.269746024923876e-06.\n",
      " 437/1780 [======>.......................] - ETA: 9:19 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18238: setting learning rate to 7.26942836344457e-06.\n",
      " 438/1780 [======>.......................] - ETA: 9:19 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18239: setting learning rate to 7.269110690427876e-06.\n",
      " 439/1780 [======>.......................] - ETA: 9:18 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18240: setting learning rate to 7.26879300587541e-06.\n",
      " 440/1780 [======>.......................] - ETA: 9:18 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18241: setting learning rate to 7.2684753097887826e-06.\n",
      " 441/1780 [======>.......................] - ETA: 9:17 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18242: setting learning rate to 7.268157602169612e-06.\n",
      " 442/1780 [======>.......................] - ETA: 9:17 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18243: setting learning rate to 7.267839883019515e-06.\n",
      " 443/1780 [======>.......................] - ETA: 9:16 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18244: setting learning rate to 7.2675221523401025e-06.\n",
      " 444/1780 [======>.......................] - ETA: 9:16 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18245: setting learning rate to 7.2672044101329945e-06.\n",
      " 445/1780 [======>.......................] - ETA: 9:16 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18246: setting learning rate to 7.266886656399802e-06.\n",
      " 446/1780 [======>.......................] - ETA: 9:15 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18247: setting learning rate to 7.266568891142144e-06.\n",
      " 447/1780 [======>.......................] - ETA: 9:15 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18248: setting learning rate to 7.266251114361634e-06.\n",
      " 448/1780 [======>.......................] - ETA: 9:14 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18249: setting learning rate to 7.265933326059886e-06.\n",
      " 449/1780 [======>.......................] - ETA: 9:14 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18250: setting learning rate to 7.2656155262385195e-06.\n",
      " 450/1780 [======>.......................] - ETA: 9:13 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18251: setting learning rate to 7.265297714899148e-06.\n",
      " 451/1780 [======>.......................] - ETA: 9:13 - accuracy: 0.9961 - loss: 0.0113\n",
      "Batch 18252: setting learning rate to 7.264979892043387e-06.\n",
      " 452/1780 [======>.......................] - ETA: 9:13 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18253: setting learning rate to 7.264662057672851e-06.\n",
      " 453/1780 [======>.......................] - ETA: 9:12 - accuracy: 0.9961 - loss: 0.0113\n",
      "Batch 18254: setting learning rate to 7.264344211789159e-06.\n",
      " 454/1780 [======>.......................] - ETA: 9:12 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18255: setting learning rate to 7.264026354393925e-06.\n",
      " 455/1780 [======>.......................] - ETA: 9:11 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18256: setting learning rate to 7.263708485488765e-06.\n",
      " 456/1780 [======>.......................] - ETA: 9:11 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18257: setting learning rate to 7.263390605075296e-06.\n",
      " 457/1780 [======>.......................] - ETA: 9:10 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18258: setting learning rate to 7.263072713155133e-06.\n",
      " 458/1780 [======>.......................] - ETA: 9:10 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18259: setting learning rate to 7.262754809729892e-06.\n",
      " 459/1780 [======>.......................] - ETA: 9:10 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18260: setting learning rate to 7.26243689480119e-06.\n",
      " 460/1780 [======>.......................] - ETA: 9:09 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18261: setting learning rate to 7.262118968370642e-06.\n",
      " 461/1780 [======>.......................] - ETA: 9:09 - accuracy: 0.9961 - loss: 0.0113\n",
      "Batch 18262: setting learning rate to 7.2618010304398644e-06.\n",
      " 462/1780 [======>.......................] - ETA: 9:08 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18263: setting learning rate to 7.261483081010475e-06.\n",
      " 463/1780 [======>.......................] - ETA: 9:08 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18264: setting learning rate to 7.261165120084091e-06.\n",
      " 464/1780 [======>.......................] - ETA: 9:08 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18265: setting learning rate to 7.260847147662325e-06.\n",
      " 465/1780 [======>.......................] - ETA: 9:07 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18266: setting learning rate to 7.260529163746797e-06.\n",
      " 466/1780 [======>.......................] - ETA: 9:07 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18267: setting learning rate to 7.260211168339122e-06.\n",
      " 467/1780 [======>.......................] - ETA: 9:06 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18268: setting learning rate to 7.259893161440916e-06.\n",
      " 468/1780 [======>.......................] - ETA: 9:06 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18269: setting learning rate to 7.259575143053798e-06.\n",
      " 469/1780 [======>.......................] - ETA: 9:05 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18270: setting learning rate to 7.259257113179383e-06.\n",
      " 470/1780 [======>.......................] - ETA: 9:05 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18271: setting learning rate to 7.2589390718192876e-06.\n",
      " 471/1780 [======>.......................] - ETA: 9:04 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18272: setting learning rate to 7.25862101897513e-06.\n",
      " 472/1780 [======>.......................] - ETA: 9:04 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18273: setting learning rate to 7.258302954648525e-06.\n",
      " 473/1780 [======>.......................] - ETA: 9:04 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18274: setting learning rate to 7.257984878841094e-06.\n",
      " 474/1780 [======>.......................] - ETA: 9:03 - accuracy: 0.9961 - loss: 0.0114\n",
      "Batch 18275: setting learning rate to 7.257666791554448e-06.\n",
      " 475/1780 [=======>......................] - ETA: 9:03 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18276: setting learning rate to 7.257348692790208e-06.\n",
      " 476/1780 [=======>......................] - ETA: 9:02 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18277: setting learning rate to 7.25703058254999e-06.\n",
      " 477/1780 [=======>......................] - ETA: 9:02 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18278: setting learning rate to 7.2567124608354136e-06.\n",
      " 478/1780 [=======>......................] - ETA: 9:01 - accuracy: 0.9961 - loss: 0.0115\n",
      "Batch 18279: setting learning rate to 7.256394327648091e-06.\n",
      " 479/1780 [=======>......................] - ETA: 9:01 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18280: setting learning rate to 7.2560761829896446e-06.\n",
      " 480/1780 [=======>......................] - ETA: 9:01 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18281: setting learning rate to 7.2557580268616875e-06.\n",
      " 481/1780 [=======>......................] - ETA: 9:00 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18282: setting learning rate to 7.255439859265841e-06.\n",
      " 482/1780 [=======>......................] - ETA: 9:00 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18283: setting learning rate to 7.255121680203722e-06.\n",
      " 483/1780 [=======>......................] - ETA: 8:59 - accuracy: 0.9961 - loss: 0.0116\n",
      "Batch 18284: setting learning rate to 7.254803489676946e-06.\n",
      " 484/1780 [=======>......................] - ETA: 8:59 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18285: setting learning rate to 7.254485287687132e-06.\n",
      " 485/1780 [=======>......................] - ETA: 8:59 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18286: setting learning rate to 7.254167074235896e-06.\n",
      " 486/1780 [=======>......................] - ETA: 8:58 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18287: setting learning rate to 7.2538488493248595e-06.\n",
      " 487/1780 [=======>......................] - ETA: 8:58 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18288: setting learning rate to 7.253530612955636e-06.\n",
      " 488/1780 [=======>......................] - ETA: 8:57 - accuracy: 0.9962 - loss: 0.0115\n",
      "Batch 18289: setting learning rate to 7.253212365129846e-06.\n",
      " 489/1780 [=======>......................] - ETA: 8:57 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18290: setting learning rate to 7.252894105849106e-06.\n",
      " 490/1780 [=======>......................] - ETA: 8:56 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18291: setting learning rate to 7.252575835115036e-06.\n",
      " 491/1780 [=======>......................] - ETA: 8:56 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18292: setting learning rate to 7.252257552929251e-06.\n",
      " 492/1780 [=======>......................] - ETA: 8:56 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18293: setting learning rate to 7.251939259293373e-06.\n",
      " 493/1780 [=======>......................] - ETA: 8:55 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18294: setting learning rate to 7.251620954209015e-06.\n",
      " 494/1780 [=======>......................] - ETA: 8:55 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18295: setting learning rate to 7.2513026376778005e-06.\n",
      " 495/1780 [=======>......................] - ETA: 8:54 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18296: setting learning rate to 7.250984309701344e-06.\n",
      " 496/1780 [=======>......................] - ETA: 8:54 - accuracy: 0.9962 - loss: 0.0114\n",
      "Batch 18297: setting learning rate to 7.250665970281267e-06.\n",
      " 497/1780 [=======>......................] - ETA: 8:53 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18298: setting learning rate to 7.250347619419185e-06.\n",
      " 498/1780 [=======>......................] - ETA: 8:53 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18299: setting learning rate to 7.2500292571167175e-06.\n",
      " 499/1780 [=======>......................] - ETA: 8:53 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18300: setting learning rate to 7.249710883375483e-06.\n",
      " 500/1780 [=======>......................] - ETA: 8:52 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18301: setting learning rate to 7.249392498197101e-06.\n",
      " 501/1780 [=======>......................] - ETA: 8:52 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18302: setting learning rate to 7.249074101583188e-06.\n",
      " 502/1780 [=======>......................] - ETA: 8:51 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18303: setting learning rate to 7.248755693535364e-06.\n",
      " 503/1780 [=======>......................] - ETA: 8:51 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18304: setting learning rate to 7.248437274055248e-06.\n",
      " 504/1780 [=======>......................] - ETA: 8:50 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18305: setting learning rate to 7.248118843144458e-06.\n",
      " 505/1780 [=======>......................] - ETA: 8:50 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18306: setting learning rate to 7.2478004008046144e-06.\n",
      " 506/1780 [=======>......................] - ETA: 8:50 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18307: setting learning rate to 7.247481947037335e-06.\n",
      " 507/1780 [=======>......................] - ETA: 8:49 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18308: setting learning rate to 7.247163481844237e-06.\n",
      " 508/1780 [=======>......................] - ETA: 8:49 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18309: setting learning rate to 7.2468450052269425e-06.\n",
      " 509/1780 [=======>......................] - ETA: 8:48 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18310: setting learning rate to 7.246526517187069e-06.\n",
      " 510/1780 [=======>......................] - ETA: 8:48 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18311: setting learning rate to 7.246208017726236e-06.\n",
      " 511/1780 [=======>......................] - ETA: 8:47 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18312: setting learning rate to 7.2458895068460625e-06.\n",
      " 512/1780 [=======>......................] - ETA: 8:47 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18313: setting learning rate to 7.245570984548168e-06.\n",
      " 513/1780 [=======>......................] - ETA: 8:46 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18314: setting learning rate to 7.2452524508341724e-06.\n",
      " 514/1780 [=======>......................] - ETA: 8:46 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18315: setting learning rate to 7.244933905705693e-06.\n",
      " 515/1780 [=======>......................] - ETA: 8:45 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18316: setting learning rate to 7.244615349164351e-06.\n",
      " 516/1780 [=======>......................] - ETA: 8:45 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18317: setting learning rate to 7.244296781211766e-06.\n",
      " 517/1780 [=======>......................] - ETA: 8:45 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18318: setting learning rate to 7.2439782018495576e-06.\n",
      " 518/1780 [=======>......................] - ETA: 8:44 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18319: setting learning rate to 7.243659611079343e-06.\n",
      " 519/1780 [=======>......................] - ETA: 8:44 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18320: setting learning rate to 7.243341008902744e-06.\n",
      " 520/1780 [=======>......................] - ETA: 8:43 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18321: setting learning rate to 7.24302239532138e-06.\n",
      " 521/1780 [=======>......................] - ETA: 8:43 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18322: setting learning rate to 7.242703770336872e-06.\n",
      " 522/1780 [=======>......................] - ETA: 8:42 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18323: setting learning rate to 7.242385133950838e-06.\n",
      " 523/1780 [=======>......................] - ETA: 8:42 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18324: setting learning rate to 7.242066486164898e-06.\n",
      " 524/1780 [=======>......................] - ETA: 8:42 - accuracy: 0.9963 - loss: 0.0111\n",
      "Batch 18325: setting learning rate to 7.241747826980673e-06.\n",
      " 525/1780 [=======>......................] - ETA: 8:41 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18326: setting learning rate to 7.241429156399782e-06.\n",
      " 526/1780 [=======>......................] - ETA: 8:41 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18327: setting learning rate to 7.241110474423845e-06.\n",
      " 527/1780 [=======>......................] - ETA: 8:40 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18328: setting learning rate to 7.2407917810544845e-06.\n",
      " 528/1780 [=======>......................] - ETA: 8:40 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18329: setting learning rate to 7.240473076293317e-06.\n",
      " 529/1780 [=======>......................] - ETA: 8:39 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18330: setting learning rate to 7.2401543601419655e-06.\n",
      " 530/1780 [=======>......................] - ETA: 8:39 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18331: setting learning rate to 7.239835632602048e-06.\n",
      " 531/1780 [=======>......................] - ETA: 8:39 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18332: setting learning rate to 7.239516893675188e-06.\n",
      " 532/1780 [=======>......................] - ETA: 8:38 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18333: setting learning rate to 7.239198143363004e-06.\n",
      " 533/1780 [=======>......................] - ETA: 8:38 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18334: setting learning rate to 7.2388793816671154e-06.\n",
      " 534/1780 [========>.....................] - ETA: 8:37 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18335: setting learning rate to 7.238560608589144e-06.\n",
      " 535/1780 [========>.....................] - ETA: 8:37 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18336: setting learning rate to 7.238241824130712e-06.\n",
      " 536/1780 [========>.....................] - ETA: 8:36 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18337: setting learning rate to 7.237923028293437e-06.\n",
      " 537/1780 [========>.....................] - ETA: 8:36 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18338: setting learning rate to 7.237604221078942e-06.\n",
      " 538/1780 [========>.....................] - ETA: 8:36 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18339: setting learning rate to 7.237285402488845e-06.\n",
      " 539/1780 [========>.....................] - ETA: 8:35 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18340: setting learning rate to 7.2369665725247706e-06.\n",
      " 540/1780 [========>.....................] - ETA: 8:35 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18341: setting learning rate to 7.236647731188338e-06.\n",
      " 541/1780 [========>.....................] - ETA: 8:34 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18342: setting learning rate to 7.236328878481166e-06.\n",
      " 542/1780 [========>.....................] - ETA: 8:34 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18343: setting learning rate to 7.236010014404878e-06.\n",
      " 543/1780 [========>.....................] - ETA: 8:33 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18344: setting learning rate to 7.235691138961095e-06.\n",
      " 544/1780 [========>.....................] - ETA: 8:33 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18345: setting learning rate to 7.235372252151438e-06.\n",
      " 545/1780 [========>.....................] - ETA: 8:32 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18346: setting learning rate to 7.235053353977527e-06.\n",
      " 546/1780 [========>.....................] - ETA: 8:32 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18347: setting learning rate to 7.2347344444409835e-06.\n",
      " 547/1780 [========>.....................] - ETA: 8:31 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18348: setting learning rate to 7.234415523543432e-06.\n",
      " 548/1780 [========>.....................] - ETA: 8:31 - accuracy: 0.9962 - loss: 0.0113\n",
      "Batch 18349: setting learning rate to 7.234096591286488e-06.\n",
      " 549/1780 [========>.....................] - ETA: 8:31 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18350: setting learning rate to 7.2337776476717785e-06.\n",
      " 550/1780 [========>.....................] - ETA: 8:30 - accuracy: 0.9962 - loss: 0.0112\n",
      "Batch 18351: setting learning rate to 7.23345869270092e-06.\n",
      " 551/1780 [========>.....................] - ETA: 8:30 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18352: setting learning rate to 7.2331397263755386e-06.\n",
      " 552/1780 [========>.....................] - ETA: 8:29 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18353: setting learning rate to 7.232820748697252e-06.\n",
      " 553/1780 [========>.....................] - ETA: 8:29 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18354: setting learning rate to 7.232501759667685e-06.\n",
      " 554/1780 [========>.....................] - ETA: 8:28 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18355: setting learning rate to 7.232182759288458e-06.\n",
      " 555/1780 [========>.....................] - ETA: 8:28 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18356: setting learning rate to 7.2318637475611916e-06.\n",
      " 556/1780 [========>.....................] - ETA: 8:28 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18357: setting learning rate to 7.231544724487509e-06.\n",
      " 557/1780 [========>.....................] - ETA: 8:27 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18358: setting learning rate to 7.231225690069032e-06.\n",
      " 558/1780 [========>.....................] - ETA: 8:27 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18359: setting learning rate to 7.230906644307382e-06.\n",
      " 559/1780 [========>.....................] - ETA: 8:26 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18360: setting learning rate to 7.2305875872041805e-06.\n",
      " 560/1780 [========>.....................] - ETA: 8:26 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18361: setting learning rate to 7.230268518761052e-06.\n",
      " 561/1780 [========>.....................] - ETA: 8:25 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18362: setting learning rate to 7.229949438979616e-06.\n",
      " 562/1780 [========>.....................] - ETA: 8:25 - accuracy: 0.9963 - loss: 0.0113\n",
      "Batch 18363: setting learning rate to 7.229630347861494e-06.\n",
      " 563/1780 [========>.....................] - ETA: 8:25 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18364: setting learning rate to 7.22931124540831e-06.\n",
      " 564/1780 [========>.....................] - ETA: 8:24 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18365: setting learning rate to 7.228992131621688e-06.\n",
      " 565/1780 [========>.....................] - ETA: 8:24 - accuracy: 0.9963 - loss: 0.0112\n",
      "Batch 18366: setting learning rate to 7.2286730065032465e-06.\n",
      " 566/1780 [========>.....................] - ETA: 8:23 - accuracy: 0.9964 - loss: 0.0112\n",
      "Batch 18367: setting learning rate to 7.22835387005461e-06.\n",
      " 567/1780 [========>.....................] - ETA: 8:23 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18368: setting learning rate to 7.228034722277402e-06.\n",
      " 568/1780 [========>.....................] - ETA: 8:22 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18369: setting learning rate to 7.227715563173241e-06.\n",
      " 569/1780 [========>.....................] - ETA: 8:22 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18370: setting learning rate to 7.227396392743754e-06.\n",
      " 570/1780 [========>.....................] - ETA: 8:22 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18371: setting learning rate to 7.227077210990561e-06.\n",
      " 571/1780 [========>.....................] - ETA: 8:21 - accuracy: 0.9963 - loss: 0.0117\n",
      "Batch 18372: setting learning rate to 7.226758017915285e-06.\n",
      " 572/1780 [========>.....................] - ETA: 8:21 - accuracy: 0.9963 - loss: 0.0117\n",
      "Batch 18373: setting learning rate to 7.22643881351955e-06.\n",
      " 573/1780 [========>.....................] - ETA: 8:20 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18374: setting learning rate to 7.226119597804977e-06.\n",
      " 574/1780 [========>.....................] - ETA: 8:20 - accuracy: 0.9963 - loss: 0.0116\n",
      "Batch 18375: setting learning rate to 7.225800370773191e-06.\n",
      " 575/1780 [========>.....................] - ETA: 8:20 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 18376: setting learning rate to 7.225481132425812e-06.\n",
      " 576/1780 [========>.....................] - ETA: 8:19 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 18377: setting learning rate to 7.225161882764465e-06.\n",
      " 577/1780 [========>.....................] - ETA: 8:19 - accuracy: 0.9963 - loss: 0.0119\n",
      "Batch 18378: setting learning rate to 7.224842621790773e-06.\n",
      " 578/1780 [========>.....................] - ETA: 8:18 - accuracy: 0.9963 - loss: 0.0120\n",
      "Batch 18379: setting learning rate to 7.22452334950636e-06.\n",
      " 579/1780 [========>.....................] - ETA: 8:18 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18380: setting learning rate to 7.224204065912846e-06.\n",
      " 580/1780 [========>.....................] - ETA: 8:17 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18381: setting learning rate to 7.223884771011855e-06.\n",
      " 581/1780 [========>.....................] - ETA: 8:17 - accuracy: 0.9963 - loss: 0.0121\n",
      "Batch 18382: setting learning rate to 7.223565464805013e-06.\n",
      " 582/1780 [========>.....................] - ETA: 8:16 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18383: setting learning rate to 7.223246147293941e-06.\n",
      " 583/1780 [========>.....................] - ETA: 8:16 - accuracy: 0.9962 - loss: 0.0122\n",
      "Batch 18384: setting learning rate to 7.222926818480262e-06.\n",
      " 584/1780 [========>.....................] - ETA: 8:16 - accuracy: 0.9962 - loss: 0.0122\n",
      "Batch 18385: setting learning rate to 7.222607478365601e-06.\n",
      " 585/1780 [========>.....................] - ETA: 8:15 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18386: setting learning rate to 7.222288126951581e-06.\n",
      " 586/1780 [========>.....................] - ETA: 8:15 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18387: setting learning rate to 7.221968764239824e-06.\n",
      " 587/1780 [========>.....................] - ETA: 8:14 - accuracy: 0.9962 - loss: 0.0121\n",
      "Batch 18388: setting learning rate to 7.221649390231956e-06.\n",
      " 588/1780 [========>.....................] - ETA: 8:14 - accuracy: 0.9962 - loss: 0.0127\n",
      "Batch 18389: setting learning rate to 7.221330004929601e-06.\n",
      " 589/1780 [========>.....................] - ETA: 8:13 - accuracy: 0.9962 - loss: 0.0127\n",
      "Batch 18390: setting learning rate to 7.221010608334379e-06.\n",
      " 590/1780 [========>.....................] - ETA: 8:13 - accuracy: 0.9962 - loss: 0.0127\n",
      "Batch 18391: setting learning rate to 7.220691200447916e-06.\n",
      " 591/1780 [========>.....................] - ETA: 8:13 - accuracy: 0.9962 - loss: 0.0127\n",
      "Batch 18392: setting learning rate to 7.220371781271837e-06.\n",
      " 592/1780 [========>.....................] - ETA: 8:12 - accuracy: 0.9962 - loss: 0.0127\n",
      "Batch 18393: setting learning rate to 7.2200523508077635e-06.\n",
      " 593/1780 [========>.....................] - ETA: 8:12 - accuracy: 0.9962 - loss: 0.0128\n",
      "Batch 18394: setting learning rate to 7.219732909057321e-06.\n",
      " 594/1780 [=========>....................] - ETA: 8:11 - accuracy: 0.9962 - loss: 0.0128\n",
      "Batch 18395: setting learning rate to 7.219413456022133e-06.\n",
      " 595/1780 [=========>....................] - ETA: 8:11 - accuracy: 0.9962 - loss: 0.0129\n",
      "Batch 18396: setting learning rate to 7.219093991703824e-06.\n",
      " 596/1780 [=========>....................] - ETA: 8:10 - accuracy: 0.9962 - loss: 0.0129\n",
      "Batch 18397: setting learning rate to 7.218774516104017e-06.\n",
      " 597/1780 [=========>....................] - ETA: 8:10 - accuracy: 0.9961 - loss: 0.0129\n",
      "Batch 18398: setting learning rate to 7.218455029224337e-06.\n",
      " 598/1780 [=========>....................] - ETA: 8:10 - accuracy: 0.9962 - loss: 0.0129\n",
      "Batch 18399: setting learning rate to 7.218135531066409e-06.\n",
      " 599/1780 [=========>....................] - ETA: 8:09 - accuracy: 0.9961 - loss: 0.0129\n",
      "Batch 18400: setting learning rate to 7.217816021631856e-06.\n",
      " 600/1780 [=========>....................] - ETA: 8:09 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18401: setting learning rate to 7.2174965009223015e-06.\n",
      " 601/1780 [=========>....................] - ETA: 8:08 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18402: setting learning rate to 7.217176968939373e-06.\n",
      " 602/1780 [=========>....................] - ETA: 8:08 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18403: setting learning rate to 7.216857425684691e-06.\n",
      " 603/1780 [=========>....................] - ETA: 8:07 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18404: setting learning rate to 7.2165378711598835e-06.\n",
      " 604/1780 [=========>....................] - ETA: 8:07 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18405: setting learning rate to 7.216218305366572e-06.\n",
      " 605/1780 [=========>....................] - ETA: 8:07 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18406: setting learning rate to 7.215898728306386e-06.\n",
      " 606/1780 [=========>....................] - ETA: 8:06 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18407: setting learning rate to 7.215579139980944e-06.\n",
      " 607/1780 [=========>....................] - ETA: 8:06 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18408: setting learning rate to 7.215259540391873e-06.\n",
      " 608/1780 [=========>....................] - ETA: 8:05 - accuracy: 0.9961 - loss: 0.0131\n",
      "Batch 18409: setting learning rate to 7.2149399295408005e-06.\n",
      " 609/1780 [=========>....................] - ETA: 8:05 - accuracy: 0.9961 - loss: 0.0131\n",
      "Batch 18410: setting learning rate to 7.214620307429349e-06.\n",
      " 610/1780 [=========>....................] - ETA: 8:05 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18411: setting learning rate to 7.214300674059143e-06.\n",
      " 611/1780 [=========>....................] - ETA: 8:04 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18412: setting learning rate to 7.213981029431807e-06.\n",
      " 612/1780 [=========>....................] - ETA: 8:04 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18413: setting learning rate to 7.213661373548968e-06.\n",
      " 613/1780 [=========>....................] - ETA: 8:03 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18414: setting learning rate to 7.213341706412251e-06.\n",
      " 614/1780 [=========>....................] - ETA: 8:03 - accuracy: 0.9961 - loss: 0.0131\n",
      "Batch 18415: setting learning rate to 7.21302202802328e-06.\n",
      " 615/1780 [=========>....................] - ETA: 8:02 - accuracy: 0.9961 - loss: 0.0131\n",
      "Batch 18416: setting learning rate to 7.212702338383682e-06.\n",
      " 616/1780 [=========>....................] - ETA: 8:02 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18417: setting learning rate to 7.212382637495078e-06.\n",
      " 617/1780 [=========>....................] - ETA: 8:02 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18418: setting learning rate to 7.212062925359097e-06.\n",
      " 618/1780 [=========>....................] - ETA: 8:01 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18419: setting learning rate to 7.2117432019773645e-06.\n",
      " 619/1780 [=========>....................] - ETA: 8:01 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18420: setting learning rate to 7.211423467351504e-06.\n",
      " 620/1780 [=========>....................] - ETA: 8:00 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18421: setting learning rate to 7.211103721483141e-06.\n",
      " 621/1780 [=========>....................] - ETA: 8:00 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18422: setting learning rate to 7.210783964373903e-06.\n",
      " 622/1780 [=========>....................] - ETA: 7:59 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18423: setting learning rate to 7.210464196025415e-06.\n",
      " 623/1780 [=========>....................] - ETA: 7:59 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18424: setting learning rate to 7.210144416439302e-06.\n",
      " 624/1780 [=========>....................] - ETA: 7:59 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18425: setting learning rate to 7.209824625617189e-06.\n",
      " 625/1780 [=========>....................] - ETA: 7:58 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18426: setting learning rate to 7.209504823560703e-06.\n",
      " 626/1780 [=========>....................] - ETA: 7:58 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18427: setting learning rate to 7.209185010271469e-06.\n",
      " 627/1780 [=========>....................] - ETA: 7:57 - accuracy: 0.9961 - loss: 0.0130\n",
      "Batch 18428: setting learning rate to 7.208865185751114e-06.\n",
      " 628/1780 [=========>....................] - ETA: 7:57 - accuracy: 0.9961 - loss: 0.0129\n",
      "Batch 18429: setting learning rate to 7.208545350001264e-06.\n",
      " 629/1780 [=========>....................] - ETA: 7:56 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18430: setting learning rate to 7.208225503023543e-06.\n",
      " 630/1780 [=========>....................] - ETA: 7:56 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18431: setting learning rate to 7.207905644819577e-06.\n",
      " 631/1780 [=========>....................] - ETA: 7:55 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18432: setting learning rate to 7.207585775390995e-06.\n",
      " 632/1780 [=========>....................] - ETA: 7:55 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18433: setting learning rate to 7.207265894739421e-06.\n",
      " 633/1780 [=========>....................] - ETA: 7:55 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18434: setting learning rate to 7.206946002866482e-06.\n",
      " 634/1780 [=========>....................] - ETA: 7:54 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18435: setting learning rate to 7.206626099773803e-06.\n",
      " 635/1780 [=========>....................] - ETA: 7:54 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18436: setting learning rate to 7.206306185463013e-06.\n",
      " 636/1780 [=========>....................] - ETA: 7:53 - accuracy: 0.9960 - loss: 0.0132\n",
      "Batch 18437: setting learning rate to 7.2059862599357354e-06.\n",
      " 637/1780 [=========>....................] - ETA: 7:53 - accuracy: 0.9960 - loss: 0.0132\n",
      "Batch 18438: setting learning rate to 7.2056663231936e-06.\n",
      " 638/1780 [=========>....................] - ETA: 7:53 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18439: setting learning rate to 7.205346375238229e-06.\n",
      " 639/1780 [=========>....................] - ETA: 7:52 - accuracy: 0.9960 - loss: 0.0132\n",
      "Batch 18440: setting learning rate to 7.205026416071252e-06.\n",
      " 640/1780 [=========>....................] - ETA: 7:52 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18441: setting learning rate to 7.204706445694295e-06.\n",
      " 641/1780 [=========>....................] - ETA: 7:51 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18442: setting learning rate to 7.204386464108984e-06.\n",
      " 642/1780 [=========>....................] - ETA: 7:51 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18443: setting learning rate to 7.204066471316948e-06.\n",
      " 643/1780 [=========>....................] - ETA: 7:50 - accuracy: 0.9960 - loss: 0.0131\n",
      "Batch 18444: setting learning rate to 7.203746467319811e-06.\n",
      " 644/1780 [=========>....................] - ETA: 7:50 - accuracy: 0.9960 - loss: 0.0132\n",
      "Batch 18445: setting learning rate to 7.2034264521192e-06.\n",
      " 645/1780 [=========>....................] - ETA: 7:49 - accuracy: 0.9960 - loss: 0.0132\n",
      "Batch 18446: setting learning rate to 7.2031064257167445e-06.\n",
      " 646/1780 [=========>....................] - ETA: 7:49 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18447: setting learning rate to 7.202786388114069e-06.\n",
      " 647/1780 [=========>....................] - ETA: 7:49 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18448: setting learning rate to 7.202466339312802e-06.\n",
      " 648/1780 [=========>....................] - ETA: 7:48 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18449: setting learning rate to 7.202146279314568e-06.\n",
      " 649/1780 [=========>....................] - ETA: 7:48 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18450: setting learning rate to 7.201826208120997e-06.\n",
      " 650/1780 [=========>....................] - ETA: 7:47 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18451: setting learning rate to 7.201506125733716e-06.\n",
      " 651/1780 [=========>....................] - ETA: 7:47 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18452: setting learning rate to 7.2011860321543505e-06.\n",
      " 652/1780 [=========>....................] - ETA: 7:47 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18453: setting learning rate to 7.20086592738453e-06.\n",
      " 653/1780 [==========>...................] - ETA: 7:46 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18454: setting learning rate to 7.200545811425878e-06.\n",
      " 654/1780 [==========>...................] - ETA: 7:46 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18455: setting learning rate to 7.200225684280027e-06.\n",
      " 655/1780 [==========>...................] - ETA: 7:45 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18456: setting learning rate to 7.199905545948601e-06.\n",
      " 656/1780 [==========>...................] - ETA: 7:45 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18457: setting learning rate to 7.199585396433228e-06.\n",
      " 657/1780 [==========>...................] - ETA: 7:44 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18458: setting learning rate to 7.199265235735537e-06.\n",
      " 658/1780 [==========>...................] - ETA: 7:44 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18459: setting learning rate to 7.1989450638571545e-06.\n",
      " 659/1780 [==========>...................] - ETA: 7:43 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18460: setting learning rate to 7.19862488079971e-06.\n",
      " 660/1780 [==========>...................] - ETA: 7:43 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18461: setting learning rate to 7.198304686564827e-06.\n",
      " 661/1780 [==========>...................] - ETA: 7:43 - accuracy: 0.9960 - loss: 0.0133\n",
      "Batch 18462: setting learning rate to 7.197984481154137e-06.\n",
      " 662/1780 [==========>...................] - ETA: 7:42 - accuracy: 0.9960 - loss: 0.0133\n",
      "Batch 18463: setting learning rate to 7.197664264569266e-06.\n",
      " 663/1780 [==========>...................] - ETA: 7:42 - accuracy: 0.9960 - loss: 0.0133\n",
      "Batch 18464: setting learning rate to 7.197344036811844e-06.\n",
      " 664/1780 [==========>...................] - ETA: 7:41 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18465: setting learning rate to 7.1970237978834966e-06.\n",
      " 665/1780 [==========>...................] - ETA: 7:41 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18466: setting learning rate to 7.196703547785855e-06.\n",
      " 666/1780 [==========>...................] - ETA: 7:40 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18467: setting learning rate to 7.196383286520544e-06.\n",
      " 667/1780 [==========>...................] - ETA: 7:40 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18468: setting learning rate to 7.196063014089193e-06.\n",
      " 668/1780 [==========>...................] - ETA: 7:40 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18469: setting learning rate to 7.19574273049343e-06.\n",
      " 669/1780 [==========>...................] - ETA: 7:39 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18470: setting learning rate to 7.195422435734885e-06.\n",
      " 670/1780 [==========>...................] - ETA: 7:39 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18471: setting learning rate to 7.195102129815183e-06.\n",
      " 671/1780 [==========>...................] - ETA: 7:38 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18472: setting learning rate to 7.194781812735956e-06.\n",
      " 672/1780 [==========>...................] - ETA: 7:38 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18473: setting learning rate to 7.19446148449883e-06.\n",
      " 673/1780 [==========>...................] - ETA: 7:37 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18474: setting learning rate to 7.194141145105434e-06.\n",
      " 674/1780 [==========>...................] - ETA: 7:37 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18475: setting learning rate to 7.193820794557398e-06.\n",
      " 675/1780 [==========>...................] - ETA: 7:37 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18476: setting learning rate to 7.1935004328563475e-06.\n",
      " 676/1780 [==========>...................] - ETA: 7:36 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18477: setting learning rate to 7.193180060003915e-06.\n",
      " 677/1780 [==========>...................] - ETA: 7:36 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18478: setting learning rate to 7.1928596760017254e-06.\n",
      " 678/1780 [==========>...................] - ETA: 7:35 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18479: setting learning rate to 7.192539280851409e-06.\n",
      " 679/1780 [==========>...................] - ETA: 7:35 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18480: setting learning rate to 7.192218874554597e-06.\n",
      " 680/1780 [==========>...................] - ETA: 7:34 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18481: setting learning rate to 7.191898457112915e-06.\n",
      " 681/1780 [==========>...................] - ETA: 7:34 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18482: setting learning rate to 7.191578028527992e-06.\n",
      " 682/1780 [==========>...................] - ETA: 7:34 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18483: setting learning rate to 7.19125758880146e-06.\n",
      " 683/1780 [==========>...................] - ETA: 7:33 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18484: setting learning rate to 7.190937137934947e-06.\n",
      " 684/1780 [==========>...................] - ETA: 7:33 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18485: setting learning rate to 7.19061667593008e-06.\n",
      " 685/1780 [==========>...................] - ETA: 7:32 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18486: setting learning rate to 7.190296202788489e-06.\n",
      " 686/1780 [==========>...................] - ETA: 7:32 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18487: setting learning rate to 7.189975718511806e-06.\n",
      " 687/1780 [==========>...................] - ETA: 7:32 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18488: setting learning rate to 7.189655223101656e-06.\n",
      " 688/1780 [==========>...................] - ETA: 7:31 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18489: setting learning rate to 7.18933471655967e-06.\n",
      " 689/1780 [==========>...................] - ETA: 7:31 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18490: setting learning rate to 7.189014198887478e-06.\n",
      " 690/1780 [==========>...................] - ETA: 7:30 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18491: setting learning rate to 7.18869367008671e-06.\n",
      " 691/1780 [==========>...................] - ETA: 7:30 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18492: setting learning rate to 7.188373130158995e-06.\n",
      " 692/1780 [==========>...................] - ETA: 7:30 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18493: setting learning rate to 7.188052579105963e-06.\n",
      " 693/1780 [==========>...................] - ETA: 7:29 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18494: setting learning rate to 7.187732016929242e-06.\n",
      " 694/1780 [==========>...................] - ETA: 7:29 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18495: setting learning rate to 7.187411443630463e-06.\n",
      " 695/1780 [==========>...................] - ETA: 7:28 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18496: setting learning rate to 7.187090859211254e-06.\n",
      " 696/1780 [==========>...................] - ETA: 7:28 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18497: setting learning rate to 7.186770263673249e-06.\n",
      " 697/1780 [==========>...................] - ETA: 7:27 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18498: setting learning rate to 7.186449657018073e-06.\n",
      " 698/1780 [==========>...................] - ETA: 7:27 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18499: setting learning rate to 7.186129039247358e-06.\n",
      " 699/1780 [==========>...................] - ETA: 7:27 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18500: setting learning rate to 7.185808410362736e-06.\n",
      " 700/1780 [==========>...................] - ETA: 7:26 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18501: setting learning rate to 7.185487770365832e-06.\n",
      " 701/1780 [==========>...................] - ETA: 7:26 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18502: setting learning rate to 7.185167119258281e-06.\n",
      " 702/1780 [==========>...................] - ETA: 7:25 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18503: setting learning rate to 7.18484645704171e-06.\n",
      " 703/1780 [==========>...................] - ETA: 7:25 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18504: setting learning rate to 7.184525783717751e-06.\n",
      " 704/1780 [==========>...................] - ETA: 7:24 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18505: setting learning rate to 7.184205099288033e-06.\n",
      " 705/1780 [==========>...................] - ETA: 7:24 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18506: setting learning rate to 7.183884403754187e-06.\n",
      " 706/1780 [==========>...................] - ETA: 7:24 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18507: setting learning rate to 7.183563697117844e-06.\n",
      " 707/1780 [==========>...................] - ETA: 7:23 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18508: setting learning rate to 7.183242979380633e-06.\n",
      " 708/1780 [==========>...................] - ETA: 7:23 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18509: setting learning rate to 7.182922250544187e-06.\n",
      " 709/1780 [==========>...................] - ETA: 7:22 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18510: setting learning rate to 7.1826015106101325e-06.\n",
      " 710/1780 [==========>...................] - ETA: 7:22 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18511: setting learning rate to 7.182280759580103e-06.\n",
      " 711/1780 [==========>...................] - ETA: 7:22 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18512: setting learning rate to 7.181959997455729e-06.\n",
      " 712/1780 [===========>..................] - ETA: 7:21 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18513: setting learning rate to 7.181639224238639e-06.\n",
      " 713/1780 [===========>..................] - ETA: 7:21 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18514: setting learning rate to 7.181318439930468e-06.\n",
      " 714/1780 [===========>..................] - ETA: 7:20 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18515: setting learning rate to 7.180997644532842e-06.\n",
      " 715/1780 [===========>..................] - ETA: 7:20 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18516: setting learning rate to 7.180676838047395e-06.\n",
      " 716/1780 [===========>..................] - ETA: 7:20 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18517: setting learning rate to 7.180356020475756e-06.\n",
      " 717/1780 [===========>..................] - ETA: 7:19 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18518: setting learning rate to 7.180035191819558e-06.\n",
      " 718/1780 [===========>..................] - ETA: 7:19 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18519: setting learning rate to 7.1797143520804305e-06.\n",
      " 719/1780 [===========>..................] - ETA: 7:18 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18520: setting learning rate to 7.179393501260005e-06.\n",
      " 720/1780 [===========>..................] - ETA: 7:18 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18521: setting learning rate to 7.1790726393599144e-06.\n",
      " 721/1780 [===========>..................] - ETA: 7:17 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18522: setting learning rate to 7.178751766381786e-06.\n",
      " 722/1780 [===========>..................] - ETA: 7:17 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18523: setting learning rate to 7.178430882327254e-06.\n",
      " 723/1780 [===========>..................] - ETA: 7:17 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18524: setting learning rate to 7.17810998719795e-06.\n",
      " 724/1780 [===========>..................] - ETA: 7:16 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18525: setting learning rate to 7.177789080995503e-06.\n",
      " 725/1780 [===========>..................] - ETA: 7:16 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18526: setting learning rate to 7.177468163721547e-06.\n",
      " 726/1780 [===========>..................] - ETA: 7:15 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18527: setting learning rate to 7.177147235377711e-06.\n",
      " 727/1780 [===========>..................] - ETA: 7:15 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18528: setting learning rate to 7.176826295965631e-06.\n",
      " 728/1780 [===========>..................] - ETA: 7:14 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18529: setting learning rate to 7.176505345486933e-06.\n",
      " 729/1780 [===========>..................] - ETA: 7:14 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18530: setting learning rate to 7.176184383943251e-06.\n",
      " 730/1780 [===========>..................] - ETA: 7:14 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18531: setting learning rate to 7.175863411336218e-06.\n",
      " 731/1780 [===========>..................] - ETA: 7:13 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18532: setting learning rate to 7.175542427667464e-06.\n",
      " 732/1780 [===========>..................] - ETA: 7:13 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18533: setting learning rate to 7.175221432938622e-06.\n",
      " 733/1780 [===========>..................] - ETA: 7:12 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18534: setting learning rate to 7.174900427151324e-06.\n",
      " 734/1780 [===========>..................] - ETA: 7:12 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18535: setting learning rate to 7.174579410307199e-06.\n",
      " 735/1780 [===========>..................] - ETA: 7:12 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18536: setting learning rate to 7.174258382407881e-06.\n",
      " 736/1780 [===========>..................] - ETA: 7:11 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18537: setting learning rate to 7.173937343455004e-06.\n",
      " 737/1780 [===========>..................] - ETA: 7:11 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18538: setting learning rate to 7.1736162934502e-06.\n",
      " 738/1780 [===========>..................] - ETA: 7:10 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18539: setting learning rate to 7.173295232395097e-06.\n",
      " 739/1780 [===========>..................] - ETA: 7:10 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18540: setting learning rate to 7.17297416029133e-06.\n",
      " 740/1780 [===========>..................] - ETA: 7:09 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18541: setting learning rate to 7.172653077140532e-06.\n",
      " 741/1780 [===========>..................] - ETA: 7:09 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18542: setting learning rate to 7.172331982944335e-06.\n",
      " 742/1780 [===========>..................] - ETA: 7:09 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18543: setting learning rate to 7.172010877704369e-06.\n",
      " 743/1780 [===========>..................] - ETA: 7:08 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18544: setting learning rate to 7.17168976142227e-06.\n",
      " 744/1780 [===========>..................] - ETA: 7:08 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18545: setting learning rate to 7.171368634099668e-06.\n",
      " 745/1780 [===========>..................] - ETA: 7:07 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18546: setting learning rate to 7.171047495738196e-06.\n",
      " 746/1780 [===========>..................] - ETA: 7:07 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18547: setting learning rate to 7.170726346339487e-06.\n",
      " 747/1780 [===========>..................] - ETA: 7:06 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18548: setting learning rate to 7.170405185905175e-06.\n",
      " 748/1780 [===========>..................] - ETA: 7:06 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18549: setting learning rate to 7.17008401443689e-06.\n",
      " 749/1780 [===========>..................] - ETA: 7:06 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18550: setting learning rate to 7.169762831936265e-06.\n",
      " 750/1780 [===========>..................] - ETA: 7:05 - accuracy: 0.9958 - loss: 0.0136\n",
      "Batch 18551: setting learning rate to 7.169441638404937e-06.\n",
      " 751/1780 [===========>..................] - ETA: 7:05 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18552: setting learning rate to 7.169120433844534e-06.\n",
      " 752/1780 [===========>..................] - ETA: 7:04 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18553: setting learning rate to 7.16879921825669e-06.\n",
      " 753/1780 [===========>..................] - ETA: 7:04 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18554: setting learning rate to 7.16847799164304e-06.\n",
      " 754/1780 [===========>..................] - ETA: 7:03 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18555: setting learning rate to 7.168156754005217e-06.\n",
      " 755/1780 [===========>..................] - ETA: 7:03 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18556: setting learning rate to 7.167835505344851e-06.\n",
      " 756/1780 [===========>..................] - ETA: 7:03 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18557: setting learning rate to 7.167514245663577e-06.\n",
      " 757/1780 [===========>..................] - ETA: 7:02 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18558: setting learning rate to 7.16719297496303e-06.\n",
      " 758/1780 [===========>..................] - ETA: 7:02 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18559: setting learning rate to 7.166871693244841e-06.\n",
      " 759/1780 [===========>..................] - ETA: 7:01 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18560: setting learning rate to 7.166550400510644e-06.\n",
      " 760/1780 [===========>..................] - ETA: 7:01 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18561: setting learning rate to 7.166229096762072e-06.\n",
      " 761/1780 [===========>..................] - ETA: 7:01 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18562: setting learning rate to 7.16590778200076e-06.\n",
      " 762/1780 [===========>..................] - ETA: 7:00 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18563: setting learning rate to 7.1655864562283385e-06.\n",
      " 763/1780 [===========>..................] - ETA: 7:00 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18564: setting learning rate to 7.165265119446443e-06.\n",
      " 764/1780 [===========>..................] - ETA: 6:59 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18565: setting learning rate to 7.164943771656709e-06.\n",
      " 765/1780 [===========>..................] - ETA: 6:59 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18566: setting learning rate to 7.164622412860766e-06.\n",
      " 766/1780 [===========>..................] - ETA: 6:58 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18567: setting learning rate to 7.164301043060252e-06.\n",
      " 767/1780 [===========>..................] - ETA: 6:58 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18568: setting learning rate to 7.163979662256797e-06.\n",
      " 768/1780 [===========>..................] - ETA: 6:58 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18569: setting learning rate to 7.163658270452039e-06.\n",
      " 769/1780 [===========>..................] - ETA: 6:57 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18570: setting learning rate to 7.163336867647608e-06.\n",
      " 770/1780 [===========>..................] - ETA: 6:57 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18571: setting learning rate to 7.163015453845139e-06.\n",
      " 771/1780 [===========>..................] - ETA: 6:56 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18572: setting learning rate to 7.162694029046267e-06.\n",
      " 772/1780 [============>.................] - ETA: 6:56 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18573: setting learning rate to 7.1623725932526244e-06.\n",
      " 773/1780 [============>.................] - ETA: 6:56 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18574: setting learning rate to 7.162051146465848e-06.\n",
      " 774/1780 [============>.................] - ETA: 6:55 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18575: setting learning rate to 7.161729688687571e-06.\n",
      " 775/1780 [============>.................] - ETA: 6:55 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18576: setting learning rate to 7.1614082199194255e-06.\n",
      " 776/1780 [============>.................] - ETA: 6:54 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18577: setting learning rate to 7.161086740163048e-06.\n",
      " 777/1780 [============>.................] - ETA: 6:54 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18578: setting learning rate to 7.160765249420073e-06.\n",
      " 778/1780 [============>.................] - ETA: 6:53 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18579: setting learning rate to 7.160443747692133e-06.\n",
      " 779/1780 [============>.................] - ETA: 6:53 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18580: setting learning rate to 7.160122234980864e-06.\n",
      " 780/1780 [============>.................] - ETA: 6:53 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18581: setting learning rate to 7.159800711287899e-06.\n",
      " 781/1780 [============>.................] - ETA: 6:52 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18582: setting learning rate to 7.159479176614876e-06.\n",
      " 782/1780 [============>.................] - ETA: 6:52 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18583: setting learning rate to 7.159157630963426e-06.\n",
      " 783/1780 [============>.................] - ETA: 6:51 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18584: setting learning rate to 7.158836074335185e-06.\n",
      " 784/1780 [============>.................] - ETA: 6:51 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18585: setting learning rate to 7.158514506731788e-06.\n",
      " 785/1780 [============>.................] - ETA: 6:51 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18586: setting learning rate to 7.158192928154869e-06.\n",
      " 786/1780 [============>.................] - ETA: 6:50 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18587: setting learning rate to 7.157871338606064e-06.\n",
      " 787/1780 [============>.................] - ETA: 6:50 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18588: setting learning rate to 7.1575497380870075e-06.\n",
      " 788/1780 [============>.................] - ETA: 6:49 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18589: setting learning rate to 7.157228126599334e-06.\n",
      " 789/1780 [============>.................] - ETA: 6:49 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18590: setting learning rate to 7.156906504144677e-06.\n",
      " 790/1780 [============>.................] - ETA: 6:48 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18591: setting learning rate to 7.1565848707246746e-06.\n",
      " 791/1780 [============>.................] - ETA: 6:48 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18592: setting learning rate to 7.156263226340963e-06.\n",
      " 792/1780 [============>.................] - ETA: 6:48 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18593: setting learning rate to 7.155941570995172e-06.\n",
      " 793/1780 [============>.................] - ETA: 6:47 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18594: setting learning rate to 7.155619904688941e-06.\n",
      " 794/1780 [============>.................] - ETA: 6:47 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18595: setting learning rate to 7.155298227423904e-06.\n",
      " 795/1780 [============>.................] - ETA: 6:46 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18596: setting learning rate to 7.154976539201695e-06.\n",
      " 796/1780 [============>.................] - ETA: 6:46 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18597: setting learning rate to 7.154654840023952e-06.\n",
      " 797/1780 [============>.................] - ETA: 6:46 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18598: setting learning rate to 7.1543331298923116e-06.\n",
      " 798/1780 [============>.................] - ETA: 6:45 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18599: setting learning rate to 7.154011408808405e-06.\n",
      " 799/1780 [============>.................] - ETA: 6:45 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18600: setting learning rate to 7.1536896767738705e-06.\n",
      " 800/1780 [============>.................] - ETA: 6:44 - accuracy: 0.9960 - loss: 0.0133\n",
      "Batch 18601: setting learning rate to 7.153367933790343e-06.\n",
      " 801/1780 [============>.................] - ETA: 6:44 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18602: setting learning rate to 7.153046179859459e-06.\n",
      " 802/1780 [============>.................] - ETA: 6:43 - accuracy: 0.9959 - loss: 0.0133\n",
      "Batch 18603: setting learning rate to 7.152724414982852e-06.\n",
      " 803/1780 [============>.................] - ETA: 6:43 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18604: setting learning rate to 7.1524026391621605e-06.\n",
      " 804/1780 [============>.................] - ETA: 6:43 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18605: setting learning rate to 7.1520808523990195e-06.\n",
      " 805/1780 [============>.................] - ETA: 6:42 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18606: setting learning rate to 7.151759054695064e-06.\n",
      " 806/1780 [============>.................] - ETA: 6:42 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18607: setting learning rate to 7.151437246051931e-06.\n",
      " 807/1780 [============>.................] - ETA: 6:41 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18608: setting learning rate to 7.151115426471256e-06.\n",
      " 808/1780 [============>.................] - ETA: 6:41 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18609: setting learning rate to 7.150793595954675e-06.\n",
      " 809/1780 [============>.................] - ETA: 6:41 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18610: setting learning rate to 7.150471754503825e-06.\n",
      " 810/1780 [============>.................] - ETA: 6:40 - accuracy: 0.9959 - loss: 0.0140\n",
      "Batch 18611: setting learning rate to 7.15014990212034e-06.\n",
      " 811/1780 [============>.................] - ETA: 6:40 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18612: setting learning rate to 7.1498280388058595e-06.\n",
      " 812/1780 [============>.................] - ETA: 6:39 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18613: setting learning rate to 7.149506164562016e-06.\n",
      " 813/1780 [============>.................] - ETA: 6:39 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18614: setting learning rate to 7.1491842793904495e-06.\n",
      " 814/1780 [============>.................] - ETA: 6:38 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18615: setting learning rate to 7.148862383292795e-06.\n",
      " 815/1780 [============>.................] - ETA: 6:38 - accuracy: 0.9958 - loss: 0.0141\n",
      "Batch 18616: setting learning rate to 7.148540476270689e-06.\n",
      " 816/1780 [============>.................] - ETA: 6:38 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18617: setting learning rate to 7.1482185583257665e-06.\n",
      " 817/1780 [============>.................] - ETA: 6:37 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18618: setting learning rate to 7.147896629459666e-06.\n",
      " 818/1780 [============>.................] - ETA: 6:37 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18619: setting learning rate to 7.147574689674024e-06.\n",
      " 819/1780 [============>.................] - ETA: 6:36 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18620: setting learning rate to 7.147252738970476e-06.\n",
      " 820/1780 [============>.................] - ETA: 6:36 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18621: setting learning rate to 7.14693077735066e-06.\n",
      " 821/1780 [============>.................] - ETA: 6:36 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18622: setting learning rate to 7.146608804816211e-06.\n",
      " 822/1780 [============>.................] - ETA: 6:35 - accuracy: 0.9959 - loss: 0.0140\n",
      "Batch 18623: setting learning rate to 7.146286821368768e-06.\n",
      " 823/1780 [============>.................] - ETA: 6:35 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18624: setting learning rate to 7.1459648270099665e-06.\n",
      " 824/1780 [============>.................] - ETA: 6:34 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18625: setting learning rate to 7.145642821741444e-06.\n",
      " 825/1780 [============>.................] - ETA: 6:34 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18626: setting learning rate to 7.14532080556484e-06.\n",
      " 826/1780 [============>.................] - ETA: 6:33 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18627: setting learning rate to 7.144998778481785e-06.\n",
      " 827/1780 [============>.................] - ETA: 6:33 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18628: setting learning rate to 7.144676740493923e-06.\n",
      " 828/1780 [============>.................] - ETA: 6:33 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18629: setting learning rate to 7.144354691602888e-06.\n",
      " 829/1780 [============>.................] - ETA: 6:32 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18630: setting learning rate to 7.144032631810317e-06.\n",
      " 830/1780 [============>.................] - ETA: 6:32 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18631: setting learning rate to 7.143710561117848e-06.\n",
      " 831/1780 [=============>................] - ETA: 6:31 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18632: setting learning rate to 7.143388479527119e-06.\n",
      " 832/1780 [=============>................] - ETA: 6:31 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18633: setting learning rate to 7.143066387039765e-06.\n",
      " 833/1780 [=============>................] - ETA: 6:31 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18634: setting learning rate to 7.142744283657426e-06.\n",
      " 834/1780 [=============>................] - ETA: 6:30 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18635: setting learning rate to 7.14242216938174e-06.\n",
      " 835/1780 [=============>................] - ETA: 6:30 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18636: setting learning rate to 7.142100044214342e-06.\n",
      " 836/1780 [=============>................] - ETA: 6:29 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18637: setting learning rate to 7.14177790815687e-06.\n",
      " 837/1780 [=============>................] - ETA: 6:29 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18638: setting learning rate to 7.141455761210965e-06.\n",
      " 838/1780 [=============>................] - ETA: 6:29 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18639: setting learning rate to 7.1411336033782605e-06.\n",
      " 839/1780 [=============>................] - ETA: 6:28 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18640: setting learning rate to 7.140811434660396e-06.\n",
      " 840/1780 [=============>................] - ETA: 6:28 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18641: setting learning rate to 7.1404892550590096e-06.\n",
      " 841/1780 [=============>................] - ETA: 6:27 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18642: setting learning rate to 7.140167064575741e-06.\n",
      " 842/1780 [=============>................] - ETA: 6:27 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18643: setting learning rate to 7.1398448632122246e-06.\n",
      " 843/1780 [=============>................] - ETA: 6:26 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18644: setting learning rate to 7.139522650970099e-06.\n",
      " 844/1780 [=============>................] - ETA: 6:26 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18645: setting learning rate to 7.139200427851004e-06.\n",
      " 845/1780 [=============>................] - ETA: 6:26 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18646: setting learning rate to 7.138878193856578e-06.\n",
      " 846/1780 [=============>................] - ETA: 6:25 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18647: setting learning rate to 7.138555948988457e-06.\n",
      " 847/1780 [=============>................] - ETA: 6:25 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18648: setting learning rate to 7.138233693248281e-06.\n",
      " 848/1780 [=============>................] - ETA: 6:24 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18649: setting learning rate to 7.137911426637687e-06.\n",
      " 849/1780 [=============>................] - ETA: 6:24 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18650: setting learning rate to 7.137589149158315e-06.\n",
      " 850/1780 [=============>................] - ETA: 6:23 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18651: setting learning rate to 7.137266860811802e-06.\n",
      " 851/1780 [=============>................] - ETA: 6:23 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18652: setting learning rate to 7.136944561599787e-06.\n",
      " 852/1780 [=============>................] - ETA: 6:23 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18653: setting learning rate to 7.13662225152391e-06.\n",
      " 853/1780 [=============>................] - ETA: 6:22 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18654: setting learning rate to 7.1362999305858064e-06.\n",
      " 854/1780 [=============>................] - ETA: 6:22 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18655: setting learning rate to 7.135977598787116e-06.\n",
      " 855/1780 [=============>................] - ETA: 6:21 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18656: setting learning rate to 7.1356552561294805e-06.\n",
      " 856/1780 [=============>................] - ETA: 6:21 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18657: setting learning rate to 7.135332902614534e-06.\n",
      " 857/1780 [=============>................] - ETA: 6:21 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18658: setting learning rate to 7.135010538243916e-06.\n",
      " 858/1780 [=============>................] - ETA: 6:20 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18659: setting learning rate to 7.134688163019269e-06.\n",
      " 859/1780 [=============>................] - ETA: 6:20 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18660: setting learning rate to 7.1343657769422295e-06.\n",
      " 860/1780 [=============>................] - ETA: 6:19 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18661: setting learning rate to 7.134043380014436e-06.\n",
      " 861/1780 [=============>................] - ETA: 6:19 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18662: setting learning rate to 7.133720972237528e-06.\n",
      " 862/1780 [=============>................] - ETA: 6:18 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18663: setting learning rate to 7.1333985536131455e-06.\n",
      " 863/1780 [=============>................] - ETA: 6:18 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18664: setting learning rate to 7.1330761241429255e-06.\n",
      " 864/1780 [=============>................] - ETA: 6:18 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18665: setting learning rate to 7.1327536838285095e-06.\n",
      " 865/1780 [=============>................] - ETA: 6:17 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18666: setting learning rate to 7.132431232671535e-06.\n",
      " 866/1780 [=============>................] - ETA: 6:17 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18667: setting learning rate to 7.132108770673643e-06.\n",
      " 867/1780 [=============>................] - ETA: 6:16 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18668: setting learning rate to 7.13178629783647e-06.\n",
      " 868/1780 [=============>................] - ETA: 6:16 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18669: setting learning rate to 7.131463814161658e-06.\n",
      " 869/1780 [=============>................] - ETA: 6:15 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18670: setting learning rate to 7.131141319650847e-06.\n",
      " 870/1780 [=============>................] - ETA: 6:15 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18671: setting learning rate to 7.130818814305673e-06.\n",
      " 871/1780 [=============>................] - ETA: 6:15 - accuracy: 0.9959 - loss: 0.0140\n",
      "Batch 18672: setting learning rate to 7.130496298127779e-06.\n",
      " 872/1780 [=============>................] - ETA: 6:14 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18673: setting learning rate to 7.130173771118804e-06.\n",
      " 873/1780 [=============>................] - ETA: 6:14 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18674: setting learning rate to 7.129851233280386e-06.\n",
      " 874/1780 [=============>................] - ETA: 6:13 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18675: setting learning rate to 7.129528684614165e-06.\n",
      " 875/1780 [=============>................] - ETA: 6:13 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18676: setting learning rate to 7.1292061251217825e-06.\n",
      " 876/1780 [=============>................] - ETA: 6:12 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18677: setting learning rate to 7.128883554804878e-06.\n",
      " 877/1780 [=============>................] - ETA: 6:12 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18678: setting learning rate to 7.128560973665088e-06.\n",
      " 878/1780 [=============>................] - ETA: 6:12 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18679: setting learning rate to 7.128238381704058e-06.\n",
      " 879/1780 [=============>................] - ETA: 6:11 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18680: setting learning rate to 7.127915778923425e-06.\n",
      " 880/1780 [=============>................] - ETA: 6:11 - accuracy: 0.9958 - loss: 0.0140\n",
      "Batch 18681: setting learning rate to 7.1275931653248285e-06.\n",
      " 881/1780 [=============>................] - ETA: 6:10 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18682: setting learning rate to 7.12727054090991e-06.\n",
      " 882/1780 [=============>................] - ETA: 6:10 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18683: setting learning rate to 7.126947905680309e-06.\n",
      " 883/1780 [=============>................] - ETA: 6:10 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18684: setting learning rate to 7.126625259637665e-06.\n",
      " 884/1780 [=============>................] - ETA: 6:09 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18685: setting learning rate to 7.126302602783619e-06.\n",
      " 885/1780 [=============>................] - ETA: 6:09 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18686: setting learning rate to 7.125979935119813e-06.\n",
      " 886/1780 [=============>................] - ETA: 6:08 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18687: setting learning rate to 7.125657256647885e-06.\n",
      " 887/1780 [=============>................] - ETA: 6:08 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18688: setting learning rate to 7.125334567369475e-06.\n",
      " 888/1780 [=============>................] - ETA: 6:07 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18689: setting learning rate to 7.125011867286225e-06.\n",
      " 889/1780 [=============>................] - ETA: 6:07 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18690: setting learning rate to 7.1246891563997765e-06.\n",
      " 890/1780 [==============>...............] - ETA: 6:07 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18691: setting learning rate to 7.124366434711768e-06.\n",
      " 891/1780 [==============>...............] - ETA: 6:06 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18692: setting learning rate to 7.1240437022238406e-06.\n",
      " 892/1780 [==============>...............] - ETA: 6:06 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18693: setting learning rate to 7.123720958937637e-06.\n",
      " 893/1780 [==============>...............] - ETA: 6:05 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18694: setting learning rate to 7.123398204854795e-06.\n",
      " 894/1780 [==============>...............] - ETA: 6:05 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18695: setting learning rate to 7.123075439976958e-06.\n",
      " 895/1780 [==============>...............] - ETA: 6:05 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18696: setting learning rate to 7.1227526643057645e-06.\n",
      " 896/1780 [==============>...............] - ETA: 6:04 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18697: setting learning rate to 7.122429877842858e-06.\n",
      " 897/1780 [==============>...............] - ETA: 6:04 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18698: setting learning rate to 7.122107080589877e-06.\n",
      " 898/1780 [==============>...............] - ETA: 6:03 - accuracy: 0.9958 - loss: 0.0139\n",
      "Batch 18699: setting learning rate to 7.121784272548465e-06.\n",
      " 899/1780 [==============>...............] - ETA: 6:03 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18700: setting learning rate to 7.121461453720259e-06.\n",
      " 900/1780 [==============>...............] - ETA: 6:02 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18701: setting learning rate to 7.121138624106905e-06.\n",
      " 901/1780 [==============>...............] - ETA: 6:02 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18702: setting learning rate to 7.120815783710042e-06.\n",
      " 902/1780 [==============>...............] - ETA: 6:02 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18703: setting learning rate to 7.1204929325313125e-06.\n",
      " 903/1780 [==============>...............] - ETA: 6:01 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18704: setting learning rate to 7.120170070572354e-06.\n",
      " 904/1780 [==============>...............] - ETA: 6:01 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18705: setting learning rate to 7.119847197834813e-06.\n",
      " 905/1780 [==============>...............] - ETA: 6:00 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18706: setting learning rate to 7.119524314320328e-06.\n",
      " 906/1780 [==============>...............] - ETA: 6:00 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18707: setting learning rate to 7.1192014200305415e-06.\n",
      " 907/1780 [==============>...............] - ETA: 6:00 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18708: setting learning rate to 7.1188785149670934e-06.\n",
      " 908/1780 [==============>...............] - ETA: 5:59 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18709: setting learning rate to 7.118555599131627e-06.\n",
      " 909/1780 [==============>...............] - ETA: 5:59 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18710: setting learning rate to 7.1182326725257845e-06.\n",
      " 910/1780 [==============>...............] - ETA: 5:58 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18711: setting learning rate to 7.117909735151205e-06.\n",
      " 911/1780 [==============>...............] - ETA: 5:58 - accuracy: 0.9958 - loss: 0.0137\n",
      "Batch 18712: setting learning rate to 7.1175867870095315e-06.\n",
      " 912/1780 [==============>...............] - ETA: 5:58 - accuracy: 0.9958 - loss: 0.0137\n",
      "Batch 18713: setting learning rate to 7.117263828102407e-06.\n",
      " 913/1780 [==============>...............] - ETA: 5:57 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18714: setting learning rate to 7.116940858431474e-06.\n",
      " 914/1780 [==============>...............] - ETA: 5:57 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18715: setting learning rate to 7.116617877998371e-06.\n",
      " 915/1780 [==============>...............] - ETA: 5:56 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18716: setting learning rate to 7.1162948868047425e-06.\n",
      " 916/1780 [==============>...............] - ETA: 5:56 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18717: setting learning rate to 7.11597188485223e-06.\n",
      " 917/1780 [==============>...............] - ETA: 5:56 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18718: setting learning rate to 7.115648872142475e-06.\n",
      " 918/1780 [==============>...............] - ETA: 5:55 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18719: setting learning rate to 7.115325848677119e-06.\n",
      " 919/1780 [==============>...............] - ETA: 5:55 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18720: setting learning rate to 7.115002814457808e-06.\n",
      " 920/1780 [==============>...............] - ETA: 5:54 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18721: setting learning rate to 7.11467976948618e-06.\n",
      " 921/1780 [==============>...............] - ETA: 5:54 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18722: setting learning rate to 7.114356713763879e-06.\n",
      " 922/1780 [==============>...............] - ETA: 5:53 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18723: setting learning rate to 7.114033647292546e-06.\n",
      " 923/1780 [==============>...............] - ETA: 5:53 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18724: setting learning rate to 7.1137105700738284e-06.\n",
      " 924/1780 [==============>...............] - ETA: 5:53 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18725: setting learning rate to 7.113387482109362e-06.\n",
      " 925/1780 [==============>...............] - ETA: 5:52 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18726: setting learning rate to 7.113064383400792e-06.\n",
      " 926/1780 [==============>...............] - ETA: 5:52 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18727: setting learning rate to 7.112741273949763e-06.\n",
      " 927/1780 [==============>...............] - ETA: 5:51 - accuracy: 0.9958 - loss: 0.0137\n",
      "Batch 18728: setting learning rate to 7.112418153757914e-06.\n",
      " 928/1780 [==============>...............] - ETA: 5:51 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18729: setting learning rate to 7.1120950228268905e-06.\n",
      " 929/1780 [==============>...............] - ETA: 5:51 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18730: setting learning rate to 7.111771881158334e-06.\n",
      " 930/1780 [==============>...............] - ETA: 5:50 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18731: setting learning rate to 7.111448728753889e-06.\n",
      " 931/1780 [==============>...............] - ETA: 5:50 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18732: setting learning rate to 7.111125565615196e-06.\n",
      " 932/1780 [==============>...............] - ETA: 5:49 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18733: setting learning rate to 7.110802391743897e-06.\n",
      " 933/1780 [==============>...............] - ETA: 5:49 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18734: setting learning rate to 7.1104792071416404e-06.\n",
      " 934/1780 [==============>...............] - ETA: 5:49 - accuracy: 0.9958 - loss: 0.0137\n",
      "Batch 18735: setting learning rate to 7.110156011810063e-06.\n",
      " 935/1780 [==============>...............] - ETA: 5:48 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18736: setting learning rate to 7.109832805750811e-06.\n",
      " 936/1780 [==============>...............] - ETA: 5:48 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18737: setting learning rate to 7.1095095889655285e-06.\n",
      " 937/1780 [==============>...............] - ETA: 5:47 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18738: setting learning rate to 7.109186361455856e-06.\n",
      " 938/1780 [==============>...............] - ETA: 5:47 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18739: setting learning rate to 7.108863123223437e-06.\n",
      " 939/1780 [==============>...............] - ETA: 5:46 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18740: setting learning rate to 7.1085398742699174e-06.\n",
      " 940/1780 [==============>...............] - ETA: 5:46 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18741: setting learning rate to 7.108216614596939e-06.\n",
      " 941/1780 [==============>...............] - ETA: 5:46 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18742: setting learning rate to 7.107893344206144e-06.\n",
      " 942/1780 [==============>...............] - ETA: 5:45 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18743: setting learning rate to 7.107570063099176e-06.\n",
      " 943/1780 [==============>...............] - ETA: 5:45 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18744: setting learning rate to 7.107246771277683e-06.\n",
      " 944/1780 [==============>...............] - ETA: 5:44 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18745: setting learning rate to 7.106923468743301e-06.\n",
      " 945/1780 [==============>...............] - ETA: 5:44 - accuracy: 0.9958 - loss: 0.0138\n",
      "Batch 18746: setting learning rate to 7.106600155497679e-06.\n",
      " 946/1780 [==============>...............] - ETA: 5:44 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18747: setting learning rate to 7.10627683154246e-06.\n",
      " 947/1780 [==============>...............] - ETA: 5:43 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18748: setting learning rate to 7.105953496879287e-06.\n",
      " 948/1780 [==============>...............] - ETA: 5:43 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18749: setting learning rate to 7.105630151509804e-06.\n",
      " 949/1780 [==============>...............] - ETA: 5:42 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18750: setting learning rate to 7.105306795435653e-06.\n",
      " 950/1780 [===============>..............] - ETA: 5:42 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18751: setting learning rate to 7.104983428658481e-06.\n",
      " 951/1780 [===============>..............] - ETA: 5:41 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18752: setting learning rate to 7.10466005117993e-06.\n",
      " 952/1780 [===============>..............] - ETA: 5:41 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18753: setting learning rate to 7.1043366630016445e-06.\n",
      " 953/1780 [===============>..............] - ETA: 5:41 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18754: setting learning rate to 7.104013264125268e-06.\n",
      " 954/1780 [===============>..............] - ETA: 5:40 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18755: setting learning rate to 7.103689854552444e-06.\n",
      " 955/1780 [===============>..............] - ETA: 5:40 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18756: setting learning rate to 7.1033664342848195e-06.\n",
      " 956/1780 [===============>..............] - ETA: 5:39 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18757: setting learning rate to 7.103043003324037e-06.\n",
      " 957/1780 [===============>..............] - ETA: 5:39 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18758: setting learning rate to 7.10271956167174e-06.\n",
      " 958/1780 [===============>..............] - ETA: 5:39 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18759: setting learning rate to 7.102396109329575e-06.\n",
      " 959/1780 [===============>..............] - ETA: 5:38 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18760: setting learning rate to 7.102072646299183e-06.\n",
      " 960/1780 [===============>..............] - ETA: 5:38 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18761: setting learning rate to 7.101749172582212e-06.\n",
      " 961/1780 [===============>..............] - ETA: 5:37 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18762: setting learning rate to 7.101425688180303e-06.\n",
      " 962/1780 [===============>..............] - ETA: 5:37 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18763: setting learning rate to 7.101102193095104e-06.\n",
      " 963/1780 [===============>..............] - ETA: 5:37 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18764: setting learning rate to 7.1007786873282584e-06.\n",
      " 964/1780 [===============>..............] - ETA: 5:36 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18765: setting learning rate to 7.10045517088141e-06.\n",
      " 965/1780 [===============>..............] - ETA: 5:36 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18766: setting learning rate to 7.100131643756203e-06.\n",
      " 966/1780 [===============>..............] - ETA: 5:35 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18767: setting learning rate to 7.099808105954282e-06.\n",
      " 967/1780 [===============>..............] - ETA: 5:35 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18768: setting learning rate to 7.0994845574772965e-06.\n",
      " 968/1780 [===============>..............] - ETA: 5:34 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18769: setting learning rate to 7.099160998326885e-06.\n",
      " 969/1780 [===============>..............] - ETA: 5:34 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18770: setting learning rate to 7.098837428504696e-06.\n",
      " 970/1780 [===============>..............] - ETA: 5:34 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18771: setting learning rate to 7.098513848012374e-06.\n",
      " 971/1780 [===============>..............] - ETA: 5:33 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18772: setting learning rate to 7.098190256851564e-06.\n",
      " 972/1780 [===============>..............] - ETA: 5:33 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18773: setting learning rate to 7.097866655023909e-06.\n",
      " 973/1780 [===============>..............] - ETA: 5:32 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18774: setting learning rate to 7.097543042531057e-06.\n",
      " 974/1780 [===============>..............] - ETA: 5:32 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18775: setting learning rate to 7.097219419374653e-06.\n",
      " 975/1780 [===============>..............] - ETA: 5:32 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18776: setting learning rate to 7.096895785556341e-06.\n",
      " 976/1780 [===============>..............] - ETA: 5:31 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18777: setting learning rate to 7.096572141077764e-06.\n",
      " 977/1780 [===============>..............] - ETA: 5:31 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18778: setting learning rate to 7.096248485940574e-06.\n",
      " 978/1780 [===============>..............] - ETA: 5:30 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18779: setting learning rate to 7.0959248201464104e-06.\n",
      " 979/1780 [===============>..............] - ETA: 5:30 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18780: setting learning rate to 7.09560114369692e-06.\n",
      " 980/1780 [===============>..............] - ETA: 5:29 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18781: setting learning rate to 7.09527745659375e-06.\n",
      " 981/1780 [===============>..............] - ETA: 5:29 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18782: setting learning rate to 7.094953758838544e-06.\n",
      " 982/1780 [===============>..............] - ETA: 5:29 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18783: setting learning rate to 7.094630050432949e-06.\n",
      " 983/1780 [===============>..............] - ETA: 5:28 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18784: setting learning rate to 7.094306331378611e-06.\n",
      " 984/1780 [===============>..............] - ETA: 5:28 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18785: setting learning rate to 7.093982601677175e-06.\n",
      " 985/1780 [===============>..............] - ETA: 5:27 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18786: setting learning rate to 7.093658861330286e-06.\n",
      " 986/1780 [===============>..............] - ETA: 5:27 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18787: setting learning rate to 7.093335110339591e-06.\n",
      " 987/1780 [===============>..............] - ETA: 5:27 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18788: setting learning rate to 7.093011348706736e-06.\n",
      " 988/1780 [===============>..............] - ETA: 5:26 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18789: setting learning rate to 7.0926875764333655e-06.\n",
      " 989/1780 [===============>..............] - ETA: 5:26 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18790: setting learning rate to 7.092363793521126e-06.\n",
      " 990/1780 [===============>..............] - ETA: 5:25 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18791: setting learning rate to 7.092039999971666e-06.\n",
      " 991/1780 [===============>..............] - ETA: 5:25 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18792: setting learning rate to 7.091716195786629e-06.\n",
      " 992/1780 [===============>..............] - ETA: 5:24 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18793: setting learning rate to 7.091392380967661e-06.\n",
      " 993/1780 [===============>..............] - ETA: 5:24 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18794: setting learning rate to 7.091068555516409e-06.\n",
      " 994/1780 [===============>..............] - ETA: 5:24 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18795: setting learning rate to 7.090744719434521e-06.\n",
      " 995/1780 [===============>..............] - ETA: 5:23 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18796: setting learning rate to 7.09042087272364e-06.\n",
      " 996/1780 [===============>..............] - ETA: 5:23 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18797: setting learning rate to 7.090097015385414e-06.\n",
      " 997/1780 [===============>..............] - ETA: 5:22 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18798: setting learning rate to 7.089773147421491e-06.\n",
      " 998/1780 [===============>..............] - ETA: 5:22 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18799: setting learning rate to 7.089449268833515e-06.\n",
      " 999/1780 [===============>..............] - ETA: 5:21 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18800: setting learning rate to 7.089125379623132e-06.\n",
      "1000/1780 [===============>..............] - ETA: 5:21 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18801: setting learning rate to 7.088801479791992e-06.\n",
      "1001/1780 [===============>..............] - ETA: 5:21 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18802: setting learning rate to 7.088477569341738e-06.\n",
      "1002/1780 [===============>..............] - ETA: 5:20 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18803: setting learning rate to 7.088153648274021e-06.\n",
      "1003/1780 [===============>..............] - ETA: 5:20 - accuracy: 0.9959 - loss: 0.0135\n",
      "Batch 18804: setting learning rate to 7.087829716590483e-06.\n",
      "1004/1780 [===============>..............] - ETA: 5:19 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18805: setting learning rate to 7.087505774292773e-06.\n",
      "1005/1780 [===============>..............] - ETA: 5:19 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18806: setting learning rate to 7.087181821382538e-06.\n",
      "1006/1780 [===============>..............] - ETA: 5:19 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18807: setting learning rate to 7.086857857861426e-06.\n",
      "1007/1780 [===============>..............] - ETA: 5:18 - accuracy: 0.9959 - loss: 0.0134\n",
      "Batch 18808: setting learning rate to 7.086533883731083e-06.\n",
      "1008/1780 [===============>..............] - ETA: 5:18 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18809: setting learning rate to 7.086209898993154e-06.\n",
      "1009/1780 [================>.............] - ETA: 5:17 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18810: setting learning rate to 7.0858859036492884e-06.\n",
      "1010/1780 [================>.............] - ETA: 5:17 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18811: setting learning rate to 7.085561897701133e-06.\n",
      "1011/1780 [================>.............] - ETA: 5:17 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18812: setting learning rate to 7.085237881150336e-06.\n",
      "1012/1780 [================>.............] - ETA: 5:16 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18813: setting learning rate to 7.084913853998542e-06.\n",
      "1013/1780 [================>.............] - ETA: 5:16 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18814: setting learning rate to 7.0845898162474e-06.\n",
      "1014/1780 [================>.............] - ETA: 5:15 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18815: setting learning rate to 7.084265767898558e-06.\n",
      "1015/1780 [================>.............] - ETA: 5:15 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18816: setting learning rate to 7.083941708953662e-06.\n",
      "1016/1780 [================>.............] - ETA: 5:14 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18817: setting learning rate to 7.08361763941436e-06.\n",
      "1017/1780 [================>.............] - ETA: 5:14 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18818: setting learning rate to 7.083293559282298e-06.\n",
      "1018/1780 [================>.............] - ETA: 5:14 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18819: setting learning rate to 7.082969468559128e-06.\n",
      "1019/1780 [================>.............] - ETA: 5:13 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18820: setting learning rate to 7.082645367246492e-06.\n",
      "1020/1780 [================>.............] - ETA: 5:13 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18821: setting learning rate to 7.082321255346042e-06.\n",
      "1021/1780 [================>.............] - ETA: 5:12 - accuracy: 0.9959 - loss: 0.0136\n",
      "Batch 18822: setting learning rate to 7.081997132859424e-06.\n",
      "1022/1780 [================>.............] - ETA: 5:12 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18823: setting learning rate to 7.081672999788285e-06.\n",
      "1023/1780 [================>.............] - ETA: 5:12 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18824: setting learning rate to 7.081348856134274e-06.\n",
      "1024/1780 [================>.............] - ETA: 5:11 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18825: setting learning rate to 7.081024701899039e-06.\n",
      "1025/1780 [================>.............] - ETA: 5:11 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18826: setting learning rate to 7.080700537084228e-06.\n",
      "1026/1780 [================>.............] - ETA: 5:10 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18827: setting learning rate to 7.0803763616914865e-06.\n",
      "1027/1780 [================>.............] - ETA: 5:10 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18828: setting learning rate to 7.080052175722466e-06.\n",
      "1028/1780 [================>.............] - ETA: 5:09 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18829: setting learning rate to 7.079727979178814e-06.\n",
      "1029/1780 [================>.............] - ETA: 5:09 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18830: setting learning rate to 7.0794037720621765e-06.\n",
      "1030/1780 [================>.............] - ETA: 5:09 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18831: setting learning rate to 7.079079554374204e-06.\n",
      "1031/1780 [================>.............] - ETA: 5:08 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18832: setting learning rate to 7.078755326116542e-06.\n",
      "1032/1780 [================>.............] - ETA: 5:08 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18833: setting learning rate to 7.078431087290842e-06.\n",
      "1033/1780 [================>.............] - ETA: 5:07 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18834: setting learning rate to 7.078106837898753e-06.\n",
      "1034/1780 [================>.............] - ETA: 5:07 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18835: setting learning rate to 7.0777825779419185e-06.\n",
      "1035/1780 [================>.............] - ETA: 5:07 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18836: setting learning rate to 7.077458307421992e-06.\n",
      "1036/1780 [================>.............] - ETA: 5:06 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18837: setting learning rate to 7.077134026340617e-06.\n",
      "1037/1780 [================>.............] - ETA: 5:06 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18838: setting learning rate to 7.076809734699448e-06.\n",
      "1038/1780 [================>.............] - ETA: 5:05 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18839: setting learning rate to 7.076485432500129e-06.\n",
      "1039/1780 [================>.............] - ETA: 5:05 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18840: setting learning rate to 7.076161119744313e-06.\n",
      "1040/1780 [================>.............] - ETA: 5:05 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18841: setting learning rate to 7.075836796433644e-06.\n",
      "1041/1780 [================>.............] - ETA: 5:04 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18842: setting learning rate to 7.075512462569774e-06.\n",
      "1042/1780 [================>.............] - ETA: 5:04 - accuracy: 0.9959 - loss: 0.0139\n",
      "Batch 18843: setting learning rate to 7.075188118154349e-06.\n",
      "1043/1780 [================>.............] - ETA: 5:03 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18844: setting learning rate to 7.074863763189022e-06.\n",
      "1044/1780 [================>.............] - ETA: 5:03 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18845: setting learning rate to 7.074539397675437e-06.\n",
      "1045/1780 [================>.............] - ETA: 5:02 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18846: setting learning rate to 7.0742150216152484e-06.\n",
      "1046/1780 [================>.............] - ETA: 5:02 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18847: setting learning rate to 7.073890635010101e-06.\n",
      "1047/1780 [================>.............] - ETA: 5:02 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18848: setting learning rate to 7.0735662378616465e-06.\n",
      "1048/1780 [================>.............] - ETA: 5:01 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18849: setting learning rate to 7.073241830171533e-06.\n",
      "1049/1780 [================>.............] - ETA: 5:01 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18850: setting learning rate to 7.0729174119414104e-06.\n",
      "1050/1780 [================>.............] - ETA: 5:00 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18851: setting learning rate to 7.0725929831729255e-06.\n",
      "1051/1780 [================>.............] - ETA: 5:00 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18852: setting learning rate to 7.072268543867731e-06.\n",
      "1052/1780 [================>.............] - ETA: 4:59 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18853: setting learning rate to 7.071944094027475e-06.\n",
      "1053/1780 [================>.............] - ETA: 4:59 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18854: setting learning rate to 7.071619633653807e-06.\n",
      "1054/1780 [================>.............] - ETA: 4:59 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18855: setting learning rate to 7.071295162748375e-06.\n",
      "1055/1780 [================>.............] - ETA: 4:58 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18856: setting learning rate to 7.070970681312831e-06.\n",
      "1056/1780 [================>.............] - ETA: 4:58 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18857: setting learning rate to 7.070646189348823e-06.\n",
      "1057/1780 [================>.............] - ETA: 4:57 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18858: setting learning rate to 7.070321686858001e-06.\n",
      "1058/1780 [================>.............] - ETA: 4:57 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18859: setting learning rate to 7.069997173842015e-06.\n",
      "1059/1780 [================>.............] - ETA: 4:57 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18860: setting learning rate to 7.069672650302515e-06.\n",
      "1060/1780 [================>.............] - ETA: 4:56 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18861: setting learning rate to 7.069348116241149e-06.\n",
      "1061/1780 [================>.............] - ETA: 4:56 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18862: setting learning rate to 7.06902357165957e-06.\n",
      "1062/1780 [================>.............] - ETA: 4:55 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18863: setting learning rate to 7.068699016559426e-06.\n",
      "1063/1780 [================>.............] - ETA: 4:55 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18864: setting learning rate to 7.068374450942367e-06.\n",
      "1064/1780 [================>.............] - ETA: 4:55 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18865: setting learning rate to 7.068049874810042e-06.\n",
      "1065/1780 [================>.............] - ETA: 4:54 - accuracy: 0.9959 - loss: 0.0138\n",
      "Batch 18866: setting learning rate to 7.0677252881641045e-06.\n",
      "1066/1780 [================>.............] - ETA: 4:54 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18867: setting learning rate to 7.067400691006202e-06.\n",
      "1067/1780 [================>.............] - ETA: 4:53 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18868: setting learning rate to 7.067076083337985e-06.\n",
      "1068/1780 [=================>............] - ETA: 4:53 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18869: setting learning rate to 7.066751465161103e-06.\n",
      "1069/1780 [=================>............] - ETA: 4:53 - accuracy: 0.9959 - loss: 0.0137\n",
      "Batch 18870: setting learning rate to 7.066426836477209e-06.\n",
      "1070/1780 [=================>............] - ETA: 4:52 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18871: setting learning rate to 7.06610219728795e-06.\n",
      "1071/1780 [=================>............] - ETA: 4:52 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18872: setting learning rate to 7.065777547594979e-06.\n",
      "1072/1780 [=================>............] - ETA: 4:51 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18873: setting learning rate to 7.065452887399946e-06.\n",
      "1073/1780 [=================>............] - ETA: 4:51 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18874: setting learning rate to 7.0651282167044995e-06.\n",
      "1074/1780 [=================>............] - ETA: 4:50 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18875: setting learning rate to 7.064803535510292e-06.\n",
      "1075/1780 [=================>............] - ETA: 4:50 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18876: setting learning rate to 7.0644788438189744e-06.\n",
      "1076/1780 [=================>............] - ETA: 4:50 - accuracy: 0.9960 - loss: 0.0137\n",
      "Batch 18877: setting learning rate to 7.064154141632195e-06.\n",
      "1077/1780 [=================>............] - ETA: 4:49 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18878: setting learning rate to 7.063829428951608e-06.\n",
      "1078/1780 [=================>............] - ETA: 4:49 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18879: setting learning rate to 7.063504705778862e-06.\n",
      "1079/1780 [=================>............] - ETA: 4:48 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18880: setting learning rate to 7.063179972115609e-06.\n",
      "1080/1780 [=================>............] - ETA: 4:48 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18881: setting learning rate to 7.0628552279634975e-06.\n",
      "1081/1780 [=================>............] - ETA: 4:48 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18882: setting learning rate to 7.06253047332418e-06.\n",
      "1082/1780 [=================>............] - ETA: 4:47 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18883: setting learning rate to 7.06220570819931e-06.\n",
      "1083/1780 [=================>............] - ETA: 4:47 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18884: setting learning rate to 7.061880932590534e-06.\n",
      "1084/1780 [=================>............] - ETA: 4:46 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18885: setting learning rate to 7.061556146499505e-06.\n",
      "1085/1780 [=================>............] - ETA: 4:46 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18886: setting learning rate to 7.061231349927875e-06.\n",
      "1086/1780 [=================>............] - ETA: 4:46 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18887: setting learning rate to 7.060906542877295e-06.\n",
      "1087/1780 [=================>............] - ETA: 4:45 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18888: setting learning rate to 7.060581725349415e-06.\n",
      "1088/1780 [=================>............] - ETA: 4:45 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18889: setting learning rate to 7.060256897345887e-06.\n",
      "1089/1780 [=================>............] - ETA: 4:44 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18890: setting learning rate to 7.059932058868364e-06.\n",
      "1090/1780 [=================>............] - ETA: 4:44 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18891: setting learning rate to 7.059607209918496e-06.\n",
      "1091/1780 [=================>............] - ETA: 4:43 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18892: setting learning rate to 7.059282350497933e-06.\n",
      "1092/1780 [=================>............] - ETA: 4:43 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18893: setting learning rate to 7.058957480608329e-06.\n",
      "1093/1780 [=================>............] - ETA: 4:43 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18894: setting learning rate to 7.058632600251334e-06.\n",
      "1094/1780 [=================>............] - ETA: 4:42 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18895: setting learning rate to 7.0583077094286e-06.\n",
      "1095/1780 [=================>............] - ETA: 4:42 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18896: setting learning rate to 7.057982808141779e-06.\n",
      "1096/1780 [=================>............] - ETA: 4:41 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18897: setting learning rate to 7.0576578963925235e-06.\n",
      "1097/1780 [=================>............] - ETA: 4:41 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18898: setting learning rate to 7.057332974182484e-06.\n",
      "1098/1780 [=================>............] - ETA: 4:41 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18899: setting learning rate to 7.0570080415133115e-06.\n",
      "1099/1780 [=================>............] - ETA: 4:40 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18900: setting learning rate to 7.05668309838666e-06.\n",
      "1100/1780 [=================>............] - ETA: 4:40 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18901: setting learning rate to 7.056358144804182e-06.\n",
      "1101/1780 [=================>............] - ETA: 4:39 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18902: setting learning rate to 7.0560331807675266e-06.\n",
      "1102/1780 [=================>............] - ETA: 4:39 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18903: setting learning rate to 7.055708206278349e-06.\n",
      "1103/1780 [=================>............] - ETA: 4:38 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18904: setting learning rate to 7.055383221338298e-06.\n",
      "1104/1780 [=================>............] - ETA: 4:38 - accuracy: 0.9960 - loss: 0.0136\n",
      "Batch 18905: setting learning rate to 7.0550582259490276e-06.\n",
      "1105/1780 [=================>............] - ETA: 4:38 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18906: setting learning rate to 7.05473322011219e-06.\n",
      "1106/1780 [=================>............] - ETA: 4:37 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18907: setting learning rate to 7.054408203829438e-06.\n",
      "1107/1780 [=================>............] - ETA: 4:37 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18908: setting learning rate to 7.0540831771024234e-06.\n",
      "1108/1780 [=================>............] - ETA: 4:36 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18909: setting learning rate to 7.053758139932797e-06.\n",
      "1109/1780 [=================>............] - ETA: 4:36 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18910: setting learning rate to 7.053433092322214e-06.\n",
      "1110/1780 [=================>............] - ETA: 4:36 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18911: setting learning rate to 7.053108034272326e-06.\n",
      "1111/1780 [=================>............] - ETA: 4:35 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18912: setting learning rate to 7.052782965784785e-06.\n",
      "1112/1780 [=================>............] - ETA: 4:35 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18913: setting learning rate to 7.0524578868612425e-06.\n",
      "1113/1780 [=================>............] - ETA: 4:34 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18914: setting learning rate to 7.052132797503353e-06.\n",
      "1114/1780 [=================>............] - ETA: 4:34 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18915: setting learning rate to 7.051807697712768e-06.\n",
      "1115/1780 [=================>............] - ETA: 4:34 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18916: setting learning rate to 7.051482587491141e-06.\n",
      "1116/1780 [=================>............] - ETA: 4:33 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18917: setting learning rate to 7.051157466840126e-06.\n",
      "1117/1780 [=================>............] - ETA: 4:33 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18918: setting learning rate to 7.050832335761374e-06.\n",
      "1118/1780 [=================>............] - ETA: 4:32 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18919: setting learning rate to 7.050507194256538e-06.\n",
      "1119/1780 [=================>............] - ETA: 4:32 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18920: setting learning rate to 7.050182042327271e-06.\n",
      "1120/1780 [=================>............] - ETA: 4:31 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18921: setting learning rate to 7.049856879975228e-06.\n",
      "1121/1780 [=================>............] - ETA: 4:31 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18922: setting learning rate to 7.049531707202059e-06.\n",
      "1122/1780 [=================>............] - ETA: 4:31 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18923: setting learning rate to 7.049206524009418e-06.\n",
      "1123/1780 [=================>............] - ETA: 4:30 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18924: setting learning rate to 7.04888133039896e-06.\n",
      "1124/1780 [=================>............] - ETA: 4:30 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18925: setting learning rate to 7.048556126372337e-06.\n",
      "1125/1780 [=================>............] - ETA: 4:29 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18926: setting learning rate to 7.048230911931202e-06.\n",
      "1126/1780 [=================>............] - ETA: 4:29 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18927: setting learning rate to 7.047905687077209e-06.\n",
      "1127/1780 [=================>............] - ETA: 4:29 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18928: setting learning rate to 7.04758045181201e-06.\n",
      "1128/1780 [==================>...........] - ETA: 4:28 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18929: setting learning rate to 7.04725520613726e-06.\n",
      "1129/1780 [==================>...........] - ETA: 4:28 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18930: setting learning rate to 7.046929950054613e-06.\n",
      "1130/1780 [==================>...........] - ETA: 4:27 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18931: setting learning rate to 7.0466046835657195e-06.\n",
      "1131/1780 [==================>...........] - ETA: 4:27 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 18932: setting learning rate to 7.0462794066722365e-06.\n",
      "1132/1780 [==================>...........] - ETA: 4:27 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18933: setting learning rate to 7.045954119375815e-06.\n",
      "1133/1780 [==================>...........] - ETA: 4:26 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18934: setting learning rate to 7.045628821678112e-06.\n",
      "1134/1780 [==================>...........] - ETA: 4:26 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18935: setting learning rate to 7.045303513580777e-06.\n",
      "1135/1780 [==================>...........] - ETA: 4:25 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18936: setting learning rate to 7.0449781950854666e-06.\n",
      "1136/1780 [==================>...........] - ETA: 4:25 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18937: setting learning rate to 7.044652866193834e-06.\n",
      "1137/1780 [==================>...........] - ETA: 4:24 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18938: setting learning rate to 7.044327526907534e-06.\n",
      "1138/1780 [==================>...........] - ETA: 4:24 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18939: setting learning rate to 7.04400217722822e-06.\n",
      "1139/1780 [==================>...........] - ETA: 4:24 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18940: setting learning rate to 7.043676817157544e-06.\n",
      "1140/1780 [==================>...........] - ETA: 4:23 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18941: setting learning rate to 7.043351446697163e-06.\n",
      "1141/1780 [==================>...........] - ETA: 4:23 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18942: setting learning rate to 7.0430260658487306e-06.\n",
      "1142/1780 [==================>...........] - ETA: 4:22 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18943: setting learning rate to 7.042700674613898e-06.\n",
      "1143/1780 [==================>...........] - ETA: 4:22 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18944: setting learning rate to 7.042375272994325e-06.\n",
      "1144/1780 [==================>...........] - ETA: 4:22 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18945: setting learning rate to 7.042049860991661e-06.\n",
      "1145/1780 [==================>...........] - ETA: 4:21 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18946: setting learning rate to 7.041724438607562e-06.\n",
      "1146/1780 [==================>...........] - ETA: 4:21 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18947: setting learning rate to 7.0413990058436835e-06.\n",
      "1147/1780 [==================>...........] - ETA: 4:20 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18948: setting learning rate to 7.041073562701677e-06.\n",
      "1148/1780 [==================>...........] - ETA: 4:20 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18949: setting learning rate to 7.0407481091832e-06.\n",
      "1149/1780 [==================>...........] - ETA: 4:19 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18950: setting learning rate to 7.040422645289905e-06.\n",
      "1150/1780 [==================>...........] - ETA: 4:19 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18951: setting learning rate to 7.040097171023449e-06.\n",
      "1151/1780 [==================>...........] - ETA: 4:19 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 18952: setting learning rate to 7.039771686385484e-06.\n",
      "1152/1780 [==================>...........] - ETA: 4:18 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18953: setting learning rate to 7.039446191377666e-06.\n",
      "1153/1780 [==================>...........] - ETA: 4:18 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18954: setting learning rate to 7.03912068600165e-06.\n",
      "1154/1780 [==================>...........] - ETA: 4:17 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18955: setting learning rate to 7.038795170259091e-06.\n",
      "1155/1780 [==================>...........] - ETA: 4:17 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18956: setting learning rate to 7.038469644151642e-06.\n",
      "1156/1780 [==================>...........] - ETA: 4:17 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18957: setting learning rate to 7.038144107680961e-06.\n",
      "1157/1780 [==================>...........] - ETA: 4:16 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18958: setting learning rate to 7.037818560848699e-06.\n",
      "1158/1780 [==================>...........] - ETA: 4:16 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18959: setting learning rate to 7.037493003656515e-06.\n",
      "1159/1780 [==================>...........] - ETA: 4:15 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18960: setting learning rate to 7.037167436106061e-06.\n",
      "1160/1780 [==================>...........] - ETA: 4:15 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18961: setting learning rate to 7.036841858198995e-06.\n",
      "1161/1780 [==================>...........] - ETA: 4:15 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18962: setting learning rate to 7.036516269936971e-06.\n",
      "1162/1780 [==================>...........] - ETA: 4:14 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18963: setting learning rate to 7.036190671321641e-06.\n",
      "1163/1780 [==================>...........] - ETA: 4:14 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18964: setting learning rate to 7.035865062354664e-06.\n",
      "1164/1780 [==================>...........] - ETA: 4:13 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18965: setting learning rate to 7.035539443037695e-06.\n",
      "1165/1780 [==================>...........] - ETA: 4:13 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18966: setting learning rate to 7.0352138133723904e-06.\n",
      "1166/1780 [==================>...........] - ETA: 4:13 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18967: setting learning rate to 7.034888173360403e-06.\n",
      "1167/1780 [==================>...........] - ETA: 4:12 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18968: setting learning rate to 7.034562523003389e-06.\n",
      "1168/1780 [==================>...........] - ETA: 4:12 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18969: setting learning rate to 7.0342368623030045e-06.\n",
      "1169/1780 [==================>...........] - ETA: 4:11 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18970: setting learning rate to 7.033911191260905e-06.\n",
      "1170/1780 [==================>...........] - ETA: 4:11 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18971: setting learning rate to 7.0335855098787464e-06.\n",
      "1171/1780 [==================>...........] - ETA: 4:10 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18972: setting learning rate to 7.033259818158185e-06.\n",
      "1172/1780 [==================>...........] - ETA: 4:10 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18973: setting learning rate to 7.032934116100874e-06.\n",
      "1173/1780 [==================>...........] - ETA: 4:10 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18974: setting learning rate to 7.032608403708472e-06.\n",
      "1174/1780 [==================>...........] - ETA: 4:09 - accuracy: 0.9961 - loss: 0.0133\n",
      "Batch 18975: setting learning rate to 7.032282680982633e-06.\n",
      "1175/1780 [==================>...........] - ETA: 4:09 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18976: setting learning rate to 7.031956947925014e-06.\n",
      "1176/1780 [==================>...........] - ETA: 4:08 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18977: setting learning rate to 7.03163120453727e-06.\n",
      "1177/1780 [==================>...........] - ETA: 4:08 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18978: setting learning rate to 7.0313054508210595e-06.\n",
      "1178/1780 [==================>...........] - ETA: 4:08 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18979: setting learning rate to 7.030979686778036e-06.\n",
      "1179/1780 [==================>...........] - ETA: 4:07 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18980: setting learning rate to 7.030653912409856e-06.\n",
      "1180/1780 [==================>...........] - ETA: 4:07 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18981: setting learning rate to 7.030328127718177e-06.\n",
      "1181/1780 [==================>...........] - ETA: 4:06 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18982: setting learning rate to 7.030002332704653e-06.\n",
      "1182/1780 [==================>...........] - ETA: 4:06 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18983: setting learning rate to 7.029676527370942e-06.\n",
      "1183/1780 [==================>...........] - ETA: 4:05 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18984: setting learning rate to 7.029350711718701e-06.\n",
      "1184/1780 [==================>...........] - ETA: 4:05 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18985: setting learning rate to 7.029024885749585e-06.\n",
      "1185/1780 [==================>...........] - ETA: 4:05 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18986: setting learning rate to 7.028699049465249e-06.\n",
      "1186/1780 [==================>...........] - ETA: 4:04 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18987: setting learning rate to 7.028373202867354e-06.\n",
      "1187/1780 [===================>..........] - ETA: 4:04 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18988: setting learning rate to 7.0280473459575525e-06.\n",
      "1188/1780 [===================>..........] - ETA: 4:03 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18989: setting learning rate to 7.027721478737501e-06.\n",
      "1189/1780 [===================>..........] - ETA: 4:03 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18990: setting learning rate to 7.027395601208859e-06.\n",
      "1190/1780 [===================>..........] - ETA: 4:03 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18991: setting learning rate to 7.027069713373282e-06.\n",
      "1191/1780 [===================>..........] - ETA: 4:02 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18992: setting learning rate to 7.026743815232426e-06.\n",
      "1192/1780 [===================>..........] - ETA: 4:02 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18993: setting learning rate to 7.026417906787949e-06.\n",
      "1193/1780 [===================>..........] - ETA: 4:01 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18994: setting learning rate to 7.026091988041508e-06.\n",
      "1194/1780 [===================>..........] - ETA: 4:01 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18995: setting learning rate to 7.025766058994757e-06.\n",
      "1195/1780 [===================>..........] - ETA: 4:01 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18996: setting learning rate to 7.025440119649356e-06.\n",
      "1196/1780 [===================>..........] - ETA: 4:00 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 18997: setting learning rate to 7.025114170006961e-06.\n",
      "1197/1780 [===================>..........] - ETA: 4:00 - accuracy: 0.9961 - loss: 0.0135\n",
      "Batch 18998: setting learning rate to 7.024788210069231e-06.\n",
      "1198/1780 [===================>..........] - ETA: 3:59 - accuracy: 0.9961 - loss: 0.0135\n",
      "Batch 18999: setting learning rate to 7.024462239837819e-06.\n",
      "1199/1780 [===================>..........] - ETA: 3:59 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19000: setting learning rate to 7.0241362593143845e-06.\n",
      "1200/1780 [===================>..........] - ETA: 3:58 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19001: setting learning rate to 7.023810268500587e-06.\n",
      "1201/1780 [===================>..........] - ETA: 3:58 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19002: setting learning rate to 7.02348426739808e-06.\n",
      "1202/1780 [===================>..........] - ETA: 3:58 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19003: setting learning rate to 7.023158256008522e-06.\n",
      "1203/1780 [===================>..........] - ETA: 3:57 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19004: setting learning rate to 7.022832234333571e-06.\n",
      "1204/1780 [===================>..........] - ETA: 3:57 - accuracy: 0.9961 - loss: 0.0134\n",
      "Batch 19005: setting learning rate to 7.022506202374886e-06.\n",
      "1205/1780 [===================>..........] - ETA: 3:56 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 19006: setting learning rate to 7.02218016013412e-06.\n",
      "1206/1780 [===================>..........] - ETA: 3:56 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 19007: setting learning rate to 7.021854107612934e-06.\n",
      "1207/1780 [===================>..........] - ETA: 3:56 - accuracy: 0.9960 - loss: 0.0134\n",
      "Batch 19008: setting learning rate to 7.0215280448129866e-06.\n",
      "1208/1780 [===================>..........] - ETA: 3:55 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 19009: setting learning rate to 7.021201971735931e-06.\n",
      "1209/1780 [===================>..........] - ETA: 3:55 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 19010: setting learning rate to 7.020875888383428e-06.\n",
      "1210/1780 [===================>..........] - ETA: 3:54 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 19011: setting learning rate to 7.020549794757136e-06.\n",
      "1211/1780 [===================>..........] - ETA: 3:54 - accuracy: 0.9960 - loss: 0.0135\n",
      "Batch 19012: setting learning rate to 7.020223690858712e-06.\n",
      "1212/1780 [===================>..........] - ETA: 3:54 - accuracy: 0.9961 - loss: 0.0135\n",
      "Batch 19013: setting learning rate to 7.019897576689813e-06.\n",
      "1213/1780 [===================>..........] - ETA: 3:53 - accuracy: 0.9961 - loss: 0.0135\n",
      "Batch 19014: setting learning rate to 7.019571452252096e-06.\n"
     ]
    }
   ],
   "source": [
    "run_training(dropout = 0.5, lr_rate = 0.00001, architecture = 'mobilenet', batch = 64, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../all_faces_bucket/trained_models/weights/mobilenet_new/highest_val_acc.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'mobilenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "564DXmWLDMxa"
   },
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "1qVdSNFxjg5-",
    "outputId": "c571704d-0a0e-4a65-a7f8-15fcb6b82127"
   },
   "outputs": [],
   "source": [
    "# run_training(dropout = 0.5, lr_rate = 0.0002, architecture = 'efficientnet', batch = 256, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'efficientnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_training(dropout = 0.5, lr_rate = 0.0002, architecture = 'densenet', batch = 256, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_from_best_weights(dropout = 0.5, lr_rate = 0.0002, architecture = 'densenet')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-6Yocnrq2u4F"
   ],
   "name": "25_May.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
