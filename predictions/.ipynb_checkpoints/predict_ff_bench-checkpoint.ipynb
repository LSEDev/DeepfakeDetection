{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # new module required for dataframe creation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math # required for prediction conversion\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import json\n",
    "\n",
    "af_dir = '../../all_faces_bucket/'\n",
    "disk_data_dir = '../../all_faces_disk/home/jupyter/forensics_split/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy benchmark to disk\n",
    "!mkdir /home/jupyter/ff_bench \n",
    "!gsutil -m cp -r gs://all_faces/benchmark_cropped_images /home/jupyter/ff_bench "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(architecture):\n",
    "    '''Loads one of the saved models based on specified architecture'''\n",
    "    \n",
    "    return load_model(af_dir + 'trained_models/saved_models/' + architecture)\n",
    "\n",
    "def get_multidim_predictions(model, bench=True):\n",
    "    '''Takes in a loaded model and outputs filenames and multi-dimensional\n",
    "    predictions for each class.\n",
    "    \n",
    "    Works by initiating an instance of ImageDataGenerator which is used for\n",
    "    flow_from_directory method.'''\n",
    "    # Normalise and centre test data\n",
    "    datagen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
    "    if bench:\n",
    "        generator = datagen.flow_from_directory('../../ff_bench', target_size=(224, 224),\n",
    "                                            shuffle = False, batch_size=1, class_mode=None)\n",
    "    else:\n",
    "        generator = datagen.flow_from_directory(disk_data_dir + '/test', target_size=(224, 224),\n",
    "                                            shuffle = False, batch_size=1, class_mode=None)\n",
    "    filenames = generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    generator.reset() # figure out this \n",
    "    predictions = model.predict(generator, steps = nb_samples, verbose=1, workers=8)\n",
    "    \n",
    "    return filenames, predictions\n",
    "\n",
    "def get_image_predictions(arr, soft=True):\n",
    "    '''Obtains image predictions.\n",
    "    soft: a true value returns probabilities as opposed to hard predictions.'''\n",
    "\n",
    "    if soft:\n",
    "        # probability of belonging to fake (second) class,\n",
    "        # hence return second value for each element in the list\n",
    "        return [el[1] for el in arr]\n",
    "    # returns a list of 0's and 1's\n",
    "    return np.argmax(arr, axis=1)\n",
    "\n",
    "def build_dataframe(filenames, predictions):\n",
    "    index = range(len(filenames))\n",
    "    df = pd.DataFrame(index = index, columns = ['method', 'video', 'image', 'test/train', 'true label',\n",
    "                                                  'probability', 'predicted label', 'acc'])\n",
    "    df = df.fillna(0)\n",
    "    methods = [el[el.find('/')+1: el.find('_')] for el in filenames]\n",
    "    video_numbers = [re.search(\"_(.*?)\\_\", el).group(1) for el in filenames]\n",
    "    image_numbers = [el[el.find('_')+1: el.find('.')][4:] for el in filenames]\n",
    "    true_labels = [0 if el[0] == 'a' else 1 for el in filenames]\n",
    "    \n",
    "    df['method'] = methods\n",
    "    df['video'] =  video_numbers\n",
    "    df['image'] =  image_numbers\n",
    "    df['true label'] = true_labels\n",
    "    df['test/train'] = ['test']*len(filenames)\n",
    "    df['probability'] = predictions\n",
    "    df['predicted label'] = ['-']*len(filenames)\n",
    "    df['acc'] = ['-']*len(filenames)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(model, bench=True):\n",
    "    '''Loads a model and returns predictions on FF++ benchmark'''\n",
    "    # with tf.device('/cpu:0'): # use if GPU is training and has no leftover memory\n",
    "    loaded_model = get_model(model)\n",
    "    filenames, multidim_predictions = get_multidim_predictions(loaded_model, bench)\n",
    "    predictions = get_image_predictions(multidim_predictions, soft=False) # adapt this if you want a threshold other than 0.5 or a different decision rule\n",
    "    \n",
    "    return filenames, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set predictions and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46199999999999997"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_filenames, tst_preds = run_all('mobilenet_new_model_fine_tunedlastepoch.h5', bench=False)\n",
    "data = build_dataframe(tst_filenames, tst_preds)\n",
    "\n",
    "# Accuracy on frame predictions (all frames)\n",
    "# predicted_labels = [1 if i>0.5 else 0 for i in data['probability']]\n",
    "similarities = [1 if i!=j else 0 for i,j in zip(tst_preds, data['true label'])]\n",
    "1-sum(similarities)/len(tst_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "1000/1000 [==============================] - 10s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "filenames, preds = run_all('mobilenet_new_model_fine_tunedlastepoch.h5', bench=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_preds = [\"real\" if i==0 else \"fake\" for i in preds]\n",
    "submission = {file[-8:]:pred for file, pred in zip(filenames, ff_preds)}\n",
    "json_file = json.dumps(submission, indent=4)\n",
    "\n",
    "with open(af_dir + 'predictions/' + 'test1.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../example_submission 4.json') as f:\n",
    "    dd = json.load(f)\n",
    "dd.keys()==submission.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
