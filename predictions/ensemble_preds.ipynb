{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/efficientnet\n",
      "  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-n8cbxo8o\n",
      "  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-n8cbxo8o\n",
      "Requirement already satisfied (use --upgrade to upgrade): efficientnet==1.1.0 from git+https://github.com/qubvel/efficientnet in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.1.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.8.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2020.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\n",
      "Building wheels for collected packages: efficientnet\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.0-py3-none-any.whl size=18397 sha256=6cc01d39f1da0656f0d26d7d8fd43806208977efbb482186b8b89e7a8c087f7f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wv6e1_59/wheels/11/69/85/814d64d694c96db0eef17b718042d644a1e54f113920481920\n",
      "Successfully built efficientnet\n",
      "Requirement already satisfied: deepstack==0.0.9 in /opt/conda/lib/python3.7/site-packages (0.0.9)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.7/site-packages (from deepstack==0.0.9) (1.19.0)\n",
      "Requirement already satisfied: tensorflow>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from deepstack==0.0.9) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /opt/conda/lib/python3.7/site-packages (from deepstack==0.0.9) (0.23.1)\n",
      "Requirement already satisfied: keras>=2.2.5 in /opt/conda/lib/python3.7/site-packages (from deepstack==0.0.9) (2.3.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (3.2.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (0.34.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.30.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (2.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.12.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (1.6.3)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.14.0->deepstack==0.0.9) (3.12.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.2->deepstack==0.0.9) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.2->deepstack==0.0.9) (2.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras>=2.2.5->deepstack==0.0.9) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras>=2.2.5->deepstack==0.0.9) (5.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.18.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (47.3.1.post20200616)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (2.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14.0->deepstack==0.0.9) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow-serving-api 2.1.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-model-analysis 0.22.2 has requirement pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.22.2 has requirement joblib<0.15,>=0.12, but you'll have joblib 0.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-data-validation 0.22.2 has requirement pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "af_dir = '../../all_faces_bucket/'\n",
    "disk_data_dir = '../../all_faces_disk/home/jupyter/forensics_split/'\n",
    "!pip install git+https://github.com/qubvel/efficientnet\n",
    "!pip install --user deepstack==0.0.9\n",
    "\n",
    "import efficientnet.tfkeras\n",
    "from deepstack.base import KerasMember\n",
    "from deepstack.ensemble import DirichletEnsemble\n",
    "from deepstack.ensemble import StackEnsemble\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# !sudo kill -9 PID # clear GPU memory where 9 is PID number\n",
    "# !watch -n0.1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    '''Loads one of the saved models based on specified config'''\n",
    "    \n",
    "    return load_model(af_dir + 'trained_models/saved_models/config' + str(models_to_load[0]) + '.h5')\n",
    "\n",
    "model1 = get_model(0)\n",
    "model2 = get_model(1)\n",
    "# model3 = get_model(2)\n",
    "# model4 = get_model(3)\n",
    "# model5 = get_model(4)\n",
    "# model6 = get_model(5)\n",
    "# model7 = get_model(6)\n",
    "# model8 = get_model(7)\n",
    "# model9 = get_model(8)\n",
    "# model10 = get_model(9)\n",
    "# model11 = get_model(10)\n",
    "# model11 = get_model(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create image generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37124 images belonging to 2 classes.\n",
      "Found 37201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "def augment_data(directory, batch):\n",
    "    '''Prepares train-time augmentation using given training and validations data)\n",
    "    \n",
    "    Returns train_data, val_data'''\n",
    "\n",
    "    datagen_train = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=True,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=True,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "            rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            shear_range=0.,  # set range for random shear\n",
    "            zoom_range=0.,  # set range for random zoom\n",
    "            channel_shift_range=0.,  # set range for random channel shifts\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode='nearest',\n",
    "            cval=0.,  # value used for fill_mode = \"constant\"\n",
    "            brightness_range=None,\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,  # randomly flip images\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale=None,\n",
    "            # set function that will be applied on each input\n",
    "#             preprocessing_function=deepaug.joint_function,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format=None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            )\n",
    "    \n",
    "    datagen_test = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "    # Classes give the folders storing the two different categories\n",
    "    train_data = datagen_train.flow_from_directory(directory + '/train',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    val_data = datagen_test.flow_from_directory(directory + '/validation',\n",
    "                                             target_size=(224,224), batch_size = batch)\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train_data, val_data = augment_data('../../forensics_split', batch=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate KerasMembers\n",
    "This will find all training and validation predictions. A fit method can then be applied to obtain to the members to create the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/deepstack/base.py:148: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "1161/1161 [==============================] - 644s 555ms/step\n",
      "1163/1163 [==============================] - 279s 240ms/step\n",
      "1161/1161 [==============================] - 769s 663ms/step\n",
      "1163/1163 [==============================] - 163s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "member1 = KerasMember(name=\"model1\", keras_model=model1, train_batches=train_data, val_batches=val_data)\n",
    "member2 = KerasMember(name=\"model2\", keras_model=model2, train_batches=train_data, val_batches=val_data)\n",
    "# member3 = KerasMember(name=\"model3\", keras_model=model3, train_batches=train_data, val_batches=val_data)\n",
    "# member4 = KerasMember(name=\"model4\", keras_model=model4, train_batches=train_data, val_batches=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit weighted average ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 - Weight: 0.3436 - roc_auc_score: 0.5000\n",
      "model2 - Weight: 0.6564 - roc_auc_score: 0.5000\n",
      "DirichletEnsemble roc_auc_score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "wAvgEnsemble = DirichletEnsemble()\n",
    "wAvgEnsemble.add_members([member1, member2])\n",
    "wAvgEnsemble.fit()\n",
    "wAvgEnsemble.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling predict\n",
      "model1 - accuracy_score: 0.5000\n",
      "model2 - accuracy_score: 0.5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4cb7ef331d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmember1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/deepstack/ensemble.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, probabilities_val, metric, maximize)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 metric.__name__, model_score)\n\u001b[1;32m    284\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mensemble_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         print(\"StackEnsemble {}: {:1.4f}\".format(\n\u001b[1;32m    287\u001b[0m             metric.__name__, ensemble_score))\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/deepstack/ensemble.py\u001b[0m in \u001b[0;36m_calculate_metric\u001b[0;34m(y_true, y_pred, metric)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "stack = StackEnsemble()\n",
    "stack.model = RandomForestRegressor(verbose=0, n_estimators=200, \n",
    "                                  max_depth=15, n_jobs=20, min_samples_split=20)\n",
    "stack.add_members([member1, member2])\n",
    "stack.fit()\n",
    "stack.describe(metric = accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version must be >= 0.22. You have: 0.23.1\n",
      "Calling predict\n",
      "model1 - accuracy_score: 0.5000\n",
      "model2 - accuracy_score: 0.5000\n",
      "StackEnsemble accuracy_score: 0.6664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6663530550254025"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure you have the scikit-learn version >= 0.22 installed\n",
    "print(\"sklearn version must be >= 0.22. You have:\", sklearn.__version__)\n",
    "\n",
    "stack = StackEnsemble()\n",
    "\n",
    "# 2nd Level Meta-Learner\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(verbose=0, n_estimators=200, max_depth=15, n_jobs=20, min_samples_split=30)),\n",
    "    ('etr', ExtraTreesClassifier(verbose=0, n_estimators=200, max_depth=10, n_jobs=20, min_samples_split=20))\n",
    "]\n",
    "# 3rd Level Meta-Learner\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stack.model = clf\n",
    "stack.add_members([member1, member2])\n",
    "stack.fit()\n",
    "stack.describe(metric=sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member1.train_probs"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
