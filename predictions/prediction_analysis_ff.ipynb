{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fveKC1NzY8lL"
   },
   "source": [
    "# Set Up\n",
    "\n",
    "Note: af_dir and disk_data_dir are modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math # required for prediction conversion\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "af_dir = '../../all_faces_bucket/'\n",
    "disk_data_dir = '../../all_faces_disk/home/jupyter/forensics_split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "**Note: Save time by only running the cells with functions but leaving the others -- they are there for you to see the intermediate steps.**\n",
    "\n",
    "## Predict Labels for Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrsAPTF9Y8m_"
   },
   "outputs": [],
   "source": [
    "# Need to load model to CPU if GPU is busy training\n",
    "# with tf.device('/cpu:0'):\n",
    "#     loaded_model = load_model(af_dir + 'trained_models/saved_models/' + architecture + '_model.h5')\n",
    "\n",
    "def get_model(architecture):\n",
    "    '''Loads one of the saved models based on specified architecture\n",
    "    (vgg, resnet50, mobilenet or xception)'''\n",
    "    \n",
    "    return load_model(af_dir + 'trained_models/saved_models/' + architecture + '_model.h5')\n",
    "\n",
    "def get_multidim_predictions(model):\n",
    "    '''Takes in a loaded model and outputs filenames and multi-dimensional\n",
    "    predictions for each class.\n",
    "    \n",
    "    Works by initiating an instance of ImageDataGenerator which is used for\n",
    "    flow_from_directory method.'''\n",
    "    # normalise and centre test data\n",
    "    datagen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
    "    generator = datagen.flow_from_directory(disk_data_dir + 'test', target_size=(224, 224),\n",
    "                                            shuffle = False, batch_size=1)\n",
    "    filenames = generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    generator.reset() # figure out this \n",
    "    predictions = model.predict(generator, steps = nb_samples, verbose=1, workers=8)\n",
    "    \n",
    "    return filenames, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23054 images belonging to 2 classes.\n",
      "23054/23054 [==============================] - 152s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "loaded_model = get_model('mobilenet_new')\n",
    "filenames, multidim_predictions = get_multidim_predictions(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywxwKFvuY8nc"
   },
   "outputs": [],
   "source": [
    "def get_image_predictions(arr, soft=True):\n",
    "    '''Obtains image predictions.\n",
    "    soft: a true value returns probabilities as opposed to hard predictions.'''\n",
    "\n",
    "    if soft:\n",
    "        # probability of belonging to fake (second) class,\n",
    "        # hence return second value for each element in the list\n",
    "        return [el[1] for el in arr]\n",
    "    # returns a list of 0's and 1's\n",
    "    return np.argmax(arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['authentic/Original_000_0150.png', 'authentic/Original_000_0165.png', 'authentic/Original_000_0180.png']\n",
      "[0.9997267, 0.05420502, 0.0054824506]\n"
     ]
    }
   ],
   "source": [
    "predictions = get_image_predictions(multidim_predictions, soft=True)\n",
    "print(filenames[10:13])\n",
    "print(predictions[10:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Information Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(filenames):\n",
    "    index = range(len(filenames))\n",
    "    df = pd.DataFrame(index = index, columns = ['method', 'video', 'image', 'test/train', 'true label',\n",
    "                                                  'probability', 'predicted label', 'acc'])\n",
    "    df = df.fillna(0)\n",
    "    methods = [el[el.find('/')+1: el.find('_')] for el in filenames]\n",
    "    video_numbers = [el[el.find('_')+1: el.rfind('_')] for el in filenames]\n",
    "    # video_numbers = [re.search(\"_(.*?)\\_\", el).group(1) for el in filenames] # older version -- does not include second video name for fake videos\n",
    "    image_numbers = [el[el.find('_')+1: el.find('.')][4:] for el in filenames]\n",
    "    true_labels = [0 if el[0] == 'a' else 1 for el in filenames]\n",
    "    \n",
    "    df['method'] = methods\n",
    "    df['video'] =  video_numbers\n",
    "    df['image'] =  image_numbers\n",
    "    df['true label'] = true_labels\n",
    "    df['test/train'] = ['test']*len(filenames)\n",
    "    df['probability'] = predictions\n",
    "    df['predicted label'] = ['-']*len(filenames)\n",
    "    df['acc'] = ['-']*len(filenames)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>video</th>\n",
       "      <th>image</th>\n",
       "      <th>test/train</th>\n",
       "      <th>true label</th>\n",
       "      <th>probability</th>\n",
       "      <th>predicted label</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0150</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0165</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Original</td>\n",
       "      <td>000</td>\n",
       "      <td>0180</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method video image test/train  true label  probability predicted label  \\\n",
       "10  Original   000  0150       test           0     0.999727               -   \n",
       "11  Original   000  0165       test           0     0.054205               -   \n",
       "12  Original   000  0180       test           0     0.005482               -   \n",
       "\n",
       "   acc  \n",
       "10   -  \n",
       "11   -  \n",
       "12   -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = build_dataframe(filenames)\n",
    "display(data[10:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Video Predictions\n",
    "\n",
    "Next cell contains three functions which are all options for combining image predictions and converting those into a single video prediction. Fraction method considers only a fraction of higest image predictions (useful when only a fraction of video has been manipulated), ConfidentStrategy takes a mean of a subset of predictions depending on popularity of each of the two classes, and Transform makes each prediction more extreme (pushed towards 0.0 or 1.0 depending on its original value) before taking a mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_of_a_fraction(lst, fraction = 1.0):\n",
    "    '''Takes in a list and outputs a mean of the fraction of the largest\n",
    "    elements for that list (by default (fraction is 1) == consider all predictions)\n",
    "        \n",
    "    if fraction equals to 1, the output is simply a mean.\n",
    "        \n",
    "    This mimics considering only the top third highest probabilities for\n",
    "    images for a given video to classify that video. The main idea is\n",
    "    that if a given video has only a fraction of it being manipulated\n",
    "    (unknown information) then it's likely to be wrongly classfied as original\n",
    "    if we average all associated probabilities, however, if we take only a\n",
    "    certain number of highest proabilities that will be much more representative\n",
    "    and overall robust.'''\n",
    "        \n",
    "    sorted_lst = sorted(lst)[::-1] if type(lst) == list else [lst]\n",
    "    sliced_lst = sorted_lst[0:math.ceil(len(lst)*fraction)] if fraction != (1 or 1.0) else sorted_lst\n",
    "    return np.mean(sliced_lst)\n",
    "\n",
    "def get_mean_with_confident_strategy(lst, fraction = 0.75, t = 0.5):\n",
    "    '''Confident strategy is implemented from first-place solution in DFDC.\n",
    "    \n",
    "    The main idea is that if there are a lot of predictions for one class,\n",
    "    then the average is taken of those predictions only. If that's not the\n",
    "    case, then a simple mean is outputted.\n",
    "    \n",
    "    Inputs:\n",
    "    1. list of predictions (converted to a list if it's a single prediction)\n",
    "    2. fraction -- (between 0 and 1) what fraction of the list should predict\n",
    "    the same class for other predictions to be disregarded when taking a mean\n",
    "    3. t -- threshold cutoff value between two classes (note: whole notebook\n",
    "    is structured for a binary classification problem only)'''\n",
    "    \n",
    "    lst = np.array(lst)\n",
    "    num_pred = len(lst)\n",
    "    num_fakes = np.count_nonzero(lst >= t)\n",
    "    num_authentic = num_pred - num_fakes\n",
    "\n",
    "    # if number of fakes is more that 75% of all predictions \n",
    "    if num_fakes > int(num_pred * fraction):\n",
    "        # take predictions which are greater than threshold and average them\n",
    "        return np.mean(lst[lst >= t])\n",
    "\n",
    "    # else if number of predictions below threshold value t is more that 75%\n",
    "    # of all predictions\n",
    "    elif num_authentic > int(num_pred * fraction):\n",
    "        # take these predictions and return their mean\n",
    "        return np.mean(lst[lst < t])\n",
    "  \n",
    "    else: # simple mean\n",
    "        return np.mean(lst)\n",
    "    \n",
    "def get_mean_of_transformed_predictions(lst):\n",
    "    '''Takes a list of predictions, transforms them by individually\n",
    "    pushing the values away from the centre (0.5) closer towards the\n",
    "    extremes (0.0 and 1.0). The visualisation is included below.\n",
    "    \n",
    "    Returns a mean of transformed predictions.'''\n",
    "\n",
    "    if type(lst) != list: lst = [lst]\n",
    "    weights = np.power([abs(el -0.5) for el in lst], 1.0) + 1e-4\n",
    "    return float((lst * weights).sum() / weights.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick visualisation of the transformation, which each individual image prediction undergoes in the Transform approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################################################\n",
    "# Illustration of the transformation for a single prediction\n",
    "# used in get_mean_of_transformed_predictions\n",
    "def transform(prob, t = 0.15):\n",
    "    if prob == 0.5:\n",
    "        return 0.5\n",
    "    elif prob <= t:\n",
    "        return 0.0\n",
    "    elif prob >= (1-t):\n",
    "        return 1.0\n",
    "    elif prob > t and prob < 0.5:\n",
    "        return 0.5 - np.power(abs(prob-0.5), 0.65)\n",
    "    elif prob < (1-t) and prob > 0.5:\n",
    "        return 0.5 + np.power(abs(prob-0.5), 0.65)\n",
    "\n",
    "pred = range(0, 101)\n",
    "pred = [el/100 for el in pred]\n",
    "transformed = [transform(el) for el in pred]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pred, pred);\n",
    "plt.plot(pred, transformed);\n",
    "plt.xlabel(\"Original prediction\", fontsize = 12);\n",
    "plt.ylabel(\"Transformed prediction\", fontsize = 12);\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions(df, threshold = 0.5, option = None, fraction = 0.33):\n",
    "    ''' Takes in a dataframe, regroups by videos (collecting all predictions\n",
    "    for a video in one nested list) then (optionally modifies by one of the three\n",
    "    methods) returning a mean prediction for each video. Lastly, an accuracy\n",
    "    column is filled by comparing a true label with the predicted one (a mean\n",
    "    probability is convered into a label subject to threshold value).\n",
    "    \n",
    "    Inputs:\n",
    "    1. df -- dataframe\n",
    "    2. threshold -- cutoff probability value between classes (by default 0.5)\n",
    "    3. option -- (by default None) choices are 'transform', 'confident strategy'\n",
    "    or 'fraction'; correspond to possible list manipulations\n",
    "    \n",
    "    Note: if you feed option = 'fraction', then you need to also specify fraction\n",
    "    value (1.0 means a simple mean, 0.33 means taking top third, et cetera)\n",
    "    \n",
    "    if option is not speficied or not among choices then a simple mean is calculated\n",
    "    4. fraction (= 0.33) -- value for 'fraction' option '''\n",
    "\n",
    "    # regroup based on method, video title, and test/train category\n",
    "    df = df.groupby(['method', 'video','test/train', 'true label', 'predicted label'])\\\n",
    "                    ['probability'].apply(list).reset_index()\n",
    "    \n",
    "    collected_labels_pred = list(df['probability']) # get the nested list\n",
    "    \n",
    "    # next, we apply one of the three methods to get means\n",
    "    \n",
    "    if option == 'transform':\n",
    "        mean_labels_pred = [get_mean_of_transformed_predictions(el) for el in collected_labels_pred]\n",
    "        \n",
    "    elif option == 'confident strategy':\n",
    "        mean_labels_pred = [get_mean_with_confident_strategy(el) for el in collected_labels_pred]\n",
    "    \n",
    "    elif option == 'fraction':\n",
    "        mean_labels_pred = [get_mean_of_a_fraction(el, fraction) for el in collected_labels_pred]\n",
    "        \n",
    "    else: # if no option is chosen (or not from the list), output a simple mean per video\n",
    "        mean_labels_pred = [np.mean(el) for el in collected_labels_pred]\n",
    "\n",
    "    labels_pred = [0 if el <= threshold else 1 for el in mean_labels_pred]\n",
    "    df['predicted label'] = labels_pred\n",
    "\n",
    "    # produce accuraacy values for each video (0 if classification is wrong and\n",
    "    # 1 if classicification is correct)\n",
    "    df['acc'] = [1 if df['true label'][i] == df['predicted label'][i]\n",
    "                            else 0 for i in range(len(df['true label']))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>video</th>\n",
       "      <th>test/train</th>\n",
       "      <th>true label</th>\n",
       "      <th>predicted label</th>\n",
       "      <th>probability</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deepfakes</td>\n",
       "      <td>000</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9999918937683105, 0.9999994039535522, 0.999...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deepfakes</td>\n",
       "      <td>003</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4041133224964142, 0.9942851662635803, 0.943...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deepfakes</td>\n",
       "      <td>012</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9833459854125977, 0.9993589520454407, 0.999...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method video test/train  true label  predicted label  \\\n",
       "0  Deepfakes   000       test           1                1   \n",
       "1  Deepfakes   003       test           1                1   \n",
       "2  Deepfakes   012       test           1                1   \n",
       "\n",
       "                                         probability  acc  \n",
       "0  [0.9999918937683105, 0.9999994039535522, 0.999...    1  \n",
       "1  [0.4041133224964142, 0.9942851662635803, 0.943...    1  \n",
       "2  [0.9833459854125977, 0.9993589520454407, 0.999...    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = convert_predictions(data)\n",
    "display(new[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(df):\n",
    "    acc_per_method = df.groupby(['test/train', 'method'])['acc'].mean()\n",
    "    acc_total = df.groupby(['test/train'])['acc'].mean()\n",
    "    display(acc_per_method)\n",
    "    display(acc_total)\n",
    "    return acc_per_method, acc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.914286\n",
       "            Face2Face         0.914286\n",
       "            FaceSwap          0.850000\n",
       "            NeuralTextures    0.792857\n",
       "            Original          0.607143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.815714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_per_method, acc_total = show_accuracy(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################\n",
      "vgg\n",
      "Found 23054 images belonging to 2 classes.\n",
      "23054/23054 [==============================] - 246s 11ms/step\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.914286\n",
       "            Face2Face         0.914286\n",
       "            FaceSwap          0.857143\n",
       "            NeuralTextures    0.785714\n",
       "            Original          0.600000\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.814286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: confident strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.914286\n",
       "            Face2Face         0.914286\n",
       "            FaceSwap          0.850000\n",
       "            NeuralTextures    0.792857\n",
       "            Original          0.607143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.815714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: fraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.985714\n",
       "            Face2Face         0.950000\n",
       "            FaceSwap          0.950000\n",
       "            NeuralTextures    0.892857\n",
       "            Original          0.364286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.828571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.914286\n",
       "            Face2Face         0.914286\n",
       "            FaceSwap          0.850000\n",
       "            NeuralTextures    0.792857\n",
       "            Original          0.607143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.815714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#############################################################\n",
      "\n",
      "\n",
      "#############################################################\n",
      "xception\n",
      "Found 23054 images belonging to 2 classes.\n",
      "23054/23054 [==============================] - 236s 10ms/step\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.921429\n",
       "            Face2Face         0.928571\n",
       "            FaceSwap          0.878571\n",
       "            NeuralTextures    0.850000\n",
       "            Original          0.692857\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.854286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: confident strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.921429\n",
       "            Face2Face         0.928571\n",
       "            FaceSwap          0.864286\n",
       "            NeuralTextures    0.835714\n",
       "            Original          0.707143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.851429\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: fraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.978571\n",
       "            Face2Face         0.992857\n",
       "            FaceSwap          0.957143\n",
       "            NeuralTextures    0.935714\n",
       "            Original          0.328571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.838571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.921429\n",
       "            Face2Face         0.928571\n",
       "            FaceSwap          0.864286\n",
       "            NeuralTextures    0.835714\n",
       "            Original          0.707143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.851429\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#############################################################\n",
      "\n",
      "\n",
      "#############################################################\n",
      "resnet50\n",
      "Found 23054 images belonging to 2 classes.\n",
      "23054/23054 [==============================] - 249s 11ms/step\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.828571\n",
       "            Face2Face         0.778571\n",
       "            FaceSwap          0.757143\n",
       "            NeuralTextures    0.692857\n",
       "            Original          0.478571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.707143\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: confident strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.814286\n",
       "            Face2Face         0.771429\n",
       "            FaceSwap          0.714286\n",
       "            NeuralTextures    0.678571\n",
       "            Original          0.500000\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.695714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: fraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.921429\n",
       "            Face2Face         0.892857\n",
       "            FaceSwap          0.928571\n",
       "            NeuralTextures    0.807143\n",
       "            Original          0.228571\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.755714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.814286\n",
       "            Face2Face         0.771429\n",
       "            FaceSwap          0.714286\n",
       "            NeuralTextures    0.678571\n",
       "            Original          0.500000\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.695714\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#############################################################\n",
      "\n",
      "\n",
      "#############################################################\n",
      "mobilenet\n",
      "Found 23054 images belonging to 2 classes.\n",
      "23054/23054 [==============================] - 147s 6ms/step\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.928571\n",
       "            Face2Face         0.964286\n",
       "            FaceSwap          0.907143\n",
       "            NeuralTextures    0.835714\n",
       "            Original          0.621429\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.851429\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: confident strategy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.928571\n",
       "            Face2Face         0.964286\n",
       "            FaceSwap          0.907143\n",
       "            NeuralTextures    0.835714\n",
       "            Original          0.614286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.85\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: fraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.978571\n",
       "            Face2Face         0.992857\n",
       "            FaceSwap          0.964286\n",
       "            NeuralTextures    0.964286\n",
       "            Original          0.300000\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.84\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "\n",
      "\n",
      "######################################\n",
      "Option: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test/train  method        \n",
       "test        Deepfakes         0.928571\n",
       "            Face2Face         0.964286\n",
       "            FaceSwap          0.907143\n",
       "            NeuralTextures    0.835714\n",
       "            Original          0.614286\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test/train\n",
       "test    0.85\n",
       "Name: acc, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for architecture in ['vgg', 'xception', 'resnet50', 'mobilenet']:\n",
    "    print('#'*61)\n",
    "    print(architecture)\n",
    "    loaded_model = get_model(architecture)\n",
    "    filenames, multidim_predictions = get_multidim_predictions(loaded_model)\n",
    "    predictions = get_image_predictions(multidim_predictions, soft=True)\n",
    "    data = build_dataframe(filenames)\n",
    "    print('\\n')\n",
    "    for option in ['transform', 'confident strategy', 'fraction', 'None']:\n",
    "        print('#'*38)\n",
    "        print(\"Option:\", option)\n",
    "        new = convert_predictions(data, option = option)\n",
    "        acc_per_method, acc_total = show_accuracy(new)\n",
    "        print('#'*38)\n",
    "        if option != 'None': print('\\n')\n",
    "    print('#'*61)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prediction_analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
